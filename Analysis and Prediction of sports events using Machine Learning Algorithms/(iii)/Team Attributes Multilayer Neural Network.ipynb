{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fixed-manitoba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.0847 - accuracy: 0.4038 - val_loss: 1.0586 - val_accuracy: 0.4598\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 0s 964us/step - loss: 1.0485 - accuracy: 0.4600 - val_loss: 1.0396 - val_accuracy: 0.4598\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 1.0273 - accuracy: 0.4922 - val_loss: 1.0184 - val_accuracy: 0.5177\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 1.0098 - accuracy: 0.5072 - val_loss: 1.0079 - val_accuracy: 0.5034\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 0s 788us/step - loss: 0.9993 - accuracy: 0.5098 - val_loss: 0.9994 - val_accuracy: 0.5099\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9944 - accuracy: 0.5147 - val_loss: 0.9917 - val_accuracy: 0.5278\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9908 - accuracy: 0.5163 - val_loss: 0.9917 - val_accuracy: 0.5154\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9880 - accuracy: 0.5180 - val_loss: 0.9968 - val_accuracy: 0.5149\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9859 - accuracy: 0.5194 - val_loss: 0.9938 - val_accuracy: 0.5186\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9852 - accuracy: 0.5177 - val_loss: 0.9886 - val_accuracy: 0.5278\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9844 - accuracy: 0.5188 - val_loss: 0.9899 - val_accuracy: 0.5223\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9835 - accuracy: 0.5205 - val_loss: 0.9876 - val_accuracy: 0.5154\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9826 - accuracy: 0.5202 - val_loss: 0.9868 - val_accuracy: 0.5305\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9827 - accuracy: 0.5200 - val_loss: 0.9863 - val_accuracy: 0.5269\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9830 - accuracy: 0.5194 - val_loss: 0.9876 - val_accuracy: 0.5149\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9805 - accuracy: 0.5226 - val_loss: 0.9873 - val_accuracy: 0.5273\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9806 - accuracy: 0.5238 - val_loss: 0.9849 - val_accuracy: 0.5296\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9802 - accuracy: 0.5239 - val_loss: 0.9862 - val_accuracy: 0.5287\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9802 - accuracy: 0.5223 - val_loss: 0.9876 - val_accuracy: 0.5278\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9794 - accuracy: 0.5233 - val_loss: 0.9834 - val_accuracy: 0.5319\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9794 - accuracy: 0.5242 - val_loss: 0.9856 - val_accuracy: 0.5269\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9786 - accuracy: 0.5232 - val_loss: 0.9843 - val_accuracy: 0.5296\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9788 - accuracy: 0.5255 - val_loss: 0.9832 - val_accuracy: 0.5319\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9785 - accuracy: 0.5248 - val_loss: 0.9834 - val_accuracy: 0.5333\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9785 - accuracy: 0.5230 - val_loss: 0.9842 - val_accuracy: 0.5282\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9781 - accuracy: 0.5262 - val_loss: 0.9865 - val_accuracy: 0.5310\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9781 - accuracy: 0.5245 - val_loss: 0.9839 - val_accuracy: 0.5282\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9778 - accuracy: 0.5269 - val_loss: 0.9852 - val_accuracy: 0.5319\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 0s 776us/step - loss: 0.9779 - accuracy: 0.5246 - val_loss: 0.9857 - val_accuracy: 0.5301\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9766 - accuracy: 0.5274 - val_loss: 0.9833 - val_accuracy: 0.5324\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9782 - accuracy: 0.5240 - val_loss: 0.9865 - val_accuracy: 0.5296\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9779 - accuracy: 0.5272 - val_loss: 0.9856 - val_accuracy: 0.5301\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 0s 831us/step - loss: 0.9772 - accuracy: 0.5257 - val_loss: 0.9856 - val_accuracy: 0.5305\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9776 - accuracy: 0.5238 - val_loss: 0.9808 - val_accuracy: 0.5324\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9771 - accuracy: 0.5265 - val_loss: 0.9830 - val_accuracy: 0.5342\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9761 - accuracy: 0.5293 - val_loss: 0.9847 - val_accuracy: 0.5338\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9767 - accuracy: 0.5254 - val_loss: 0.9881 - val_accuracy: 0.5168\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9766 - accuracy: 0.5256 - val_loss: 0.9861 - val_accuracy: 0.5273\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9767 - accuracy: 0.5251 - val_loss: 0.9849 - val_accuracy: 0.5278\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9767 - accuracy: 0.5273 - val_loss: 0.9853 - val_accuracy: 0.5310\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9763 - accuracy: 0.5256 - val_loss: 0.9804 - val_accuracy: 0.5333\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9762 - accuracy: 0.5268 - val_loss: 0.9835 - val_accuracy: 0.5310\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9763 - accuracy: 0.5275 - val_loss: 0.9822 - val_accuracy: 0.5374\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9761 - accuracy: 0.5267 - val_loss: 0.9835 - val_accuracy: 0.5305\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9757 - accuracy: 0.5269 - val_loss: 0.9842 - val_accuracy: 0.5301\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9761 - accuracy: 0.5267 - val_loss: 0.9822 - val_accuracy: 0.5301\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9765 - accuracy: 0.5261 - val_loss: 0.9834 - val_accuracy: 0.5347\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9757 - accuracy: 0.5279 - val_loss: 0.9846 - val_accuracy: 0.5333\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9761 - accuracy: 0.5278 - val_loss: 0.9825 - val_accuracy: 0.5319\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9762 - accuracy: 0.5267 - val_loss: 0.9828 - val_accuracy: 0.5361\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9753 - accuracy: 0.5270 - val_loss: 0.9868 - val_accuracy: 0.5186\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9760 - accuracy: 0.5272 - val_loss: 0.9805 - val_accuracy: 0.5255\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9767 - accuracy: 0.5269 - val_loss: 0.9821 - val_accuracy: 0.5296\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9752 - accuracy: 0.5270 - val_loss: 0.9826 - val_accuracy: 0.5333\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 0s 845us/step - loss: 0.9767 - accuracy: 0.5262 - val_loss: 0.9825 - val_accuracy: 0.5356\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9760 - accuracy: 0.5251 - val_loss: 0.9829 - val_accuracy: 0.5338\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9752 - accuracy: 0.5285 - val_loss: 0.9825 - val_accuracy: 0.5338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "89/89 [==============================] - 0s 804us/step - loss: 0.9759 - accuracy: 0.5280 - val_loss: 0.9809 - val_accuracy: 0.5370\n",
      "Epoch 59/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9757 - accuracy: 0.5282 - val_loss: 0.9799 - val_accuracy: 0.5356\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9754 - accuracy: 0.5285 - val_loss: 0.9833 - val_accuracy: 0.5305\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9823 - val_accuracy: 0.5365\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9755 - accuracy: 0.5262 - val_loss: 0.9843 - val_accuracy: 0.5319\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9752 - accuracy: 0.5283 - val_loss: 0.9825 - val_accuracy: 0.5361\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9768 - accuracy: 0.5260 - val_loss: 0.9832 - val_accuracy: 0.5328\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9748 - accuracy: 0.5282 - val_loss: 0.9832 - val_accuracy: 0.5324\n",
      "Epoch 66/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9754 - accuracy: 0.5280 - val_loss: 0.9841 - val_accuracy: 0.5333\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9747 - accuracy: 0.5282 - val_loss: 0.9827 - val_accuracy: 0.5342\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9755 - accuracy: 0.5286 - val_loss: 0.9835 - val_accuracy: 0.5333\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 0s 853us/step - loss: 0.9750 - accuracy: 0.5269 - val_loss: 0.9840 - val_accuracy: 0.5292\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 0s 765us/step - loss: 0.9748 - accuracy: 0.5278 - val_loss: 0.9844 - val_accuracy: 0.5269\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 0s 966us/step - loss: 0.9745 - accuracy: 0.5276 - val_loss: 0.9825 - val_accuracy: 0.5333\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9756 - accuracy: 0.5289 - val_loss: 0.9871 - val_accuracy: 0.5168\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 0s 823us/step - loss: 0.9758 - accuracy: 0.5284 - val_loss: 0.9829 - val_accuracy: 0.5305\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 0s 839us/step - loss: 0.9746 - accuracy: 0.5280 - val_loss: 0.9826 - val_accuracy: 0.5361\n",
      "Epoch 75/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9753 - accuracy: 0.5278 - val_loss: 0.9804 - val_accuracy: 0.5328\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9745 - accuracy: 0.5285 - val_loss: 0.9824 - val_accuracy: 0.5328\n",
      "Epoch 77/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9756 - accuracy: 0.5269 - val_loss: 0.9838 - val_accuracy: 0.5342\n",
      "Epoch 78/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9749 - accuracy: 0.5282 - val_loss: 0.9806 - val_accuracy: 0.5315\n",
      "Epoch 79/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9745 - accuracy: 0.5294 - val_loss: 0.9847 - val_accuracy: 0.5282\n",
      "Epoch 80/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9753 - accuracy: 0.5271 - val_loss: 0.9838 - val_accuracy: 0.5292\n",
      "Epoch 81/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9744 - accuracy: 0.5289 - val_loss: 0.9828 - val_accuracy: 0.5319\n",
      "Epoch 82/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9746 - accuracy: 0.5297 - val_loss: 0.9839 - val_accuracy: 0.5338\n",
      "Epoch 83/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9750 - accuracy: 0.5274 - val_loss: 0.9819 - val_accuracy: 0.5333\n",
      "Epoch 84/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9754 - accuracy: 0.5285 - val_loss: 0.9858 - val_accuracy: 0.5315\n",
      "Epoch 85/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9745 - accuracy: 0.5284 - val_loss: 0.9820 - val_accuracy: 0.5324\n",
      "Epoch 86/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9753 - accuracy: 0.5285 - val_loss: 0.9831 - val_accuracy: 0.5356\n",
      "Epoch 87/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9742 - accuracy: 0.5266 - val_loss: 0.9825 - val_accuracy: 0.5351\n",
      "Epoch 88/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9741 - accuracy: 0.5287 - val_loss: 0.9831 - val_accuracy: 0.5328\n",
      "Epoch 89/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9745 - accuracy: 0.5294 - val_loss: 0.9827 - val_accuracy: 0.5250\n",
      "Epoch 90/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9743 - accuracy: 0.5287 - val_loss: 0.9837 - val_accuracy: 0.5269\n",
      "Epoch 91/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9743 - accuracy: 0.5284 - val_loss: 0.9823 - val_accuracy: 0.5365\n",
      "Epoch 92/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9747 - accuracy: 0.5277 - val_loss: 0.9819 - val_accuracy: 0.5324\n",
      "Epoch 93/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9741 - accuracy: 0.5262 - val_loss: 0.9821 - val_accuracy: 0.5351\n",
      "Epoch 94/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9744 - accuracy: 0.5285 - val_loss: 0.9874 - val_accuracy: 0.5108\n",
      "Epoch 95/200\n",
      "89/89 [==============================] - 0s 815us/step - loss: 0.9740 - accuracy: 0.5276 - val_loss: 0.9838 - val_accuracy: 0.5333\n",
      "Epoch 96/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9742 - accuracy: 0.5285 - val_loss: 0.9813 - val_accuracy: 0.5342\n",
      "Epoch 97/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9742 - accuracy: 0.5286 - val_loss: 0.9824 - val_accuracy: 0.5338\n",
      "Epoch 98/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9752 - accuracy: 0.5293 - val_loss: 0.9836 - val_accuracy: 0.5232\n",
      "Epoch 99/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9743 - accuracy: 0.5285 - val_loss: 0.9847 - val_accuracy: 0.5310\n",
      "Epoch 100/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9747 - accuracy: 0.5282 - val_loss: 0.9804 - val_accuracy: 0.5365\n",
      "Epoch 101/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9739 - accuracy: 0.5282 - val_loss: 0.9850 - val_accuracy: 0.5227\n",
      "Epoch 102/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9745 - accuracy: 0.5279 - val_loss: 0.9813 - val_accuracy: 0.5351\n",
      "Epoch 103/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9741 - accuracy: 0.5311 - val_loss: 0.9809 - val_accuracy: 0.5315\n",
      "Epoch 104/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9752 - accuracy: 0.5284 - val_loss: 0.9805 - val_accuracy: 0.5292\n",
      "Epoch 105/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9742 - accuracy: 0.5271 - val_loss: 0.9827 - val_accuracy: 0.5333\n",
      "Epoch 106/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9736 - accuracy: 0.5277 - val_loss: 0.9804 - val_accuracy: 0.5296\n",
      "Epoch 107/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9744 - accuracy: 0.5300 - val_loss: 0.9844 - val_accuracy: 0.5319\n",
      "Epoch 108/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9743 - accuracy: 0.5294 - val_loss: 0.9816 - val_accuracy: 0.5361\n",
      "Epoch 109/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9737 - accuracy: 0.5290 - val_loss: 0.9813 - val_accuracy: 0.5361\n",
      "Epoch 110/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9832 - val_accuracy: 0.5365\n",
      "Epoch 111/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9739 - accuracy: 0.5288 - val_loss: 0.9826 - val_accuracy: 0.5370\n",
      "Epoch 112/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9742 - accuracy: 0.5292 - val_loss: 0.9823 - val_accuracy: 0.5292\n",
      "Epoch 113/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9735 - accuracy: 0.5278 - val_loss: 0.9813 - val_accuracy: 0.5324\n",
      "Epoch 114/200\n",
      "89/89 [==============================] - 0s 784us/step - loss: 0.9740 - accuracy: 0.5272 - val_loss: 0.9803 - val_accuracy: 0.5365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9736 - accuracy: 0.5281 - val_loss: 0.9820 - val_accuracy: 0.5287\n",
      "Epoch 116/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9739 - accuracy: 0.5290 - val_loss: 0.9811 - val_accuracy: 0.5356\n",
      "Epoch 117/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9740 - accuracy: 0.5290 - val_loss: 0.9815 - val_accuracy: 0.5310\n",
      "Epoch 118/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9741 - accuracy: 0.5269 - val_loss: 0.9833 - val_accuracy: 0.5333\n",
      "Epoch 119/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9744 - accuracy: 0.5284 - val_loss: 0.9818 - val_accuracy: 0.5356\n",
      "Epoch 120/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9738 - accuracy: 0.5273 - val_loss: 0.9858 - val_accuracy: 0.5214\n",
      "Epoch 121/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9739 - accuracy: 0.5288 - val_loss: 0.9808 - val_accuracy: 0.5310\n",
      "Epoch 122/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9743 - accuracy: 0.5271 - val_loss: 0.9844 - val_accuracy: 0.5278\n",
      "Epoch 123/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9752 - accuracy: 0.5273 - val_loss: 0.9808 - val_accuracy: 0.5292\n",
      "Epoch 124/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9739 - accuracy: 0.5290 - val_loss: 0.9825 - val_accuracy: 0.5255\n",
      "Epoch 125/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9736 - accuracy: 0.5297 - val_loss: 0.9833 - val_accuracy: 0.5287\n",
      "Epoch 126/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9742 - accuracy: 0.5283 - val_loss: 0.9820 - val_accuracy: 0.5356\n",
      "Epoch 127/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9741 - accuracy: 0.5280 - val_loss: 0.9810 - val_accuracy: 0.5315\n",
      "Epoch 128/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9735 - accuracy: 0.5292 - val_loss: 0.9826 - val_accuracy: 0.5315\n",
      "Epoch 129/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9746 - accuracy: 0.5278 - val_loss: 0.9805 - val_accuracy: 0.5310\n",
      "Epoch 130/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9731 - accuracy: 0.5298 - val_loss: 0.9806 - val_accuracy: 0.5301\n",
      "Epoch 131/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9730 - accuracy: 0.5294 - val_loss: 0.9833 - val_accuracy: 0.5351\n",
      "Epoch 132/200\n",
      "89/89 [==============================] - 0s 793us/step - loss: 0.9738 - accuracy: 0.5292 - val_loss: 0.9830 - val_accuracy: 0.5296\n",
      "Epoch 133/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9738 - accuracy: 0.5306 - val_loss: 0.9829 - val_accuracy: 0.5296\n",
      "Epoch 134/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9737 - accuracy: 0.5283 - val_loss: 0.9841 - val_accuracy: 0.5342\n",
      "Epoch 135/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9738 - accuracy: 0.5270 - val_loss: 0.9834 - val_accuracy: 0.5282\n",
      "Epoch 136/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9731 - accuracy: 0.5288 - val_loss: 0.9807 - val_accuracy: 0.5319\n",
      "Epoch 137/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9740 - accuracy: 0.5284 - val_loss: 0.9852 - val_accuracy: 0.5204\n",
      "Epoch 138/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9747 - accuracy: 0.5282 - val_loss: 0.9823 - val_accuracy: 0.5351\n",
      "Epoch 139/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9727 - accuracy: 0.5289 - val_loss: 0.9869 - val_accuracy: 0.5113\n",
      "Epoch 140/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9736 - accuracy: 0.5292 - val_loss: 0.9833 - val_accuracy: 0.5328\n",
      "Epoch 141/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9741 - accuracy: 0.5294 - val_loss: 0.9827 - val_accuracy: 0.5310\n",
      "Epoch 142/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9742 - accuracy: 0.5294 - val_loss: 0.9883 - val_accuracy: 0.5264\n",
      "Epoch 143/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9742 - accuracy: 0.5279 - val_loss: 0.9807 - val_accuracy: 0.5310\n",
      "Epoch 144/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9730 - accuracy: 0.5299 - val_loss: 0.9856 - val_accuracy: 0.5186\n",
      "Epoch 145/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9731 - accuracy: 0.5303 - val_loss: 0.9808 - val_accuracy: 0.5292\n",
      "Epoch 146/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9854 - val_accuracy: 0.5214\n",
      "Epoch 147/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9738 - accuracy: 0.5287 - val_loss: 0.9851 - val_accuracy: 0.5241\n",
      "Epoch 148/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9734 - accuracy: 0.5301 - val_loss: 0.9824 - val_accuracy: 0.5301\n",
      "Epoch 149/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9844 - val_accuracy: 0.5282\n",
      "Epoch 150/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9735 - accuracy: 0.5293 - val_loss: 0.9826 - val_accuracy: 0.5287\n",
      "Epoch 151/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9737 - accuracy: 0.5281 - val_loss: 0.9826 - val_accuracy: 0.5282\n",
      "Epoch 152/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9732 - accuracy: 0.5282 - val_loss: 0.9804 - val_accuracy: 0.5310\n",
      "Epoch 153/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9735 - accuracy: 0.5315 - val_loss: 0.9875 - val_accuracy: 0.5232\n",
      "Epoch 154/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9733 - accuracy: 0.5290 - val_loss: 0.9823 - val_accuracy: 0.5347\n",
      "Epoch 155/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9731 - accuracy: 0.5287 - val_loss: 0.9839 - val_accuracy: 0.5255\n",
      "Epoch 156/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9728 - accuracy: 0.5282 - val_loss: 0.9810 - val_accuracy: 0.5292\n",
      "Epoch 157/200\n",
      "89/89 [==============================] - 0s 822us/step - loss: 0.9729 - accuracy: 0.5300 - val_loss: 0.9799 - val_accuracy: 0.5292\n",
      "Epoch 158/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9739 - accuracy: 0.5284 - val_loss: 0.9833 - val_accuracy: 0.5324\n",
      "Epoch 159/200\n",
      "89/89 [==============================] - 0s 830us/step - loss: 0.9733 - accuracy: 0.5290 - val_loss: 0.9814 - val_accuracy: 0.5324\n",
      "Epoch 160/200\n",
      "89/89 [==============================] - 0s 839us/step - loss: 0.9733 - accuracy: 0.5294 - val_loss: 0.9808 - val_accuracy: 0.5315\n",
      "Epoch 161/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9733 - accuracy: 0.5291 - val_loss: 0.9808 - val_accuracy: 0.5305\n",
      "Epoch 162/200\n",
      "89/89 [==============================] - 0s 846us/step - loss: 0.9727 - accuracy: 0.5291 - val_loss: 0.9859 - val_accuracy: 0.5282\n",
      "Epoch 163/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9733 - accuracy: 0.5301 - val_loss: 0.9829 - val_accuracy: 0.5305\n",
      "Epoch 164/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9733 - accuracy: 0.5292 - val_loss: 0.9811 - val_accuracy: 0.5287\n",
      "Epoch 165/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9749 - accuracy: 0.5277 - val_loss: 0.9816 - val_accuracy: 0.5296\n",
      "Epoch 166/200\n",
      "89/89 [==============================] - 0s 818us/step - loss: 0.9729 - accuracy: 0.5291 - val_loss: 0.9827 - val_accuracy: 0.5315\n",
      "Epoch 167/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9731 - accuracy: 0.5296 - val_loss: 0.9808 - val_accuracy: 0.5347\n",
      "Epoch 168/200\n",
      "89/89 [==============================] - 0s 775us/step - loss: 0.9732 - accuracy: 0.5283 - val_loss: 0.9832 - val_accuracy: 0.5292\n",
      "Epoch 169/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9738 - accuracy: 0.5278 - val_loss: 0.9837 - val_accuracy: 0.5227\n",
      "Epoch 170/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9729 - accuracy: 0.5285 - val_loss: 0.9812 - val_accuracy: 0.5260\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 805us/step - loss: 0.9729 - accuracy: 0.5287 - val_loss: 0.9824 - val_accuracy: 0.5269\n",
      "Epoch 172/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9734 - accuracy: 0.5290 - val_loss: 0.9824 - val_accuracy: 0.5347\n",
      "Epoch 173/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9730 - accuracy: 0.5293 - val_loss: 0.9805 - val_accuracy: 0.5319\n",
      "Epoch 174/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9724 - accuracy: 0.5294 - val_loss: 0.9813 - val_accuracy: 0.5292\n",
      "Epoch 175/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9736 - accuracy: 0.5294 - val_loss: 0.9815 - val_accuracy: 0.5315\n",
      "Epoch 176/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9726 - accuracy: 0.5290 - val_loss: 0.9832 - val_accuracy: 0.5310\n",
      "Epoch 177/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9726 - accuracy: 0.5285 - val_loss: 0.9813 - val_accuracy: 0.5310\n",
      "Epoch 178/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9732 - accuracy: 0.5296 - val_loss: 0.9821 - val_accuracy: 0.5296\n",
      "Epoch 179/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9730 - accuracy: 0.5284 - val_loss: 0.9821 - val_accuracy: 0.5305\n",
      "Epoch 180/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9727 - accuracy: 0.5290 - val_loss: 0.9822 - val_accuracy: 0.5305\n",
      "Epoch 181/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9732 - accuracy: 0.5281 - val_loss: 0.9830 - val_accuracy: 0.5264\n",
      "Epoch 182/200\n",
      "89/89 [==============================] - 0s 785us/step - loss: 0.9731 - accuracy: 0.5287 - val_loss: 0.9833 - val_accuracy: 0.5319\n",
      "Epoch 183/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9731 - accuracy: 0.5302 - val_loss: 0.9830 - val_accuracy: 0.5278\n",
      "Epoch 184/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9739 - accuracy: 0.5277 - val_loss: 0.9815 - val_accuracy: 0.5278\n",
      "Epoch 185/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9727 - accuracy: 0.5273 - val_loss: 0.9826 - val_accuracy: 0.5264\n",
      "Epoch 186/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9723 - accuracy: 0.5304 - val_loss: 0.9838 - val_accuracy: 0.5305\n",
      "Epoch 187/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9738 - accuracy: 0.5271 - val_loss: 0.9812 - val_accuracy: 0.5278\n",
      "Epoch 188/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9728 - accuracy: 0.5295 - val_loss: 0.9834 - val_accuracy: 0.5264\n",
      "Epoch 189/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9727 - accuracy: 0.5297 - val_loss: 0.9853 - val_accuracy: 0.5278\n",
      "Epoch 190/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9723 - accuracy: 0.5296 - val_loss: 0.9811 - val_accuracy: 0.5319\n",
      "Epoch 191/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9725 - accuracy: 0.5285 - val_loss: 0.9817 - val_accuracy: 0.5260\n",
      "Epoch 192/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9727 - accuracy: 0.5290 - val_loss: 0.9819 - val_accuracy: 0.5296\n",
      "Epoch 193/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9731 - accuracy: 0.5306 - val_loss: 0.9821 - val_accuracy: 0.5273\n",
      "Epoch 194/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9725 - accuracy: 0.5289 - val_loss: 0.9822 - val_accuracy: 0.5278\n",
      "Epoch 195/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9727 - accuracy: 0.5286 - val_loss: 0.9823 - val_accuracy: 0.5278\n",
      "Epoch 196/200\n",
      "89/89 [==============================] - 0s 803us/step - loss: 0.9737 - accuracy: 0.5278 - val_loss: 0.9801 - val_accuracy: 0.5296\n",
      "Epoch 197/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9725 - accuracy: 0.5278 - val_loss: 0.9836 - val_accuracy: 0.5278\n",
      "Epoch 198/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9723 - accuracy: 0.5292 - val_loss: 0.9815 - val_accuracy: 0.5282\n",
      "Epoch 199/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9730 - accuracy: 0.5286 - val_loss: 0.9837 - val_accuracy: 0.5269\n",
      "Epoch 200/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9728 - accuracy: 0.5294 - val_loss: 0.9814 - val_accuracy: 0.5319\n",
      "\n",
      "Train split:\n",
      "612/612 [==============================] - 0s 592us/step - loss: 0.9718 - accuracy: 0.5321\n",
      "Accuracy : 0.5321180820465088\n",
      "\n",
      "Test split:\n",
      "69/69 - 0s - loss: 0.9814 - accuracy: 0.5319\n",
      "Accuracy : 0.5319246649742126\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 1.0596 - accuracy: 0.4530 - val_loss: 1.0496 - val_accuracy: 0.4600\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 0s 822us/step - loss: 1.0414 - accuracy: 0.4664 - val_loss: 1.0308 - val_accuracy: 0.4614\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 1.0221 - accuracy: 0.5004 - val_loss: 1.0062 - val_accuracy: 0.5312\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 1.0078 - accuracy: 0.5143 - val_loss: 1.0126 - val_accuracy: 0.4991\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9999 - accuracy: 0.5168 - val_loss: 1.0020 - val_accuracy: 0.5170\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9934 - accuracy: 0.5184 - val_loss: 0.9900 - val_accuracy: 0.5322\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9920 - accuracy: 0.5174 - val_loss: 0.9962 - val_accuracy: 0.5317\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9882 - accuracy: 0.5210 - val_loss: 0.9868 - val_accuracy: 0.5221\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9855 - accuracy: 0.5219 - val_loss: 0.9896 - val_accuracy: 0.5326\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9847 - accuracy: 0.5212 - val_loss: 0.9871 - val_accuracy: 0.5262\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9850 - accuracy: 0.5222 - val_loss: 0.9817 - val_accuracy: 0.5303\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9832 - accuracy: 0.5221 - val_loss: 0.9836 - val_accuracy: 0.5276\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 0s 793us/step - loss: 0.9822 - accuracy: 0.5238 - val_loss: 0.9858 - val_accuracy: 0.5257\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9817 - accuracy: 0.5240 - val_loss: 0.9843 - val_accuracy: 0.5257\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9814 - accuracy: 0.5266 - val_loss: 0.9810 - val_accuracy: 0.5299\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9803 - accuracy: 0.5249 - val_loss: 0.9798 - val_accuracy: 0.5308\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9808 - accuracy: 0.5272 - val_loss: 0.9836 - val_accuracy: 0.5290\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9814 - accuracy: 0.5271 - val_loss: 0.9795 - val_accuracy: 0.5308\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 0s 818us/step - loss: 0.9797 - accuracy: 0.5251 - val_loss: 0.9778 - val_accuracy: 0.5354\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9794 - accuracy: 0.5270 - val_loss: 0.9838 - val_accuracy: 0.5285\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9802 - accuracy: 0.5255 - val_loss: 0.9782 - val_accuracy: 0.5335\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9788 - accuracy: 0.5286 - val_loss: 0.9781 - val_accuracy: 0.5335\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9809 - accuracy: 0.5226 - val_loss: 0.9794 - val_accuracy: 0.5280\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9795 - accuracy: 0.5262 - val_loss: 0.9821 - val_accuracy: 0.5290\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9800 - accuracy: 0.5251 - val_loss: 0.9835 - val_accuracy: 0.5276\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 808us/step - loss: 0.9782 - accuracy: 0.5278 - val_loss: 0.9777 - val_accuracy: 0.5317\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9775 - accuracy: 0.5290 - val_loss: 0.9785 - val_accuracy: 0.5303\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9773 - accuracy: 0.5298 - val_loss: 0.9800 - val_accuracy: 0.5257\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9786 - accuracy: 0.5277 - val_loss: 0.9888 - val_accuracy: 0.5207\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9802 - accuracy: 0.5243 - val_loss: 0.9807 - val_accuracy: 0.5276\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9779 - accuracy: 0.5286 - val_loss: 0.9786 - val_accuracy: 0.5326\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9782 - accuracy: 0.5285 - val_loss: 0.9824 - val_accuracy: 0.5271\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9783 - accuracy: 0.5267 - val_loss: 0.9814 - val_accuracy: 0.5239\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9764 - accuracy: 0.5290 - val_loss: 0.9790 - val_accuracy: 0.5271\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9768 - accuracy: 0.5284 - val_loss: 0.9788 - val_accuracy: 0.5276\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9768 - accuracy: 0.5293 - val_loss: 0.9786 - val_accuracy: 0.5340\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9769 - accuracy: 0.5285 - val_loss: 0.9797 - val_accuracy: 0.5276\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9813 - val_accuracy: 0.5294\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9769 - accuracy: 0.5304 - val_loss: 0.9777 - val_accuracy: 0.5317\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9757 - accuracy: 0.5296 - val_loss: 0.9795 - val_accuracy: 0.5230\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9768 - accuracy: 0.5291 - val_loss: 0.9799 - val_accuracy: 0.5294\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9756 - accuracy: 0.5303 - val_loss: 0.9770 - val_accuracy: 0.5372\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9782 - val_accuracy: 0.5299\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9765 - accuracy: 0.5280 - val_loss: 0.9790 - val_accuracy: 0.5262\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9830 - val_accuracy: 0.5216\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9756 - accuracy: 0.5289 - val_loss: 0.9776 - val_accuracy: 0.5267\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9756 - accuracy: 0.5289 - val_loss: 0.9800 - val_accuracy: 0.5257\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9752 - accuracy: 0.5292 - val_loss: 0.9793 - val_accuracy: 0.5280\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9760 - accuracy: 0.5286 - val_loss: 0.9803 - val_accuracy: 0.5290\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 0s 803us/step - loss: 0.9774 - accuracy: 0.5304 - val_loss: 0.9797 - val_accuracy: 0.5267\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9766 - val_accuracy: 0.5322\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9757 - accuracy: 0.5300 - val_loss: 0.9774 - val_accuracy: 0.5354\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9755 - accuracy: 0.5302 - val_loss: 0.9783 - val_accuracy: 0.5368\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9753 - accuracy: 0.5286 - val_loss: 0.9806 - val_accuracy: 0.5303\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 0s 803us/step - loss: 0.9749 - accuracy: 0.5305 - val_loss: 0.9783 - val_accuracy: 0.5345\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9755 - accuracy: 0.5306 - val_loss: 0.9777 - val_accuracy: 0.5349\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9746 - accuracy: 0.5314 - val_loss: 0.9847 - val_accuracy: 0.5188\n",
      "Epoch 58/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9760 - accuracy: 0.5279 - val_loss: 0.9773 - val_accuracy: 0.5340\n",
      "Epoch 59/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9747 - accuracy: 0.5318 - val_loss: 0.9776 - val_accuracy: 0.5317\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9743 - accuracy: 0.5291 - val_loss: 0.9801 - val_accuracy: 0.5271\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9744 - accuracy: 0.5292 - val_loss: 0.9786 - val_accuracy: 0.5285\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9740 - accuracy: 0.5302 - val_loss: 0.9789 - val_accuracy: 0.5257\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9836 - val_accuracy: 0.5175\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9781 - accuracy: 0.5266 - val_loss: 0.9793 - val_accuracy: 0.5312\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9762 - accuracy: 0.5272 - val_loss: 0.9811 - val_accuracy: 0.5303\n",
      "Epoch 66/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9768 - accuracy: 0.5287 - val_loss: 0.9812 - val_accuracy: 0.5267\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9760 - accuracy: 0.5300 - val_loss: 0.9797 - val_accuracy: 0.5317\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9748 - accuracy: 0.5313 - val_loss: 0.9819 - val_accuracy: 0.5331\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 0s 877us/step - loss: 0.9757 - accuracy: 0.5306 - val_loss: 0.9807 - val_accuracy: 0.5322\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 0s 888us/step - loss: 0.9758 - accuracy: 0.5289 - val_loss: 0.9823 - val_accuracy: 0.5271\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 0s 877us/step - loss: 0.9757 - accuracy: 0.5302 - val_loss: 0.9801 - val_accuracy: 0.5285\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9756 - accuracy: 0.5286 - val_loss: 0.9805 - val_accuracy: 0.5317\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 0s 859us/step - loss: 0.9757 - accuracy: 0.5275 - val_loss: 0.9804 - val_accuracy: 0.5285\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 0s 873us/step - loss: 0.9749 - accuracy: 0.5308 - val_loss: 0.9787 - val_accuracy: 0.5322\n",
      "Epoch 75/200\n",
      "89/89 [==============================] - 0s 934us/step - loss: 0.9749 - accuracy: 0.5299 - val_loss: 0.9783 - val_accuracy: 0.5331\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9788 - val_accuracy: 0.5294\n",
      "Epoch 77/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9749 - accuracy: 0.5299 - val_loss: 0.9811 - val_accuracy: 0.5299\n",
      "Epoch 78/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9741 - accuracy: 0.5319 - val_loss: 0.9791 - val_accuracy: 0.5345\n",
      "Epoch 79/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9753 - accuracy: 0.5297 - val_loss: 0.9780 - val_accuracy: 0.5340\n",
      "Epoch 80/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9747 - accuracy: 0.5314 - val_loss: 0.9784 - val_accuracy: 0.5335\n",
      "Epoch 81/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9750 - accuracy: 0.5324 - val_loss: 0.9808 - val_accuracy: 0.5322\n",
      "Epoch 82/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9792 - val_accuracy: 0.5317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9742 - accuracy: 0.5321 - val_loss: 0.9798 - val_accuracy: 0.5267\n",
      "Epoch 84/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9748 - accuracy: 0.5308 - val_loss: 0.9818 - val_accuracy: 0.5326\n",
      "Epoch 85/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9760 - accuracy: 0.5269 - val_loss: 0.9865 - val_accuracy: 0.5303\n",
      "Epoch 86/200\n",
      "89/89 [==============================] - 0s 778us/step - loss: 0.9743 - accuracy: 0.5306 - val_loss: 0.9841 - val_accuracy: 0.5317\n",
      "Epoch 87/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9749 - accuracy: 0.5300 - val_loss: 0.9801 - val_accuracy: 0.5303\n",
      "Epoch 88/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 0.9789 - val_accuracy: 0.5290\n",
      "Epoch 89/200\n",
      "89/89 [==============================] - 0s 846us/step - loss: 0.9740 - accuracy: 0.5299 - val_loss: 0.9807 - val_accuracy: 0.5335\n",
      "Epoch 90/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9742 - accuracy: 0.5291 - val_loss: 0.9782 - val_accuracy: 0.5349\n",
      "Epoch 91/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9748 - accuracy: 0.5295 - val_loss: 0.9817 - val_accuracy: 0.5262\n",
      "Epoch 92/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9742 - accuracy: 0.5305 - val_loss: 0.9790 - val_accuracy: 0.5335\n",
      "Epoch 93/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9741 - accuracy: 0.5312 - val_loss: 0.9799 - val_accuracy: 0.5331\n",
      "Epoch 94/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9751 - accuracy: 0.5291 - val_loss: 0.9783 - val_accuracy: 0.5317\n",
      "Epoch 95/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9750 - accuracy: 0.5300 - val_loss: 0.9792 - val_accuracy: 0.5299\n",
      "Epoch 96/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9747 - accuracy: 0.5269 - val_loss: 0.9792 - val_accuracy: 0.5354\n",
      "Epoch 97/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9739 - accuracy: 0.5304 - val_loss: 0.9802 - val_accuracy: 0.5290\n",
      "Epoch 98/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9737 - accuracy: 0.5329 - val_loss: 0.9806 - val_accuracy: 0.5285\n",
      "Epoch 99/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9740 - accuracy: 0.5299 - val_loss: 0.9785 - val_accuracy: 0.5340\n",
      "Epoch 100/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 0.9809 - val_accuracy: 0.5354\n",
      "Epoch 101/200\n",
      "89/89 [==============================] - 0s 820us/step - loss: 0.9738 - accuracy: 0.5294 - val_loss: 0.9786 - val_accuracy: 0.5340\n",
      "Epoch 102/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9742 - accuracy: 0.5288 - val_loss: 0.9798 - val_accuracy: 0.5312\n",
      "Epoch 103/200\n",
      "89/89 [==============================] - 0s 831us/step - loss: 0.9744 - accuracy: 0.5315 - val_loss: 0.9790 - val_accuracy: 0.5322\n",
      "Epoch 104/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9741 - accuracy: 0.5287 - val_loss: 0.9793 - val_accuracy: 0.5372\n",
      "Epoch 105/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9739 - accuracy: 0.5299 - val_loss: 0.9802 - val_accuracy: 0.5322\n",
      "Epoch 106/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9745 - accuracy: 0.5299 - val_loss: 0.9784 - val_accuracy: 0.5345\n",
      "Epoch 107/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9737 - accuracy: 0.5297 - val_loss: 0.9802 - val_accuracy: 0.5308\n",
      "Epoch 108/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9738 - accuracy: 0.5304 - val_loss: 0.9826 - val_accuracy: 0.5290\n",
      "Epoch 109/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9742 - accuracy: 0.5300 - val_loss: 0.9814 - val_accuracy: 0.5308\n",
      "Epoch 110/200\n",
      "89/89 [==============================] - 0s 788us/step - loss: 0.9733 - accuracy: 0.5290 - val_loss: 0.9790 - val_accuracy: 0.5322\n",
      "Epoch 111/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9732 - accuracy: 0.5293 - val_loss: 0.9797 - val_accuracy: 0.5340\n",
      "Epoch 112/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9742 - accuracy: 0.5303 - val_loss: 0.9826 - val_accuracy: 0.5271\n",
      "Epoch 113/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9791 - val_accuracy: 0.5312\n",
      "Epoch 114/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9797 - val_accuracy: 0.5335\n",
      "Epoch 115/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9736 - accuracy: 0.5303 - val_loss: 0.9784 - val_accuracy: 0.5354\n",
      "Epoch 116/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9740 - accuracy: 0.5303 - val_loss: 0.9797 - val_accuracy: 0.5290\n",
      "Epoch 117/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9737 - accuracy: 0.5304 - val_loss: 0.9811 - val_accuracy: 0.5276\n",
      "Epoch 118/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9735 - accuracy: 0.5287 - val_loss: 0.9832 - val_accuracy: 0.5299\n",
      "Epoch 119/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9739 - accuracy: 0.5298 - val_loss: 0.9793 - val_accuracy: 0.5331\n",
      "Epoch 120/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9744 - accuracy: 0.5311 - val_loss: 0.9812 - val_accuracy: 0.5290\n",
      "Epoch 121/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9739 - accuracy: 0.5302 - val_loss: 0.9791 - val_accuracy: 0.5363\n",
      "Epoch 122/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 0.9800 - val_accuracy: 0.5358\n",
      "Epoch 123/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9728 - accuracy: 0.5323 - val_loss: 0.9801 - val_accuracy: 0.5335\n",
      "Epoch 124/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9738 - accuracy: 0.5297 - val_loss: 0.9817 - val_accuracy: 0.5326\n",
      "Epoch 125/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9735 - accuracy: 0.5316 - val_loss: 0.9815 - val_accuracy: 0.5303\n",
      "Epoch 126/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9741 - accuracy: 0.5299 - val_loss: 0.9809 - val_accuracy: 0.5299\n",
      "Epoch 127/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9732 - accuracy: 0.5309 - val_loss: 0.9881 - val_accuracy: 0.5230\n",
      "Epoch 128/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9732 - accuracy: 0.5304 - val_loss: 0.9809 - val_accuracy: 0.5303\n",
      "Epoch 129/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9741 - accuracy: 0.5297 - val_loss: 0.9863 - val_accuracy: 0.5248\n",
      "Epoch 130/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9734 - accuracy: 0.5296 - val_loss: 0.9816 - val_accuracy: 0.5312\n",
      "Epoch 131/200\n",
      "89/89 [==============================] - 0s 836us/step - loss: 0.9734 - accuracy: 0.5305 - val_loss: 0.9815 - val_accuracy: 0.5253\n",
      "Epoch 132/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9729 - accuracy: 0.5298 - val_loss: 0.9810 - val_accuracy: 0.5317\n",
      "Epoch 133/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9791 - val_accuracy: 0.5340\n",
      "Epoch 134/200\n",
      "89/89 [==============================] - 0s 779us/step - loss: 0.9739 - accuracy: 0.5315 - val_loss: 0.9803 - val_accuracy: 0.5290\n",
      "Epoch 135/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9729 - accuracy: 0.5312 - val_loss: 0.9809 - val_accuracy: 0.5340\n",
      "Epoch 136/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9727 - accuracy: 0.5308 - val_loss: 0.9800 - val_accuracy: 0.5322\n",
      "Epoch 137/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9807 - val_accuracy: 0.5271\n",
      "Epoch 138/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9732 - accuracy: 0.5311 - val_loss: 0.9811 - val_accuracy: 0.5308\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 793us/step - loss: 0.9738 - accuracy: 0.5309 - val_loss: 0.9854 - val_accuracy: 0.5326\n",
      "Epoch 140/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9729 - accuracy: 0.5288 - val_loss: 0.9800 - val_accuracy: 0.5358\n",
      "Epoch 141/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9734 - accuracy: 0.5313 - val_loss: 0.9809 - val_accuracy: 0.5331\n",
      "Epoch 142/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9733 - accuracy: 0.5297 - val_loss: 0.9801 - val_accuracy: 0.5303\n",
      "Epoch 143/200\n",
      "89/89 [==============================] - 0s 869us/step - loss: 0.9734 - accuracy: 0.5292 - val_loss: 0.9802 - val_accuracy: 0.5303\n",
      "Epoch 144/200\n",
      "89/89 [==============================] - 0s 858us/step - loss: 0.9726 - accuracy: 0.5289 - val_loss: 0.9806 - val_accuracy: 0.5322\n",
      "Epoch 145/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 0.9810 - val_accuracy: 0.5377\n",
      "Epoch 146/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9728 - accuracy: 0.5317 - val_loss: 0.9796 - val_accuracy: 0.5349\n",
      "Epoch 147/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9734 - accuracy: 0.5303 - val_loss: 0.9805 - val_accuracy: 0.5290\n",
      "Epoch 148/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9731 - accuracy: 0.5315 - val_loss: 0.9807 - val_accuracy: 0.5326\n",
      "Epoch 149/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9729 - accuracy: 0.5299 - val_loss: 0.9814 - val_accuracy: 0.5308\n",
      "Epoch 150/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9726 - accuracy: 0.5312 - val_loss: 0.9790 - val_accuracy: 0.5354\n",
      "Epoch 151/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9729 - accuracy: 0.5317 - val_loss: 0.9802 - val_accuracy: 0.5340\n",
      "Epoch 152/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 0.9808 - val_accuracy: 0.5280\n",
      "Epoch 153/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9726 - accuracy: 0.5309 - val_loss: 0.9822 - val_accuracy: 0.5271\n",
      "Epoch 154/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9727 - accuracy: 0.5308 - val_loss: 0.9819 - val_accuracy: 0.5349\n",
      "Epoch 155/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9734 - accuracy: 0.5308 - val_loss: 0.9801 - val_accuracy: 0.5340\n",
      "Epoch 156/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 0.9819 - val_accuracy: 0.5312\n",
      "Epoch 157/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9732 - accuracy: 0.5300 - val_loss: 0.9803 - val_accuracy: 0.5349\n",
      "Epoch 158/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9721 - accuracy: 0.5306 - val_loss: 0.9843 - val_accuracy: 0.5303\n",
      "Epoch 159/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9730 - accuracy: 0.5301 - val_loss: 0.9840 - val_accuracy: 0.5317\n",
      "Epoch 160/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9737 - accuracy: 0.5290 - val_loss: 0.9818 - val_accuracy: 0.5326\n",
      "Epoch 161/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9725 - accuracy: 0.5312 - val_loss: 0.9803 - val_accuracy: 0.5368\n",
      "Epoch 162/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9832 - val_accuracy: 0.5299\n",
      "Epoch 163/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9721 - accuracy: 0.5322 - val_loss: 0.9807 - val_accuracy: 0.5354\n",
      "Epoch 164/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9722 - accuracy: 0.5326 - val_loss: 0.9801 - val_accuracy: 0.5363\n",
      "Epoch 165/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9728 - accuracy: 0.5298 - val_loss: 0.9818 - val_accuracy: 0.5363\n",
      "Epoch 166/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9733 - accuracy: 0.5318 - val_loss: 0.9808 - val_accuracy: 0.5326\n",
      "Epoch 167/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9730 - accuracy: 0.5296 - val_loss: 0.9823 - val_accuracy: 0.5354\n",
      "Epoch 168/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9721 - accuracy: 0.5325 - val_loss: 0.9787 - val_accuracy: 0.5349\n",
      "Epoch 169/200\n",
      "89/89 [==============================] - 0s 822us/step - loss: 0.9728 - accuracy: 0.5305 - val_loss: 0.9811 - val_accuracy: 0.5340\n",
      "Epoch 170/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9726 - accuracy: 0.5316 - val_loss: 0.9812 - val_accuracy: 0.5326\n",
      "Epoch 171/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9720 - accuracy: 0.5311 - val_loss: 0.9846 - val_accuracy: 0.5290\n",
      "Epoch 172/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9738 - accuracy: 0.5305 - val_loss: 0.9818 - val_accuracy: 0.5340\n",
      "Epoch 173/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9725 - accuracy: 0.5304 - val_loss: 0.9818 - val_accuracy: 0.5345\n",
      "Epoch 174/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9722 - accuracy: 0.5334 - val_loss: 0.9812 - val_accuracy: 0.5299\n",
      "Epoch 175/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9722 - accuracy: 0.5322 - val_loss: 0.9836 - val_accuracy: 0.5345\n",
      "Epoch 176/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9731 - accuracy: 0.5316 - val_loss: 0.9808 - val_accuracy: 0.5354\n",
      "Epoch 177/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9728 - accuracy: 0.5327 - val_loss: 0.9829 - val_accuracy: 0.5317\n",
      "Epoch 178/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9714 - accuracy: 0.5300 - val_loss: 0.9811 - val_accuracy: 0.5308\n",
      "Epoch 179/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9840 - val_accuracy: 0.5299\n",
      "Epoch 180/200\n",
      "89/89 [==============================] - 0s 795us/step - loss: 0.9722 - accuracy: 0.5311 - val_loss: 0.9811 - val_accuracy: 0.5312\n",
      "Epoch 181/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9723 - accuracy: 0.5309 - val_loss: 0.9827 - val_accuracy: 0.5257\n",
      "Epoch 182/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9720 - accuracy: 0.5319 - val_loss: 0.9815 - val_accuracy: 0.5303\n",
      "Epoch 183/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9721 - accuracy: 0.5327 - val_loss: 0.9813 - val_accuracy: 0.5363\n",
      "Epoch 184/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9733 - accuracy: 0.5296 - val_loss: 0.9809 - val_accuracy: 0.5322\n",
      "Epoch 185/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9734 - accuracy: 0.5299 - val_loss: 0.9805 - val_accuracy: 0.5322\n",
      "Epoch 186/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9721 - accuracy: 0.5310 - val_loss: 0.9847 - val_accuracy: 0.5317\n",
      "Epoch 187/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9724 - accuracy: 0.5303 - val_loss: 0.9798 - val_accuracy: 0.5363\n",
      "Epoch 188/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9722 - accuracy: 0.5313 - val_loss: 0.9811 - val_accuracy: 0.5349\n",
      "Epoch 189/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9722 - accuracy: 0.5296 - val_loss: 0.9819 - val_accuracy: 0.5312\n",
      "Epoch 190/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9719 - accuracy: 0.5317 - val_loss: 0.9827 - val_accuracy: 0.5331\n",
      "Epoch 191/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9722 - accuracy: 0.5320 - val_loss: 0.9836 - val_accuracy: 0.5303\n",
      "Epoch 192/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9722 - accuracy: 0.5308 - val_loss: 0.9807 - val_accuracy: 0.5331\n",
      "Epoch 193/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9720 - accuracy: 0.5326 - val_loss: 0.9812 - val_accuracy: 0.5349\n",
      "Epoch 194/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9717 - accuracy: 0.5326 - val_loss: 0.9801 - val_accuracy: 0.5322\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 821us/step - loss: 0.9724 - accuracy: 0.5322 - val_loss: 0.9813 - val_accuracy: 0.5340\n",
      "Epoch 196/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9726 - accuracy: 0.5330 - val_loss: 0.9808 - val_accuracy: 0.5363\n",
      "Epoch 197/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9728 - accuracy: 0.5305 - val_loss: 0.9822 - val_accuracy: 0.5322\n",
      "Epoch 198/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9726 - accuracy: 0.5321 - val_loss: 0.9821 - val_accuracy: 0.5326\n",
      "Epoch 199/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9721 - accuracy: 0.5316 - val_loss: 0.9819 - val_accuracy: 0.5326\n",
      "Epoch 200/200\n",
      "89/89 [==============================] - 0s 829us/step - loss: 0.9724 - accuracy: 0.5326 - val_loss: 0.9820 - val_accuracy: 0.5326\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 354us/step - loss: 0.9723 - accuracy: 0.5299\n",
      "Accuracy : 0.5298953056335449\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9820 - accuracy: 0.5326\n",
      "Accuracy : 0.5326286554336548\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.0722 - accuracy: 0.4248 - val_loss: 1.0600 - val_accuracy: 0.4600\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 1.0501 - accuracy: 0.4600 - val_loss: 1.0497 - val_accuracy: 0.4600\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 1.0216 - accuracy: 0.4864 - val_loss: 1.0270 - val_accuracy: 0.4972\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9950 - accuracy: 0.5174 - val_loss: 1.0166 - val_accuracy: 0.5097\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9857 - accuracy: 0.5246 - val_loss: 1.0144 - val_accuracy: 0.5041\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9833 - accuracy: 0.5250 - val_loss: 1.0178 - val_accuracy: 0.5069\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9809 - accuracy: 0.5252 - val_loss: 1.0132 - val_accuracy: 0.5097\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9783 - accuracy: 0.5264 - val_loss: 1.0131 - val_accuracy: 0.5124\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9772 - accuracy: 0.5265 - val_loss: 1.0120 - val_accuracy: 0.5097\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9768 - accuracy: 0.5291 - val_loss: 1.0112 - val_accuracy: 0.5110\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9769 - accuracy: 0.5274 - val_loss: 1.0122 - val_accuracy: 0.5119\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9774 - accuracy: 0.5262 - val_loss: 1.0111 - val_accuracy: 0.5087\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9760 - accuracy: 0.5259 - val_loss: 1.0130 - val_accuracy: 0.5028\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9749 - accuracy: 0.5274 - val_loss: 1.0094 - val_accuracy: 0.5092\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9749 - accuracy: 0.5288 - val_loss: 1.0109 - val_accuracy: 0.5097\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 0s 839us/step - loss: 0.9749 - accuracy: 0.5277 - val_loss: 1.0103 - val_accuracy: 0.5156\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9740 - accuracy: 0.5296 - val_loss: 1.0127 - val_accuracy: 0.5106\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9752 - accuracy: 0.5283 - val_loss: 1.0145 - val_accuracy: 0.5051\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9751 - accuracy: 0.5276 - val_loss: 1.0101 - val_accuracy: 0.5124\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9740 - accuracy: 0.5310 - val_loss: 1.0085 - val_accuracy: 0.5138\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9760 - accuracy: 0.5291 - val_loss: 1.0083 - val_accuracy: 0.5184\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9745 - accuracy: 0.5291 - val_loss: 1.0109 - val_accuracy: 0.5092\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9738 - accuracy: 0.5293 - val_loss: 1.0120 - val_accuracy: 0.5119\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 0s 820us/step - loss: 0.9738 - accuracy: 0.5314 - val_loss: 1.0101 - val_accuracy: 0.5156\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9733 - accuracy: 0.5288 - val_loss: 1.0091 - val_accuracy: 0.5147\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9729 - accuracy: 0.5292 - val_loss: 1.0115 - val_accuracy: 0.5106\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9746 - accuracy: 0.5287 - val_loss: 1.0103 - val_accuracy: 0.5110\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9737 - accuracy: 0.5291 - val_loss: 1.0097 - val_accuracy: 0.5119\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9733 - accuracy: 0.5294 - val_loss: 1.0095 - val_accuracy: 0.5152\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9730 - accuracy: 0.5295 - val_loss: 1.0094 - val_accuracy: 0.5124\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9737 - accuracy: 0.5293 - val_loss: 1.0096 - val_accuracy: 0.5202\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9728 - accuracy: 0.5303 - val_loss: 1.0103 - val_accuracy: 0.5110\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9723 - accuracy: 0.5302 - val_loss: 1.0107 - val_accuracy: 0.5110\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9723 - accuracy: 0.5291 - val_loss: 1.0114 - val_accuracy: 0.5087\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9727 - accuracy: 0.5306 - val_loss: 1.0130 - val_accuracy: 0.5101\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9738 - accuracy: 0.5284 - val_loss: 1.0139 - val_accuracy: 0.5124\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9727 - accuracy: 0.5304 - val_loss: 1.0125 - val_accuracy: 0.5051\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9724 - accuracy: 0.5308 - val_loss: 1.0103 - val_accuracy: 0.5156\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9723 - accuracy: 0.5304 - val_loss: 1.0080 - val_accuracy: 0.5170\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9728 - accuracy: 0.5316 - val_loss: 1.0070 - val_accuracy: 0.5175\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9732 - accuracy: 0.5296 - val_loss: 1.0088 - val_accuracy: 0.5184\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 0s 846us/step - loss: 0.9723 - accuracy: 0.5309 - val_loss: 1.0104 - val_accuracy: 0.5129\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9731 - accuracy: 0.5296 - val_loss: 1.0135 - val_accuracy: 0.5028\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 1.0097 - val_accuracy: 0.5110\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9722 - accuracy: 0.5315 - val_loss: 1.0116 - val_accuracy: 0.5124\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 1.0093 - val_accuracy: 0.5147\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9726 - accuracy: 0.5316 - val_loss: 1.0099 - val_accuracy: 0.5152\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9720 - accuracy: 0.5297 - val_loss: 1.0097 - val_accuracy: 0.5133\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9731 - accuracy: 0.5298 - val_loss: 1.0103 - val_accuracy: 0.5179\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 810us/step - loss: 0.9734 - accuracy: 0.5289 - val_loss: 1.0086 - val_accuracy: 0.5142\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9720 - accuracy: 0.5287 - val_loss: 1.0106 - val_accuracy: 0.5129\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9722 - accuracy: 0.5299 - val_loss: 1.0092 - val_accuracy: 0.5179\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9720 - accuracy: 0.5318 - val_loss: 1.0079 - val_accuracy: 0.5198\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9722 - accuracy: 0.5309 - val_loss: 1.0091 - val_accuracy: 0.5165\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9721 - accuracy: 0.5299 - val_loss: 1.0076 - val_accuracy: 0.5193\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9713 - accuracy: 0.5307 - val_loss: 1.0118 - val_accuracy: 0.5124\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9711 - accuracy: 0.5333 - val_loss: 1.0084 - val_accuracy: 0.5198\n",
      "Epoch 58/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9720 - accuracy: 0.5302 - val_loss: 1.0102 - val_accuracy: 0.5170\n",
      "Epoch 59/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9737 - accuracy: 0.5287 - val_loss: 1.0117 - val_accuracy: 0.5133\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9716 - accuracy: 0.5304 - val_loss: 1.0113 - val_accuracy: 0.5106\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9719 - accuracy: 0.5316 - val_loss: 1.0086 - val_accuracy: 0.5225\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9718 - accuracy: 0.5311 - val_loss: 1.0079 - val_accuracy: 0.5184\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9718 - accuracy: 0.5305 - val_loss: 1.0076 - val_accuracy: 0.5198\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9717 - accuracy: 0.5305 - val_loss: 1.0076 - val_accuracy: 0.5230\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9722 - accuracy: 0.5319 - val_loss: 1.0080 - val_accuracy: 0.5188\n",
      "Epoch 66/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9710 - accuracy: 0.5312 - val_loss: 1.0074 - val_accuracy: 0.5184\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9716 - accuracy: 0.5309 - val_loss: 1.0074 - val_accuracy: 0.5184\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9710 - accuracy: 0.5318 - val_loss: 1.0096 - val_accuracy: 0.5142\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 0s 820us/step - loss: 0.9718 - accuracy: 0.5310 - val_loss: 1.0105 - val_accuracy: 0.5083\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9710 - accuracy: 0.5295 - val_loss: 1.0079 - val_accuracy: 0.5202\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9720 - accuracy: 0.5286 - val_loss: 1.0078 - val_accuracy: 0.5101\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 0s 861us/step - loss: 0.9716 - accuracy: 0.5295 - val_loss: 1.0094 - val_accuracy: 0.5119\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9713 - accuracy: 0.5296 - val_loss: 1.0089 - val_accuracy: 0.5106\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 0s 888us/step - loss: 0.9710 - accuracy: 0.5291 - val_loss: 1.0092 - val_accuracy: 0.5083\n",
      "Epoch 75/200\n",
      "89/89 [==============================] - 0s 857us/step - loss: 0.9718 - accuracy: 0.5283 - val_loss: 1.0086 - val_accuracy: 0.5244\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 0s 877us/step - loss: 0.9711 - accuracy: 0.5322 - val_loss: 1.0073 - val_accuracy: 0.5179\n",
      "Epoch 77/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9711 - accuracy: 0.5313 - val_loss: 1.0089 - val_accuracy: 0.5175\n",
      "Epoch 78/200\n",
      "89/89 [==============================] - 0s 883us/step - loss: 0.9712 - accuracy: 0.5309 - val_loss: 1.0072 - val_accuracy: 0.5202\n",
      "Epoch 79/200\n",
      "89/89 [==============================] - 0s 815us/step - loss: 0.9713 - accuracy: 0.5316 - val_loss: 1.0080 - val_accuracy: 0.5124\n",
      "Epoch 80/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9708 - accuracy: 0.5316 - val_loss: 1.0072 - val_accuracy: 0.5170\n",
      "Epoch 81/200\n",
      "89/89 [==============================] - 0s 820us/step - loss: 0.9709 - accuracy: 0.5308 - val_loss: 1.0087 - val_accuracy: 0.5129\n",
      "Epoch 82/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9720 - accuracy: 0.5303 - val_loss: 1.0071 - val_accuracy: 0.5152\n",
      "Epoch 83/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9701 - accuracy: 0.5321 - val_loss: 1.0077 - val_accuracy: 0.5202\n",
      "Epoch 84/200\n",
      "89/89 [==============================] - 0s 822us/step - loss: 0.9703 - accuracy: 0.5309 - val_loss: 1.0091 - val_accuracy: 0.5101\n",
      "Epoch 85/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9709 - accuracy: 0.5320 - val_loss: 1.0083 - val_accuracy: 0.5161\n",
      "Epoch 86/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9709 - accuracy: 0.5307 - val_loss: 1.0063 - val_accuracy: 0.5179\n",
      "Epoch 87/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9705 - accuracy: 0.5318 - val_loss: 1.0124 - val_accuracy: 0.5106\n",
      "Epoch 88/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9711 - accuracy: 0.5291 - val_loss: 1.0080 - val_accuracy: 0.5175\n",
      "Epoch 89/200\n",
      "89/89 [==============================] - 0s 803us/step - loss: 0.9703 - accuracy: 0.5332 - val_loss: 1.0114 - val_accuracy: 0.5124\n",
      "Epoch 90/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9703 - accuracy: 0.5313 - val_loss: 1.0087 - val_accuracy: 0.5147\n",
      "Epoch 91/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9704 - accuracy: 0.5307 - val_loss: 1.0086 - val_accuracy: 0.5198\n",
      "Epoch 92/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9693 - accuracy: 0.5322 - val_loss: 1.0077 - val_accuracy: 0.5119\n",
      "Epoch 93/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9698 - accuracy: 0.5323 - val_loss: 1.0084 - val_accuracy: 0.5198\n",
      "Epoch 94/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9713 - accuracy: 0.5315 - val_loss: 1.0072 - val_accuracy: 0.5179\n",
      "Epoch 95/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9703 - accuracy: 0.5312 - val_loss: 1.0078 - val_accuracy: 0.5129\n",
      "Epoch 96/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9701 - accuracy: 0.5313 - val_loss: 1.0070 - val_accuracy: 0.5216\n",
      "Epoch 97/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9694 - accuracy: 0.5328 - val_loss: 1.0076 - val_accuracy: 0.5138\n",
      "Epoch 98/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9702 - accuracy: 0.5312 - val_loss: 1.0073 - val_accuracy: 0.5184\n",
      "Epoch 99/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9700 - accuracy: 0.5311 - val_loss: 1.0085 - val_accuracy: 0.5129\n",
      "Epoch 100/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9701 - accuracy: 0.5328 - val_loss: 1.0073 - val_accuracy: 0.5188\n",
      "Epoch 101/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9712 - accuracy: 0.5291 - val_loss: 1.0088 - val_accuracy: 0.5230\n",
      "Epoch 102/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9702 - accuracy: 0.5313 - val_loss: 1.0099 - val_accuracy: 0.5124\n",
      "Epoch 103/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9700 - accuracy: 0.5317 - val_loss: 1.0084 - val_accuracy: 0.5115\n",
      "Epoch 104/200\n",
      "89/89 [==============================] - 0s 803us/step - loss: 0.9697 - accuracy: 0.5319 - val_loss: 1.0095 - val_accuracy: 0.5184\n",
      "Epoch 105/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9698 - accuracy: 0.5323 - val_loss: 1.0076 - val_accuracy: 0.5138\n",
      "Epoch 106/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9693 - accuracy: 0.5312 - val_loss: 1.0076 - val_accuracy: 0.5119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9701 - accuracy: 0.5301 - val_loss: 1.0084 - val_accuracy: 0.5142\n",
      "Epoch 108/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9701 - accuracy: 0.5300 - val_loss: 1.0077 - val_accuracy: 0.5142\n",
      "Epoch 109/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9699 - accuracy: 0.5335 - val_loss: 1.0066 - val_accuracy: 0.5216\n",
      "Epoch 110/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9701 - accuracy: 0.5334 - val_loss: 1.0064 - val_accuracy: 0.5156\n",
      "Epoch 111/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9686 - accuracy: 0.5336 - val_loss: 1.0096 - val_accuracy: 0.5115\n",
      "Epoch 112/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9701 - accuracy: 0.5321 - val_loss: 1.0097 - val_accuracy: 0.5184\n",
      "Epoch 113/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9706 - accuracy: 0.5305 - val_loss: 1.0103 - val_accuracy: 0.5115\n",
      "Epoch 114/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9699 - accuracy: 0.5307 - val_loss: 1.0078 - val_accuracy: 0.5147\n",
      "Epoch 115/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9694 - accuracy: 0.5323 - val_loss: 1.0094 - val_accuracy: 0.5124\n",
      "Epoch 116/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9698 - accuracy: 0.5303 - val_loss: 1.0075 - val_accuracy: 0.5175\n",
      "Epoch 117/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9693 - accuracy: 0.5310 - val_loss: 1.0081 - val_accuracy: 0.5188\n",
      "Epoch 118/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9695 - accuracy: 0.5310 - val_loss: 1.0113 - val_accuracy: 0.5060\n",
      "Epoch 119/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9698 - accuracy: 0.5308 - val_loss: 1.0079 - val_accuracy: 0.5193\n",
      "Epoch 120/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9698 - accuracy: 0.5309 - val_loss: 1.0102 - val_accuracy: 0.5106\n",
      "Epoch 121/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9693 - accuracy: 0.5311 - val_loss: 1.0093 - val_accuracy: 0.5175\n",
      "Epoch 122/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9702 - accuracy: 0.5316 - val_loss: 1.0072 - val_accuracy: 0.5216\n",
      "Epoch 123/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9691 - accuracy: 0.5322 - val_loss: 1.0065 - val_accuracy: 0.5179\n",
      "Epoch 124/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9690 - accuracy: 0.5329 - val_loss: 1.0079 - val_accuracy: 0.5129\n",
      "Epoch 125/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9692 - accuracy: 0.5316 - val_loss: 1.0074 - val_accuracy: 0.5138\n",
      "Epoch 126/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9690 - accuracy: 0.5302 - val_loss: 1.0107 - val_accuracy: 0.5119\n",
      "Epoch 127/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9686 - accuracy: 0.5329 - val_loss: 1.0075 - val_accuracy: 0.5184\n",
      "Epoch 128/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9692 - accuracy: 0.5313 - val_loss: 1.0078 - val_accuracy: 0.5221\n",
      "Epoch 129/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9686 - accuracy: 0.5324 - val_loss: 1.0084 - val_accuracy: 0.5129\n",
      "Epoch 130/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9688 - accuracy: 0.5314 - val_loss: 1.0065 - val_accuracy: 0.5179\n",
      "Epoch 131/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9693 - accuracy: 0.5327 - val_loss: 1.0089 - val_accuracy: 0.5115\n",
      "Epoch 132/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9695 - accuracy: 0.5328 - val_loss: 1.0079 - val_accuracy: 0.5147\n",
      "Epoch 133/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9692 - accuracy: 0.5323 - val_loss: 1.0072 - val_accuracy: 0.5161\n",
      "Epoch 134/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9683 - accuracy: 0.5327 - val_loss: 1.0083 - val_accuracy: 0.5133\n",
      "Epoch 135/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9690 - accuracy: 0.5319 - val_loss: 1.0066 - val_accuracy: 0.5193\n",
      "Epoch 136/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9692 - accuracy: 0.5321 - val_loss: 1.0085 - val_accuracy: 0.5152\n",
      "Epoch 137/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9683 - accuracy: 0.5319 - val_loss: 1.0085 - val_accuracy: 0.5129\n",
      "Epoch 138/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9680 - accuracy: 0.5335 - val_loss: 1.0101 - val_accuracy: 0.5083\n",
      "Epoch 139/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9688 - accuracy: 0.5313 - val_loss: 1.0056 - val_accuracy: 0.5165\n",
      "Epoch 140/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9686 - accuracy: 0.5323 - val_loss: 1.0078 - val_accuracy: 0.5175\n",
      "Epoch 141/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9689 - accuracy: 0.5320 - val_loss: 1.0085 - val_accuracy: 0.5138\n",
      "Epoch 142/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9698 - accuracy: 0.5317 - val_loss: 1.0082 - val_accuracy: 0.5138\n",
      "Epoch 143/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9683 - accuracy: 0.5332 - val_loss: 1.0084 - val_accuracy: 0.5101\n",
      "Epoch 144/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9678 - accuracy: 0.5311 - val_loss: 1.0072 - val_accuracy: 0.5184\n",
      "Epoch 145/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9679 - accuracy: 0.5307 - val_loss: 1.0081 - val_accuracy: 0.5110\n",
      "Epoch 146/200\n",
      "89/89 [==============================] - 0s 804us/step - loss: 0.9687 - accuracy: 0.5311 - val_loss: 1.0066 - val_accuracy: 0.5175\n",
      "Epoch 147/200\n",
      "89/89 [==============================] - 0s 818us/step - loss: 0.9679 - accuracy: 0.5314 - val_loss: 1.0074 - val_accuracy: 0.5142\n",
      "Epoch 148/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9680 - accuracy: 0.5323 - val_loss: 1.0085 - val_accuracy: 0.5147\n",
      "Epoch 149/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9683 - accuracy: 0.5309 - val_loss: 1.0073 - val_accuracy: 0.5221\n",
      "Epoch 150/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9677 - accuracy: 0.5339 - val_loss: 1.0066 - val_accuracy: 0.5188\n",
      "Epoch 151/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9686 - accuracy: 0.5326 - val_loss: 1.0080 - val_accuracy: 0.5147\n",
      "Epoch 152/200\n",
      "89/89 [==============================] - 0s 838us/step - loss: 0.9693 - accuracy: 0.5314 - val_loss: 1.0059 - val_accuracy: 0.5221\n",
      "Epoch 153/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9677 - accuracy: 0.5329 - val_loss: 1.0101 - val_accuracy: 0.5083\n",
      "Epoch 154/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9691 - accuracy: 0.5339 - val_loss: 1.0089 - val_accuracy: 0.5138\n",
      "Epoch 155/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9691 - accuracy: 0.5310 - val_loss: 1.0134 - val_accuracy: 0.5092\n",
      "Epoch 156/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9685 - accuracy: 0.5289 - val_loss: 1.0075 - val_accuracy: 0.5193\n",
      "Epoch 157/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9694 - accuracy: 0.5300 - val_loss: 1.0077 - val_accuracy: 0.5115\n",
      "Epoch 158/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9686 - accuracy: 0.5328 - val_loss: 1.0075 - val_accuracy: 0.5170\n",
      "Epoch 159/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9680 - accuracy: 0.5340 - val_loss: 1.0090 - val_accuracy: 0.5124\n",
      "Epoch 160/200\n",
      "89/89 [==============================] - 0s 890us/step - loss: 0.9674 - accuracy: 0.5313 - val_loss: 1.0087 - val_accuracy: 0.5147\n",
      "Epoch 161/200\n",
      "89/89 [==============================] - 0s 863us/step - loss: 0.9681 - accuracy: 0.5312 - val_loss: 1.0093 - val_accuracy: 0.5138\n",
      "Epoch 162/200\n",
      "89/89 [==============================] - 0s 873us/step - loss: 0.9679 - accuracy: 0.5331 - val_loss: 1.0105 - val_accuracy: 0.5129\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 888us/step - loss: 0.9677 - accuracy: 0.5321 - val_loss: 1.0076 - val_accuracy: 0.5161\n",
      "Epoch 164/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9684 - accuracy: 0.5339 - val_loss: 1.0084 - val_accuracy: 0.5110\n",
      "Epoch 165/200\n",
      "89/89 [==============================] - 0s 900us/step - loss: 0.9679 - accuracy: 0.5335 - val_loss: 1.0086 - val_accuracy: 0.5142\n",
      "Epoch 166/200\n",
      "89/89 [==============================] - 0s 889us/step - loss: 0.9687 - accuracy: 0.5315 - val_loss: 1.0085 - val_accuracy: 0.5119\n",
      "Epoch 167/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9676 - accuracy: 0.5344 - val_loss: 1.0092 - val_accuracy: 0.5069\n",
      "Epoch 168/200\n",
      "89/89 [==============================] - 0s 847us/step - loss: 0.9679 - accuracy: 0.5316 - val_loss: 1.0088 - val_accuracy: 0.5133\n",
      "Epoch 169/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9677 - accuracy: 0.5322 - val_loss: 1.0078 - val_accuracy: 0.5124\n",
      "Epoch 170/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9675 - accuracy: 0.5333 - val_loss: 1.0110 - val_accuracy: 0.5119\n",
      "Epoch 171/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9686 - accuracy: 0.5322 - val_loss: 1.0104 - val_accuracy: 0.5083\n",
      "Epoch 172/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9695 - accuracy: 0.5310 - val_loss: 1.0075 - val_accuracy: 0.5179\n",
      "Epoch 173/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9676 - accuracy: 0.5320 - val_loss: 1.0075 - val_accuracy: 0.5188\n",
      "Epoch 174/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9682 - accuracy: 0.5315 - val_loss: 1.0085 - val_accuracy: 0.5156\n",
      "Epoch 175/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9687 - accuracy: 0.5338 - val_loss: 1.0078 - val_accuracy: 0.5161\n",
      "Epoch 176/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9678 - accuracy: 0.5315 - val_loss: 1.0099 - val_accuracy: 0.5124\n",
      "Epoch 177/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9688 - accuracy: 0.5330 - val_loss: 1.0088 - val_accuracy: 0.5133\n",
      "Epoch 178/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9677 - accuracy: 0.5332 - val_loss: 1.0083 - val_accuracy: 0.5147\n",
      "Epoch 179/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9676 - accuracy: 0.5324 - val_loss: 1.0070 - val_accuracy: 0.5188\n",
      "Epoch 180/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9678 - accuracy: 0.5331 - val_loss: 1.0070 - val_accuracy: 0.5147\n",
      "Epoch 181/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9683 - accuracy: 0.5320 - val_loss: 1.0085 - val_accuracy: 0.5152\n",
      "Epoch 182/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9688 - accuracy: 0.5313 - val_loss: 1.0080 - val_accuracy: 0.5152\n",
      "Epoch 183/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9685 - accuracy: 0.5319 - val_loss: 1.0074 - val_accuracy: 0.5133\n",
      "Epoch 184/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9679 - accuracy: 0.5321 - val_loss: 1.0076 - val_accuracy: 0.5216\n",
      "Epoch 185/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9673 - accuracy: 0.5334 - val_loss: 1.0062 - val_accuracy: 0.5184\n",
      "Epoch 186/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9672 - accuracy: 0.5327 - val_loss: 1.0091 - val_accuracy: 0.5170\n",
      "Epoch 187/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9677 - accuracy: 0.5319 - val_loss: 1.0089 - val_accuracy: 0.5101\n",
      "Epoch 188/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9673 - accuracy: 0.5326 - val_loss: 1.0083 - val_accuracy: 0.5202\n",
      "Epoch 189/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9672 - accuracy: 0.5331 - val_loss: 1.0076 - val_accuracy: 0.5188\n",
      "Epoch 190/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9674 - accuracy: 0.5321 - val_loss: 1.0081 - val_accuracy: 0.5110\n",
      "Epoch 191/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9676 - accuracy: 0.5329 - val_loss: 1.0097 - val_accuracy: 0.5147\n",
      "Epoch 192/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9674 - accuracy: 0.5324 - val_loss: 1.0090 - val_accuracy: 0.5175\n",
      "Epoch 193/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9678 - accuracy: 0.5327 - val_loss: 1.0078 - val_accuracy: 0.5152\n",
      "Epoch 194/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9667 - accuracy: 0.5320 - val_loss: 1.0078 - val_accuracy: 0.5124\n",
      "Epoch 195/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9680 - accuracy: 0.5322 - val_loss: 1.0082 - val_accuracy: 0.5188\n",
      "Epoch 196/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9671 - accuracy: 0.5320 - val_loss: 1.0075 - val_accuracy: 0.5175\n",
      "Epoch 197/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9675 - accuracy: 0.5322 - val_loss: 1.0091 - val_accuracy: 0.5110\n",
      "Epoch 198/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9668 - accuracy: 0.5320 - val_loss: 1.0084 - val_accuracy: 0.5184\n",
      "Epoch 199/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9670 - accuracy: 0.5352 - val_loss: 1.0067 - val_accuracy: 0.5198\n",
      "Epoch 200/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9663 - accuracy: 0.5346 - val_loss: 1.0103 - val_accuracy: 0.5069\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 365us/step - loss: 0.9670 - accuracy: 0.5288\n",
      "Accuracy : 0.5288230776786804\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 1.0103 - accuracy: 0.5069\n",
      "Accuracy : 0.5068933963775635\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.0622 - accuracy: 0.4532 - val_loss: 1.0525 - val_accuracy: 0.4600\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 0s 823us/step - loss: 1.0411 - accuracy: 0.4639 - val_loss: 1.0376 - val_accuracy: 0.4747\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 1.0190 - accuracy: 0.5016 - val_loss: 1.0196 - val_accuracy: 0.4922\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 1.0028 - accuracy: 0.5146 - val_loss: 1.0158 - val_accuracy: 0.4945\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9949 - accuracy: 0.5194 - val_loss: 1.0119 - val_accuracy: 0.5005\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9899 - accuracy: 0.5174 - val_loss: 1.0129 - val_accuracy: 0.4917\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9858 - accuracy: 0.5206 - val_loss: 1.0081 - val_accuracy: 0.5014\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9848 - accuracy: 0.5223 - val_loss: 1.0099 - val_accuracy: 0.5028\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9827 - accuracy: 0.5222 - val_loss: 1.0093 - val_accuracy: 0.4986\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9819 - accuracy: 0.5218 - val_loss: 1.0092 - val_accuracy: 0.4959\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9812 - accuracy: 0.5222 - val_loss: 1.0074 - val_accuracy: 0.5069\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9803 - accuracy: 0.5235 - val_loss: 1.0040 - val_accuracy: 0.4972\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9785 - accuracy: 0.5252 - val_loss: 1.0068 - val_accuracy: 0.4995\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9797 - accuracy: 0.5254 - val_loss: 1.0037 - val_accuracy: 0.5097\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9789 - accuracy: 0.5261 - val_loss: 1.0061 - val_accuracy: 0.4995\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 0s 804us/step - loss: 0.9789 - accuracy: 0.5271 - val_loss: 1.0027 - val_accuracy: 0.5005\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9774 - accuracy: 0.5281 - val_loss: 1.0052 - val_accuracy: 0.5106\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 808us/step - loss: 0.9773 - accuracy: 0.5270 - val_loss: 1.0070 - val_accuracy: 0.5092\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9772 - accuracy: 0.5277 - val_loss: 1.0069 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9773 - accuracy: 0.5275 - val_loss: 1.0080 - val_accuracy: 0.5028\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9773 - accuracy: 0.5281 - val_loss: 1.0048 - val_accuracy: 0.5083\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9767 - accuracy: 0.5271 - val_loss: 1.0054 - val_accuracy: 0.5087\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 0s 818us/step - loss: 0.9786 - accuracy: 0.5260 - val_loss: 1.0067 - val_accuracy: 0.5101\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9775 - accuracy: 0.5261 - val_loss: 1.0059 - val_accuracy: 0.5005\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9759 - accuracy: 0.5303 - val_loss: 1.0058 - val_accuracy: 0.5028\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9755 - accuracy: 0.5290 - val_loss: 1.0055 - val_accuracy: 0.5092\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9759 - accuracy: 0.5282 - val_loss: 1.0081 - val_accuracy: 0.5101\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9762 - accuracy: 0.5278 - val_loss: 1.0042 - val_accuracy: 0.5092\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9747 - accuracy: 0.5309 - val_loss: 1.0052 - val_accuracy: 0.5078\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9756 - accuracy: 0.5290 - val_loss: 1.0098 - val_accuracy: 0.5046\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9747 - accuracy: 0.5283 - val_loss: 1.0053 - val_accuracy: 0.5078\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 1.0036 - val_accuracy: 0.5078\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9737 - accuracy: 0.5311 - val_loss: 1.0037 - val_accuracy: 0.5078\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9755 - accuracy: 0.5280 - val_loss: 1.0063 - val_accuracy: 0.5028\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9746 - accuracy: 0.5298 - val_loss: 1.0057 - val_accuracy: 0.5069\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9751 - accuracy: 0.5274 - val_loss: 1.0044 - val_accuracy: 0.5083\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9747 - accuracy: 0.5301 - val_loss: 1.0041 - val_accuracy: 0.5101\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9743 - accuracy: 0.5301 - val_loss: 1.0058 - val_accuracy: 0.5055\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9746 - accuracy: 0.5288 - val_loss: 1.0040 - val_accuracy: 0.5133\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9741 - accuracy: 0.5292 - val_loss: 1.0029 - val_accuracy: 0.5115\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9739 - accuracy: 0.5313 - val_loss: 1.0043 - val_accuracy: 0.5014\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9732 - accuracy: 0.5300 - val_loss: 1.0060 - val_accuracy: 0.5101\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 0s 776us/step - loss: 0.9738 - accuracy: 0.5308 - val_loss: 1.0065 - val_accuracy: 0.5078\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 1.0044 - val_accuracy: 0.5064\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9735 - accuracy: 0.5317 - val_loss: 1.0067 - val_accuracy: 0.5051\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9739 - accuracy: 0.5291 - val_loss: 1.0043 - val_accuracy: 0.5087\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9733 - accuracy: 0.5284 - val_loss: 1.0055 - val_accuracy: 0.5092\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9734 - accuracy: 0.5296 - val_loss: 1.0049 - val_accuracy: 0.5060\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9737 - accuracy: 0.5294 - val_loss: 1.0071 - val_accuracy: 0.5046\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9730 - accuracy: 0.5331 - val_loss: 1.0042 - val_accuracy: 0.5032\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 0s 823us/step - loss: 0.9735 - accuracy: 0.5299 - val_loss: 1.0070 - val_accuracy: 0.5014\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 1.0054 - val_accuracy: 0.5055\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9738 - accuracy: 0.5311 - val_loss: 1.0047 - val_accuracy: 0.5018\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9722 - accuracy: 0.5319 - val_loss: 1.0033 - val_accuracy: 0.5092\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9727 - accuracy: 0.5315 - val_loss: 1.0048 - val_accuracy: 0.5032\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9731 - accuracy: 0.5309 - val_loss: 1.0048 - val_accuracy: 0.5074\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9726 - accuracy: 0.5317 - val_loss: 1.0078 - val_accuracy: 0.5023\n",
      "Epoch 58/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9725 - accuracy: 0.5322 - val_loss: 1.0063 - val_accuracy: 0.5106\n",
      "Epoch 59/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9722 - accuracy: 0.5292 - val_loss: 1.0040 - val_accuracy: 0.5097\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9733 - accuracy: 0.5310 - val_loss: 1.0073 - val_accuracy: 0.5037\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9732 - accuracy: 0.5315 - val_loss: 1.0044 - val_accuracy: 0.5101\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9732 - accuracy: 0.5303 - val_loss: 1.0063 - val_accuracy: 0.5041\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9729 - accuracy: 0.5307 - val_loss: 1.0066 - val_accuracy: 0.5074\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9727 - accuracy: 0.5294 - val_loss: 1.0047 - val_accuracy: 0.5097\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 0s 831us/step - loss: 0.9724 - accuracy: 0.5312 - val_loss: 1.0042 - val_accuracy: 0.5060\n",
      "Epoch 66/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9714 - accuracy: 0.5304 - val_loss: 1.0048 - val_accuracy: 0.5018\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9722 - accuracy: 0.5304 - val_loss: 1.0034 - val_accuracy: 0.5119\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9722 - accuracy: 0.5302 - val_loss: 1.0058 - val_accuracy: 0.5092\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9715 - accuracy: 0.5326 - val_loss: 1.0060 - val_accuracy: 0.5087\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9716 - accuracy: 0.5308 - val_loss: 1.0048 - val_accuracy: 0.5055\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9727 - accuracy: 0.5314 - val_loss: 1.0053 - val_accuracy: 0.5101\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9719 - accuracy: 0.5306 - val_loss: 1.0041 - val_accuracy: 0.5119\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9714 - accuracy: 0.5338 - val_loss: 1.0074 - val_accuracy: 0.4959\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 0s 831us/step - loss: 0.9715 - accuracy: 0.5325 - val_loss: 1.0066 - val_accuracy: 0.5074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "89/89 [==============================] - 0s 847us/step - loss: 0.9741 - accuracy: 0.5316 - val_loss: 1.0071 - val_accuracy: 0.5124\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9726 - accuracy: 0.5311 - val_loss: 1.0062 - val_accuracy: 0.5064\n",
      "Epoch 77/200\n",
      "89/89 [==============================] - 0s 853us/step - loss: 0.9714 - accuracy: 0.5327 - val_loss: 1.0052 - val_accuracy: 0.5101\n",
      "Epoch 78/200\n",
      "89/89 [==============================] - 0s 869us/step - loss: 0.9713 - accuracy: 0.5316 - val_loss: 1.0068 - val_accuracy: 0.5087\n",
      "Epoch 79/200\n",
      "89/89 [==============================] - 0s 900us/step - loss: 0.9723 - accuracy: 0.5321 - val_loss: 1.0064 - val_accuracy: 0.5092\n",
      "Epoch 80/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9718 - accuracy: 0.5344 - val_loss: 1.0040 - val_accuracy: 0.5037\n",
      "Epoch 81/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9717 - accuracy: 0.5331 - val_loss: 1.0041 - val_accuracy: 0.5087\n",
      "Epoch 82/200\n",
      "89/89 [==============================] - 0s 814us/step - loss: 0.9718 - accuracy: 0.5319 - val_loss: 1.0065 - val_accuracy: 0.5106\n",
      "Epoch 83/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9717 - accuracy: 0.5321 - val_loss: 1.0026 - val_accuracy: 0.5087\n",
      "Epoch 84/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9728 - accuracy: 0.5298 - val_loss: 1.0035 - val_accuracy: 0.5133\n",
      "Epoch 85/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9721 - accuracy: 0.5306 - val_loss: 1.0074 - val_accuracy: 0.5064\n",
      "Epoch 86/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9713 - accuracy: 0.5310 - val_loss: 1.0068 - val_accuracy: 0.5092\n",
      "Epoch 87/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9714 - accuracy: 0.5332 - val_loss: 1.0109 - val_accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9715 - accuracy: 0.5311 - val_loss: 1.0061 - val_accuracy: 0.5064\n",
      "Epoch 89/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9727 - accuracy: 0.5331 - val_loss: 1.0057 - val_accuracy: 0.5055\n",
      "Epoch 90/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9721 - accuracy: 0.5331 - val_loss: 1.0041 - val_accuracy: 0.5074\n",
      "Epoch 91/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9715 - accuracy: 0.5324 - val_loss: 1.0048 - val_accuracy: 0.5078\n",
      "Epoch 92/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9716 - accuracy: 0.5305 - val_loss: 1.0050 - val_accuracy: 0.5092\n",
      "Epoch 93/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9716 - accuracy: 0.5272 - val_loss: 1.0051 - val_accuracy: 0.5083\n",
      "Epoch 94/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9711 - accuracy: 0.5322 - val_loss: 1.0068 - val_accuracy: 0.5041\n",
      "Epoch 95/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9712 - accuracy: 0.5315 - val_loss: 1.0058 - val_accuracy: 0.5083\n",
      "Epoch 96/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9706 - accuracy: 0.5323 - val_loss: 1.0079 - val_accuracy: 0.5074\n",
      "Epoch 97/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9720 - accuracy: 0.5318 - val_loss: 1.0037 - val_accuracy: 0.5101\n",
      "Epoch 98/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9711 - accuracy: 0.5333 - val_loss: 1.0076 - val_accuracy: 0.5023\n",
      "Epoch 99/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9718 - accuracy: 0.5318 - val_loss: 1.0048 - val_accuracy: 0.5087\n",
      "Epoch 100/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9713 - accuracy: 0.5312 - val_loss: 1.0047 - val_accuracy: 0.5064\n",
      "Epoch 101/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9710 - accuracy: 0.5330 - val_loss: 1.0048 - val_accuracy: 0.5060\n",
      "Epoch 102/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9710 - accuracy: 0.5320 - val_loss: 1.0044 - val_accuracy: 0.5129\n",
      "Epoch 103/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9710 - accuracy: 0.5335 - val_loss: 1.0042 - val_accuracy: 0.5078\n",
      "Epoch 104/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9712 - accuracy: 0.5326 - val_loss: 1.0045 - val_accuracy: 0.5060\n",
      "Epoch 105/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9706 - accuracy: 0.5326 - val_loss: 1.0075 - val_accuracy: 0.5037\n",
      "Epoch 106/200\n",
      "89/89 [==============================] - 0s 877us/step - loss: 0.9707 - accuracy: 0.5338 - val_loss: 1.0056 - val_accuracy: 0.5018\n",
      "Epoch 107/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9712 - accuracy: 0.5334 - val_loss: 1.0058 - val_accuracy: 0.5101\n",
      "Epoch 108/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9707 - accuracy: 0.5328 - val_loss: 1.0069 - val_accuracy: 0.4977\n",
      "Epoch 109/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9710 - accuracy: 0.5321 - val_loss: 1.0061 - val_accuracy: 0.5129\n",
      "Epoch 110/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9713 - accuracy: 0.5322 - val_loss: 1.0058 - val_accuracy: 0.5060\n",
      "Epoch 111/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9715 - accuracy: 0.5321 - val_loss: 1.0063 - val_accuracy: 0.5097\n",
      "Epoch 112/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9708 - accuracy: 0.5301 - val_loss: 1.0044 - val_accuracy: 0.5110\n",
      "Epoch 113/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9704 - accuracy: 0.5324 - val_loss: 1.0051 - val_accuracy: 0.5074\n",
      "Epoch 114/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9705 - accuracy: 0.5336 - val_loss: 1.0089 - val_accuracy: 0.5101\n",
      "Epoch 115/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9706 - accuracy: 0.5333 - val_loss: 1.0070 - val_accuracy: 0.5051\n",
      "Epoch 116/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9701 - accuracy: 0.5331 - val_loss: 1.0090 - val_accuracy: 0.5064\n",
      "Epoch 117/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9713 - accuracy: 0.5319 - val_loss: 1.0069 - val_accuracy: 0.5064\n",
      "Epoch 118/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9716 - accuracy: 0.5313 - val_loss: 1.0063 - val_accuracy: 0.5097\n",
      "Epoch 119/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9700 - accuracy: 0.5335 - val_loss: 1.0062 - val_accuracy: 0.5092\n",
      "Epoch 120/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9710 - accuracy: 0.5322 - val_loss: 1.0082 - val_accuracy: 0.5087\n",
      "Epoch 121/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9708 - accuracy: 0.5338 - val_loss: 1.0054 - val_accuracy: 0.5078\n",
      "Epoch 122/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9703 - accuracy: 0.5315 - val_loss: 1.0058 - val_accuracy: 0.5087\n",
      "Epoch 123/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9707 - accuracy: 0.5337 - val_loss: 1.0090 - val_accuracy: 0.5060\n",
      "Epoch 124/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9720 - accuracy: 0.5308 - val_loss: 1.0063 - val_accuracy: 0.5028\n",
      "Epoch 125/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9702 - accuracy: 0.5334 - val_loss: 1.0073 - val_accuracy: 0.5046\n",
      "Epoch 126/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9703 - accuracy: 0.5333 - val_loss: 1.0040 - val_accuracy: 0.5124\n",
      "Epoch 127/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9699 - accuracy: 0.5328 - val_loss: 1.0068 - val_accuracy: 0.5087\n",
      "Epoch 128/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9707 - accuracy: 0.5320 - val_loss: 1.0045 - val_accuracy: 0.5074\n",
      "Epoch 129/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9707 - accuracy: 0.5313 - val_loss: 1.0064 - val_accuracy: 0.5106\n",
      "Epoch 130/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9699 - accuracy: 0.5323 - val_loss: 1.0060 - val_accuracy: 0.5060\n",
      "Epoch 131/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9717 - accuracy: 0.5308 - val_loss: 1.0063 - val_accuracy: 0.5119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9704 - accuracy: 0.5317 - val_loss: 1.0094 - val_accuracy: 0.5069\n",
      "Epoch 133/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9698 - accuracy: 0.5330 - val_loss: 1.0058 - val_accuracy: 0.5087\n",
      "Epoch 134/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9697 - accuracy: 0.5335 - val_loss: 1.0042 - val_accuracy: 0.5124\n",
      "Epoch 135/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9702 - accuracy: 0.5348 - val_loss: 1.0060 - val_accuracy: 0.5115\n",
      "Epoch 136/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9705 - accuracy: 0.5324 - val_loss: 1.0049 - val_accuracy: 0.5069\n",
      "Epoch 137/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9702 - accuracy: 0.5317 - val_loss: 1.0067 - val_accuracy: 0.5051\n",
      "Epoch 138/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9700 - accuracy: 0.5328 - val_loss: 1.0074 - val_accuracy: 0.5083\n",
      "Epoch 139/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9703 - accuracy: 0.5312 - val_loss: 1.0068 - val_accuracy: 0.5092\n",
      "Epoch 140/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9698 - accuracy: 0.5335 - val_loss: 1.0077 - val_accuracy: 0.5060\n",
      "Epoch 141/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9697 - accuracy: 0.5327 - val_loss: 1.0055 - val_accuracy: 0.5069\n",
      "Epoch 142/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9701 - accuracy: 0.5331 - val_loss: 1.0090 - val_accuracy: 0.5078\n",
      "Epoch 143/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9705 - accuracy: 0.5336 - val_loss: 1.0055 - val_accuracy: 0.5097\n",
      "Epoch 144/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9707 - accuracy: 0.5325 - val_loss: 1.0076 - val_accuracy: 0.5074\n",
      "Epoch 145/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9698 - accuracy: 0.5337 - val_loss: 1.0054 - val_accuracy: 0.5083\n",
      "Epoch 146/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9697 - accuracy: 0.5324 - val_loss: 1.0073 - val_accuracy: 0.5014\n",
      "Epoch 147/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9701 - accuracy: 0.5320 - val_loss: 1.0086 - val_accuracy: 0.4991\n",
      "Epoch 148/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9711 - accuracy: 0.5321 - val_loss: 1.0054 - val_accuracy: 0.5032\n",
      "Epoch 149/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9694 - accuracy: 0.5335 - val_loss: 1.0057 - val_accuracy: 0.5106\n",
      "Epoch 150/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9705 - accuracy: 0.5322 - val_loss: 1.0043 - val_accuracy: 0.5119\n",
      "Epoch 151/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9695 - accuracy: 0.5332 - val_loss: 1.0064 - val_accuracy: 0.5087\n",
      "Epoch 152/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9694 - accuracy: 0.5324 - val_loss: 1.0053 - val_accuracy: 0.5078\n",
      "Epoch 153/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9700 - accuracy: 0.5326 - val_loss: 1.0059 - val_accuracy: 0.5110\n",
      "Epoch 154/200\n",
      "89/89 [==============================] - 0s 795us/step - loss: 0.9704 - accuracy: 0.5311 - val_loss: 1.0062 - val_accuracy: 0.5060\n",
      "Epoch 155/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9698 - accuracy: 0.5325 - val_loss: 1.0091 - val_accuracy: 0.5014\n",
      "Epoch 156/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9696 - accuracy: 0.5328 - val_loss: 1.0045 - val_accuracy: 0.5087\n",
      "Epoch 157/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9695 - accuracy: 0.5341 - val_loss: 1.0051 - val_accuracy: 0.5097\n",
      "Epoch 158/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9697 - accuracy: 0.5324 - val_loss: 1.0089 - val_accuracy: 0.5069\n",
      "Epoch 159/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9699 - accuracy: 0.5354 - val_loss: 1.0086 - val_accuracy: 0.5032\n",
      "Epoch 160/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9693 - accuracy: 0.5352 - val_loss: 1.0062 - val_accuracy: 0.5037\n",
      "Epoch 161/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9694 - accuracy: 0.5342 - val_loss: 1.0063 - val_accuracy: 0.5078\n",
      "Epoch 162/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9707 - accuracy: 0.5295 - val_loss: 1.0046 - val_accuracy: 0.5119\n",
      "Epoch 163/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9696 - accuracy: 0.5326 - val_loss: 1.0053 - val_accuracy: 0.5092\n",
      "Epoch 164/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9703 - accuracy: 0.5332 - val_loss: 1.0066 - val_accuracy: 0.5092\n",
      "Epoch 165/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9699 - accuracy: 0.5330 - val_loss: 1.0046 - val_accuracy: 0.5133\n",
      "Epoch 166/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9692 - accuracy: 0.5342 - val_loss: 1.0055 - val_accuracy: 0.5119\n",
      "Epoch 167/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9693 - accuracy: 0.5347 - val_loss: 1.0070 - val_accuracy: 0.5041\n",
      "Epoch 168/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9706 - accuracy: 0.5330 - val_loss: 1.0062 - val_accuracy: 0.5101\n",
      "Epoch 169/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9694 - accuracy: 0.5313 - val_loss: 1.0085 - val_accuracy: 0.5014\n",
      "Epoch 170/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9686 - accuracy: 0.5337 - val_loss: 1.0077 - val_accuracy: 0.5074\n",
      "Epoch 171/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9698 - accuracy: 0.5327 - val_loss: 1.0058 - val_accuracy: 0.5087\n",
      "Epoch 172/200\n",
      "89/89 [==============================] - 0s 825us/step - loss: 0.9688 - accuracy: 0.5330 - val_loss: 1.0058 - val_accuracy: 0.5074\n",
      "Epoch 173/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9695 - accuracy: 0.5362 - val_loss: 1.0067 - val_accuracy: 0.5018\n",
      "Epoch 174/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9698 - accuracy: 0.5337 - val_loss: 1.0077 - val_accuracy: 0.5101\n",
      "Epoch 175/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9686 - accuracy: 0.5331 - val_loss: 1.0054 - val_accuracy: 0.5060\n",
      "Epoch 176/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9688 - accuracy: 0.5338 - val_loss: 1.0073 - val_accuracy: 0.5087\n",
      "Epoch 177/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9692 - accuracy: 0.5327 - val_loss: 1.0059 - val_accuracy: 0.5069\n",
      "Epoch 178/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9696 - accuracy: 0.5325 - val_loss: 1.0074 - val_accuracy: 0.5097\n",
      "Epoch 179/200\n",
      "89/89 [==============================] - 0s 836us/step - loss: 0.9691 - accuracy: 0.5323 - val_loss: 1.0085 - val_accuracy: 0.5097\n",
      "Epoch 180/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9701 - accuracy: 0.5351 - val_loss: 1.0081 - val_accuracy: 0.5014\n",
      "Epoch 181/200\n",
      "89/89 [==============================] - 0s 825us/step - loss: 0.9693 - accuracy: 0.5330 - val_loss: 1.0066 - val_accuracy: 0.5051\n",
      "Epoch 182/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9696 - accuracy: 0.5327 - val_loss: 1.0052 - val_accuracy: 0.5092\n",
      "Epoch 183/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9689 - accuracy: 0.5336 - val_loss: 1.0066 - val_accuracy: 0.5092\n",
      "Epoch 184/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9697 - accuracy: 0.5334 - val_loss: 1.0070 - val_accuracy: 0.5115\n",
      "Epoch 185/200\n",
      "89/89 [==============================] - 0s 831us/step - loss: 0.9696 - accuracy: 0.5324 - val_loss: 1.0058 - val_accuracy: 0.5101\n",
      "Epoch 186/200\n",
      "89/89 [==============================] - 0s 846us/step - loss: 0.9700 - accuracy: 0.5331 - val_loss: 1.0109 - val_accuracy: 0.5051\n",
      "Epoch 187/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9700 - accuracy: 0.5340 - val_loss: 1.0080 - val_accuracy: 0.5092\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 858us/step - loss: 0.9694 - accuracy: 0.5321 - val_loss: 1.0076 - val_accuracy: 0.5083\n",
      "Epoch 189/200\n",
      "89/89 [==============================] - 0s 839us/step - loss: 0.9691 - accuracy: 0.5334 - val_loss: 1.0058 - val_accuracy: 0.5097\n",
      "Epoch 190/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9692 - accuracy: 0.5333 - val_loss: 1.0072 - val_accuracy: 0.5115\n",
      "Epoch 191/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9704 - accuracy: 0.5346 - val_loss: 1.0078 - val_accuracy: 0.5078\n",
      "Epoch 192/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9695 - accuracy: 0.5327 - val_loss: 1.0093 - val_accuracy: 0.5092\n",
      "Epoch 193/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9693 - accuracy: 0.5336 - val_loss: 1.0061 - val_accuracy: 0.5087\n",
      "Epoch 194/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9685 - accuracy: 0.5345 - val_loss: 1.0066 - val_accuracy: 0.5124\n",
      "Epoch 195/200\n",
      "89/89 [==============================] - 0s 846us/step - loss: 0.9687 - accuracy: 0.5329 - val_loss: 1.0062 - val_accuracy: 0.5106\n",
      "Epoch 196/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9683 - accuracy: 0.5339 - val_loss: 1.0057 - val_accuracy: 0.5101\n",
      "Epoch 197/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9698 - accuracy: 0.5339 - val_loss: 1.0059 - val_accuracy: 0.5101\n",
      "Epoch 198/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9685 - accuracy: 0.5349 - val_loss: 1.0067 - val_accuracy: 0.5092\n",
      "Epoch 199/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9693 - accuracy: 0.5324 - val_loss: 1.0074 - val_accuracy: 0.5119\n",
      "Epoch 200/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9694 - accuracy: 0.5342 - val_loss: 1.0130 - val_accuracy: 0.4982\n",
      "\n",
      "Train split:\n",
      "  1/613 [..............................] - ETA: 0s - loss: 1.0862 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "613/613 [==============================] - 0s 374us/step - loss: 0.9724 - accuracy: 0.5273\n",
      "Accuracy : 0.5273423790931702\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 1.0130 - accuracy: 0.4982\n",
      "Accuracy : 0.49816176295280457\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.0582 - accuracy: 0.4600 - val_loss: 1.0529 - val_accuracy: 0.4600\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 1.0391 - accuracy: 0.4600 - val_loss: 1.0322 - val_accuracy: 0.4697\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 1.0095 - accuracy: 0.5083 - val_loss: 1.0088 - val_accuracy: 0.5078\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9921 - accuracy: 0.5189 - val_loss: 1.0085 - val_accuracy: 0.4936\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9891 - accuracy: 0.5191 - val_loss: 1.0026 - val_accuracy: 0.5005\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9852 - accuracy: 0.5216 - val_loss: 1.0098 - val_accuracy: 0.4913\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9832 - accuracy: 0.5240 - val_loss: 0.9988 - val_accuracy: 0.5188\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9822 - accuracy: 0.5252 - val_loss: 0.9988 - val_accuracy: 0.5119\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9814 - accuracy: 0.5239 - val_loss: 0.9973 - val_accuracy: 0.5119\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9812 - accuracy: 0.5235 - val_loss: 1.0007 - val_accuracy: 0.5055\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9805 - accuracy: 0.5275 - val_loss: 0.9982 - val_accuracy: 0.5069\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9793 - accuracy: 0.5272 - val_loss: 0.9971 - val_accuracy: 0.5138\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9807 - accuracy: 0.5249 - val_loss: 0.9958 - val_accuracy: 0.5101\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9800 - accuracy: 0.5253 - val_loss: 0.9937 - val_accuracy: 0.5184\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9789 - accuracy: 0.5242 - val_loss: 0.9938 - val_accuracy: 0.5152\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 0s 784us/step - loss: 0.9791 - accuracy: 0.5251 - val_loss: 0.9934 - val_accuracy: 0.5124\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9786 - accuracy: 0.5271 - val_loss: 0.9974 - val_accuracy: 0.5037\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9772 - accuracy: 0.5294 - val_loss: 0.9937 - val_accuracy: 0.5138\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9788 - accuracy: 0.5267 - val_loss: 0.9952 - val_accuracy: 0.5119\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 0s 771us/step - loss: 0.9777 - accuracy: 0.5280 - val_loss: 0.9928 - val_accuracy: 0.5161\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9768 - accuracy: 0.5297 - val_loss: 0.9947 - val_accuracy: 0.5133\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9778 - accuracy: 0.5263 - val_loss: 0.9933 - val_accuracy: 0.5138\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9777 - accuracy: 0.5283 - val_loss: 0.9939 - val_accuracy: 0.5147\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9771 - accuracy: 0.5269 - val_loss: 0.9944 - val_accuracy: 0.5133\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9765 - accuracy: 0.5300 - val_loss: 0.9960 - val_accuracy: 0.5152\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9975 - val_accuracy: 0.5184\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9789 - accuracy: 0.5261 - val_loss: 0.9934 - val_accuracy: 0.5184\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9757 - accuracy: 0.5287 - val_loss: 0.9941 - val_accuracy: 0.5198\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9761 - accuracy: 0.5300 - val_loss: 0.9928 - val_accuracy: 0.5179\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9754 - accuracy: 0.5302 - val_loss: 0.9955 - val_accuracy: 0.5124\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9767 - accuracy: 0.5307 - val_loss: 0.9968 - val_accuracy: 0.5110\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9756 - accuracy: 0.5289 - val_loss: 0.9977 - val_accuracy: 0.5087\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9758 - accuracy: 0.5307 - val_loss: 0.9948 - val_accuracy: 0.5156\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 0.9977 - val_accuracy: 0.5106\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9743 - accuracy: 0.5322 - val_loss: 0.9929 - val_accuracy: 0.5225\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 0s 789us/step - loss: 0.9749 - accuracy: 0.5311 - val_loss: 0.9977 - val_accuracy: 0.5207\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9764 - accuracy: 0.5297 - val_loss: 0.9949 - val_accuracy: 0.5198\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9932 - val_accuracy: 0.5156\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9745 - accuracy: 0.5312 - val_loss: 0.9958 - val_accuracy: 0.5115\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9742 - accuracy: 0.5305 - val_loss: 0.9998 - val_accuracy: 0.5129\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 794us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 0.9977 - val_accuracy: 0.5064\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9738 - accuracy: 0.5296 - val_loss: 0.9928 - val_accuracy: 0.5225\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9753 - accuracy: 0.5307 - val_loss: 0.9947 - val_accuracy: 0.5175\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9739 - accuracy: 0.5311 - val_loss: 0.9946 - val_accuracy: 0.5124\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9739 - accuracy: 0.5316 - val_loss: 0.9938 - val_accuracy: 0.5193\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9744 - accuracy: 0.5318 - val_loss: 0.9942 - val_accuracy: 0.5142\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9741 - accuracy: 0.5316 - val_loss: 0.9953 - val_accuracy: 0.5142\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9931 - val_accuracy: 0.5179\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9747 - accuracy: 0.5308 - val_loss: 0.9936 - val_accuracy: 0.5110\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 0s 753us/step - loss: 0.9741 - accuracy: 0.5305 - val_loss: 0.9941 - val_accuracy: 0.5124\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 0s 872us/step - loss: 0.9731 - accuracy: 0.5328 - val_loss: 0.9936 - val_accuracy: 0.5193\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9735 - accuracy: 0.5319 - val_loss: 0.9950 - val_accuracy: 0.5179\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9749 - accuracy: 0.5287 - val_loss: 0.9945 - val_accuracy: 0.5078\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 0.9951 - val_accuracy: 0.5188\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9747 - accuracy: 0.5295 - val_loss: 0.9956 - val_accuracy: 0.5046\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 0s 793us/step - loss: 0.9732 - accuracy: 0.5319 - val_loss: 0.9931 - val_accuracy: 0.5147\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9937 - val_accuracy: 0.5216\n",
      "Epoch 58/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9740 - accuracy: 0.5310 - val_loss: 0.9921 - val_accuracy: 0.5124\n",
      "Epoch 59/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9732 - accuracy: 0.5313 - val_loss: 0.9921 - val_accuracy: 0.5225\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 0s 833us/step - loss: 0.9742 - accuracy: 0.5289 - val_loss: 0.9961 - val_accuracy: 0.5221\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9745 - accuracy: 0.5302 - val_loss: 0.9924 - val_accuracy: 0.5198\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9738 - accuracy: 0.5321 - val_loss: 0.9955 - val_accuracy: 0.5101\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 0s 789us/step - loss: 0.9729 - accuracy: 0.5322 - val_loss: 0.9937 - val_accuracy: 0.5152\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9733 - accuracy: 0.5333 - val_loss: 0.9970 - val_accuracy: 0.5087\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9736 - accuracy: 0.5322 - val_loss: 0.9921 - val_accuracy: 0.5207\n",
      "Epoch 66/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9733 - accuracy: 0.5308 - val_loss: 0.9985 - val_accuracy: 0.5028\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9747 - accuracy: 0.5306 - val_loss: 0.9940 - val_accuracy: 0.5175\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9733 - accuracy: 0.5313 - val_loss: 0.9923 - val_accuracy: 0.5244\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9732 - accuracy: 0.5296 - val_loss: 0.9941 - val_accuracy: 0.5106\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9734 - accuracy: 0.5326 - val_loss: 0.9919 - val_accuracy: 0.5221\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9729 - accuracy: 0.5315 - val_loss: 0.9929 - val_accuracy: 0.5198\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9725 - accuracy: 0.5332 - val_loss: 0.9910 - val_accuracy: 0.5170\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9737 - accuracy: 0.5313 - val_loss: 0.9915 - val_accuracy: 0.5175\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9729 - accuracy: 0.5314 - val_loss: 0.9927 - val_accuracy: 0.5179\n",
      "Epoch 75/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9731 - accuracy: 0.5335 - val_loss: 0.9933 - val_accuracy: 0.5165\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9919 - val_accuracy: 0.5211\n",
      "Epoch 77/200\n",
      "89/89 [==============================] - 0s 793us/step - loss: 0.9723 - accuracy: 0.5321 - val_loss: 0.9910 - val_accuracy: 0.5184\n",
      "Epoch 78/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9723 - accuracy: 0.5347 - val_loss: 0.9897 - val_accuracy: 0.5267\n",
      "Epoch 79/200\n",
      "89/89 [==============================] - 0s 834us/step - loss: 0.9727 - accuracy: 0.5325 - val_loss: 0.9896 - val_accuracy: 0.5211\n",
      "Epoch 80/200\n",
      "89/89 [==============================] - 0s 846us/step - loss: 0.9725 - accuracy: 0.5314 - val_loss: 0.9919 - val_accuracy: 0.5188\n",
      "Epoch 81/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9728 - accuracy: 0.5320 - val_loss: 0.9922 - val_accuracy: 0.5165\n",
      "Epoch 82/200\n",
      "89/89 [==============================] - 0s 842us/step - loss: 0.9727 - accuracy: 0.5325 - val_loss: 0.9917 - val_accuracy: 0.5248\n",
      "Epoch 83/200\n",
      "89/89 [==============================] - 0s 849us/step - loss: 0.9730 - accuracy: 0.5311 - val_loss: 0.9916 - val_accuracy: 0.5138\n",
      "Epoch 84/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9724 - accuracy: 0.5311 - val_loss: 0.9924 - val_accuracy: 0.5202\n",
      "Epoch 85/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9722 - accuracy: 0.5302 - val_loss: 0.9906 - val_accuracy: 0.5257\n",
      "Epoch 86/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9721 - accuracy: 0.5321 - val_loss: 0.9915 - val_accuracy: 0.5184\n",
      "Epoch 87/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9725 - accuracy: 0.5315 - val_loss: 0.9927 - val_accuracy: 0.5175\n",
      "Epoch 88/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9736 - accuracy: 0.5329 - val_loss: 0.9910 - val_accuracy: 0.5248\n",
      "Epoch 89/200\n",
      "89/89 [==============================] - 0s 804us/step - loss: 0.9722 - accuracy: 0.5321 - val_loss: 0.9920 - val_accuracy: 0.5211\n",
      "Epoch 90/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9723 - accuracy: 0.5338 - val_loss: 0.9922 - val_accuracy: 0.5156\n",
      "Epoch 91/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9918 - val_accuracy: 0.5184\n",
      "Epoch 92/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9733 - accuracy: 0.5304 - val_loss: 0.9927 - val_accuracy: 0.5147\n",
      "Epoch 93/200\n",
      "89/89 [==============================] - 0s 784us/step - loss: 0.9723 - accuracy: 0.5329 - val_loss: 0.9917 - val_accuracy: 0.5156\n",
      "Epoch 94/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9719 - accuracy: 0.5323 - val_loss: 0.9930 - val_accuracy: 0.5147\n",
      "Epoch 95/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9717 - accuracy: 0.5326 - val_loss: 0.9907 - val_accuracy: 0.5225\n",
      "Epoch 96/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9727 - accuracy: 0.5303 - val_loss: 0.9929 - val_accuracy: 0.5193\n",
      "Epoch 97/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9721 - accuracy: 0.5324 - val_loss: 0.9907 - val_accuracy: 0.5188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9723 - accuracy: 0.5350 - val_loss: 0.9901 - val_accuracy: 0.5221\n",
      "Epoch 99/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9725 - accuracy: 0.5322 - val_loss: 0.9926 - val_accuracy: 0.5184\n",
      "Epoch 100/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9721 - accuracy: 0.5324 - val_loss: 0.9888 - val_accuracy: 0.5267\n",
      "Epoch 101/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9719 - accuracy: 0.5324 - val_loss: 0.9907 - val_accuracy: 0.5248\n",
      "Epoch 102/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9725 - accuracy: 0.5338 - val_loss: 0.9911 - val_accuracy: 0.5216\n",
      "Epoch 103/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9722 - accuracy: 0.5320 - val_loss: 0.9910 - val_accuracy: 0.5198\n",
      "Epoch 104/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9723 - accuracy: 0.5325 - val_loss: 0.9913 - val_accuracy: 0.5211\n",
      "Epoch 105/200\n",
      "89/89 [==============================] - 0s 803us/step - loss: 0.9718 - accuracy: 0.5323 - val_loss: 0.9936 - val_accuracy: 0.5119\n",
      "Epoch 106/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9722 - accuracy: 0.5315 - val_loss: 0.9906 - val_accuracy: 0.5239\n",
      "Epoch 107/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9719 - accuracy: 0.5327 - val_loss: 0.9905 - val_accuracy: 0.5119\n",
      "Epoch 108/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9724 - accuracy: 0.5353 - val_loss: 0.9918 - val_accuracy: 0.5221\n",
      "Epoch 109/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9721 - accuracy: 0.5333 - val_loss: 0.9953 - val_accuracy: 0.5106\n",
      "Epoch 110/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9727 - accuracy: 0.5324 - val_loss: 0.9930 - val_accuracy: 0.5198\n",
      "Epoch 111/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9718 - accuracy: 0.5311 - val_loss: 0.9924 - val_accuracy: 0.5106\n",
      "Epoch 112/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9718 - accuracy: 0.5332 - val_loss: 0.9925 - val_accuracy: 0.5147\n",
      "Epoch 113/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9723 - accuracy: 0.5337 - val_loss: 0.9908 - val_accuracy: 0.5198\n",
      "Epoch 114/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9713 - accuracy: 0.5341 - val_loss: 0.9929 - val_accuracy: 0.5216\n",
      "Epoch 115/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9721 - accuracy: 0.5311 - val_loss: 0.9929 - val_accuracy: 0.5152\n",
      "Epoch 116/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9709 - accuracy: 0.5322 - val_loss: 0.9910 - val_accuracy: 0.5216\n",
      "Epoch 117/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9721 - accuracy: 0.5310 - val_loss: 0.9917 - val_accuracy: 0.5184\n",
      "Epoch 118/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9719 - accuracy: 0.5333 - val_loss: 0.9892 - val_accuracy: 0.5276\n",
      "Epoch 119/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9711 - accuracy: 0.5321 - val_loss: 0.9911 - val_accuracy: 0.5184\n",
      "Epoch 120/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9706 - accuracy: 0.5358 - val_loss: 0.9905 - val_accuracy: 0.5244\n",
      "Epoch 121/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9726 - accuracy: 0.5318 - val_loss: 0.9953 - val_accuracy: 0.5101\n",
      "Epoch 122/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9721 - accuracy: 0.5324 - val_loss: 0.9902 - val_accuracy: 0.5239\n",
      "Epoch 123/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9715 - accuracy: 0.5329 - val_loss: 0.9914 - val_accuracy: 0.5193\n",
      "Epoch 124/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9716 - accuracy: 0.5330 - val_loss: 0.9918 - val_accuracy: 0.5133\n",
      "Epoch 125/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9711 - accuracy: 0.5333 - val_loss: 0.9896 - val_accuracy: 0.5184\n",
      "Epoch 126/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9714 - accuracy: 0.5326 - val_loss: 0.9907 - val_accuracy: 0.5239\n",
      "Epoch 127/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9718 - accuracy: 0.5335 - val_loss: 0.9907 - val_accuracy: 0.5202\n",
      "Epoch 128/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9709 - accuracy: 0.5334 - val_loss: 0.9920 - val_accuracy: 0.5207\n",
      "Epoch 129/200\n",
      "89/89 [==============================] - 0s 836us/step - loss: 0.9726 - accuracy: 0.5341 - val_loss: 0.9918 - val_accuracy: 0.5225\n",
      "Epoch 130/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9714 - accuracy: 0.5340 - val_loss: 0.9913 - val_accuracy: 0.5225\n",
      "Epoch 131/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9711 - accuracy: 0.5326 - val_loss: 0.9919 - val_accuracy: 0.5115\n",
      "Epoch 132/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9716 - accuracy: 0.5344 - val_loss: 0.9893 - val_accuracy: 0.5179\n",
      "Epoch 133/200\n",
      "89/89 [==============================] - 0s 789us/step - loss: 0.9708 - accuracy: 0.5347 - val_loss: 0.9926 - val_accuracy: 0.5106\n",
      "Epoch 134/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9712 - accuracy: 0.5341 - val_loss: 0.9903 - val_accuracy: 0.5207\n",
      "Epoch 135/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9717 - accuracy: 0.5308 - val_loss: 0.9903 - val_accuracy: 0.5165\n",
      "Epoch 136/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9708 - accuracy: 0.5322 - val_loss: 0.9914 - val_accuracy: 0.5221\n",
      "Epoch 137/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9712 - accuracy: 0.5328 - val_loss: 0.9931 - val_accuracy: 0.5170\n",
      "Epoch 138/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9721 - accuracy: 0.5302 - val_loss: 0.9923 - val_accuracy: 0.5106\n",
      "Epoch 139/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9715 - accuracy: 0.5319 - val_loss: 0.9952 - val_accuracy: 0.5060\n",
      "Epoch 140/200\n",
      "89/89 [==============================] - 0s 795us/step - loss: 0.9711 - accuracy: 0.5337 - val_loss: 0.9905 - val_accuracy: 0.5216\n",
      "Epoch 141/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9713 - accuracy: 0.5339 - val_loss: 0.9903 - val_accuracy: 0.5262\n",
      "Epoch 142/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9701 - accuracy: 0.5335 - val_loss: 0.9902 - val_accuracy: 0.5207\n",
      "Epoch 143/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9714 - accuracy: 0.5332 - val_loss: 0.9921 - val_accuracy: 0.5165\n",
      "Epoch 144/200\n",
      "89/89 [==============================] - 0s 793us/step - loss: 0.9733 - accuracy: 0.5330 - val_loss: 0.9903 - val_accuracy: 0.5161\n",
      "Epoch 145/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9712 - accuracy: 0.5317 - val_loss: 0.9912 - val_accuracy: 0.5239\n",
      "Epoch 146/200\n",
      "89/89 [==============================] - 0s 820us/step - loss: 0.9706 - accuracy: 0.5350 - val_loss: 0.9909 - val_accuracy: 0.5248\n",
      "Epoch 147/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9706 - accuracy: 0.5319 - val_loss: 0.9899 - val_accuracy: 0.5244\n",
      "Epoch 148/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9709 - accuracy: 0.5330 - val_loss: 0.9913 - val_accuracy: 0.5170\n",
      "Epoch 149/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9719 - accuracy: 0.5325 - val_loss: 0.9909 - val_accuracy: 0.5188\n",
      "Epoch 150/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9714 - accuracy: 0.5318 - val_loss: 0.9905 - val_accuracy: 0.5216\n",
      "Epoch 151/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9707 - accuracy: 0.5324 - val_loss: 0.9934 - val_accuracy: 0.5156\n",
      "Epoch 152/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9713 - accuracy: 0.5337 - val_loss: 0.9892 - val_accuracy: 0.5175\n",
      "Epoch 153/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9707 - accuracy: 0.5332 - val_loss: 0.9918 - val_accuracy: 0.5198\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 821us/step - loss: 0.9711 - accuracy: 0.5340 - val_loss: 0.9898 - val_accuracy: 0.5193\n",
      "Epoch 155/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9711 - accuracy: 0.5337 - val_loss: 0.9934 - val_accuracy: 0.5078\n",
      "Epoch 156/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9716 - accuracy: 0.5330 - val_loss: 0.9894 - val_accuracy: 0.5271\n",
      "Epoch 157/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9704 - accuracy: 0.5335 - val_loss: 0.9902 - val_accuracy: 0.5248\n",
      "Epoch 158/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9716 - accuracy: 0.5325 - val_loss: 0.9916 - val_accuracy: 0.5184\n",
      "Epoch 159/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9710 - accuracy: 0.5330 - val_loss: 0.9911 - val_accuracy: 0.5234\n",
      "Epoch 160/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9709 - accuracy: 0.5333 - val_loss: 0.9900 - val_accuracy: 0.5193\n",
      "Epoch 161/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9708 - accuracy: 0.5339 - val_loss: 0.9914 - val_accuracy: 0.5184\n",
      "Epoch 162/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9713 - accuracy: 0.5338 - val_loss: 0.9921 - val_accuracy: 0.5142\n",
      "Epoch 163/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9706 - accuracy: 0.5320 - val_loss: 0.9964 - val_accuracy: 0.5064\n",
      "Epoch 164/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9706 - accuracy: 0.5340 - val_loss: 0.9906 - val_accuracy: 0.5253\n",
      "Epoch 165/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9704 - accuracy: 0.5339 - val_loss: 0.9959 - val_accuracy: 0.5064\n",
      "Epoch 166/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9712 - accuracy: 0.5339 - val_loss: 0.9899 - val_accuracy: 0.5239\n",
      "Epoch 167/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9714 - accuracy: 0.5338 - val_loss: 0.9897 - val_accuracy: 0.5271\n",
      "Epoch 168/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9706 - accuracy: 0.5336 - val_loss: 0.9900 - val_accuracy: 0.5216\n",
      "Epoch 169/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9705 - accuracy: 0.5345 - val_loss: 0.9935 - val_accuracy: 0.5193\n",
      "Epoch 170/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9706 - accuracy: 0.5340 - val_loss: 0.9912 - val_accuracy: 0.5225\n",
      "Epoch 171/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9701 - accuracy: 0.5332 - val_loss: 0.9907 - val_accuracy: 0.5202\n",
      "Epoch 172/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9700 - accuracy: 0.5350 - val_loss: 0.9901 - val_accuracy: 0.5184\n",
      "Epoch 173/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9711 - accuracy: 0.5342 - val_loss: 0.9910 - val_accuracy: 0.5165\n",
      "Epoch 174/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9703 - accuracy: 0.5328 - val_loss: 0.9895 - val_accuracy: 0.5216\n",
      "Epoch 175/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9708 - accuracy: 0.5322 - val_loss: 0.9928 - val_accuracy: 0.5078\n",
      "Epoch 176/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9708 - accuracy: 0.5340 - val_loss: 0.9899 - val_accuracy: 0.5257\n",
      "Epoch 177/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9708 - accuracy: 0.5327 - val_loss: 0.9893 - val_accuracy: 0.5248\n",
      "Epoch 178/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9702 - accuracy: 0.5338 - val_loss: 0.9901 - val_accuracy: 0.5179\n",
      "Epoch 179/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9703 - accuracy: 0.5316 - val_loss: 0.9907 - val_accuracy: 0.5267\n",
      "Epoch 180/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9702 - accuracy: 0.5339 - val_loss: 0.9901 - val_accuracy: 0.5271\n",
      "Epoch 181/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9700 - accuracy: 0.5342 - val_loss: 0.9917 - val_accuracy: 0.5106\n",
      "Epoch 182/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9709 - accuracy: 0.5330 - val_loss: 0.9924 - val_accuracy: 0.5147\n",
      "Epoch 183/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9704 - accuracy: 0.5343 - val_loss: 0.9889 - val_accuracy: 0.5230\n",
      "Epoch 184/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9711 - accuracy: 0.5346 - val_loss: 0.9913 - val_accuracy: 0.5221\n",
      "Epoch 185/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9728 - accuracy: 0.5322 - val_loss: 0.9889 - val_accuracy: 0.5225\n",
      "Epoch 186/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9710 - accuracy: 0.5329 - val_loss: 0.9882 - val_accuracy: 0.5244\n",
      "Epoch 187/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9701 - accuracy: 0.5336 - val_loss: 0.9940 - val_accuracy: 0.5216\n",
      "Epoch 188/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9709 - accuracy: 0.5347 - val_loss: 0.9907 - val_accuracy: 0.5230\n",
      "Epoch 189/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9699 - accuracy: 0.5344 - val_loss: 0.9906 - val_accuracy: 0.5225\n",
      "Epoch 190/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9703 - accuracy: 0.5336 - val_loss: 0.9919 - val_accuracy: 0.5110\n",
      "Epoch 191/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9706 - accuracy: 0.5344 - val_loss: 0.9890 - val_accuracy: 0.5248\n",
      "Epoch 192/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9706 - accuracy: 0.5327 - val_loss: 0.9907 - val_accuracy: 0.5239\n",
      "Epoch 193/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9710 - accuracy: 0.5342 - val_loss: 0.9893 - val_accuracy: 0.5262\n",
      "Epoch 194/200\n",
      "89/89 [==============================] - 0s 788us/step - loss: 0.9706 - accuracy: 0.5330 - val_loss: 0.9933 - val_accuracy: 0.5138\n",
      "Epoch 195/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9704 - accuracy: 0.5344 - val_loss: 0.9918 - val_accuracy: 0.5156\n",
      "Epoch 196/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9700 - accuracy: 0.5343 - val_loss: 0.9905 - val_accuracy: 0.5225\n",
      "Epoch 197/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9713 - accuracy: 0.5328 - val_loss: 0.9892 - val_accuracy: 0.5267\n",
      "Epoch 198/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9710 - accuracy: 0.5343 - val_loss: 0.9899 - val_accuracy: 0.5225\n",
      "Epoch 199/200\n",
      "89/89 [==============================] - 0s 833us/step - loss: 0.9704 - accuracy: 0.5350 - val_loss: 0.9947 - val_accuracy: 0.5051\n",
      "Epoch 200/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9701 - accuracy: 0.5338 - val_loss: 0.9908 - val_accuracy: 0.5156\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 371us/step - loss: 0.9694 - accuracy: 0.5345\n",
      "Accuracy : 0.5345417261123657\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9908 - accuracy: 0.5156\n",
      "Accuracy : 0.515625\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.0635 - accuracy: 0.4526 - val_loss: 1.0591 - val_accuracy: 0.4600\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 0s 877us/step - loss: 1.0513 - accuracy: 0.4600 - val_loss: 1.0494 - val_accuracy: 0.4600\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 1.0374 - accuracy: 0.4662 - val_loss: 1.0324 - val_accuracy: 0.4890\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 1.0205 - accuracy: 0.5076 - val_loss: 1.0193 - val_accuracy: 0.5051\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 1.0075 - accuracy: 0.5104 - val_loss: 1.0077 - val_accuracy: 0.4972\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9983 - accuracy: 0.5143 - val_loss: 1.0024 - val_accuracy: 0.5165\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9933 - accuracy: 0.5170 - val_loss: 0.9983 - val_accuracy: 0.5188\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9902 - accuracy: 0.5163 - val_loss: 0.9943 - val_accuracy: 0.5175\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 813us/step - loss: 0.9900 - accuracy: 0.5175 - val_loss: 0.9904 - val_accuracy: 0.5230\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9892 - accuracy: 0.5191 - val_loss: 0.9943 - val_accuracy: 0.5225\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9880 - accuracy: 0.5187 - val_loss: 1.0044 - val_accuracy: 0.5037\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 0s 878us/step - loss: 0.9875 - accuracy: 0.5195 - val_loss: 0.9934 - val_accuracy: 0.5253\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9863 - accuracy: 0.5173 - val_loss: 0.9961 - val_accuracy: 0.5110\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9856 - accuracy: 0.5181 - val_loss: 0.9913 - val_accuracy: 0.5280\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9858 - accuracy: 0.5198 - val_loss: 0.9924 - val_accuracy: 0.5322\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9845 - accuracy: 0.5197 - val_loss: 0.9997 - val_accuracy: 0.5051\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9840 - accuracy: 0.5190 - val_loss: 0.9950 - val_accuracy: 0.5230\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9842 - accuracy: 0.5203 - val_loss: 0.9995 - val_accuracy: 0.5041\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9839 - accuracy: 0.5210 - val_loss: 0.9899 - val_accuracy: 0.5262\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9828 - accuracy: 0.5214 - val_loss: 0.9985 - val_accuracy: 0.5069\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9825 - accuracy: 0.5235 - val_loss: 0.9922 - val_accuracy: 0.5257\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9822 - accuracy: 0.5211 - val_loss: 0.9904 - val_accuracy: 0.5349\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9825 - accuracy: 0.5200 - val_loss: 0.9934 - val_accuracy: 0.5147\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9818 - accuracy: 0.5213 - val_loss: 0.9944 - val_accuracy: 0.5170\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 0s 844us/step - loss: 0.9829 - accuracy: 0.5193 - val_loss: 0.9904 - val_accuracy: 0.5276\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9836 - accuracy: 0.5203 - val_loss: 0.9926 - val_accuracy: 0.5188\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9811 - accuracy: 0.5212 - val_loss: 0.9921 - val_accuracy: 0.5175\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9813 - accuracy: 0.5218 - val_loss: 0.9917 - val_accuracy: 0.5202\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9811 - accuracy: 0.5217 - val_loss: 0.9916 - val_accuracy: 0.5267\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9811 - accuracy: 0.5214 - val_loss: 0.9913 - val_accuracy: 0.5308\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9804 - accuracy: 0.5222 - val_loss: 0.9945 - val_accuracy: 0.5161\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9811 - accuracy: 0.5213 - val_loss: 0.9943 - val_accuracy: 0.5156\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9801 - accuracy: 0.5247 - val_loss: 0.9858 - val_accuracy: 0.5290\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9817 - accuracy: 0.5248 - val_loss: 0.9880 - val_accuracy: 0.5363\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9805 - accuracy: 0.5240 - val_loss: 0.9901 - val_accuracy: 0.5345\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9811 - accuracy: 0.5228 - val_loss: 0.9879 - val_accuracy: 0.5354\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9807 - accuracy: 0.5221 - val_loss: 0.9888 - val_accuracy: 0.5322\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9799 - accuracy: 0.5247 - val_loss: 0.9877 - val_accuracy: 0.5312\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9795 - accuracy: 0.5252 - val_loss: 0.9899 - val_accuracy: 0.5221\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 0s 831us/step - loss: 0.9795 - accuracy: 0.5230 - val_loss: 0.9884 - val_accuracy: 0.5294\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9803 - accuracy: 0.5228 - val_loss: 0.9874 - val_accuracy: 0.5294\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9790 - accuracy: 0.5250 - val_loss: 0.9873 - val_accuracy: 0.5290\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9787 - accuracy: 0.5243 - val_loss: 0.9897 - val_accuracy: 0.5207\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9789 - accuracy: 0.5241 - val_loss: 0.9861 - val_accuracy: 0.5363\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9800 - accuracy: 0.5238 - val_loss: 0.9884 - val_accuracy: 0.5253\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9789 - accuracy: 0.5240 - val_loss: 0.9876 - val_accuracy: 0.5271\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9794 - accuracy: 0.5258 - val_loss: 0.9878 - val_accuracy: 0.5280\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9797 - accuracy: 0.5239 - val_loss: 0.9878 - val_accuracy: 0.5326\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9785 - accuracy: 0.5259 - val_loss: 0.9852 - val_accuracy: 0.5290\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9794 - accuracy: 0.5237 - val_loss: 0.9866 - val_accuracy: 0.5312\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9799 - accuracy: 0.5243 - val_loss: 0.9862 - val_accuracy: 0.5248\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9781 - accuracy: 0.5262 - val_loss: 0.9895 - val_accuracy: 0.5216\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9798 - accuracy: 0.5247 - val_loss: 0.9891 - val_accuracy: 0.5248\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 0s 847us/step - loss: 0.9787 - accuracy: 0.5254 - val_loss: 0.9898 - val_accuracy: 0.5267\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 0s 793us/step - loss: 0.9788 - accuracy: 0.5257 - val_loss: 0.9856 - val_accuracy: 0.5358\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9779 - accuracy: 0.5272 - val_loss: 0.9882 - val_accuracy: 0.5202\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9793 - accuracy: 0.5228 - val_loss: 0.9865 - val_accuracy: 0.5308\n",
      "Epoch 58/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9784 - accuracy: 0.5253 - val_loss: 0.9866 - val_accuracy: 0.5271\n",
      "Epoch 59/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9775 - accuracy: 0.5254 - val_loss: 0.9880 - val_accuracy: 0.5234\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9778 - accuracy: 0.5256 - val_loss: 0.9844 - val_accuracy: 0.5290\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9780 - accuracy: 0.5255 - val_loss: 0.9864 - val_accuracy: 0.5312\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9780 - accuracy: 0.5260 - val_loss: 0.9862 - val_accuracy: 0.5280\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9776 - accuracy: 0.5264 - val_loss: 0.9889 - val_accuracy: 0.5170\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9785 - accuracy: 0.5225 - val_loss: 0.9872 - val_accuracy: 0.5294\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9784 - accuracy: 0.5243 - val_loss: 0.9862 - val_accuracy: 0.5290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9784 - accuracy: 0.5238 - val_loss: 0.9839 - val_accuracy: 0.5326\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9782 - accuracy: 0.5254 - val_loss: 0.9882 - val_accuracy: 0.5225\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 0s 856us/step - loss: 0.9777 - accuracy: 0.5264 - val_loss: 0.9840 - val_accuracy: 0.5317\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9772 - accuracy: 0.5250 - val_loss: 0.9845 - val_accuracy: 0.5308\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9773 - accuracy: 0.5263 - val_loss: 0.9828 - val_accuracy: 0.5294\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9776 - accuracy: 0.5253 - val_loss: 0.9835 - val_accuracy: 0.5271\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9775 - accuracy: 0.5268 - val_loss: 0.9847 - val_accuracy: 0.5267\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9771 - accuracy: 0.5276 - val_loss: 0.9841 - val_accuracy: 0.5340\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9773 - accuracy: 0.5266 - val_loss: 0.9850 - val_accuracy: 0.5322\n",
      "Epoch 75/200\n",
      "89/89 [==============================] - 0s 792us/step - loss: 0.9776 - accuracy: 0.5266 - val_loss: 0.9883 - val_accuracy: 0.5312\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9778 - accuracy: 0.5246 - val_loss: 0.9831 - val_accuracy: 0.5312\n",
      "Epoch 77/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9767 - accuracy: 0.5278 - val_loss: 0.9859 - val_accuracy: 0.5262\n",
      "Epoch 78/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9770 - accuracy: 0.5254 - val_loss: 0.9847 - val_accuracy: 0.5331\n",
      "Epoch 79/200\n",
      "89/89 [==============================] - 0s 877us/step - loss: 0.9780 - accuracy: 0.5261 - val_loss: 0.9850 - val_accuracy: 0.5331\n",
      "Epoch 80/200\n",
      "89/89 [==============================] - 0s 877us/step - loss: 0.9768 - accuracy: 0.5262 - val_loss: 0.9812 - val_accuracy: 0.5303\n",
      "Epoch 81/200\n",
      "89/89 [==============================] - 0s 926us/step - loss: 0.9778 - accuracy: 0.5267 - val_loss: 0.9834 - val_accuracy: 0.5308\n",
      "Epoch 82/200\n",
      "89/89 [==============================] - 0s 880us/step - loss: 0.9768 - accuracy: 0.5245 - val_loss: 0.9830 - val_accuracy: 0.5308\n",
      "Epoch 83/200\n",
      "89/89 [==============================] - 0s 857us/step - loss: 0.9773 - accuracy: 0.5259 - val_loss: 0.9837 - val_accuracy: 0.5308\n",
      "Epoch 84/200\n",
      "89/89 [==============================] - 0s 861us/step - loss: 0.9763 - accuracy: 0.5257 - val_loss: 0.9850 - val_accuracy: 0.5340\n",
      "Epoch 85/200\n",
      "89/89 [==============================] - 0s 900us/step - loss: 0.9766 - accuracy: 0.5279 - val_loss: 0.9837 - val_accuracy: 0.5285\n",
      "Epoch 86/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9773 - accuracy: 0.5274 - val_loss: 0.9846 - val_accuracy: 0.5248\n",
      "Epoch 87/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9768 - accuracy: 0.5255 - val_loss: 0.9816 - val_accuracy: 0.5331\n",
      "Epoch 88/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9774 - accuracy: 0.5259 - val_loss: 0.9813 - val_accuracy: 0.5368\n",
      "Epoch 89/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9780 - accuracy: 0.5254 - val_loss: 0.9840 - val_accuracy: 0.5317\n",
      "Epoch 90/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9760 - accuracy: 0.5281 - val_loss: 0.9814 - val_accuracy: 0.5303\n",
      "Epoch 91/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9770 - accuracy: 0.5257 - val_loss: 0.9817 - val_accuracy: 0.5349\n",
      "Epoch 92/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9765 - accuracy: 0.5265 - val_loss: 0.9856 - val_accuracy: 0.5335\n",
      "Epoch 93/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9764 - accuracy: 0.5259 - val_loss: 0.9837 - val_accuracy: 0.5358\n",
      "Epoch 94/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9768 - accuracy: 0.5274 - val_loss: 0.9832 - val_accuracy: 0.5331\n",
      "Epoch 95/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9767 - accuracy: 0.5266 - val_loss: 0.9810 - val_accuracy: 0.5331\n",
      "Epoch 96/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9775 - accuracy: 0.5272 - val_loss: 0.9813 - val_accuracy: 0.5308\n",
      "Epoch 97/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9777 - accuracy: 0.5257 - val_loss: 0.9811 - val_accuracy: 0.5368\n",
      "Epoch 98/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9780 - accuracy: 0.5252 - val_loss: 0.9817 - val_accuracy: 0.5326\n",
      "Epoch 99/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9761 - accuracy: 0.5271 - val_loss: 0.9812 - val_accuracy: 0.5363\n",
      "Epoch 100/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9767 - accuracy: 0.5269 - val_loss: 0.9797 - val_accuracy: 0.5349\n",
      "Epoch 101/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9762 - accuracy: 0.5269 - val_loss: 0.9796 - val_accuracy: 0.5363\n",
      "Epoch 102/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9755 - accuracy: 0.5273 - val_loss: 0.9836 - val_accuracy: 0.5358\n",
      "Epoch 103/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9759 - accuracy: 0.5249 - val_loss: 0.9827 - val_accuracy: 0.5317\n",
      "Epoch 104/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9764 - accuracy: 0.5269 - val_loss: 0.9835 - val_accuracy: 0.5363\n",
      "Epoch 105/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9757 - accuracy: 0.5271 - val_loss: 0.9834 - val_accuracy: 0.5312\n",
      "Epoch 106/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9764 - accuracy: 0.5263 - val_loss: 0.9835 - val_accuracy: 0.5354\n",
      "Epoch 107/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9762 - accuracy: 0.5265 - val_loss: 0.9824 - val_accuracy: 0.5303\n",
      "Epoch 108/200\n",
      "89/89 [==============================] - 0s 847us/step - loss: 0.9762 - accuracy: 0.5257 - val_loss: 0.9834 - val_accuracy: 0.5317\n",
      "Epoch 109/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9766 - accuracy: 0.5252 - val_loss: 0.9825 - val_accuracy: 0.5372\n",
      "Epoch 110/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9759 - accuracy: 0.5269 - val_loss: 0.9838 - val_accuracy: 0.5299\n",
      "Epoch 111/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9780 - accuracy: 0.5257 - val_loss: 0.9900 - val_accuracy: 0.5239\n",
      "Epoch 112/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9783 - accuracy: 0.5241 - val_loss: 0.9837 - val_accuracy: 0.5340\n",
      "Epoch 113/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9762 - accuracy: 0.5275 - val_loss: 0.9854 - val_accuracy: 0.5326\n",
      "Epoch 114/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9761 - accuracy: 0.5267 - val_loss: 0.9804 - val_accuracy: 0.5381\n",
      "Epoch 115/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9756 - accuracy: 0.5276 - val_loss: 0.9818 - val_accuracy: 0.5331\n",
      "Epoch 116/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9762 - accuracy: 0.5258 - val_loss: 0.9819 - val_accuracy: 0.5303\n",
      "Epoch 117/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9751 - accuracy: 0.5282 - val_loss: 0.9831 - val_accuracy: 0.5280\n",
      "Epoch 118/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9762 - accuracy: 0.5266 - val_loss: 0.9809 - val_accuracy: 0.5386\n",
      "Epoch 119/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9771 - accuracy: 0.5255 - val_loss: 0.9823 - val_accuracy: 0.5340\n",
      "Epoch 120/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9752 - accuracy: 0.5265 - val_loss: 0.9806 - val_accuracy: 0.5349\n",
      "Epoch 121/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9750 - accuracy: 0.5279 - val_loss: 0.9817 - val_accuracy: 0.5358\n",
      "Epoch 122/200\n",
      "89/89 [==============================] - 0s 842us/step - loss: 0.9757 - accuracy: 0.5289 - val_loss: 0.9808 - val_accuracy: 0.5335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "89/89 [==============================] - 0s 820us/step - loss: 0.9769 - accuracy: 0.5270 - val_loss: 0.9802 - val_accuracy: 0.5368\n",
      "Epoch 124/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9759 - accuracy: 0.5270 - val_loss: 0.9806 - val_accuracy: 0.5354\n",
      "Epoch 125/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9760 - accuracy: 0.5276 - val_loss: 0.9809 - val_accuracy: 0.5372\n",
      "Epoch 126/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9750 - accuracy: 0.5279 - val_loss: 0.9799 - val_accuracy: 0.5326\n",
      "Epoch 127/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9750 - accuracy: 0.5275 - val_loss: 0.9836 - val_accuracy: 0.5267\n",
      "Epoch 128/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9764 - accuracy: 0.5282 - val_loss: 0.9811 - val_accuracy: 0.5391\n",
      "Epoch 129/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9767 - accuracy: 0.5270 - val_loss: 0.9822 - val_accuracy: 0.5317\n",
      "Epoch 130/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9766 - accuracy: 0.5253 - val_loss: 0.9816 - val_accuracy: 0.5418\n",
      "Epoch 131/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9762 - accuracy: 0.5249 - val_loss: 0.9813 - val_accuracy: 0.5303\n",
      "Epoch 132/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9760 - accuracy: 0.5259 - val_loss: 0.9857 - val_accuracy: 0.5234\n",
      "Epoch 133/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9765 - accuracy: 0.5253 - val_loss: 0.9811 - val_accuracy: 0.5335\n",
      "Epoch 134/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9751 - accuracy: 0.5285 - val_loss: 0.9791 - val_accuracy: 0.5377\n",
      "Epoch 135/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9751 - accuracy: 0.5275 - val_loss: 0.9814 - val_accuracy: 0.5322\n",
      "Epoch 136/200\n",
      "89/89 [==============================] - 0s 830us/step - loss: 0.9757 - accuracy: 0.5286 - val_loss: 0.9797 - val_accuracy: 0.5335\n",
      "Epoch 137/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9752 - accuracy: 0.5271 - val_loss: 0.9807 - val_accuracy: 0.5368\n",
      "Epoch 138/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9746 - accuracy: 0.5284 - val_loss: 0.9795 - val_accuracy: 0.5381\n",
      "Epoch 139/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9749 - accuracy: 0.5281 - val_loss: 0.9800 - val_accuracy: 0.5354\n",
      "Epoch 140/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9759 - accuracy: 0.5264 - val_loss: 0.9866 - val_accuracy: 0.5244\n",
      "Epoch 141/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9764 - accuracy: 0.5257 - val_loss: 0.9829 - val_accuracy: 0.5345\n",
      "Epoch 142/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9758 - accuracy: 0.5287 - val_loss: 0.9796 - val_accuracy: 0.5368\n",
      "Epoch 143/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9750 - accuracy: 0.5267 - val_loss: 0.9819 - val_accuracy: 0.5331\n",
      "Epoch 144/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9754 - accuracy: 0.5276 - val_loss: 0.9805 - val_accuracy: 0.5363\n",
      "Epoch 145/200\n",
      "89/89 [==============================] - 0s 825us/step - loss: 0.9747 - accuracy: 0.5275 - val_loss: 0.9797 - val_accuracy: 0.5386\n",
      "Epoch 146/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9756 - accuracy: 0.5282 - val_loss: 0.9829 - val_accuracy: 0.5400\n",
      "Epoch 147/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9758 - accuracy: 0.5264 - val_loss: 0.9819 - val_accuracy: 0.5335\n",
      "Epoch 148/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9755 - accuracy: 0.5284 - val_loss: 0.9814 - val_accuracy: 0.5326\n",
      "Epoch 149/200\n",
      "89/89 [==============================] - 0s 829us/step - loss: 0.9762 - accuracy: 0.5260 - val_loss: 0.9806 - val_accuracy: 0.5335\n",
      "Epoch 150/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9755 - accuracy: 0.5262 - val_loss: 0.9820 - val_accuracy: 0.5368\n",
      "Epoch 151/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9763 - accuracy: 0.5269 - val_loss: 0.9802 - val_accuracy: 0.5349\n",
      "Epoch 152/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9751 - accuracy: 0.5267 - val_loss: 0.9816 - val_accuracy: 0.5308\n",
      "Epoch 153/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9751 - accuracy: 0.5275 - val_loss: 0.9816 - val_accuracy: 0.5303\n",
      "Epoch 154/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9761 - accuracy: 0.5273 - val_loss: 0.9808 - val_accuracy: 0.5377\n",
      "Epoch 155/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9749 - accuracy: 0.5275 - val_loss: 0.9804 - val_accuracy: 0.5391\n",
      "Epoch 156/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9748 - accuracy: 0.5260 - val_loss: 0.9812 - val_accuracy: 0.5331\n",
      "Epoch 157/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9744 - accuracy: 0.5279 - val_loss: 0.9814 - val_accuracy: 0.5322\n",
      "Epoch 158/200\n",
      "89/89 [==============================] - 0s 804us/step - loss: 0.9746 - accuracy: 0.5264 - val_loss: 0.9844 - val_accuracy: 0.5294\n",
      "Epoch 159/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9751 - accuracy: 0.5292 - val_loss: 0.9855 - val_accuracy: 0.5299\n",
      "Epoch 160/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9751 - accuracy: 0.5285 - val_loss: 0.9815 - val_accuracy: 0.5322\n",
      "Epoch 161/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9750 - accuracy: 0.5283 - val_loss: 0.9865 - val_accuracy: 0.5372\n",
      "Epoch 162/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9750 - accuracy: 0.5280 - val_loss: 0.9817 - val_accuracy: 0.5322\n",
      "Epoch 163/200\n",
      "89/89 [==============================] - 0s 831us/step - loss: 0.9752 - accuracy: 0.5263 - val_loss: 0.9837 - val_accuracy: 0.5280\n",
      "Epoch 164/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9747 - accuracy: 0.5295 - val_loss: 0.9802 - val_accuracy: 0.5349\n",
      "Epoch 165/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9759 - accuracy: 0.5248 - val_loss: 0.9816 - val_accuracy: 0.5326\n",
      "Epoch 166/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9760 - accuracy: 0.5267 - val_loss: 0.9793 - val_accuracy: 0.5358\n",
      "Epoch 167/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9748 - accuracy: 0.5265 - val_loss: 0.9818 - val_accuracy: 0.5317\n",
      "Epoch 168/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9756 - accuracy: 0.5264 - val_loss: 0.9838 - val_accuracy: 0.5299\n",
      "Epoch 169/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9749 - accuracy: 0.5284 - val_loss: 0.9810 - val_accuracy: 0.5335\n",
      "Epoch 170/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9749 - accuracy: 0.5265 - val_loss: 0.9834 - val_accuracy: 0.5368\n",
      "Epoch 171/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9749 - accuracy: 0.5267 - val_loss: 0.9807 - val_accuracy: 0.5308\n",
      "Epoch 172/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9753 - accuracy: 0.5269 - val_loss: 0.9829 - val_accuracy: 0.5404\n",
      "Epoch 173/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9822 - val_accuracy: 0.5354\n",
      "Epoch 174/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9756 - accuracy: 0.5278 - val_loss: 0.9810 - val_accuracy: 0.5349\n",
      "Epoch 175/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9741 - accuracy: 0.5275 - val_loss: 0.9811 - val_accuracy: 0.5322\n",
      "Epoch 176/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9758 - accuracy: 0.5274 - val_loss: 0.9845 - val_accuracy: 0.5372\n",
      "Epoch 177/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9744 - accuracy: 0.5279 - val_loss: 0.9796 - val_accuracy: 0.5358\n",
      "Epoch 178/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9750 - accuracy: 0.5273 - val_loss: 0.9837 - val_accuracy: 0.5331\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 809us/step - loss: 0.9749 - accuracy: 0.5272 - val_loss: 0.9815 - val_accuracy: 0.5285\n",
      "Epoch 180/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9742 - accuracy: 0.5274 - val_loss: 0.9819 - val_accuracy: 0.5372\n",
      "Epoch 181/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9738 - accuracy: 0.5269 - val_loss: 0.9829 - val_accuracy: 0.5303\n",
      "Epoch 182/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9751 - accuracy: 0.5275 - val_loss: 0.9851 - val_accuracy: 0.5303\n",
      "Epoch 183/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9754 - accuracy: 0.5258 - val_loss: 0.9824 - val_accuracy: 0.5317\n",
      "Epoch 184/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9752 - accuracy: 0.5280 - val_loss: 0.9836 - val_accuracy: 0.5294\n",
      "Epoch 185/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9749 - accuracy: 0.5281 - val_loss: 0.9830 - val_accuracy: 0.5271\n",
      "Epoch 186/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9757 - accuracy: 0.5254 - val_loss: 0.9825 - val_accuracy: 0.5368\n",
      "Epoch 187/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9751 - accuracy: 0.5275 - val_loss: 0.9804 - val_accuracy: 0.5345\n",
      "Epoch 188/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9748 - accuracy: 0.5251 - val_loss: 0.9832 - val_accuracy: 0.5368\n",
      "Epoch 189/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9752 - accuracy: 0.5274 - val_loss: 0.9850 - val_accuracy: 0.5211\n",
      "Epoch 190/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9763 - accuracy: 0.5246 - val_loss: 0.9819 - val_accuracy: 0.5372\n",
      "Epoch 191/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9746 - accuracy: 0.5278 - val_loss: 0.9801 - val_accuracy: 0.5400\n",
      "Epoch 192/200\n",
      "89/89 [==============================] - 0s 826us/step - loss: 0.9748 - accuracy: 0.5258 - val_loss: 0.9797 - val_accuracy: 0.5409\n",
      "Epoch 193/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9743 - accuracy: 0.5271 - val_loss: 0.9806 - val_accuracy: 0.5354\n",
      "Epoch 194/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9745 - accuracy: 0.5271 - val_loss: 0.9825 - val_accuracy: 0.5358\n",
      "Epoch 195/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9752 - accuracy: 0.5256 - val_loss: 0.9812 - val_accuracy: 0.5381\n",
      "Epoch 196/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9762 - accuracy: 0.5270 - val_loss: 0.9810 - val_accuracy: 0.5349\n",
      "Epoch 197/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9748 - accuracy: 0.5264 - val_loss: 0.9829 - val_accuracy: 0.5368\n",
      "Epoch 198/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9742 - accuracy: 0.5290 - val_loss: 0.9797 - val_accuracy: 0.5368\n",
      "Epoch 199/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9745 - accuracy: 0.5283 - val_loss: 0.9826 - val_accuracy: 0.5303\n",
      "Epoch 200/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9748 - accuracy: 0.5264 - val_loss: 0.9808 - val_accuracy: 0.5363\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 356us/step - loss: 0.9733 - accuracy: 0.5293\n",
      "Accuracy : 0.5293336510658264\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9808 - accuracy: 0.5363\n",
      "Accuracy : 0.5363051295280457\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.0592 - accuracy: 0.4600 - val_loss: 1.0467 - val_accuracy: 0.4600\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 0s 889us/step - loss: 1.0419 - accuracy: 0.4638 - val_loss: 1.0155 - val_accuracy: 0.4706\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 0s 756us/step - loss: 1.0124 - accuracy: 0.5049 - val_loss: 0.9835 - val_accuracy: 0.5262\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 0s 839us/step - loss: 0.9967 - accuracy: 0.5156 - val_loss: 0.9745 - val_accuracy: 0.5363\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9913 - accuracy: 0.5179 - val_loss: 0.9699 - val_accuracy: 0.5345\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9900 - accuracy: 0.5174 - val_loss: 0.9689 - val_accuracy: 0.5335\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9862 - accuracy: 0.5217 - val_loss: 0.9681 - val_accuracy: 0.5409\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9856 - accuracy: 0.5214 - val_loss: 0.9681 - val_accuracy: 0.5340\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9851 - accuracy: 0.5212 - val_loss: 0.9806 - val_accuracy: 0.5216\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9851 - accuracy: 0.5220 - val_loss: 0.9737 - val_accuracy: 0.5267\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9826 - accuracy: 0.5242 - val_loss: 0.9677 - val_accuracy: 0.5299\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 0s 795us/step - loss: 0.9828 - accuracy: 0.5229 - val_loss: 0.9698 - val_accuracy: 0.5285\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9827 - accuracy: 0.5248 - val_loss: 0.9676 - val_accuracy: 0.5349\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9810 - accuracy: 0.5232 - val_loss: 0.9704 - val_accuracy: 0.5354\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9816 - accuracy: 0.5253 - val_loss: 0.9681 - val_accuracy: 0.5335\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9811 - accuracy: 0.5221 - val_loss: 0.9704 - val_accuracy: 0.5299\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9804 - accuracy: 0.5269 - val_loss: 0.9695 - val_accuracy: 0.5312\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9810 - accuracy: 0.5234 - val_loss: 0.9679 - val_accuracy: 0.5312\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9803 - accuracy: 0.5257 - val_loss: 0.9691 - val_accuracy: 0.5262\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9808 - accuracy: 0.5245 - val_loss: 0.9693 - val_accuracy: 0.5322\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9798 - accuracy: 0.5248 - val_loss: 0.9703 - val_accuracy: 0.5368\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9791 - accuracy: 0.5236 - val_loss: 0.9705 - val_accuracy: 0.5276\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9790 - accuracy: 0.5234 - val_loss: 0.9682 - val_accuracy: 0.5349\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9802 - accuracy: 0.5235 - val_loss: 0.9700 - val_accuracy: 0.5345\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9786 - accuracy: 0.5235 - val_loss: 0.9661 - val_accuracy: 0.5317\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9790 - accuracy: 0.5280 - val_loss: 0.9715 - val_accuracy: 0.5303\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9789 - accuracy: 0.5271 - val_loss: 0.9707 - val_accuracy: 0.5331\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9787 - accuracy: 0.5261 - val_loss: 0.9713 - val_accuracy: 0.5331\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9794 - accuracy: 0.5250 - val_loss: 0.9713 - val_accuracy: 0.5303\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9792 - accuracy: 0.5259 - val_loss: 0.9687 - val_accuracy: 0.5331\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9784 - accuracy: 0.5259 - val_loss: 0.9689 - val_accuracy: 0.5372\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9779 - accuracy: 0.5264 - val_loss: 0.9707 - val_accuracy: 0.5358\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9789 - accuracy: 0.5266 - val_loss: 0.9702 - val_accuracy: 0.5400\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 833us/step - loss: 0.9777 - accuracy: 0.5262 - val_loss: 0.9686 - val_accuracy: 0.5381\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9797 - accuracy: 0.5265 - val_loss: 0.9661 - val_accuracy: 0.5372\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 0s 823us/step - loss: 0.9784 - accuracy: 0.5268 - val_loss: 0.9679 - val_accuracy: 0.5322\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9773 - accuracy: 0.5271 - val_loss: 0.9711 - val_accuracy: 0.5312\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9789 - accuracy: 0.5272 - val_loss: 0.9678 - val_accuracy: 0.5358\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9772 - accuracy: 0.5259 - val_loss: 0.9718 - val_accuracy: 0.5372\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9786 - accuracy: 0.5249 - val_loss: 0.9685 - val_accuracy: 0.5290\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 0s 637us/step - loss: 0.9778 - accuracy: 0.5264 - val_loss: 0.9709 - val_accuracy: 0.5299\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 0s 977us/step - loss: 0.9777 - accuracy: 0.5269 - val_loss: 0.9691 - val_accuracy: 0.5368\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9777 - accuracy: 0.5270 - val_loss: 0.9686 - val_accuracy: 0.5335\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9783 - accuracy: 0.5262 - val_loss: 0.9693 - val_accuracy: 0.5354\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9768 - accuracy: 0.5273 - val_loss: 0.9686 - val_accuracy: 0.5317\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9767 - accuracy: 0.5275 - val_loss: 0.9689 - val_accuracy: 0.5386\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9766 - accuracy: 0.5263 - val_loss: 0.9665 - val_accuracy: 0.5308\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 0s 662us/step - loss: 0.9765 - accuracy: 0.5280 - val_loss: 0.9674 - val_accuracy: 0.5381\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 0s 942us/step - loss: 0.9765 - accuracy: 0.5284 - val_loss: 0.9682 - val_accuracy: 0.5368\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 0s 654us/step - loss: 0.9768 - accuracy: 0.5252 - val_loss: 0.9673 - val_accuracy: 0.5368\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 0s 757us/step - loss: 0.9781 - accuracy: 0.5268 - val_loss: 0.9677 - val_accuracy: 0.5358\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9764 - accuracy: 0.5284 - val_loss: 0.9670 - val_accuracy: 0.5349\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9771 - accuracy: 0.5288 - val_loss: 0.9667 - val_accuracy: 0.5404\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9763 - accuracy: 0.5267 - val_loss: 0.9663 - val_accuracy: 0.5354\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9769 - accuracy: 0.5262 - val_loss: 0.9690 - val_accuracy: 0.5368\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 0s 844us/step - loss: 0.9775 - accuracy: 0.5270 - val_loss: 0.9713 - val_accuracy: 0.5317\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9762 - accuracy: 0.5276 - val_loss: 0.9690 - val_accuracy: 0.5354\n",
      "Epoch 58/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9764 - accuracy: 0.5280 - val_loss: 0.9683 - val_accuracy: 0.5391\n",
      "Epoch 59/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9768 - accuracy: 0.5255 - val_loss: 0.9664 - val_accuracy: 0.5381\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9763 - accuracy: 0.5267 - val_loss: 0.9666 - val_accuracy: 0.5349\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9765 - accuracy: 0.5257 - val_loss: 0.9704 - val_accuracy: 0.5363\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9772 - accuracy: 0.5261 - val_loss: 0.9683 - val_accuracy: 0.5400\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9762 - accuracy: 0.5275 - val_loss: 0.9683 - val_accuracy: 0.5395\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9763 - accuracy: 0.5279 - val_loss: 0.9729 - val_accuracy: 0.5368\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 0s 776us/step - loss: 0.9759 - accuracy: 0.5269 - val_loss: 0.9707 - val_accuracy: 0.5372\n",
      "Epoch 66/200\n",
      "89/89 [==============================] - 0s 795us/step - loss: 0.9763 - accuracy: 0.5269 - val_loss: 0.9711 - val_accuracy: 0.5391\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9768 - accuracy: 0.5286 - val_loss: 0.9683 - val_accuracy: 0.5404\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9759 - accuracy: 0.5278 - val_loss: 0.9692 - val_accuracy: 0.5358\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9685 - val_accuracy: 0.5312\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 0s 689us/step - loss: 0.9767 - accuracy: 0.5268 - val_loss: 0.9673 - val_accuracy: 0.5372\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 0s 951us/step - loss: 0.9752 - accuracy: 0.5281 - val_loss: 0.9715 - val_accuracy: 0.5386\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9771 - accuracy: 0.5265 - val_loss: 0.9676 - val_accuracy: 0.5377\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9762 - accuracy: 0.5264 - val_loss: 0.9682 - val_accuracy: 0.5404\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9757 - accuracy: 0.5275 - val_loss: 0.9686 - val_accuracy: 0.5331\n",
      "Epoch 75/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9758 - accuracy: 0.5280 - val_loss: 0.9650 - val_accuracy: 0.5372\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9751 - accuracy: 0.5295 - val_loss: 0.9678 - val_accuracy: 0.5404\n",
      "Epoch 77/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9749 - accuracy: 0.5288 - val_loss: 0.9673 - val_accuracy: 0.5386\n",
      "Epoch 78/200\n",
      "89/89 [==============================] - 0s 836us/step - loss: 0.9753 - accuracy: 0.5278 - val_loss: 0.9683 - val_accuracy: 0.5340\n",
      "Epoch 79/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9751 - accuracy: 0.5290 - val_loss: 0.9696 - val_accuracy: 0.5381\n",
      "Epoch 80/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9753 - accuracy: 0.5278 - val_loss: 0.9647 - val_accuracy: 0.5368\n",
      "Epoch 81/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9753 - accuracy: 0.5284 - val_loss: 0.9686 - val_accuracy: 0.5372\n",
      "Epoch 82/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9745 - accuracy: 0.5287 - val_loss: 0.9687 - val_accuracy: 0.5358\n",
      "Epoch 83/200\n",
      "89/89 [==============================] - 0s 872us/step - loss: 0.9750 - accuracy: 0.5275 - val_loss: 0.9691 - val_accuracy: 0.5354\n",
      "Epoch 84/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9749 - accuracy: 0.5285 - val_loss: 0.9680 - val_accuracy: 0.5335\n",
      "Epoch 85/200\n",
      "89/89 [==============================] - 0s 853us/step - loss: 0.9747 - accuracy: 0.5290 - val_loss: 0.9681 - val_accuracy: 0.5345\n",
      "Epoch 86/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9755 - accuracy: 0.5284 - val_loss: 0.9686 - val_accuracy: 0.5312\n",
      "Epoch 87/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9746 - accuracy: 0.5309 - val_loss: 0.9675 - val_accuracy: 0.5368\n",
      "Epoch 88/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9746 - accuracy: 0.5276 - val_loss: 0.9676 - val_accuracy: 0.5395\n",
      "Epoch 89/200\n",
      "89/89 [==============================] - 0s 877us/step - loss: 0.9752 - accuracy: 0.5299 - val_loss: 0.9659 - val_accuracy: 0.5400\n",
      "Epoch 90/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9748 - accuracy: 0.5294 - val_loss: 0.9696 - val_accuracy: 0.5331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9748 - accuracy: 0.5291 - val_loss: 0.9696 - val_accuracy: 0.5386\n",
      "Epoch 92/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9744 - accuracy: 0.5291 - val_loss: 0.9667 - val_accuracy: 0.5317\n",
      "Epoch 93/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9746 - accuracy: 0.5288 - val_loss: 0.9675 - val_accuracy: 0.5404\n",
      "Epoch 94/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9743 - accuracy: 0.5291 - val_loss: 0.9670 - val_accuracy: 0.5363\n",
      "Epoch 95/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9746 - accuracy: 0.5281 - val_loss: 0.9681 - val_accuracy: 0.5377\n",
      "Epoch 96/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9745 - accuracy: 0.5292 - val_loss: 0.9656 - val_accuracy: 0.5363\n",
      "Epoch 97/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9673 - val_accuracy: 0.5368\n",
      "Epoch 98/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9744 - accuracy: 0.5293 - val_loss: 0.9676 - val_accuracy: 0.5349\n",
      "Epoch 99/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9754 - accuracy: 0.5278 - val_loss: 0.9676 - val_accuracy: 0.5400\n",
      "Epoch 100/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9743 - accuracy: 0.5293 - val_loss: 0.9685 - val_accuracy: 0.5372\n",
      "Epoch 101/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9744 - accuracy: 0.5285 - val_loss: 0.9687 - val_accuracy: 0.5381\n",
      "Epoch 102/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9742 - accuracy: 0.5295 - val_loss: 0.9660 - val_accuracy: 0.5414\n",
      "Epoch 103/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9740 - accuracy: 0.5301 - val_loss: 0.9687 - val_accuracy: 0.5395\n",
      "Epoch 104/200\n",
      "89/89 [==============================] - 0s 818us/step - loss: 0.9748 - accuracy: 0.5290 - val_loss: 0.9682 - val_accuracy: 0.5381\n",
      "Epoch 105/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9745 - accuracy: 0.5291 - val_loss: 0.9689 - val_accuracy: 0.5345\n",
      "Epoch 106/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9744 - accuracy: 0.5310 - val_loss: 0.9683 - val_accuracy: 0.5331\n",
      "Epoch 107/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9747 - accuracy: 0.5282 - val_loss: 0.9675 - val_accuracy: 0.5358\n",
      "Epoch 108/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9730 - accuracy: 0.5299 - val_loss: 0.9759 - val_accuracy: 0.5322\n",
      "Epoch 109/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9745 - accuracy: 0.5288 - val_loss: 0.9685 - val_accuracy: 0.5358\n",
      "Epoch 110/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9747 - accuracy: 0.5270 - val_loss: 0.9713 - val_accuracy: 0.5372\n",
      "Epoch 111/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9738 - accuracy: 0.5275 - val_loss: 0.9698 - val_accuracy: 0.5354\n",
      "Epoch 112/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9745 - accuracy: 0.5285 - val_loss: 0.9683 - val_accuracy: 0.5354\n",
      "Epoch 113/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9738 - accuracy: 0.5292 - val_loss: 0.9670 - val_accuracy: 0.5349\n",
      "Epoch 114/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9735 - accuracy: 0.5292 - val_loss: 0.9726 - val_accuracy: 0.5349\n",
      "Epoch 115/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9738 - accuracy: 0.5305 - val_loss: 0.9699 - val_accuracy: 0.5386\n",
      "Epoch 116/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9742 - accuracy: 0.5307 - val_loss: 0.9699 - val_accuracy: 0.5391\n",
      "Epoch 117/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9730 - accuracy: 0.5289 - val_loss: 0.9676 - val_accuracy: 0.5372\n",
      "Epoch 118/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9740 - accuracy: 0.5308 - val_loss: 0.9677 - val_accuracy: 0.5345\n",
      "Epoch 119/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9735 - accuracy: 0.5295 - val_loss: 0.9685 - val_accuracy: 0.5400\n",
      "Epoch 120/200\n",
      "89/89 [==============================] - 0s 772us/step - loss: 0.9736 - accuracy: 0.5284 - val_loss: 0.9677 - val_accuracy: 0.5331\n",
      "Epoch 121/200\n",
      "89/89 [==============================] - 0s 779us/step - loss: 0.9742 - accuracy: 0.5291 - val_loss: 0.9704 - val_accuracy: 0.5377\n",
      "Epoch 122/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9736 - accuracy: 0.5310 - val_loss: 0.9687 - val_accuracy: 0.5391\n",
      "Epoch 123/200\n",
      "89/89 [==============================] - 0s 772us/step - loss: 0.9734 - accuracy: 0.5303 - val_loss: 0.9693 - val_accuracy: 0.5358\n",
      "Epoch 124/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9733 - accuracy: 0.5290 - val_loss: 0.9718 - val_accuracy: 0.5432\n",
      "Epoch 125/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9699 - val_accuracy: 0.5423\n",
      "Epoch 126/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9735 - accuracy: 0.5299 - val_loss: 0.9706 - val_accuracy: 0.5331\n",
      "Epoch 127/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9736 - accuracy: 0.5284 - val_loss: 0.9707 - val_accuracy: 0.5409\n",
      "Epoch 128/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9737 - accuracy: 0.5293 - val_loss: 0.9663 - val_accuracy: 0.5326\n",
      "Epoch 129/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9740 - accuracy: 0.5310 - val_loss: 0.9685 - val_accuracy: 0.5303\n",
      "Epoch 130/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9747 - accuracy: 0.5305 - val_loss: 0.9681 - val_accuracy: 0.5349\n",
      "Epoch 131/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9744 - accuracy: 0.5304 - val_loss: 0.9685 - val_accuracy: 0.5372\n",
      "Epoch 132/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9744 - accuracy: 0.5291 - val_loss: 0.9677 - val_accuracy: 0.5368\n",
      "Epoch 133/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9743 - accuracy: 0.5303 - val_loss: 0.9685 - val_accuracy: 0.5395\n",
      "Epoch 134/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9748 - accuracy: 0.5323 - val_loss: 0.9672 - val_accuracy: 0.5372\n",
      "Epoch 135/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9745 - accuracy: 0.5287 - val_loss: 0.9667 - val_accuracy: 0.5414\n",
      "Epoch 136/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9737 - accuracy: 0.5303 - val_loss: 0.9660 - val_accuracy: 0.5335\n",
      "Epoch 137/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9739 - accuracy: 0.5310 - val_loss: 0.9674 - val_accuracy: 0.5354\n",
      "Epoch 138/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9741 - accuracy: 0.5305 - val_loss: 0.9693 - val_accuracy: 0.5377\n",
      "Epoch 139/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9740 - accuracy: 0.5298 - val_loss: 0.9665 - val_accuracy: 0.5354\n",
      "Epoch 140/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9743 - accuracy: 0.5297 - val_loss: 0.9676 - val_accuracy: 0.5354\n",
      "Epoch 141/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9750 - accuracy: 0.5300 - val_loss: 0.9716 - val_accuracy: 0.5377\n",
      "Epoch 142/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 0.9704 - val_accuracy: 0.5400\n",
      "Epoch 143/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9737 - accuracy: 0.5292 - val_loss: 0.9676 - val_accuracy: 0.5418\n",
      "Epoch 144/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 0.9673 - val_accuracy: 0.5345\n",
      "Epoch 145/200\n",
      "89/89 [==============================] - 0s 776us/step - loss: 0.9742 - accuracy: 0.5316 - val_loss: 0.9728 - val_accuracy: 0.5349\n",
      "Epoch 146/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9743 - accuracy: 0.5319 - val_loss: 0.9695 - val_accuracy: 0.5354\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 817us/step - loss: 0.9737 - accuracy: 0.5296 - val_loss: 0.9651 - val_accuracy: 0.5358\n",
      "Epoch 148/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9743 - accuracy: 0.5288 - val_loss: 0.9672 - val_accuracy: 0.5386\n",
      "Epoch 149/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9662 - val_accuracy: 0.5391\n",
      "Epoch 150/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9734 - accuracy: 0.5302 - val_loss: 0.9701 - val_accuracy: 0.5345\n",
      "Epoch 151/200\n",
      "89/89 [==============================] - 0s 779us/step - loss: 0.9735 - accuracy: 0.5305 - val_loss: 0.9679 - val_accuracy: 0.5331\n",
      "Epoch 152/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9732 - accuracy: 0.5313 - val_loss: 0.9673 - val_accuracy: 0.5354\n",
      "Epoch 153/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9743 - accuracy: 0.5276 - val_loss: 0.9690 - val_accuracy: 0.5381\n",
      "Epoch 154/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9735 - accuracy: 0.5317 - val_loss: 0.9692 - val_accuracy: 0.5345\n",
      "Epoch 155/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9737 - accuracy: 0.5296 - val_loss: 0.9679 - val_accuracy: 0.5404\n",
      "Epoch 156/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9739 - accuracy: 0.5313 - val_loss: 0.9680 - val_accuracy: 0.5345\n",
      "Epoch 157/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9737 - accuracy: 0.5309 - val_loss: 0.9678 - val_accuracy: 0.5414\n",
      "Epoch 158/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9736 - accuracy: 0.5295 - val_loss: 0.9689 - val_accuracy: 0.5409\n",
      "Epoch 159/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9738 - accuracy: 0.5308 - val_loss: 0.9678 - val_accuracy: 0.5349\n",
      "Epoch 160/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9738 - accuracy: 0.5303 - val_loss: 0.9680 - val_accuracy: 0.5335\n",
      "Epoch 161/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9739 - accuracy: 0.5297 - val_loss: 0.9668 - val_accuracy: 0.5345\n",
      "Epoch 162/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9735 - accuracy: 0.5326 - val_loss: 0.9661 - val_accuracy: 0.5391\n",
      "Epoch 163/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9742 - accuracy: 0.5298 - val_loss: 0.9671 - val_accuracy: 0.5322\n",
      "Epoch 164/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9738 - accuracy: 0.5300 - val_loss: 0.9683 - val_accuracy: 0.5363\n",
      "Epoch 165/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9738 - accuracy: 0.5306 - val_loss: 0.9695 - val_accuracy: 0.5331\n",
      "Epoch 166/200\n",
      "89/89 [==============================] - 0s 804us/step - loss: 0.9742 - accuracy: 0.5294 - val_loss: 0.9682 - val_accuracy: 0.5409\n",
      "Epoch 167/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9732 - accuracy: 0.5296 - val_loss: 0.9664 - val_accuracy: 0.5400\n",
      "Epoch 168/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9731 - accuracy: 0.5293 - val_loss: 0.9681 - val_accuracy: 0.5368\n",
      "Epoch 169/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9746 - accuracy: 0.5299 - val_loss: 0.9641 - val_accuracy: 0.5363\n",
      "Epoch 170/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9733 - accuracy: 0.5289 - val_loss: 0.9684 - val_accuracy: 0.5368\n",
      "Epoch 171/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9734 - accuracy: 0.5302 - val_loss: 0.9727 - val_accuracy: 0.5354\n",
      "Epoch 172/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9738 - accuracy: 0.5290 - val_loss: 0.9692 - val_accuracy: 0.5326\n",
      "Epoch 173/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9747 - accuracy: 0.5305 - val_loss: 0.9674 - val_accuracy: 0.5358\n",
      "Epoch 174/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9737 - accuracy: 0.5295 - val_loss: 0.9656 - val_accuracy: 0.5368\n",
      "Epoch 175/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9733 - accuracy: 0.5308 - val_loss: 0.9679 - val_accuracy: 0.5377\n",
      "Epoch 176/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9729 - accuracy: 0.5305 - val_loss: 0.9694 - val_accuracy: 0.5372\n",
      "Epoch 177/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9734 - accuracy: 0.5304 - val_loss: 0.9693 - val_accuracy: 0.5368\n",
      "Epoch 178/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9707 - val_accuracy: 0.5354\n",
      "Epoch 179/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9742 - accuracy: 0.5314 - val_loss: 0.9673 - val_accuracy: 0.5372\n",
      "Epoch 180/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 0.9681 - val_accuracy: 0.5358\n",
      "Epoch 181/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9732 - accuracy: 0.5303 - val_loss: 0.9734 - val_accuracy: 0.5335\n",
      "Epoch 182/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9738 - accuracy: 0.5311 - val_loss: 0.9679 - val_accuracy: 0.5363\n",
      "Epoch 183/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9734 - accuracy: 0.5314 - val_loss: 0.9678 - val_accuracy: 0.5354\n",
      "Epoch 184/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9733 - accuracy: 0.5304 - val_loss: 0.9706 - val_accuracy: 0.5381\n",
      "Epoch 185/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9736 - accuracy: 0.5304 - val_loss: 0.9697 - val_accuracy: 0.5317\n",
      "Epoch 186/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9695 - val_accuracy: 0.5368\n",
      "Epoch 187/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9729 - accuracy: 0.5297 - val_loss: 0.9698 - val_accuracy: 0.5349\n",
      "Epoch 188/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9712 - val_accuracy: 0.5368\n",
      "Epoch 189/200\n",
      "89/89 [==============================] - 0s 814us/step - loss: 0.9740 - accuracy: 0.5300 - val_loss: 0.9686 - val_accuracy: 0.5395\n",
      "Epoch 190/200\n",
      "89/89 [==============================] - 0s 789us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9706 - val_accuracy: 0.5395\n",
      "Epoch 191/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9734 - accuracy: 0.5293 - val_loss: 0.9694 - val_accuracy: 0.5358\n",
      "Epoch 192/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9725 - accuracy: 0.5297 - val_loss: 0.9667 - val_accuracy: 0.5345\n",
      "Epoch 193/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9728 - accuracy: 0.5304 - val_loss: 0.9684 - val_accuracy: 0.5354\n",
      "Epoch 194/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9730 - accuracy: 0.5304 - val_loss: 0.9693 - val_accuracy: 0.5331\n",
      "Epoch 195/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9732 - accuracy: 0.5304 - val_loss: 0.9675 - val_accuracy: 0.5372\n",
      "Epoch 196/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9734 - accuracy: 0.5300 - val_loss: 0.9695 - val_accuracy: 0.5372\n",
      "Epoch 197/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9727 - val_accuracy: 0.5358\n",
      "Epoch 198/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9734 - accuracy: 0.5292 - val_loss: 0.9693 - val_accuracy: 0.5391\n",
      "Epoch 199/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9732 - accuracy: 0.5303 - val_loss: 0.9668 - val_accuracy: 0.5349\n",
      "Epoch 200/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9730 - accuracy: 0.5300 - val_loss: 0.9707 - val_accuracy: 0.5372\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 362us/step - loss: 0.9720 - accuracy: 0.5321\n",
      "Accuracy : 0.5320909023284912\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9707 - accuracy: 0.5372\n",
      "Accuracy : 0.537224292755127\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.0609 - accuracy: 0.4600 - val_loss: 1.0507 - val_accuracy: 0.4600\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 969us/step - loss: 1.0462 - accuracy: 0.4600 - val_loss: 1.0248 - val_accuracy: 0.4600\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 1.0233 - accuracy: 0.5000 - val_loss: 0.9881 - val_accuracy: 0.5386\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 1.0053 - accuracy: 0.5150 - val_loss: 0.9746 - val_accuracy: 0.5326\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 0s 818us/step - loss: 0.9987 - accuracy: 0.5171 - val_loss: 0.9628 - val_accuracy: 0.5377\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9955 - accuracy: 0.5146 - val_loss: 0.9600 - val_accuracy: 0.5391\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9943 - accuracy: 0.5178 - val_loss: 0.9598 - val_accuracy: 0.5358\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9934 - accuracy: 0.5183 - val_loss: 0.9572 - val_accuracy: 0.5368\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9918 - accuracy: 0.5200 - val_loss: 0.9552 - val_accuracy: 0.5404\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9913 - accuracy: 0.5202 - val_loss: 0.9529 - val_accuracy: 0.5331\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9906 - accuracy: 0.5196 - val_loss: 0.9540 - val_accuracy: 0.5331\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9911 - accuracy: 0.5195 - val_loss: 0.9560 - val_accuracy: 0.5446\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9894 - accuracy: 0.5213 - val_loss: 0.9548 - val_accuracy: 0.5377\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9884 - accuracy: 0.5229 - val_loss: 0.9536 - val_accuracy: 0.5349\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9879 - accuracy: 0.5202 - val_loss: 0.9498 - val_accuracy: 0.5363\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9875 - accuracy: 0.5203 - val_loss: 0.9526 - val_accuracy: 0.5418\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9874 - accuracy: 0.5250 - val_loss: 0.9492 - val_accuracy: 0.5381\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 0s 838us/step - loss: 0.9879 - accuracy: 0.5218 - val_loss: 0.9494 - val_accuracy: 0.5386\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9858 - accuracy: 0.5244 - val_loss: 0.9509 - val_accuracy: 0.5381\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9860 - accuracy: 0.5260 - val_loss: 0.9497 - val_accuracy: 0.5414\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9856 - accuracy: 0.5240 - val_loss: 0.9486 - val_accuracy: 0.5400\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9849 - accuracy: 0.5244 - val_loss: 0.9504 - val_accuracy: 0.5345\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9854 - accuracy: 0.5245 - val_loss: 0.9492 - val_accuracy: 0.5409\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9848 - accuracy: 0.5254 - val_loss: 0.9503 - val_accuracy: 0.5377\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9845 - accuracy: 0.5258 - val_loss: 0.9473 - val_accuracy: 0.5363\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 0s 822us/step - loss: 0.9858 - accuracy: 0.5240 - val_loss: 0.9496 - val_accuracy: 0.5441\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9847 - accuracy: 0.5242 - val_loss: 0.9500 - val_accuracy: 0.5404\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9860 - accuracy: 0.5241 - val_loss: 0.9504 - val_accuracy: 0.5377\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9856 - accuracy: 0.5227 - val_loss: 0.9473 - val_accuracy: 0.5381\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9842 - accuracy: 0.5258 - val_loss: 0.9488 - val_accuracy: 0.5409\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9839 - accuracy: 0.5244 - val_loss: 0.9464 - val_accuracy: 0.5391\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9834 - accuracy: 0.5258 - val_loss: 0.9508 - val_accuracy: 0.5386\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9845 - accuracy: 0.5251 - val_loss: 0.9461 - val_accuracy: 0.5437\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9832 - accuracy: 0.5268 - val_loss: 0.9495 - val_accuracy: 0.5414\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9838 - accuracy: 0.5254 - val_loss: 0.9484 - val_accuracy: 0.5427\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9833 - accuracy: 0.5258 - val_loss: 0.9501 - val_accuracy: 0.5386\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9836 - accuracy: 0.5245 - val_loss: 0.9496 - val_accuracy: 0.5478\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9832 - accuracy: 0.5252 - val_loss: 0.9474 - val_accuracy: 0.5381\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9827 - accuracy: 0.5247 - val_loss: 0.9464 - val_accuracy: 0.5432\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9826 - accuracy: 0.5270 - val_loss: 0.9451 - val_accuracy: 0.5460\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9831 - accuracy: 0.5266 - val_loss: 0.9471 - val_accuracy: 0.5414\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9822 - accuracy: 0.5266 - val_loss: 0.9484 - val_accuracy: 0.5423\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9827 - accuracy: 0.5259 - val_loss: 0.9492 - val_accuracy: 0.5377\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9832 - accuracy: 0.5250 - val_loss: 0.9513 - val_accuracy: 0.5427\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9830 - accuracy: 0.5273 - val_loss: 0.9480 - val_accuracy: 0.5409\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9818 - accuracy: 0.5268 - val_loss: 0.9464 - val_accuracy: 0.5460\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9828 - accuracy: 0.5270 - val_loss: 0.9473 - val_accuracy: 0.5377\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9816 - accuracy: 0.5271 - val_loss: 0.9465 - val_accuracy: 0.5386\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9811 - accuracy: 0.5280 - val_loss: 0.9521 - val_accuracy: 0.5455\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9813 - accuracy: 0.5275 - val_loss: 0.9496 - val_accuracy: 0.5432\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9806 - accuracy: 0.5270 - val_loss: 0.9493 - val_accuracy: 0.5423\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9811 - accuracy: 0.5291 - val_loss: 0.9443 - val_accuracy: 0.5423\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9826 - accuracy: 0.5239 - val_loss: 0.9475 - val_accuracy: 0.5427\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9813 - accuracy: 0.5270 - val_loss: 0.9477 - val_accuracy: 0.5391\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9806 - accuracy: 0.5270 - val_loss: 0.9469 - val_accuracy: 0.5409\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9800 - accuracy: 0.5282 - val_loss: 0.9498 - val_accuracy: 0.5418\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9802 - accuracy: 0.5289 - val_loss: 0.9525 - val_accuracy: 0.5386\n",
      "Epoch 58/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9811 - accuracy: 0.5247 - val_loss: 0.9480 - val_accuracy: 0.5414\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 808us/step - loss: 0.9815 - accuracy: 0.5265 - val_loss: 0.9461 - val_accuracy: 0.5404\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9808 - accuracy: 0.5266 - val_loss: 0.9555 - val_accuracy: 0.5372\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9807 - accuracy: 0.5273 - val_loss: 0.9494 - val_accuracy: 0.5409\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9804 - accuracy: 0.5268 - val_loss: 0.9488 - val_accuracy: 0.5414\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9810 - accuracy: 0.5258 - val_loss: 0.9490 - val_accuracy: 0.5450\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9803 - accuracy: 0.5296 - val_loss: 0.9482 - val_accuracy: 0.5372\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9797 - accuracy: 0.5295 - val_loss: 0.9465 - val_accuracy: 0.5418\n",
      "Epoch 66/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9794 - accuracy: 0.5289 - val_loss: 0.9515 - val_accuracy: 0.5441\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 0s 815us/step - loss: 0.9792 - accuracy: 0.5296 - val_loss: 0.9459 - val_accuracy: 0.5441\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9803 - accuracy: 0.5287 - val_loss: 0.9463 - val_accuracy: 0.5423\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9793 - accuracy: 0.5285 - val_loss: 0.9468 - val_accuracy: 0.5423\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9794 - accuracy: 0.5275 - val_loss: 0.9496 - val_accuracy: 0.5400\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9796 - accuracy: 0.5291 - val_loss: 0.9464 - val_accuracy: 0.5450\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9795 - accuracy: 0.5280 - val_loss: 0.9536 - val_accuracy: 0.5386\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9802 - accuracy: 0.5275 - val_loss: 0.9461 - val_accuracy: 0.5404\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 0s 853us/step - loss: 0.9793 - accuracy: 0.5266 - val_loss: 0.9521 - val_accuracy: 0.5473\n",
      "Epoch 75/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9805 - accuracy: 0.5262 - val_loss: 0.9458 - val_accuracy: 0.5414\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9796 - accuracy: 0.5297 - val_loss: 0.9506 - val_accuracy: 0.5432\n",
      "Epoch 77/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9802 - accuracy: 0.5284 - val_loss: 0.9550 - val_accuracy: 0.5391\n",
      "Epoch 78/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9799 - accuracy: 0.5295 - val_loss: 0.9505 - val_accuracy: 0.5460\n",
      "Epoch 79/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9801 - accuracy: 0.5295 - val_loss: 0.9525 - val_accuracy: 0.5345\n",
      "Epoch 80/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9800 - accuracy: 0.5284 - val_loss: 0.9518 - val_accuracy: 0.5455\n",
      "Epoch 81/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9798 - accuracy: 0.5272 - val_loss: 0.9465 - val_accuracy: 0.5395\n",
      "Epoch 82/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9796 - accuracy: 0.5283 - val_loss: 0.9478 - val_accuracy: 0.5409\n",
      "Epoch 83/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9795 - accuracy: 0.5287 - val_loss: 0.9495 - val_accuracy: 0.5427\n",
      "Epoch 84/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9791 - accuracy: 0.5274 - val_loss: 0.9474 - val_accuracy: 0.5423\n",
      "Epoch 85/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9786 - accuracy: 0.5291 - val_loss: 0.9528 - val_accuracy: 0.5404\n",
      "Epoch 86/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9789 - accuracy: 0.5287 - val_loss: 0.9486 - val_accuracy: 0.5418\n",
      "Epoch 87/200\n",
      "89/89 [==============================] - 0s 888us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9471 - val_accuracy: 0.5372\n",
      "Epoch 88/200\n",
      "89/89 [==============================] - 0s 888us/step - loss: 0.9797 - accuracy: 0.5282 - val_loss: 0.9536 - val_accuracy: 0.5464\n",
      "Epoch 89/200\n",
      "89/89 [==============================] - 0s 867us/step - loss: 0.9798 - accuracy: 0.5275 - val_loss: 0.9492 - val_accuracy: 0.5446\n",
      "Epoch 90/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9784 - accuracy: 0.5294 - val_loss: 0.9480 - val_accuracy: 0.5418\n",
      "Epoch 91/200\n",
      "89/89 [==============================] - 0s 900us/step - loss: 0.9789 - accuracy: 0.5280 - val_loss: 0.9506 - val_accuracy: 0.5423\n",
      "Epoch 92/200\n",
      "89/89 [==============================] - 0s 877us/step - loss: 0.9779 - accuracy: 0.5292 - val_loss: 0.9498 - val_accuracy: 0.5404\n",
      "Epoch 93/200\n",
      "89/89 [==============================] - 0s 933us/step - loss: 0.9799 - accuracy: 0.5275 - val_loss: 0.9487 - val_accuracy: 0.5418\n",
      "Epoch 94/200\n",
      "89/89 [==============================] - 0s 807us/step - loss: 0.9799 - accuracy: 0.5265 - val_loss: 0.9474 - val_accuracy: 0.5418\n",
      "Epoch 95/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9783 - accuracy: 0.5293 - val_loss: 0.9474 - val_accuracy: 0.5418\n",
      "Epoch 96/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9780 - accuracy: 0.5303 - val_loss: 0.9498 - val_accuracy: 0.5427\n",
      "Epoch 97/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9798 - accuracy: 0.5287 - val_loss: 0.9494 - val_accuracy: 0.5395\n",
      "Epoch 98/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9784 - accuracy: 0.5283 - val_loss: 0.9486 - val_accuracy: 0.5473\n",
      "Epoch 99/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9791 - accuracy: 0.5287 - val_loss: 0.9484 - val_accuracy: 0.5409\n",
      "Epoch 100/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9791 - accuracy: 0.5291 - val_loss: 0.9516 - val_accuracy: 0.5446\n",
      "Epoch 101/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9788 - accuracy: 0.5287 - val_loss: 0.9479 - val_accuracy: 0.5391\n",
      "Epoch 102/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9785 - accuracy: 0.5270 - val_loss: 0.9553 - val_accuracy: 0.5372\n",
      "Epoch 103/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9784 - accuracy: 0.5306 - val_loss: 0.9505 - val_accuracy: 0.5473\n",
      "Epoch 104/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9785 - accuracy: 0.5279 - val_loss: 0.9533 - val_accuracy: 0.5423\n",
      "Epoch 105/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9778 - accuracy: 0.5290 - val_loss: 0.9490 - val_accuracy: 0.5391\n",
      "Epoch 106/200\n",
      "89/89 [==============================] - 0s 814us/step - loss: 0.9782 - accuracy: 0.5282 - val_loss: 0.9505 - val_accuracy: 0.5414\n",
      "Epoch 107/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9780 - accuracy: 0.5275 - val_loss: 0.9490 - val_accuracy: 0.5391\n",
      "Epoch 108/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9783 - accuracy: 0.5291 - val_loss: 0.9470 - val_accuracy: 0.5381\n",
      "Epoch 109/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9787 - accuracy: 0.5296 - val_loss: 0.9504 - val_accuracy: 0.5455\n",
      "Epoch 110/200\n",
      "89/89 [==============================] - 0s 820us/step - loss: 0.9786 - accuracy: 0.5293 - val_loss: 0.9508 - val_accuracy: 0.5423\n",
      "Epoch 111/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9781 - accuracy: 0.5298 - val_loss: 0.9534 - val_accuracy: 0.5391\n",
      "Epoch 112/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9780 - accuracy: 0.5305 - val_loss: 0.9502 - val_accuracy: 0.5455\n",
      "Epoch 113/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9786 - accuracy: 0.5299 - val_loss: 0.9470 - val_accuracy: 0.5409\n",
      "Epoch 114/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9778 - accuracy: 0.5279 - val_loss: 0.9506 - val_accuracy: 0.5427\n",
      "Epoch 115/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9786 - accuracy: 0.5270 - val_loss: 0.9524 - val_accuracy: 0.5414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9784 - accuracy: 0.5275 - val_loss: 0.9504 - val_accuracy: 0.5464\n",
      "Epoch 117/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9792 - accuracy: 0.5292 - val_loss: 0.9499 - val_accuracy: 0.5446\n",
      "Epoch 118/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9779 - accuracy: 0.5283 - val_loss: 0.9497 - val_accuracy: 0.5432\n",
      "Epoch 119/200\n",
      "89/89 [==============================] - 0s 833us/step - loss: 0.9771 - accuracy: 0.5296 - val_loss: 0.9522 - val_accuracy: 0.5478\n",
      "Epoch 120/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9791 - accuracy: 0.5297 - val_loss: 0.9519 - val_accuracy: 0.5427\n",
      "Epoch 121/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9773 - accuracy: 0.5299 - val_loss: 0.9511 - val_accuracy: 0.5446\n",
      "Epoch 122/200\n",
      "89/89 [==============================] - 0s 804us/step - loss: 0.9781 - accuracy: 0.5287 - val_loss: 0.9459 - val_accuracy: 0.5464\n",
      "Epoch 123/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9783 - accuracy: 0.5277 - val_loss: 0.9498 - val_accuracy: 0.5427\n",
      "Epoch 124/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9782 - accuracy: 0.5304 - val_loss: 0.9570 - val_accuracy: 0.5391\n",
      "Epoch 125/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9780 - accuracy: 0.5277 - val_loss: 0.9480 - val_accuracy: 0.5409\n",
      "Epoch 126/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9787 - accuracy: 0.5284 - val_loss: 0.9471 - val_accuracy: 0.5432\n",
      "Epoch 127/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9775 - accuracy: 0.5284 - val_loss: 0.9489 - val_accuracy: 0.5450\n",
      "Epoch 128/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9788 - accuracy: 0.5288 - val_loss: 0.9501 - val_accuracy: 0.5437\n",
      "Epoch 129/200\n",
      "89/89 [==============================] - 0s 823us/step - loss: 0.9780 - accuracy: 0.5308 - val_loss: 0.9508 - val_accuracy: 0.5418\n",
      "Epoch 130/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9776 - accuracy: 0.5282 - val_loss: 0.9508 - val_accuracy: 0.5437\n",
      "Epoch 131/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9780 - accuracy: 0.5285 - val_loss: 0.9511 - val_accuracy: 0.5418\n",
      "Epoch 132/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9779 - accuracy: 0.5289 - val_loss: 0.9564 - val_accuracy: 0.5437\n",
      "Epoch 133/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9791 - accuracy: 0.5262 - val_loss: 0.9473 - val_accuracy: 0.5404\n",
      "Epoch 134/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9773 - accuracy: 0.5291 - val_loss: 0.9549 - val_accuracy: 0.5469\n",
      "Epoch 135/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9773 - accuracy: 0.5290 - val_loss: 0.9501 - val_accuracy: 0.5427\n",
      "Epoch 136/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9775 - accuracy: 0.5299 - val_loss: 0.9499 - val_accuracy: 0.5414\n",
      "Epoch 137/200\n",
      "89/89 [==============================] - 0s 820us/step - loss: 0.9777 - accuracy: 0.5289 - val_loss: 0.9463 - val_accuracy: 0.5418\n",
      "Epoch 138/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9782 - accuracy: 0.5308 - val_loss: 0.9555 - val_accuracy: 0.5455\n",
      "Epoch 139/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9776 - accuracy: 0.5287 - val_loss: 0.9531 - val_accuracy: 0.5423\n",
      "Epoch 140/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9773 - accuracy: 0.5292 - val_loss: 0.9476 - val_accuracy: 0.5414\n",
      "Epoch 141/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9778 - accuracy: 0.5285 - val_loss: 0.9500 - val_accuracy: 0.5455\n",
      "Epoch 142/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9779 - accuracy: 0.5289 - val_loss: 0.9512 - val_accuracy: 0.5409\n",
      "Epoch 143/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9777 - accuracy: 0.5303 - val_loss: 0.9516 - val_accuracy: 0.5404\n",
      "Epoch 144/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9774 - accuracy: 0.5291 - val_loss: 0.9491 - val_accuracy: 0.5418\n",
      "Epoch 145/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9784 - accuracy: 0.5302 - val_loss: 0.9533 - val_accuracy: 0.5427\n",
      "Epoch 146/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9773 - accuracy: 0.5297 - val_loss: 0.9483 - val_accuracy: 0.5446\n",
      "Epoch 147/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9784 - accuracy: 0.5286 - val_loss: 0.9524 - val_accuracy: 0.5409\n",
      "Epoch 148/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9779 - accuracy: 0.5295 - val_loss: 0.9526 - val_accuracy: 0.5446\n",
      "Epoch 149/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9778 - accuracy: 0.5297 - val_loss: 0.9505 - val_accuracy: 0.5432\n",
      "Epoch 150/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9770 - accuracy: 0.5293 - val_loss: 0.9537 - val_accuracy: 0.5455\n",
      "Epoch 151/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9779 - accuracy: 0.5295 - val_loss: 0.9529 - val_accuracy: 0.5423\n",
      "Epoch 152/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9773 - accuracy: 0.5283 - val_loss: 0.9469 - val_accuracy: 0.5404\n",
      "Epoch 153/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9775 - accuracy: 0.5296 - val_loss: 0.9472 - val_accuracy: 0.5386\n",
      "Epoch 154/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9773 - accuracy: 0.5299 - val_loss: 0.9588 - val_accuracy: 0.5404\n",
      "Epoch 155/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9775 - accuracy: 0.5284 - val_loss: 0.9496 - val_accuracy: 0.5423\n",
      "Epoch 156/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9778 - accuracy: 0.5286 - val_loss: 0.9541 - val_accuracy: 0.5432\n",
      "Epoch 157/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9484 - val_accuracy: 0.5400\n",
      "Epoch 158/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9768 - accuracy: 0.5301 - val_loss: 0.9566 - val_accuracy: 0.5409\n",
      "Epoch 159/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9773 - accuracy: 0.5304 - val_loss: 0.9547 - val_accuracy: 0.5432\n",
      "Epoch 160/200\n",
      "89/89 [==============================] - 0s 825us/step - loss: 0.9777 - accuracy: 0.5295 - val_loss: 0.9583 - val_accuracy: 0.5372\n",
      "Epoch 161/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9773 - accuracy: 0.5298 - val_loss: 0.9595 - val_accuracy: 0.5432\n",
      "Epoch 162/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9772 - accuracy: 0.5291 - val_loss: 0.9497 - val_accuracy: 0.5432\n",
      "Epoch 163/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9773 - accuracy: 0.5317 - val_loss: 0.9534 - val_accuracy: 0.5464\n",
      "Epoch 164/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9769 - accuracy: 0.5294 - val_loss: 0.9572 - val_accuracy: 0.5409\n",
      "Epoch 165/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9772 - accuracy: 0.5298 - val_loss: 0.9517 - val_accuracy: 0.5473\n",
      "Epoch 166/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9776 - accuracy: 0.5299 - val_loss: 0.9557 - val_accuracy: 0.5409\n",
      "Epoch 167/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9505 - val_accuracy: 0.5483\n",
      "Epoch 168/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9771 - accuracy: 0.5302 - val_loss: 0.9538 - val_accuracy: 0.5492\n",
      "Epoch 169/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9771 - accuracy: 0.5287 - val_loss: 0.9542 - val_accuracy: 0.5404\n",
      "Epoch 170/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9769 - accuracy: 0.5299 - val_loss: 0.9515 - val_accuracy: 0.5446\n",
      "Epoch 171/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9769 - accuracy: 0.5291 - val_loss: 0.9525 - val_accuracy: 0.5437\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 797us/step - loss: 0.9767 - accuracy: 0.5293 - val_loss: 0.9513 - val_accuracy: 0.5386\n",
      "Epoch 173/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9559 - val_accuracy: 0.5386\n",
      "Epoch 174/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9771 - accuracy: 0.5299 - val_loss: 0.9541 - val_accuracy: 0.5441\n",
      "Epoch 175/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9774 - accuracy: 0.5305 - val_loss: 0.9559 - val_accuracy: 0.5441\n",
      "Epoch 176/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9766 - accuracy: 0.5307 - val_loss: 0.9480 - val_accuracy: 0.5414\n",
      "Epoch 177/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9522 - val_accuracy: 0.5427\n",
      "Epoch 178/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9765 - accuracy: 0.5302 - val_loss: 0.9510 - val_accuracy: 0.5441\n",
      "Epoch 179/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9770 - accuracy: 0.5307 - val_loss: 0.9521 - val_accuracy: 0.5386\n",
      "Epoch 180/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9769 - accuracy: 0.5312 - val_loss: 0.9533 - val_accuracy: 0.5409\n",
      "Epoch 181/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9771 - accuracy: 0.5303 - val_loss: 0.9552 - val_accuracy: 0.5427\n",
      "Epoch 182/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9775 - accuracy: 0.5291 - val_loss: 0.9504 - val_accuracy: 0.5418\n",
      "Epoch 183/200\n",
      "89/89 [==============================] - 0s 831us/step - loss: 0.9766 - accuracy: 0.5311 - val_loss: 0.9520 - val_accuracy: 0.5455\n",
      "Epoch 184/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9772 - accuracy: 0.5314 - val_loss: 0.9561 - val_accuracy: 0.5404\n",
      "Epoch 185/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9768 - accuracy: 0.5303 - val_loss: 0.9500 - val_accuracy: 0.5432\n",
      "Epoch 186/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9555 - val_accuracy: 0.5460\n",
      "Epoch 187/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9771 - accuracy: 0.5296 - val_loss: 0.9572 - val_accuracy: 0.5400\n",
      "Epoch 188/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9770 - accuracy: 0.5303 - val_loss: 0.9528 - val_accuracy: 0.5409\n",
      "Epoch 189/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9761 - accuracy: 0.5299 - val_loss: 0.9537 - val_accuracy: 0.5455\n",
      "Epoch 190/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9776 - accuracy: 0.5299 - val_loss: 0.9620 - val_accuracy: 0.5432\n",
      "Epoch 191/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9767 - accuracy: 0.5303 - val_loss: 0.9619 - val_accuracy: 0.5409\n",
      "Epoch 192/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9766 - accuracy: 0.5284 - val_loss: 0.9582 - val_accuracy: 0.5400\n",
      "Epoch 193/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9764 - accuracy: 0.5312 - val_loss: 0.9523 - val_accuracy: 0.5446\n",
      "Epoch 194/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9763 - accuracy: 0.5317 - val_loss: 0.9525 - val_accuracy: 0.5437\n",
      "Epoch 195/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9761 - accuracy: 0.5297 - val_loss: 0.9599 - val_accuracy: 0.5427\n",
      "Epoch 196/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9768 - accuracy: 0.5303 - val_loss: 0.9560 - val_accuracy: 0.5455\n",
      "Epoch 197/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9766 - accuracy: 0.5295 - val_loss: 0.9571 - val_accuracy: 0.5414\n",
      "Epoch 198/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9759 - accuracy: 0.5303 - val_loss: 0.9578 - val_accuracy: 0.5409\n",
      "Epoch 199/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9768 - accuracy: 0.5299 - val_loss: 0.9551 - val_accuracy: 0.5418\n",
      "Epoch 200/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9759 - accuracy: 0.5296 - val_loss: 0.9597 - val_accuracy: 0.5418\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 360us/step - loss: 0.9754 - accuracy: 0.5327\n",
      "Accuracy : 0.5327035784721375\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9597 - accuracy: 0.5418\n",
      "Accuracy : 0.5418198704719543\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.0670 - accuracy: 0.4475 - val_loss: 1.0597 - val_accuracy: 0.4600\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 0s 973us/step - loss: 1.0567 - accuracy: 0.4600 - val_loss: 1.0541 - val_accuracy: 0.4600\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 1.0479 - accuracy: 0.4600 - val_loss: 1.0440 - val_accuracy: 0.4600\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 1.0324 - accuracy: 0.4711 - val_loss: 1.0317 - val_accuracy: 0.4600\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 1.0138 - accuracy: 0.5095 - val_loss: 1.0101 - val_accuracy: 0.5087\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 1.0027 - accuracy: 0.5148 - val_loss: 1.0040 - val_accuracy: 0.5051\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 0s 788us/step - loss: 0.9970 - accuracy: 0.5163 - val_loss: 1.0008 - val_accuracy: 0.5064\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9949 - accuracy: 0.5171 - val_loss: 0.9966 - val_accuracy: 0.5078\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9922 - accuracy: 0.5163 - val_loss: 0.9932 - val_accuracy: 0.5078\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9918 - accuracy: 0.5176 - val_loss: 0.9958 - val_accuracy: 0.5124\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9898 - accuracy: 0.5171 - val_loss: 1.0025 - val_accuracy: 0.5106\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9899 - accuracy: 0.5161 - val_loss: 0.9863 - val_accuracy: 0.5142\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9888 - accuracy: 0.5204 - val_loss: 0.9885 - val_accuracy: 0.5115\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9876 - accuracy: 0.5207 - val_loss: 0.9892 - val_accuracy: 0.5124\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 0s 793us/step - loss: 0.9877 - accuracy: 0.5191 - val_loss: 0.9934 - val_accuracy: 0.5037\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 0s 776us/step - loss: 0.9872 - accuracy: 0.5218 - val_loss: 0.9882 - val_accuracy: 0.5165\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9871 - accuracy: 0.5198 - val_loss: 0.9908 - val_accuracy: 0.5097\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9862 - accuracy: 0.5219 - val_loss: 0.9911 - val_accuracy: 0.5147\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9870 - accuracy: 0.5219 - val_loss: 0.9864 - val_accuracy: 0.5161\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9856 - accuracy: 0.5218 - val_loss: 0.9841 - val_accuracy: 0.5147\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9850 - accuracy: 0.5232 - val_loss: 0.9842 - val_accuracy: 0.5170\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9862 - accuracy: 0.5212 - val_loss: 0.9884 - val_accuracy: 0.5152\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9850 - accuracy: 0.5211 - val_loss: 0.9849 - val_accuracy: 0.5156\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9854 - accuracy: 0.5222 - val_loss: 0.9892 - val_accuracy: 0.5152\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9857 - accuracy: 0.5246 - val_loss: 0.9902 - val_accuracy: 0.5069\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9842 - accuracy: 0.5236 - val_loss: 0.9853 - val_accuracy: 0.5156\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 810us/step - loss: 0.9839 - accuracy: 0.5249 - val_loss: 0.9859 - val_accuracy: 0.5152\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9833 - accuracy: 0.5235 - val_loss: 0.9859 - val_accuracy: 0.5156\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9837 - accuracy: 0.5248 - val_loss: 0.9876 - val_accuracy: 0.5165\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9846 - accuracy: 0.5241 - val_loss: 0.9838 - val_accuracy: 0.5198\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9826 - accuracy: 0.5242 - val_loss: 0.9815 - val_accuracy: 0.5188\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9829 - accuracy: 0.5253 - val_loss: 0.9853 - val_accuracy: 0.5193\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9835 - accuracy: 0.5232 - val_loss: 0.9864 - val_accuracy: 0.5161\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9834 - accuracy: 0.5260 - val_loss: 0.9826 - val_accuracy: 0.5193\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9826 - accuracy: 0.5252 - val_loss: 0.9831 - val_accuracy: 0.5234\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9817 - accuracy: 0.5259 - val_loss: 0.9847 - val_accuracy: 0.5175\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9828 - accuracy: 0.5255 - val_loss: 0.9881 - val_accuracy: 0.5184\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 0s 829us/step - loss: 0.9815 - accuracy: 0.5267 - val_loss: 0.9886 - val_accuracy: 0.5129\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9824 - accuracy: 0.5243 - val_loss: 0.9892 - val_accuracy: 0.5074\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9820 - accuracy: 0.5242 - val_loss: 0.9808 - val_accuracy: 0.5234\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9814 - accuracy: 0.5256 - val_loss: 0.9837 - val_accuracy: 0.5188\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9813 - accuracy: 0.5259 - val_loss: 0.9824 - val_accuracy: 0.5221\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9817 - accuracy: 0.5284 - val_loss: 0.9856 - val_accuracy: 0.5221\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9819 - accuracy: 0.5268 - val_loss: 0.9805 - val_accuracy: 0.5188\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9808 - accuracy: 0.5274 - val_loss: 0.9794 - val_accuracy: 0.5230\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9808 - accuracy: 0.5263 - val_loss: 0.9816 - val_accuracy: 0.5170\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9806 - accuracy: 0.5273 - val_loss: 0.9815 - val_accuracy: 0.5211\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9799 - accuracy: 0.5288 - val_loss: 0.9825 - val_accuracy: 0.5161\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9817 - accuracy: 0.5261 - val_loss: 0.9847 - val_accuracy: 0.5211\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9806 - accuracy: 0.5281 - val_loss: 0.9814 - val_accuracy: 0.5193\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9803 - accuracy: 0.5278 - val_loss: 0.9814 - val_accuracy: 0.5207\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9813 - accuracy: 0.5296 - val_loss: 0.9815 - val_accuracy: 0.5234\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9804 - accuracy: 0.5272 - val_loss: 0.9869 - val_accuracy: 0.5188\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9803 - accuracy: 0.5282 - val_loss: 0.9780 - val_accuracy: 0.5230\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9796 - accuracy: 0.5276 - val_loss: 0.9804 - val_accuracy: 0.5221\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9800 - accuracy: 0.5281 - val_loss: 0.9853 - val_accuracy: 0.5207\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9797 - accuracy: 0.5287 - val_loss: 0.9803 - val_accuracy: 0.5257\n",
      "Epoch 58/200\n",
      "89/89 [==============================] - 0s 786us/step - loss: 0.9802 - accuracy: 0.5287 - val_loss: 0.9821 - val_accuracy: 0.5211\n",
      "Epoch 59/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9808 - accuracy: 0.5267 - val_loss: 0.9814 - val_accuracy: 0.5207\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9793 - accuracy: 0.5299 - val_loss: 0.9795 - val_accuracy: 0.5239\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9790 - accuracy: 0.5292 - val_loss: 0.9824 - val_accuracy: 0.5253\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9805 - accuracy: 0.5275 - val_loss: 0.9840 - val_accuracy: 0.5221\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9796 - accuracy: 0.5281 - val_loss: 0.9824 - val_accuracy: 0.5257\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9807 - accuracy: 0.5279 - val_loss: 0.9800 - val_accuracy: 0.5234\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9800 - accuracy: 0.5275 - val_loss: 0.9790 - val_accuracy: 0.5207\n",
      "Epoch 66/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9796 - accuracy: 0.5293 - val_loss: 0.9797 - val_accuracy: 0.5234\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9790 - accuracy: 0.5297 - val_loss: 0.9787 - val_accuracy: 0.5234\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9791 - accuracy: 0.5295 - val_loss: 0.9808 - val_accuracy: 0.5253\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9804 - accuracy: 0.5298 - val_loss: 0.9807 - val_accuracy: 0.5239\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9797 - accuracy: 0.5267 - val_loss: 0.9788 - val_accuracy: 0.5221\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9788 - accuracy: 0.5292 - val_loss: 0.9784 - val_accuracy: 0.5239\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9781 - accuracy: 0.5304 - val_loss: 0.9790 - val_accuracy: 0.5234\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9795 - accuracy: 0.5294 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9787 - accuracy: 0.5291 - val_loss: 0.9814 - val_accuracy: 0.5271\n",
      "Epoch 75/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9788 - accuracy: 0.5291 - val_loss: 0.9793 - val_accuracy: 0.5239\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 0s 804us/step - loss: 0.9782 - accuracy: 0.5293 - val_loss: 0.9782 - val_accuracy: 0.5267\n",
      "Epoch 77/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9785 - accuracy: 0.5296 - val_loss: 0.9806 - val_accuracy: 0.5248\n",
      "Epoch 78/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9783 - accuracy: 0.5302 - val_loss: 0.9785 - val_accuracy: 0.5257\n",
      "Epoch 79/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9782 - accuracy: 0.5300 - val_loss: 0.9833 - val_accuracy: 0.5221\n",
      "Epoch 80/200\n",
      "89/89 [==============================] - 0s 818us/step - loss: 0.9792 - accuracy: 0.5287 - val_loss: 0.9832 - val_accuracy: 0.5239\n",
      "Epoch 81/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9783 - accuracy: 0.5300 - val_loss: 0.9790 - val_accuracy: 0.5216\n",
      "Epoch 82/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9786 - accuracy: 0.5300 - val_loss: 0.9795 - val_accuracy: 0.5253\n",
      "Epoch 83/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9795 - accuracy: 0.5283 - val_loss: 0.9808 - val_accuracy: 0.5239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9794 - accuracy: 0.5297 - val_loss: 0.9776 - val_accuracy: 0.5239\n",
      "Epoch 85/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9787 - accuracy: 0.5302 - val_loss: 0.9805 - val_accuracy: 0.5257\n",
      "Epoch 86/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9778 - accuracy: 0.5297 - val_loss: 0.9790 - val_accuracy: 0.5244\n",
      "Epoch 87/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9782 - accuracy: 0.5296 - val_loss: 0.9794 - val_accuracy: 0.5239\n",
      "Epoch 88/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9780 - accuracy: 0.5296 - val_loss: 0.9773 - val_accuracy: 0.5257\n",
      "Epoch 89/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9781 - accuracy: 0.5289 - val_loss: 0.9791 - val_accuracy: 0.5188\n",
      "Epoch 90/200\n",
      "89/89 [==============================] - 0s 866us/step - loss: 0.9779 - accuracy: 0.5292 - val_loss: 0.9853 - val_accuracy: 0.5244\n",
      "Epoch 91/200\n",
      "89/89 [==============================] - 0s 867us/step - loss: 0.9789 - accuracy: 0.5303 - val_loss: 0.9789 - val_accuracy: 0.5253\n",
      "Epoch 92/200\n",
      "89/89 [==============================] - 0s 888us/step - loss: 0.9794 - accuracy: 0.5308 - val_loss: 0.9782 - val_accuracy: 0.5253\n",
      "Epoch 93/200\n",
      "89/89 [==============================] - 0s 888us/step - loss: 0.9795 - accuracy: 0.5291 - val_loss: 0.9789 - val_accuracy: 0.5211\n",
      "Epoch 94/200\n",
      "89/89 [==============================] - 0s 956us/step - loss: 0.9781 - accuracy: 0.5309 - val_loss: 0.9787 - val_accuracy: 0.5257\n",
      "Epoch 95/200\n",
      "89/89 [==============================] - 0s 833us/step - loss: 0.9778 - accuracy: 0.5299 - val_loss: 0.9784 - val_accuracy: 0.5253\n",
      "Epoch 96/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9775 - accuracy: 0.5315 - val_loss: 0.9816 - val_accuracy: 0.5221\n",
      "Epoch 97/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9776 - accuracy: 0.5303 - val_loss: 0.9789 - val_accuracy: 0.5276\n",
      "Epoch 98/200\n",
      "89/89 [==============================] - 0s 793us/step - loss: 0.9774 - accuracy: 0.5303 - val_loss: 0.9790 - val_accuracy: 0.5262\n",
      "Epoch 99/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9781 - accuracy: 0.5299 - val_loss: 0.9851 - val_accuracy: 0.5262\n",
      "Epoch 100/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9785 - accuracy: 0.5295 - val_loss: 0.9811 - val_accuracy: 0.5248\n",
      "Epoch 101/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9785 - accuracy: 0.5307 - val_loss: 0.9784 - val_accuracy: 0.5225\n",
      "Epoch 102/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9785 - accuracy: 0.5312 - val_loss: 0.9786 - val_accuracy: 0.5248\n",
      "Epoch 103/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9787 - accuracy: 0.5303 - val_loss: 0.9798 - val_accuracy: 0.5234\n",
      "Epoch 104/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9789 - accuracy: 0.5297 - val_loss: 0.9769 - val_accuracy: 0.5216\n",
      "Epoch 105/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9787 - accuracy: 0.5308 - val_loss: 0.9785 - val_accuracy: 0.5239\n",
      "Epoch 106/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9790 - accuracy: 0.5288 - val_loss: 0.9775 - val_accuracy: 0.5239\n",
      "Epoch 107/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9778 - accuracy: 0.5304 - val_loss: 0.9774 - val_accuracy: 0.5244\n",
      "Epoch 108/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9779 - accuracy: 0.5305 - val_loss: 0.9852 - val_accuracy: 0.5170\n",
      "Epoch 109/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9786 - accuracy: 0.5305 - val_loss: 0.9795 - val_accuracy: 0.5193\n",
      "Epoch 110/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9772 - accuracy: 0.5309 - val_loss: 0.9787 - val_accuracy: 0.5267\n",
      "Epoch 111/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9777 - accuracy: 0.5297 - val_loss: 0.9776 - val_accuracy: 0.5207\n",
      "Epoch 112/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9784 - accuracy: 0.5302 - val_loss: 0.9811 - val_accuracy: 0.5257\n",
      "Epoch 113/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9776 - accuracy: 0.5314 - val_loss: 0.9775 - val_accuracy: 0.5244\n",
      "Epoch 114/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9769 - accuracy: 0.5298 - val_loss: 0.9772 - val_accuracy: 0.5271\n",
      "Epoch 115/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9777 - accuracy: 0.5305 - val_loss: 0.9779 - val_accuracy: 0.5234\n",
      "Epoch 116/200\n",
      "89/89 [==============================] - 0s 777us/step - loss: 0.9774 - accuracy: 0.5311 - val_loss: 0.9801 - val_accuracy: 0.5234\n",
      "Epoch 117/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9785 - accuracy: 0.5292 - val_loss: 0.9843 - val_accuracy: 0.5152\n",
      "Epoch 118/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9780 - accuracy: 0.5313 - val_loss: 0.9779 - val_accuracy: 0.5239\n",
      "Epoch 119/200\n",
      "89/89 [==============================] - 0s 822us/step - loss: 0.9782 - accuracy: 0.5287 - val_loss: 0.9811 - val_accuracy: 0.5216\n",
      "Epoch 120/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9777 - accuracy: 0.5306 - val_loss: 0.9786 - val_accuracy: 0.5198\n",
      "Epoch 121/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9782 - accuracy: 0.5295 - val_loss: 0.9774 - val_accuracy: 0.5253\n",
      "Epoch 122/200\n",
      "89/89 [==============================] - 0s 843us/step - loss: 0.9782 - accuracy: 0.5303 - val_loss: 0.9801 - val_accuracy: 0.5262\n",
      "Epoch 123/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9769 - accuracy: 0.5323 - val_loss: 0.9793 - val_accuracy: 0.5248\n",
      "Epoch 124/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9776 - accuracy: 0.5300 - val_loss: 0.9771 - val_accuracy: 0.5267\n",
      "Epoch 125/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9773 - accuracy: 0.5303 - val_loss: 0.9780 - val_accuracy: 0.5244\n",
      "Epoch 126/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9785 - accuracy: 0.5308 - val_loss: 0.9804 - val_accuracy: 0.5239\n",
      "Epoch 127/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9776 - accuracy: 0.5299 - val_loss: 0.9782 - val_accuracy: 0.5262\n",
      "Epoch 128/200\n",
      "89/89 [==============================] - 0s 795us/step - loss: 0.9777 - accuracy: 0.5299 - val_loss: 0.9770 - val_accuracy: 0.5267\n",
      "Epoch 129/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9777 - accuracy: 0.5308 - val_loss: 0.9767 - val_accuracy: 0.5271\n",
      "Epoch 130/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9774 - accuracy: 0.5299 - val_loss: 0.9793 - val_accuracy: 0.5248\n",
      "Epoch 131/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9780 - accuracy: 0.5298 - val_loss: 0.9808 - val_accuracy: 0.5248\n",
      "Epoch 132/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9770 - accuracy: 0.5305 - val_loss: 0.9806 - val_accuracy: 0.5244\n",
      "Epoch 133/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9766 - accuracy: 0.5314 - val_loss: 0.9768 - val_accuracy: 0.5248\n",
      "Epoch 134/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9769 - accuracy: 0.5307 - val_loss: 0.9794 - val_accuracy: 0.5248\n",
      "Epoch 135/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9783 - accuracy: 0.5312 - val_loss: 0.9809 - val_accuracy: 0.5239\n",
      "Epoch 136/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9779 - accuracy: 0.5315 - val_loss: 0.9773 - val_accuracy: 0.5253\n",
      "Epoch 137/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9777 - accuracy: 0.5298 - val_loss: 0.9814 - val_accuracy: 0.5244\n",
      "Epoch 138/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9783 - accuracy: 0.5295 - val_loss: 0.9777 - val_accuracy: 0.5267\n",
      "Epoch 139/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9773 - accuracy: 0.5318 - val_loss: 0.9827 - val_accuracy: 0.5170\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 787us/step - loss: 0.9772 - accuracy: 0.5307 - val_loss: 0.9778 - val_accuracy: 0.5253\n",
      "Epoch 141/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9771 - accuracy: 0.5317 - val_loss: 0.9773 - val_accuracy: 0.5234\n",
      "Epoch 142/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9790 - accuracy: 0.5308 - val_loss: 0.9797 - val_accuracy: 0.5234\n",
      "Epoch 143/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9766 - accuracy: 0.5319 - val_loss: 0.9816 - val_accuracy: 0.5262\n",
      "Epoch 144/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9780 - accuracy: 0.5307 - val_loss: 0.9774 - val_accuracy: 0.5267\n",
      "Epoch 145/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9774 - accuracy: 0.5315 - val_loss: 0.9786 - val_accuracy: 0.5225\n",
      "Epoch 146/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9774 - accuracy: 0.5315 - val_loss: 0.9802 - val_accuracy: 0.5244\n",
      "Epoch 147/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9772 - accuracy: 0.5312 - val_loss: 0.9787 - val_accuracy: 0.5280\n",
      "Epoch 148/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9773 - accuracy: 0.5313 - val_loss: 0.9802 - val_accuracy: 0.5248\n",
      "Epoch 149/200\n",
      "89/89 [==============================] - 0s 822us/step - loss: 0.9779 - accuracy: 0.5293 - val_loss: 0.9843 - val_accuracy: 0.5115\n",
      "Epoch 150/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9777 - accuracy: 0.5312 - val_loss: 0.9777 - val_accuracy: 0.5225\n",
      "Epoch 151/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9767 - accuracy: 0.5319 - val_loss: 0.9811 - val_accuracy: 0.5198\n",
      "Epoch 152/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9772 - accuracy: 0.5310 - val_loss: 0.9827 - val_accuracy: 0.5221\n",
      "Epoch 153/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9774 - accuracy: 0.5308 - val_loss: 0.9798 - val_accuracy: 0.5216\n",
      "Epoch 154/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9771 - accuracy: 0.5322 - val_loss: 0.9797 - val_accuracy: 0.5262\n",
      "Epoch 155/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9773 - accuracy: 0.5313 - val_loss: 0.9785 - val_accuracy: 0.5276\n",
      "Epoch 156/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9774 - accuracy: 0.5318 - val_loss: 0.9807 - val_accuracy: 0.5248\n",
      "Epoch 157/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9775 - accuracy: 0.5305 - val_loss: 0.9809 - val_accuracy: 0.5207\n",
      "Epoch 158/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9776 - accuracy: 0.5306 - val_loss: 0.9786 - val_accuracy: 0.5248\n",
      "Epoch 159/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9762 - accuracy: 0.5317 - val_loss: 0.9818 - val_accuracy: 0.5239\n",
      "Epoch 160/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9773 - accuracy: 0.5306 - val_loss: 0.9787 - val_accuracy: 0.5267\n",
      "Epoch 161/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9770 - accuracy: 0.5309 - val_loss: 0.9803 - val_accuracy: 0.5253\n",
      "Epoch 162/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9767 - accuracy: 0.5313 - val_loss: 0.9802 - val_accuracy: 0.5267\n",
      "Epoch 163/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9781 - accuracy: 0.5318 - val_loss: 0.9814 - val_accuracy: 0.5257\n",
      "Epoch 164/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9781 - accuracy: 0.5297 - val_loss: 0.9776 - val_accuracy: 0.5225\n",
      "Epoch 165/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9780 - accuracy: 0.5294 - val_loss: 0.9784 - val_accuracy: 0.5244\n",
      "Epoch 166/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9771 - accuracy: 0.5310 - val_loss: 0.9781 - val_accuracy: 0.5221\n",
      "Epoch 167/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9766 - accuracy: 0.5317 - val_loss: 0.9796 - val_accuracy: 0.5244\n",
      "Epoch 168/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9764 - accuracy: 0.5317 - val_loss: 0.9786 - val_accuracy: 0.5239\n",
      "Epoch 169/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9773 - accuracy: 0.5314 - val_loss: 0.9842 - val_accuracy: 0.5083\n",
      "Epoch 170/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9773 - accuracy: 0.5306 - val_loss: 0.9807 - val_accuracy: 0.5253\n",
      "Epoch 171/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9770 - accuracy: 0.5321 - val_loss: 0.9766 - val_accuracy: 0.5257\n",
      "Epoch 172/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9768 - accuracy: 0.5318 - val_loss: 0.9817 - val_accuracy: 0.5253\n",
      "Epoch 173/200\n",
      "89/89 [==============================] - 0s 796us/step - loss: 0.9771 - accuracy: 0.5314 - val_loss: 0.9823 - val_accuracy: 0.5202\n",
      "Epoch 174/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9765 - accuracy: 0.5315 - val_loss: 0.9782 - val_accuracy: 0.5239\n",
      "Epoch 175/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9771 - accuracy: 0.5311 - val_loss: 0.9778 - val_accuracy: 0.5221\n",
      "Epoch 176/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9771 - accuracy: 0.5305 - val_loss: 0.9796 - val_accuracy: 0.5257\n",
      "Epoch 177/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9765 - accuracy: 0.5320 - val_loss: 0.9796 - val_accuracy: 0.5198\n",
      "Epoch 178/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9782 - accuracy: 0.5291 - val_loss: 0.9776 - val_accuracy: 0.5253\n",
      "Epoch 179/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9772 - accuracy: 0.5288 - val_loss: 0.9798 - val_accuracy: 0.5262\n",
      "Epoch 180/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9770 - accuracy: 0.5320 - val_loss: 0.9793 - val_accuracy: 0.5244\n",
      "Epoch 181/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9772 - accuracy: 0.5314 - val_loss: 0.9802 - val_accuracy: 0.5234\n",
      "Epoch 182/200\n",
      "89/89 [==============================] - 0s 793us/step - loss: 0.9764 - accuracy: 0.5318 - val_loss: 0.9789 - val_accuracy: 0.5253\n",
      "Epoch 183/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9765 - accuracy: 0.5320 - val_loss: 0.9838 - val_accuracy: 0.5262\n",
      "Epoch 184/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9773 - accuracy: 0.5300 - val_loss: 0.9822 - val_accuracy: 0.5248\n",
      "Epoch 185/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9762 - accuracy: 0.5321 - val_loss: 0.9815 - val_accuracy: 0.5239\n",
      "Epoch 186/200\n",
      "89/89 [==============================] - 0s 839us/step - loss: 0.9769 - accuracy: 0.5320 - val_loss: 0.9833 - val_accuracy: 0.5234\n",
      "Epoch 187/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9758 - accuracy: 0.5308 - val_loss: 0.9772 - val_accuracy: 0.5234\n",
      "Epoch 188/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9764 - accuracy: 0.5311 - val_loss: 0.9793 - val_accuracy: 0.5262\n",
      "Epoch 189/200\n",
      "89/89 [==============================] - 0s 785us/step - loss: 0.9765 - accuracy: 0.5304 - val_loss: 0.9778 - val_accuracy: 0.5267\n",
      "Epoch 190/200\n",
      "89/89 [==============================] - 0s 811us/step - loss: 0.9761 - accuracy: 0.5313 - val_loss: 0.9847 - val_accuracy: 0.5198\n",
      "Epoch 191/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9765 - accuracy: 0.5316 - val_loss: 0.9839 - val_accuracy: 0.5234\n",
      "Epoch 192/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9764 - accuracy: 0.5300 - val_loss: 0.9770 - val_accuracy: 0.5239\n",
      "Epoch 193/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9761 - accuracy: 0.5311 - val_loss: 0.9795 - val_accuracy: 0.5230\n",
      "Epoch 194/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9760 - accuracy: 0.5319 - val_loss: 0.9810 - val_accuracy: 0.5244\n",
      "Epoch 195/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9771 - accuracy: 0.5303 - val_loss: 0.9813 - val_accuracy: 0.5239\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 816us/step - loss: 0.9753 - accuracy: 0.5322 - val_loss: 0.9776 - val_accuracy: 0.5267\n",
      "Epoch 197/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9759 - accuracy: 0.5305 - val_loss: 0.9807 - val_accuracy: 0.5262\n",
      "Epoch 198/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9755 - accuracy: 0.5322 - val_loss: 0.9808 - val_accuracy: 0.5239\n",
      "Epoch 199/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9759 - accuracy: 0.5320 - val_loss: 0.9792 - val_accuracy: 0.5257\n",
      "Epoch 200/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9765 - accuracy: 0.5302 - val_loss: 0.9817 - val_accuracy: 0.5262\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 359us/step - loss: 0.9750 - accuracy: 0.5327\n",
      "Accuracy : 0.5326525568962097\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9817 - accuracy: 0.5262\n",
      "Accuracy : 0.5261948704719543\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      "89/89 [==============================] - 0s 2ms/step - loss: 1.0849 - accuracy: 0.4185 - val_loss: 1.0596 - val_accuracy: 0.4600\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 0s 898us/step - loss: 1.0577 - accuracy: 0.4600 - val_loss: 1.0533 - val_accuracy: 0.4600\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 1.0515 - accuracy: 0.4600 - val_loss: 1.0458 - val_accuracy: 0.4600\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 1.0427 - accuracy: 0.4600 - val_loss: 1.0362 - val_accuracy: 0.4600\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 1.0328 - accuracy: 0.4611 - val_loss: 1.0221 - val_accuracy: 0.4600\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 1.0224 - accuracy: 0.4899 - val_loss: 1.0120 - val_accuracy: 0.5083\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 1.0152 - accuracy: 0.5077 - val_loss: 1.0019 - val_accuracy: 0.5257\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 1.0105 - accuracy: 0.5091 - val_loss: 0.9971 - val_accuracy: 0.5244\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 1.0102 - accuracy: 0.5036 - val_loss: 0.9968 - val_accuracy: 0.5244\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 0s 795us/step - loss: 1.0066 - accuracy: 0.5117 - val_loss: 0.9924 - val_accuracy: 0.5303\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 1.0036 - accuracy: 0.5128 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 1.0024 - accuracy: 0.5137 - val_loss: 0.9896 - val_accuracy: 0.5239\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 1.0015 - accuracy: 0.5144 - val_loss: 0.9919 - val_accuracy: 0.5280\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 1.0007 - accuracy: 0.5137 - val_loss: 0.9891 - val_accuracy: 0.5253\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 1.0007 - accuracy: 0.5152 - val_loss: 0.9865 - val_accuracy: 0.5188\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9984 - accuracy: 0.5163 - val_loss: 0.9841 - val_accuracy: 0.5276\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9975 - accuracy: 0.5172 - val_loss: 0.9848 - val_accuracy: 0.5257\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9980 - accuracy: 0.5148 - val_loss: 0.9838 - val_accuracy: 0.5280\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9983 - accuracy: 0.5162 - val_loss: 0.9843 - val_accuracy: 0.5253\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9967 - accuracy: 0.5162 - val_loss: 0.9868 - val_accuracy: 0.5280\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 0s 846us/step - loss: 0.9965 - accuracy: 0.5159 - val_loss: 0.9845 - val_accuracy: 0.5276\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9959 - accuracy: 0.5188 - val_loss: 0.9852 - val_accuracy: 0.5285\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9952 - accuracy: 0.5182 - val_loss: 0.9883 - val_accuracy: 0.5294\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9952 - accuracy: 0.5175 - val_loss: 0.9836 - val_accuracy: 0.5253\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9949 - accuracy: 0.5186 - val_loss: 0.9888 - val_accuracy: 0.5257\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9948 - accuracy: 0.5168 - val_loss: 0.9834 - val_accuracy: 0.5257\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9955 - accuracy: 0.5188 - val_loss: 0.9850 - val_accuracy: 0.5276\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9950 - accuracy: 0.5184 - val_loss: 0.9804 - val_accuracy: 0.5285\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9940 - accuracy: 0.5184 - val_loss: 0.9850 - val_accuracy: 0.5267\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9950 - accuracy: 0.5181 - val_loss: 0.9805 - val_accuracy: 0.5294\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9942 - accuracy: 0.5191 - val_loss: 0.9818 - val_accuracy: 0.5285\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9931 - accuracy: 0.5191 - val_loss: 0.9866 - val_accuracy: 0.5285\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9932 - accuracy: 0.5189 - val_loss: 0.9844 - val_accuracy: 0.5326\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9937 - accuracy: 0.5199 - val_loss: 0.9812 - val_accuracy: 0.5280\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9943 - accuracy: 0.5179 - val_loss: 0.9806 - val_accuracy: 0.5276\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9937 - accuracy: 0.5193 - val_loss: 0.9849 - val_accuracy: 0.5280\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9949 - accuracy: 0.5198 - val_loss: 0.9789 - val_accuracy: 0.5280\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9942 - accuracy: 0.5193 - val_loss: 0.9853 - val_accuracy: 0.5312\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9938 - accuracy: 0.5201 - val_loss: 0.9795 - val_accuracy: 0.5280\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9930 - accuracy: 0.5202 - val_loss: 0.9885 - val_accuracy: 0.5363\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9937 - accuracy: 0.5206 - val_loss: 0.9860 - val_accuracy: 0.5290\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9926 - accuracy: 0.5204 - val_loss: 0.9808 - val_accuracy: 0.5303\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9929 - accuracy: 0.5207 - val_loss: 0.9851 - val_accuracy: 0.5280\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9929 - accuracy: 0.5206 - val_loss: 0.9811 - val_accuracy: 0.5299\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9923 - accuracy: 0.5209 - val_loss: 0.9781 - val_accuracy: 0.5294\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9925 - accuracy: 0.5216 - val_loss: 0.9840 - val_accuracy: 0.5326\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9920 - accuracy: 0.5212 - val_loss: 0.9805 - val_accuracy: 0.5322\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9934 - accuracy: 0.5222 - val_loss: 0.9790 - val_accuracy: 0.5276\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9940 - accuracy: 0.5208 - val_loss: 0.9825 - val_accuracy: 0.5312\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9922 - accuracy: 0.5227 - val_loss: 0.9812 - val_accuracy: 0.5294\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 797us/step - loss: 0.9924 - accuracy: 0.5241 - val_loss: 0.9828 - val_accuracy: 0.5299\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9924 - accuracy: 0.5219 - val_loss: 0.9802 - val_accuracy: 0.5303\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9921 - accuracy: 0.5221 - val_loss: 0.9953 - val_accuracy: 0.5280\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9924 - accuracy: 0.5232 - val_loss: 0.9817 - val_accuracy: 0.5294\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9911 - accuracy: 0.5225 - val_loss: 0.9780 - val_accuracy: 0.5303\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9916 - accuracy: 0.5230 - val_loss: 0.9775 - val_accuracy: 0.5308\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9917 - accuracy: 0.5235 - val_loss: 0.9855 - val_accuracy: 0.5285\n",
      "Epoch 58/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9916 - accuracy: 0.5226 - val_loss: 0.9833 - val_accuracy: 0.5317\n",
      "Epoch 59/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9924 - accuracy: 0.5201 - val_loss: 0.9798 - val_accuracy: 0.5285\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9919 - accuracy: 0.5257 - val_loss: 0.9842 - val_accuracy: 0.5331\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9918 - accuracy: 0.5232 - val_loss: 0.9789 - val_accuracy: 0.5285\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 0s 828us/step - loss: 0.9915 - accuracy: 0.5226 - val_loss: 0.9807 - val_accuracy: 0.5271\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9907 - accuracy: 0.5237 - val_loss: 0.9851 - val_accuracy: 0.5312\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9918 - accuracy: 0.5237 - val_loss: 0.9797 - val_accuracy: 0.5276\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9911 - accuracy: 0.5235 - val_loss: 0.9834 - val_accuracy: 0.5271\n",
      "Epoch 66/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9917 - accuracy: 0.5240 - val_loss: 0.9795 - val_accuracy: 0.5299\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9914 - accuracy: 0.5234 - val_loss: 0.9862 - val_accuracy: 0.5317\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9912 - accuracy: 0.5228 - val_loss: 0.9885 - val_accuracy: 0.5294\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9915 - accuracy: 0.5230 - val_loss: 0.9817 - val_accuracy: 0.5331\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9903 - accuracy: 0.5245 - val_loss: 0.9908 - val_accuracy: 0.5303\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9913 - accuracy: 0.5236 - val_loss: 0.9854 - val_accuracy: 0.5335\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9906 - accuracy: 0.5247 - val_loss: 0.9779 - val_accuracy: 0.5317\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9903 - accuracy: 0.5257 - val_loss: 0.9778 - val_accuracy: 0.5312\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9907 - accuracy: 0.5240 - val_loss: 0.9836 - val_accuracy: 0.5322\n",
      "Epoch 75/200\n",
      "89/89 [==============================] - 0s 793us/step - loss: 0.9905 - accuracy: 0.5240 - val_loss: 0.9790 - val_accuracy: 0.5308\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9907 - accuracy: 0.5257 - val_loss: 0.9829 - val_accuracy: 0.5326\n",
      "Epoch 77/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9912 - accuracy: 0.5255 - val_loss: 0.9765 - val_accuracy: 0.5322\n",
      "Epoch 78/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9902 - accuracy: 0.5262 - val_loss: 0.9860 - val_accuracy: 0.5377\n",
      "Epoch 79/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9902 - accuracy: 0.5244 - val_loss: 0.9856 - val_accuracy: 0.5326\n",
      "Epoch 80/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9894 - accuracy: 0.5251 - val_loss: 0.9829 - val_accuracy: 0.5354\n",
      "Epoch 81/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9898 - accuracy: 0.5245 - val_loss: 0.9818 - val_accuracy: 0.5345\n",
      "Epoch 82/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9902 - accuracy: 0.5250 - val_loss: 0.9826 - val_accuracy: 0.5358\n",
      "Epoch 83/200\n",
      "89/89 [==============================] - 0s 812us/step - loss: 0.9908 - accuracy: 0.5250 - val_loss: 0.9785 - val_accuracy: 0.5349\n",
      "Epoch 84/200\n",
      "89/89 [==============================] - 0s 806us/step - loss: 0.9900 - accuracy: 0.5274 - val_loss: 0.9811 - val_accuracy: 0.5317\n",
      "Epoch 85/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9900 - accuracy: 0.5252 - val_loss: 0.9800 - val_accuracy: 0.5354\n",
      "Epoch 86/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9905 - accuracy: 0.5255 - val_loss: 0.9806 - val_accuracy: 0.5354\n",
      "Epoch 87/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9899 - accuracy: 0.5257 - val_loss: 0.9803 - val_accuracy: 0.5354\n",
      "Epoch 88/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9899 - accuracy: 0.5260 - val_loss: 0.9784 - val_accuracy: 0.5358\n",
      "Epoch 89/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9898 - accuracy: 0.5263 - val_loss: 0.9756 - val_accuracy: 0.5354\n",
      "Epoch 90/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9898 - accuracy: 0.5260 - val_loss: 0.9779 - val_accuracy: 0.5354\n",
      "Epoch 91/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9901 - accuracy: 0.5265 - val_loss: 0.9791 - val_accuracy: 0.5363\n",
      "Epoch 92/200\n",
      "89/89 [==============================] - 0s 832us/step - loss: 0.9897 - accuracy: 0.5272 - val_loss: 0.9763 - val_accuracy: 0.5340\n",
      "Epoch 93/200\n",
      "89/89 [==============================] - 0s 842us/step - loss: 0.9890 - accuracy: 0.5255 - val_loss: 0.9790 - val_accuracy: 0.5285\n",
      "Epoch 94/200\n",
      "89/89 [==============================] - 0s 846us/step - loss: 0.9900 - accuracy: 0.5247 - val_loss: 0.9847 - val_accuracy: 0.5331\n",
      "Epoch 95/200\n",
      "89/89 [==============================] - 0s 855us/step - loss: 0.9897 - accuracy: 0.5270 - val_loss: 0.9797 - val_accuracy: 0.5363\n",
      "Epoch 96/200\n",
      "89/89 [==============================] - 0s 853us/step - loss: 0.9891 - accuracy: 0.5287 - val_loss: 0.9761 - val_accuracy: 0.5331\n",
      "Epoch 97/200\n",
      "89/89 [==============================] - 0s 835us/step - loss: 0.9889 - accuracy: 0.5271 - val_loss: 0.9758 - val_accuracy: 0.5312\n",
      "Epoch 98/200\n",
      "89/89 [==============================] - 0s 862us/step - loss: 0.9897 - accuracy: 0.5272 - val_loss: 0.9882 - val_accuracy: 0.5340\n",
      "Epoch 99/200\n",
      "89/89 [==============================] - 0s 846us/step - loss: 0.9898 - accuracy: 0.5272 - val_loss: 0.9771 - val_accuracy: 0.5354\n",
      "Epoch 100/200\n",
      "89/89 [==============================] - 0s 846us/step - loss: 0.9893 - accuracy: 0.5273 - val_loss: 0.9835 - val_accuracy: 0.5368\n",
      "Epoch 101/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9888 - accuracy: 0.5255 - val_loss: 0.9806 - val_accuracy: 0.5248\n",
      "Epoch 102/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9894 - accuracy: 0.5264 - val_loss: 0.9795 - val_accuracy: 0.5368\n",
      "Epoch 103/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9887 - accuracy: 0.5282 - val_loss: 0.9809 - val_accuracy: 0.5349\n",
      "Epoch 104/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9891 - accuracy: 0.5281 - val_loss: 0.9750 - val_accuracy: 0.5335\n",
      "Epoch 105/200\n",
      "89/89 [==============================] - 0s 831us/step - loss: 0.9885 - accuracy: 0.5265 - val_loss: 0.9776 - val_accuracy: 0.5358\n",
      "Epoch 106/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9891 - accuracy: 0.5264 - val_loss: 0.9762 - val_accuracy: 0.5244\n",
      "Epoch 107/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9894 - accuracy: 0.5270 - val_loss: 0.9762 - val_accuracy: 0.5331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9885 - accuracy: 0.5279 - val_loss: 0.9763 - val_accuracy: 0.5363\n",
      "Epoch 109/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9884 - accuracy: 0.5288 - val_loss: 0.9739 - val_accuracy: 0.5322\n",
      "Epoch 110/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9892 - accuracy: 0.5256 - val_loss: 0.9800 - val_accuracy: 0.5340\n",
      "Epoch 111/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9892 - accuracy: 0.5284 - val_loss: 0.9813 - val_accuracy: 0.5345\n",
      "Epoch 112/200\n",
      "89/89 [==============================] - 0s 804us/step - loss: 0.9878 - accuracy: 0.5299 - val_loss: 0.9742 - val_accuracy: 0.5312\n",
      "Epoch 113/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9892 - accuracy: 0.5262 - val_loss: 0.9779 - val_accuracy: 0.5326\n",
      "Epoch 114/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9885 - accuracy: 0.5285 - val_loss: 0.9746 - val_accuracy: 0.5335\n",
      "Epoch 115/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9880 - accuracy: 0.5279 - val_loss: 0.9753 - val_accuracy: 0.5326\n",
      "Epoch 116/200\n",
      "89/89 [==============================] - 0s 800us/step - loss: 0.9878 - accuracy: 0.5294 - val_loss: 0.9793 - val_accuracy: 0.5285\n",
      "Epoch 117/200\n",
      "89/89 [==============================] - 0s 818us/step - loss: 0.9888 - accuracy: 0.5294 - val_loss: 0.9784 - val_accuracy: 0.5335\n",
      "Epoch 118/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9882 - accuracy: 0.5284 - val_loss: 0.9750 - val_accuracy: 0.5340\n",
      "Epoch 119/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9878 - accuracy: 0.5286 - val_loss: 0.9763 - val_accuracy: 0.5340\n",
      "Epoch 120/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9880 - accuracy: 0.5288 - val_loss: 0.9781 - val_accuracy: 0.5312\n",
      "Epoch 121/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9892 - accuracy: 0.5287 - val_loss: 0.9745 - val_accuracy: 0.5354\n",
      "Epoch 122/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9881 - accuracy: 0.5290 - val_loss: 0.9812 - val_accuracy: 0.5345\n",
      "Epoch 123/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9885 - accuracy: 0.5289 - val_loss: 0.9892 - val_accuracy: 0.5340\n",
      "Epoch 124/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9878 - accuracy: 0.5300 - val_loss: 0.9859 - val_accuracy: 0.5345\n",
      "Epoch 125/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9878 - accuracy: 0.5271 - val_loss: 0.9764 - val_accuracy: 0.5340\n",
      "Epoch 126/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9887 - accuracy: 0.5287 - val_loss: 0.9722 - val_accuracy: 0.5335\n",
      "Epoch 127/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9881 - accuracy: 0.5288 - val_loss: 0.9732 - val_accuracy: 0.5326\n",
      "Epoch 128/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9887 - accuracy: 0.5296 - val_loss: 0.9787 - val_accuracy: 0.5354\n",
      "Epoch 129/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9880 - accuracy: 0.5292 - val_loss: 0.9758 - val_accuracy: 0.5349\n",
      "Epoch 130/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9876 - accuracy: 0.5294 - val_loss: 0.9773 - val_accuracy: 0.5340\n",
      "Epoch 131/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9881 - accuracy: 0.5280 - val_loss: 0.9759 - val_accuracy: 0.5345\n",
      "Epoch 132/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9877 - accuracy: 0.5287 - val_loss: 0.9822 - val_accuracy: 0.5354\n",
      "Epoch 133/200\n",
      "89/89 [==============================] - 0s 827us/step - loss: 0.9871 - accuracy: 0.5292 - val_loss: 0.9794 - val_accuracy: 0.5345\n",
      "Epoch 134/200\n",
      "89/89 [==============================] - 0s 791us/step - loss: 0.9873 - accuracy: 0.5283 - val_loss: 0.9769 - val_accuracy: 0.5322\n",
      "Epoch 135/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9867 - accuracy: 0.5308 - val_loss: 0.9827 - val_accuracy: 0.5285\n",
      "Epoch 136/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9884 - accuracy: 0.5272 - val_loss: 0.9764 - val_accuracy: 0.5349\n",
      "Epoch 137/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9878 - accuracy: 0.5285 - val_loss: 0.9852 - val_accuracy: 0.5349\n",
      "Epoch 138/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9875 - accuracy: 0.5311 - val_loss: 0.9732 - val_accuracy: 0.5345\n",
      "Epoch 139/200\n",
      "89/89 [==============================] - 0s 820us/step - loss: 0.9864 - accuracy: 0.5305 - val_loss: 0.9754 - val_accuracy: 0.5340\n",
      "Epoch 140/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9874 - accuracy: 0.5306 - val_loss: 0.9749 - val_accuracy: 0.5326\n",
      "Epoch 141/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9881 - accuracy: 0.5296 - val_loss: 0.9792 - val_accuracy: 0.5331\n",
      "Epoch 142/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9872 - accuracy: 0.5287 - val_loss: 0.9729 - val_accuracy: 0.5317\n",
      "Epoch 143/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9869 - accuracy: 0.5293 - val_loss: 0.9717 - val_accuracy: 0.5326\n",
      "Epoch 144/200\n",
      "89/89 [==============================] - 0s 809us/step - loss: 0.9876 - accuracy: 0.5300 - val_loss: 0.9819 - val_accuracy: 0.5340\n",
      "Epoch 145/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9870 - accuracy: 0.5313 - val_loss: 0.9757 - val_accuracy: 0.5331\n",
      "Epoch 146/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9868 - accuracy: 0.5309 - val_loss: 0.9881 - val_accuracy: 0.5290\n",
      "Epoch 147/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9871 - accuracy: 0.5300 - val_loss: 0.9813 - val_accuracy: 0.5317\n",
      "Epoch 148/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9873 - accuracy: 0.5300 - val_loss: 0.9734 - val_accuracy: 0.5340\n",
      "Epoch 149/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9874 - accuracy: 0.5309 - val_loss: 0.9757 - val_accuracy: 0.5345\n",
      "Epoch 150/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9867 - accuracy: 0.5306 - val_loss: 0.9725 - val_accuracy: 0.5345\n",
      "Epoch 151/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9873 - accuracy: 0.5297 - val_loss: 0.9725 - val_accuracy: 0.5349\n",
      "Epoch 152/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9865 - accuracy: 0.5295 - val_loss: 0.9728 - val_accuracy: 0.5349\n",
      "Epoch 153/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9870 - accuracy: 0.5295 - val_loss: 0.9751 - val_accuracy: 0.5335\n",
      "Epoch 154/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9864 - accuracy: 0.5302 - val_loss: 0.9774 - val_accuracy: 0.5345\n",
      "Epoch 155/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9861 - accuracy: 0.5306 - val_loss: 0.9723 - val_accuracy: 0.5331\n",
      "Epoch 156/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9864 - accuracy: 0.5311 - val_loss: 0.9727 - val_accuracy: 0.5331\n",
      "Epoch 157/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9865 - accuracy: 0.5295 - val_loss: 0.9732 - val_accuracy: 0.5335\n",
      "Epoch 158/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9866 - accuracy: 0.5295 - val_loss: 0.9793 - val_accuracy: 0.5331\n",
      "Epoch 159/200\n",
      "89/89 [==============================] - 0s 816us/step - loss: 0.9865 - accuracy: 0.5292 - val_loss: 0.9715 - val_accuracy: 0.5340\n",
      "Epoch 160/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9867 - accuracy: 0.5310 - val_loss: 0.9710 - val_accuracy: 0.5308\n",
      "Epoch 161/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9881 - accuracy: 0.5289 - val_loss: 0.9735 - val_accuracy: 0.5331\n",
      "Epoch 162/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9870 - accuracy: 0.5289 - val_loss: 0.9741 - val_accuracy: 0.5340\n",
      "Epoch 163/200\n",
      "89/89 [==============================] - 0s 799us/step - loss: 0.9869 - accuracy: 0.5311 - val_loss: 0.9786 - val_accuracy: 0.5340\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 794us/step - loss: 0.9866 - accuracy: 0.5308 - val_loss: 0.9743 - val_accuracy: 0.5349\n",
      "Epoch 165/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9864 - accuracy: 0.5299 - val_loss: 0.9742 - val_accuracy: 0.5326\n",
      "Epoch 166/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9860 - accuracy: 0.5299 - val_loss: 0.9731 - val_accuracy: 0.5317\n",
      "Epoch 167/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9857 - accuracy: 0.5323 - val_loss: 0.9719 - val_accuracy: 0.5335\n",
      "Epoch 168/200\n",
      "89/89 [==============================] - 0s 797us/step - loss: 0.9868 - accuracy: 0.5292 - val_loss: 0.9730 - val_accuracy: 0.5345\n",
      "Epoch 169/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9868 - accuracy: 0.5299 - val_loss: 0.9758 - val_accuracy: 0.5335\n",
      "Epoch 170/200\n",
      "89/89 [==============================] - 0s 790us/step - loss: 0.9858 - accuracy: 0.5299 - val_loss: 0.9737 - val_accuracy: 0.5340\n",
      "Epoch 171/200\n",
      "89/89 [==============================] - 0s 817us/step - loss: 0.9860 - accuracy: 0.5315 - val_loss: 0.9740 - val_accuracy: 0.5331\n",
      "Epoch 172/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9866 - accuracy: 0.5307 - val_loss: 0.9732 - val_accuracy: 0.5345\n",
      "Epoch 173/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9869 - accuracy: 0.5283 - val_loss: 0.9719 - val_accuracy: 0.5285\n",
      "Epoch 174/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9867 - accuracy: 0.5310 - val_loss: 0.9720 - val_accuracy: 0.5331\n",
      "Epoch 175/200\n",
      "89/89 [==============================] - 0s 824us/step - loss: 0.9871 - accuracy: 0.5303 - val_loss: 0.9751 - val_accuracy: 0.5326\n",
      "Epoch 176/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9859 - accuracy: 0.5303 - val_loss: 0.9721 - val_accuracy: 0.5322\n",
      "Epoch 177/200\n",
      "89/89 [==============================] - 0s 777us/step - loss: 0.9866 - accuracy: 0.5302 - val_loss: 0.9718 - val_accuracy: 0.5326\n",
      "Epoch 178/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9858 - accuracy: 0.5307 - val_loss: 0.9723 - val_accuracy: 0.5326\n",
      "Epoch 179/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9857 - accuracy: 0.5306 - val_loss: 0.9723 - val_accuracy: 0.5340\n",
      "Epoch 180/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9859 - accuracy: 0.5302 - val_loss: 0.9714 - val_accuracy: 0.5340\n",
      "Epoch 181/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9873 - accuracy: 0.5294 - val_loss: 0.9763 - val_accuracy: 0.5317\n",
      "Epoch 182/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9864 - accuracy: 0.5294 - val_loss: 0.9742 - val_accuracy: 0.5331\n",
      "Epoch 183/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9864 - accuracy: 0.5306 - val_loss: 0.9833 - val_accuracy: 0.5340\n",
      "Epoch 184/200\n",
      "89/89 [==============================] - 0s 782us/step - loss: 0.9860 - accuracy: 0.5307 - val_loss: 0.9705 - val_accuracy: 0.5322\n",
      "Epoch 185/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9860 - accuracy: 0.5314 - val_loss: 0.9718 - val_accuracy: 0.5340\n",
      "Epoch 186/200\n",
      "89/89 [==============================] - 0s 805us/step - loss: 0.9866 - accuracy: 0.5295 - val_loss: 0.9702 - val_accuracy: 0.5331\n",
      "Epoch 187/200\n",
      "89/89 [==============================] - 0s 810us/step - loss: 0.9869 - accuracy: 0.5303 - val_loss: 0.9741 - val_accuracy: 0.5345\n",
      "Epoch 188/200\n",
      "89/89 [==============================] - 0s 819us/step - loss: 0.9861 - accuracy: 0.5299 - val_loss: 0.9721 - val_accuracy: 0.5340\n",
      "Epoch 189/200\n",
      "89/89 [==============================] - 0s 821us/step - loss: 0.9853 - accuracy: 0.5310 - val_loss: 0.9763 - val_accuracy: 0.5326\n",
      "Epoch 190/200\n",
      "89/89 [==============================] - 0s 808us/step - loss: 0.9859 - accuracy: 0.5291 - val_loss: 0.9718 - val_accuracy: 0.5326\n",
      "Epoch 191/200\n",
      "89/89 [==============================] - 0s 783us/step - loss: 0.9854 - accuracy: 0.5324 - val_loss: 0.9745 - val_accuracy: 0.5322\n",
      "Epoch 192/200\n",
      "89/89 [==============================] - 0s 801us/step - loss: 0.9857 - accuracy: 0.5300 - val_loss: 0.9744 - val_accuracy: 0.5340\n",
      "Epoch 193/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9856 - accuracy: 0.5310 - val_loss: 0.9724 - val_accuracy: 0.5331\n",
      "Epoch 194/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9853 - accuracy: 0.5316 - val_loss: 0.9736 - val_accuracy: 0.5335\n",
      "Epoch 195/200\n",
      "89/89 [==============================] - 0s 802us/step - loss: 0.9853 - accuracy: 0.5320 - val_loss: 0.9752 - val_accuracy: 0.5331\n",
      "Epoch 196/200\n",
      "89/89 [==============================] - 0s 794us/step - loss: 0.9857 - accuracy: 0.5314 - val_loss: 0.9774 - val_accuracy: 0.5326\n",
      "Epoch 197/200\n",
      "89/89 [==============================] - 0s 787us/step - loss: 0.9853 - accuracy: 0.5312 - val_loss: 0.9772 - val_accuracy: 0.5322\n",
      "Epoch 198/200\n",
      "89/89 [==============================] - 0s 798us/step - loss: 0.9856 - accuracy: 0.5304 - val_loss: 0.9712 - val_accuracy: 0.5326\n",
      "Epoch 199/200\n",
      "89/89 [==============================] - 0s 804us/step - loss: 0.9853 - accuracy: 0.5313 - val_loss: 0.9750 - val_accuracy: 0.5340\n",
      "Epoch 200/200\n",
      "89/89 [==============================] - 0s 813us/step - loss: 0.9857 - accuracy: 0.5297 - val_loss: 0.9762 - val_accuracy: 0.5335\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 374us/step - loss: 0.9844 - accuracy: 0.5317\n",
      "Accuracy : 0.5316824316978455\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9762 - accuracy: 0.5335\n",
      "Accuracy : 0.5335478186607361\n",
      "\n",
      "The final train accuracy is:0.531118369102478 \n",
      "\n",
      "The final test accuracy is:0.5260325461626053 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data_3.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data = np.array(df.iloc[:,0:28])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "    \n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "    \n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (28,1)),\n",
    "        keras.layers.Dense(28,activation='sigmoid'),\n",
    "        keras.layers.Dense(28,activation='sigmoid'),\n",
    "        keras.layers.Dense(3,activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels,batch_size = 221, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confident-invalid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promising-nursing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legal-jersey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-closer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
