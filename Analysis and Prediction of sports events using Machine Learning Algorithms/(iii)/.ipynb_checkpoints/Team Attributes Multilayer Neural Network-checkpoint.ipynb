{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fixed-manitoba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "612/612 [==============================] - 0s 724us/step - loss: 1.0372 - accuracy: 0.4714 - val_loss: 1.0061 - val_accuracy: 0.5039\n",
      "Epoch 2/200\n",
      "612/612 [==============================] - 0s 535us/step - loss: 1.0002 - accuracy: 0.5109 - val_loss: 1.0076 - val_accuracy: 0.4998\n",
      "Epoch 3/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9960 - accuracy: 0.5118 - val_loss: 0.9983 - val_accuracy: 0.5071\n",
      "Epoch 4/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9915 - accuracy: 0.5186 - val_loss: 0.9974 - val_accuracy: 0.4989\n",
      "Epoch 5/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9927 - accuracy: 0.5167 - val_loss: 0.9948 - val_accuracy: 0.5145\n",
      "Epoch 6/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9908 - accuracy: 0.5180 - val_loss: 1.0023 - val_accuracy: 0.5145\n",
      "Epoch 7/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9923 - accuracy: 0.5172 - val_loss: 0.9973 - val_accuracy: 0.4989\n",
      "Epoch 8/200\n",
      "612/612 [==============================] - 0s 518us/step - loss: 0.9915 - accuracy: 0.5169 - val_loss: 1.0022 - val_accuracy: 0.5113\n",
      "Epoch 9/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9871 - accuracy: 0.5185 - val_loss: 0.9914 - val_accuracy: 0.5158\n",
      "Epoch 10/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9898 - accuracy: 0.5190 - val_loss: 0.9873 - val_accuracy: 0.5200\n",
      "Epoch 11/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9857 - accuracy: 0.5190 - val_loss: 0.9894 - val_accuracy: 0.5145\n",
      "Epoch 12/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9854 - accuracy: 0.5217 - val_loss: 0.9889 - val_accuracy: 0.5209\n",
      "Epoch 13/200\n",
      "612/612 [==============================] - 0s 521us/step - loss: 0.9854 - accuracy: 0.5209 - val_loss: 0.9910 - val_accuracy: 0.5255\n",
      "Epoch 14/200\n",
      "612/612 [==============================] - 0s 516us/step - loss: 0.9849 - accuracy: 0.5212 - val_loss: 0.9908 - val_accuracy: 0.5131\n",
      "Epoch 15/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9833 - accuracy: 0.5215 - val_loss: 0.9931 - val_accuracy: 0.5021\n",
      "Epoch 16/200\n",
      "612/612 [==============================] - 0s 588us/step - loss: 0.9858 - accuracy: 0.5186 - val_loss: 0.9864 - val_accuracy: 0.5241\n",
      "Epoch 17/200\n",
      "612/612 [==============================] - 0s 574us/step - loss: 0.9851 - accuracy: 0.5206 - val_loss: 1.0002 - val_accuracy: 0.5149\n",
      "Epoch 18/200\n",
      "612/612 [==============================] - 0s 559us/step - loss: 0.9833 - accuracy: 0.5242 - val_loss: 0.9914 - val_accuracy: 0.5145\n",
      "Epoch 19/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9842 - accuracy: 0.5245 - val_loss: 0.9921 - val_accuracy: 0.5136\n",
      "Epoch 20/200\n",
      "612/612 [==============================] - 0s 532us/step - loss: 0.9823 - accuracy: 0.5243 - val_loss: 0.9885 - val_accuracy: 0.5209\n",
      "Epoch 21/200\n",
      "612/612 [==============================] - 0s 531us/step - loss: 0.9847 - accuracy: 0.5233 - val_loss: 0.9885 - val_accuracy: 0.5168\n",
      "Epoch 22/200\n",
      "612/612 [==============================] - 0s 532us/step - loss: 0.9834 - accuracy: 0.5239 - val_loss: 0.9854 - val_accuracy: 0.5237\n",
      "Epoch 23/200\n",
      "612/612 [==============================] - 0s 533us/step - loss: 0.9845 - accuracy: 0.5261 - val_loss: 0.9915 - val_accuracy: 0.5090\n",
      "Epoch 24/200\n",
      "612/612 [==============================] - 0s 538us/step - loss: 0.9827 - accuracy: 0.5230 - val_loss: 0.9848 - val_accuracy: 0.5177\n",
      "Epoch 25/200\n",
      "612/612 [==============================] - 0s 533us/step - loss: 0.9831 - accuracy: 0.5233 - val_loss: 0.9915 - val_accuracy: 0.5177\n",
      "Epoch 26/200\n",
      "612/612 [==============================] - 0s 533us/step - loss: 0.9822 - accuracy: 0.5221 - val_loss: 0.9941 - val_accuracy: 0.5044\n",
      "Epoch 27/200\n",
      "612/612 [==============================] - 0s 531us/step - loss: 0.9839 - accuracy: 0.5220 - val_loss: 0.9844 - val_accuracy: 0.5255\n",
      "Epoch 28/200\n",
      "612/612 [==============================] - 0s 572us/step - loss: 0.9822 - accuracy: 0.5227 - val_loss: 0.9858 - val_accuracy: 0.5181\n",
      "Epoch 29/200\n",
      "612/612 [==============================] - 0s 539us/step - loss: 0.9830 - accuracy: 0.5245 - val_loss: 0.9894 - val_accuracy: 0.5140\n",
      "Epoch 30/200\n",
      "612/612 [==============================] - 0s 545us/step - loss: 0.9828 - accuracy: 0.5205 - val_loss: 0.9897 - val_accuracy: 0.5227\n",
      "Epoch 31/200\n",
      "612/612 [==============================] - 0s 535us/step - loss: 0.9810 - accuracy: 0.5234 - val_loss: 0.9869 - val_accuracy: 0.5250\n",
      "Epoch 32/200\n",
      "612/612 [==============================] - 0s 527us/step - loss: 0.9811 - accuracy: 0.5257 - val_loss: 0.9871 - val_accuracy: 0.5214\n",
      "Epoch 33/200\n",
      "612/612 [==============================] - 0s 528us/step - loss: 0.9804 - accuracy: 0.5226 - val_loss: 0.9929 - val_accuracy: 0.5177\n",
      "Epoch 34/200\n",
      "612/612 [==============================] - 0s 535us/step - loss: 0.9812 - accuracy: 0.5229 - val_loss: 0.9893 - val_accuracy: 0.5131\n",
      "Epoch 35/200\n",
      "612/612 [==============================] - 0s 528us/step - loss: 0.9812 - accuracy: 0.5226 - val_loss: 0.9876 - val_accuracy: 0.5232\n",
      "Epoch 36/200\n",
      "612/612 [==============================] - 0s 526us/step - loss: 0.9802 - accuracy: 0.5265 - val_loss: 0.9865 - val_accuracy: 0.5163\n",
      "Epoch 37/200\n",
      "612/612 [==============================] - 0s 556us/step - loss: 0.9803 - accuracy: 0.5239 - val_loss: 0.9816 - val_accuracy: 0.5246\n",
      "Epoch 38/200\n",
      "612/612 [==============================] - 0s 523us/step - loss: 0.9795 - accuracy: 0.5249 - val_loss: 0.9909 - val_accuracy: 0.5186\n",
      "Epoch 39/200\n",
      "612/612 [==============================] - 0s 527us/step - loss: 0.9831 - accuracy: 0.5214 - val_loss: 0.9932 - val_accuracy: 0.5172\n",
      "Epoch 40/200\n",
      "612/612 [==============================] - 0s 530us/step - loss: 0.9807 - accuracy: 0.5238 - val_loss: 0.9874 - val_accuracy: 0.5214\n",
      "Epoch 41/200\n",
      "612/612 [==============================] - 0s 514us/step - loss: 0.9822 - accuracy: 0.5247 - val_loss: 0.9932 - val_accuracy: 0.5209\n",
      "Epoch 42/200\n",
      "612/612 [==============================] - 0s 518us/step - loss: 0.9821 - accuracy: 0.5275 - val_loss: 0.9853 - val_accuracy: 0.5237\n",
      "Epoch 43/200\n",
      "612/612 [==============================] - 0s 527us/step - loss: 0.9803 - accuracy: 0.5251 - val_loss: 0.9901 - val_accuracy: 0.5204\n",
      "Epoch 44/200\n",
      "612/612 [==============================] - 0s 508us/step - loss: 0.9802 - accuracy: 0.5242 - val_loss: 0.9853 - val_accuracy: 0.5282\n",
      "Epoch 45/200\n",
      "612/612 [==============================] - 0s 538us/step - loss: 0.9806 - accuracy: 0.5261 - val_loss: 0.9899 - val_accuracy: 0.5186\n",
      "Epoch 46/200\n",
      "612/612 [==============================] - 0s 528us/step - loss: 0.9802 - accuracy: 0.5258 - val_loss: 0.9850 - val_accuracy: 0.5241\n",
      "Epoch 47/200\n",
      "612/612 [==============================] - 0s 533us/step - loss: 0.9815 - accuracy: 0.5274 - val_loss: 0.9924 - val_accuracy: 0.5177\n",
      "Epoch 48/200\n",
      "612/612 [==============================] - 0s 533us/step - loss: 0.9814 - accuracy: 0.5258 - val_loss: 0.9889 - val_accuracy: 0.5186\n",
      "Epoch 49/200\n",
      "612/612 [==============================] - 0s 533us/step - loss: 0.9810 - accuracy: 0.5257 - val_loss: 0.9873 - val_accuracy: 0.5191\n",
      "Epoch 50/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9804 - accuracy: 0.5263 - val_loss: 0.9907 - val_accuracy: 0.5122\n",
      "Epoch 51/200\n",
      "612/612 [==============================] - 0s 535us/step - loss: 0.9817 - accuracy: 0.5241 - val_loss: 0.9856 - val_accuracy: 0.5223\n",
      "Epoch 52/200\n",
      "612/612 [==============================] - 0s 521us/step - loss: 0.9817 - accuracy: 0.5226 - val_loss: 0.9837 - val_accuracy: 0.5113\n",
      "Epoch 53/200\n",
      "612/612 [==============================] - 0s 545us/step - loss: 0.9805 - accuracy: 0.5230 - val_loss: 0.9865 - val_accuracy: 0.5237\n",
      "Epoch 54/200\n",
      "612/612 [==============================] - 0s 535us/step - loss: 0.9807 - accuracy: 0.5249 - val_loss: 0.9875 - val_accuracy: 0.5223\n",
      "Epoch 55/200\n",
      "612/612 [==============================] - 0s 530us/step - loss: 0.9815 - accuracy: 0.5258 - val_loss: 0.9836 - val_accuracy: 0.5319\n",
      "Epoch 56/200\n",
      "612/612 [==============================] - 0s 537us/step - loss: 0.9786 - accuracy: 0.5289 - val_loss: 0.9856 - val_accuracy: 0.5204\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 0s 532us/step - loss: 0.9798 - accuracy: 0.5281 - val_loss: 0.9848 - val_accuracy: 0.5246\n",
      "Epoch 58/200\n",
      "612/612 [==============================] - 0s 529us/step - loss: 0.9787 - accuracy: 0.5260 - val_loss: 0.9827 - val_accuracy: 0.5250\n",
      "Epoch 59/200\n",
      "612/612 [==============================] - 0s 544us/step - loss: 0.9810 - accuracy: 0.5259 - val_loss: 0.9839 - val_accuracy: 0.5209\n",
      "Epoch 60/200\n",
      "612/612 [==============================] - 0s 510us/step - loss: 0.9795 - accuracy: 0.5270 - val_loss: 0.9891 - val_accuracy: 0.5214\n",
      "Epoch 61/200\n",
      "612/612 [==============================] - 0s 542us/step - loss: 0.9787 - accuracy: 0.5274 - val_loss: 0.9856 - val_accuracy: 0.5223\n",
      "Epoch 62/200\n",
      "612/612 [==============================] - 0s 539us/step - loss: 0.9793 - accuracy: 0.5265 - val_loss: 0.9900 - val_accuracy: 0.5108\n",
      "Epoch 63/200\n",
      "612/612 [==============================] - 0s 535us/step - loss: 0.9796 - accuracy: 0.5254 - val_loss: 0.9853 - val_accuracy: 0.5237\n",
      "Epoch 64/200\n",
      "612/612 [==============================] - 0s 541us/step - loss: 0.9797 - accuracy: 0.5264 - val_loss: 0.9837 - val_accuracy: 0.5282\n",
      "Epoch 65/200\n",
      "612/612 [==============================] - 0s 572us/step - loss: 0.9789 - accuracy: 0.5260 - val_loss: 0.9861 - val_accuracy: 0.5209\n",
      "Epoch 66/200\n",
      "612/612 [==============================] - 0s 540us/step - loss: 0.9796 - accuracy: 0.5277 - val_loss: 0.9831 - val_accuracy: 0.5218\n",
      "Epoch 67/200\n",
      "612/612 [==============================] - 0s 522us/step - loss: 0.9812 - accuracy: 0.5211 - val_loss: 0.9852 - val_accuracy: 0.5296\n",
      "Epoch 68/200\n",
      "612/612 [==============================] - 0s 495us/step - loss: 0.9786 - accuracy: 0.5222 - val_loss: 0.9850 - val_accuracy: 0.5195\n",
      "Epoch 69/200\n",
      "612/612 [==============================] - 0s 574us/step - loss: 0.9792 - accuracy: 0.5287 - val_loss: 0.9925 - val_accuracy: 0.5191\n",
      "Epoch 70/200\n",
      "612/612 [==============================] - 0s 510us/step - loss: 0.9792 - accuracy: 0.5272 - val_loss: 0.9862 - val_accuracy: 0.5195\n",
      "Epoch 71/200\n",
      "612/612 [==============================] - 0s 516us/step - loss: 0.9809 - accuracy: 0.5262 - val_loss: 0.9881 - val_accuracy: 0.5177\n",
      "Epoch 72/200\n",
      "612/612 [==============================] - 0s 532us/step - loss: 0.9801 - accuracy: 0.5261 - val_loss: 0.9874 - val_accuracy: 0.5113\n",
      "Epoch 73/200\n",
      "612/612 [==============================] - 0s 535us/step - loss: 0.9792 - accuracy: 0.5267 - val_loss: 0.9872 - val_accuracy: 0.5140\n",
      "Epoch 74/200\n",
      "612/612 [==============================] - 0s 536us/step - loss: 0.9793 - accuracy: 0.5260 - val_loss: 0.9903 - val_accuracy: 0.5186\n",
      "Epoch 75/200\n",
      "612/612 [==============================] - 0s 533us/step - loss: 0.9798 - accuracy: 0.5249 - val_loss: 0.9829 - val_accuracy: 0.5273\n",
      "Epoch 76/200\n",
      "612/612 [==============================] - 0s 532us/step - loss: 0.9795 - accuracy: 0.5269 - val_loss: 0.9849 - val_accuracy: 0.5246\n",
      "Epoch 77/200\n",
      "612/612 [==============================] - 0s 514us/step - loss: 0.9785 - accuracy: 0.5251 - val_loss: 0.9820 - val_accuracy: 0.5264\n",
      "Epoch 78/200\n",
      "612/612 [==============================] - 0s 495us/step - loss: 0.9785 - accuracy: 0.5266 - val_loss: 0.9891 - val_accuracy: 0.5241\n",
      "Epoch 79/200\n",
      "612/612 [==============================] - 0s 512us/step - loss: 0.9805 - accuracy: 0.5267 - val_loss: 0.9838 - val_accuracy: 0.5250\n",
      "Epoch 80/200\n",
      "612/612 [==============================] - 0s 515us/step - loss: 0.9806 - accuracy: 0.5282 - val_loss: 0.9926 - val_accuracy: 0.5214\n",
      "Epoch 81/200\n",
      "612/612 [==============================] - 0s 532us/step - loss: 0.9789 - accuracy: 0.5297 - val_loss: 0.9858 - val_accuracy: 0.5218\n",
      "Epoch 82/200\n",
      "612/612 [==============================] - 0s 554us/step - loss: 0.9788 - accuracy: 0.5301 - val_loss: 0.9845 - val_accuracy: 0.5209\n",
      "Epoch 83/200\n",
      "612/612 [==============================] - 0s 556us/step - loss: 0.9782 - accuracy: 0.5256 - val_loss: 0.9886 - val_accuracy: 0.5255\n",
      "Epoch 84/200\n",
      "612/612 [==============================] - 0s 545us/step - loss: 0.9786 - accuracy: 0.5259 - val_loss: 0.9933 - val_accuracy: 0.5278\n",
      "Epoch 85/200\n",
      "612/612 [==============================] - 0s 534us/step - loss: 0.9788 - accuracy: 0.5269 - val_loss: 0.9889 - val_accuracy: 0.5223\n",
      "Epoch 86/200\n",
      "612/612 [==============================] - 0s 528us/step - loss: 0.9774 - accuracy: 0.5282 - val_loss: 0.9843 - val_accuracy: 0.5223\n",
      "Epoch 87/200\n",
      "612/612 [==============================] - 0s 522us/step - loss: 0.9774 - accuracy: 0.5262 - val_loss: 0.9795 - val_accuracy: 0.5260\n",
      "Epoch 88/200\n",
      "612/612 [==============================] - 0s 547us/step - loss: 0.9782 - accuracy: 0.5270 - val_loss: 0.9827 - val_accuracy: 0.5301\n",
      "Epoch 89/200\n",
      "612/612 [==============================] - 0s 528us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9878 - val_accuracy: 0.5246\n",
      "Epoch 90/200\n",
      "612/612 [==============================] - 0s 525us/step - loss: 0.9765 - accuracy: 0.5288 - val_loss: 0.9846 - val_accuracy: 0.5260\n",
      "Epoch 91/200\n",
      "612/612 [==============================] - 0s 523us/step - loss: 0.9792 - accuracy: 0.5283 - val_loss: 0.9851 - val_accuracy: 0.5237\n",
      "Epoch 92/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9789 - accuracy: 0.5282 - val_loss: 0.9912 - val_accuracy: 0.5076\n",
      "Epoch 93/200\n",
      "612/612 [==============================] - 0s 515us/step - loss: 0.9799 - accuracy: 0.5262 - val_loss: 0.9881 - val_accuracy: 0.5191\n",
      "Epoch 94/200\n",
      "612/612 [==============================] - 0s 545us/step - loss: 0.9786 - accuracy: 0.5252 - val_loss: 0.9847 - val_accuracy: 0.5214\n",
      "Epoch 95/200\n",
      "612/612 [==============================] - 0s 528us/step - loss: 0.9777 - accuracy: 0.5279 - val_loss: 0.9830 - val_accuracy: 0.5315\n",
      "Epoch 96/200\n",
      "612/612 [==============================] - 0s 507us/step - loss: 0.9780 - accuracy: 0.5281 - val_loss: 0.9871 - val_accuracy: 0.5218\n",
      "Epoch 97/200\n",
      "612/612 [==============================] - 0s 554us/step - loss: 0.9802 - accuracy: 0.5272 - val_loss: 0.9865 - val_accuracy: 0.5200\n",
      "Epoch 98/200\n",
      "612/612 [==============================] - 0s 529us/step - loss: 0.9808 - accuracy: 0.5255 - val_loss: 0.9868 - val_accuracy: 0.5154\n",
      "Epoch 99/200\n",
      "612/612 [==============================] - 0s 523us/step - loss: 0.9809 - accuracy: 0.5251 - val_loss: 0.9878 - val_accuracy: 0.5145\n",
      "Epoch 100/200\n",
      "612/612 [==============================] - 0s 556us/step - loss: 0.9801 - accuracy: 0.5274 - val_loss: 0.9860 - val_accuracy: 0.5227\n",
      "Epoch 101/200\n",
      "612/612 [==============================] - 0s 581us/step - loss: 0.9782 - accuracy: 0.5277 - val_loss: 0.9867 - val_accuracy: 0.5260\n",
      "Epoch 102/200\n",
      "612/612 [==============================] - 0s 557us/step - loss: 0.9785 - accuracy: 0.5294 - val_loss: 0.9820 - val_accuracy: 0.5260\n",
      "Epoch 103/200\n",
      "612/612 [==============================] - 0s 557us/step - loss: 0.9784 - accuracy: 0.5301 - val_loss: 0.9886 - val_accuracy: 0.5191\n",
      "Epoch 104/200\n",
      "612/612 [==============================] - 0s 538us/step - loss: 0.9786 - accuracy: 0.5272 - val_loss: 0.9879 - val_accuracy: 0.5204\n",
      "Epoch 105/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9784 - accuracy: 0.5291 - val_loss: 0.9887 - val_accuracy: 0.5145\n",
      "Epoch 106/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9791 - accuracy: 0.5256 - val_loss: 0.9903 - val_accuracy: 0.5122\n",
      "Epoch 107/200\n",
      "612/612 [==============================] - 0s 518us/step - loss: 0.9790 - accuracy: 0.5263 - val_loss: 0.9852 - val_accuracy: 0.5237\n",
      "Epoch 108/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9774 - accuracy: 0.5306 - val_loss: 0.9831 - val_accuracy: 0.5282\n",
      "Epoch 109/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9785 - accuracy: 0.5287 - val_loss: 0.9840 - val_accuracy: 0.5264\n",
      "Epoch 110/200\n",
      "612/612 [==============================] - 0s 550us/step - loss: 0.9791 - accuracy: 0.5275 - val_loss: 0.9838 - val_accuracy: 0.5181\n",
      "Epoch 111/200\n",
      "612/612 [==============================] - 0s 509us/step - loss: 0.9787 - accuracy: 0.5297 - val_loss: 0.9831 - val_accuracy: 0.5269\n",
      "Epoch 112/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9798 - accuracy: 0.5277 - val_loss: 0.9920 - val_accuracy: 0.5062\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 0s 553us/step - loss: 0.9783 - accuracy: 0.5257 - val_loss: 0.9879 - val_accuracy: 0.5278\n",
      "Epoch 114/200\n",
      "612/612 [==============================] - 0s 556us/step - loss: 0.9796 - accuracy: 0.5268 - val_loss: 0.9880 - val_accuracy: 0.5181\n",
      "Epoch 115/200\n",
      "612/612 [==============================] - 0s 520us/step - loss: 0.9783 - accuracy: 0.5287 - val_loss: 0.9872 - val_accuracy: 0.5246\n",
      "Epoch 116/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9775 - accuracy: 0.5264 - val_loss: 0.9860 - val_accuracy: 0.5223\n",
      "Epoch 117/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9798 - accuracy: 0.5273 - val_loss: 0.9856 - val_accuracy: 0.5269\n",
      "Epoch 118/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9789 - accuracy: 0.5270 - val_loss: 0.9838 - val_accuracy: 0.5250\n",
      "Epoch 119/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9789 - accuracy: 0.5292 - val_loss: 0.9856 - val_accuracy: 0.5223\n",
      "Epoch 120/200\n",
      "612/612 [==============================] - 0s 545us/step - loss: 0.9761 - accuracy: 0.5307 - val_loss: 0.9849 - val_accuracy: 0.5214\n",
      "Epoch 121/200\n",
      "612/612 [==============================] - 0s 520us/step - loss: 0.9783 - accuracy: 0.5257 - val_loss: 0.9872 - val_accuracy: 0.5260\n",
      "Epoch 122/200\n",
      "612/612 [==============================] - 0s 571us/step - loss: 0.9783 - accuracy: 0.5297 - val_loss: 0.9851 - val_accuracy: 0.5278\n",
      "Epoch 123/200\n",
      "612/612 [==============================] - 0s 535us/step - loss: 0.9781 - accuracy: 0.5275 - val_loss: 0.9887 - val_accuracy: 0.5214\n",
      "Epoch 124/200\n",
      "612/612 [==============================] - 0s 526us/step - loss: 0.9773 - accuracy: 0.5278 - val_loss: 0.9819 - val_accuracy: 0.5269\n",
      "Epoch 125/200\n",
      "612/612 [==============================] - 0s 536us/step - loss: 0.9780 - accuracy: 0.5299 - val_loss: 0.9806 - val_accuracy: 0.5315\n",
      "Epoch 126/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9775 - accuracy: 0.5278 - val_loss: 0.9941 - val_accuracy: 0.5172\n",
      "Epoch 127/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9771 - accuracy: 0.5228 - val_loss: 0.9855 - val_accuracy: 0.5237\n",
      "Epoch 128/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9786 - accuracy: 0.5273 - val_loss: 0.9847 - val_accuracy: 0.5181\n",
      "Epoch 129/200\n",
      "612/612 [==============================] - 0s 506us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9899 - val_accuracy: 0.5227\n",
      "Epoch 130/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9779 - accuracy: 0.5278 - val_loss: 0.9834 - val_accuracy: 0.5264\n",
      "Epoch 131/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9844 - val_accuracy: 0.5158\n",
      "Epoch 132/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9833 - val_accuracy: 0.5305\n",
      "Epoch 133/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9778 - accuracy: 0.5297 - val_loss: 0.9884 - val_accuracy: 0.5232\n",
      "Epoch 134/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9763 - accuracy: 0.5285 - val_loss: 0.9806 - val_accuracy: 0.5241\n",
      "Epoch 135/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9779 - accuracy: 0.5277 - val_loss: 0.9843 - val_accuracy: 0.5269\n",
      "Epoch 136/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9778 - accuracy: 0.5276 - val_loss: 0.9823 - val_accuracy: 0.5237\n",
      "Epoch 137/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9782 - accuracy: 0.5260 - val_loss: 0.9809 - val_accuracy: 0.5237\n",
      "Epoch 138/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9815 - val_accuracy: 0.5282\n",
      "Epoch 139/200\n",
      "612/612 [==============================] - 0s 545us/step - loss: 0.9769 - accuracy: 0.5286 - val_loss: 0.9883 - val_accuracy: 0.5163\n",
      "Epoch 140/200\n",
      "612/612 [==============================] - 0s 518us/step - loss: 0.9778 - accuracy: 0.5282 - val_loss: 0.9867 - val_accuracy: 0.5264\n",
      "Epoch 141/200\n",
      "612/612 [==============================] - 0s 550us/step - loss: 0.9774 - accuracy: 0.5294 - val_loss: 0.9842 - val_accuracy: 0.5250\n",
      "Epoch 142/200\n",
      "612/612 [==============================] - 0s 509us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9852 - val_accuracy: 0.5191\n",
      "Epoch 143/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9788 - accuracy: 0.5267 - val_loss: 0.9833 - val_accuracy: 0.5250\n",
      "Epoch 144/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9847 - val_accuracy: 0.5246\n",
      "Epoch 145/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9779 - accuracy: 0.5286 - val_loss: 0.9848 - val_accuracy: 0.5255\n",
      "Epoch 146/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9834 - val_accuracy: 0.5278\n",
      "Epoch 147/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9788 - accuracy: 0.5280 - val_loss: 0.9806 - val_accuracy: 0.5301\n",
      "Epoch 148/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9822 - val_accuracy: 0.5218\n",
      "Epoch 149/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9782 - accuracy: 0.5282 - val_loss: 0.9827 - val_accuracy: 0.5232\n",
      "Epoch 150/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9778 - accuracy: 0.5275 - val_loss: 0.9820 - val_accuracy: 0.5292\n",
      "Epoch 151/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9777 - accuracy: 0.5280 - val_loss: 0.9871 - val_accuracy: 0.5223\n",
      "Epoch 152/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9761 - accuracy: 0.5266 - val_loss: 0.9845 - val_accuracy: 0.5260\n",
      "Epoch 153/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9763 - accuracy: 0.5285 - val_loss: 0.9857 - val_accuracy: 0.5237\n",
      "Epoch 154/200\n",
      "612/612 [==============================] - 0s 527us/step - loss: 0.9765 - accuracy: 0.5277 - val_loss: 0.9864 - val_accuracy: 0.5237\n",
      "Epoch 155/200\n",
      "612/612 [==============================] - 0s 510us/step - loss: 0.9786 - accuracy: 0.5281 - val_loss: 0.9836 - val_accuracy: 0.5278\n",
      "Epoch 156/200\n",
      "612/612 [==============================] - 0s 544us/step - loss: 0.9766 - accuracy: 0.5311 - val_loss: 0.9842 - val_accuracy: 0.5255\n",
      "Epoch 157/200\n",
      "612/612 [==============================] - 0s 518us/step - loss: 0.9764 - accuracy: 0.5291 - val_loss: 0.9891 - val_accuracy: 0.5296\n",
      "Epoch 158/200\n",
      "612/612 [==============================] - 0s 529us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9840 - val_accuracy: 0.5287\n",
      "Epoch 159/200\n",
      "612/612 [==============================] - 0s 534us/step - loss: 0.9767 - accuracy: 0.5293 - val_loss: 0.9875 - val_accuracy: 0.5255\n",
      "Epoch 160/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9771 - accuracy: 0.5263 - val_loss: 0.9810 - val_accuracy: 0.5273\n",
      "Epoch 161/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9772 - accuracy: 0.5291 - val_loss: 0.9838 - val_accuracy: 0.5191\n",
      "Epoch 162/200\n",
      "612/612 [==============================] - 0s 558us/step - loss: 0.9765 - accuracy: 0.5301 - val_loss: 0.9822 - val_accuracy: 0.5209\n",
      "Epoch 163/200\n",
      "612/612 [==============================] - 0s 571us/step - loss: 0.9769 - accuracy: 0.5257 - val_loss: 0.9837 - val_accuracy: 0.5200\n",
      "Epoch 164/200\n",
      "612/612 [==============================] - 0s 524us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9850 - val_accuracy: 0.5241\n",
      "Epoch 165/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9826 - val_accuracy: 0.5273\n",
      "Epoch 166/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9778 - accuracy: 0.5285 - val_loss: 0.9844 - val_accuracy: 0.5241\n",
      "Epoch 167/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9763 - accuracy: 0.5276 - val_loss: 0.9829 - val_accuracy: 0.5237\n",
      "Epoch 168/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9777 - accuracy: 0.5283 - val_loss: 0.9824 - val_accuracy: 0.5292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9765 - accuracy: 0.5291 - val_loss: 0.9873 - val_accuracy: 0.5204\n",
      "Epoch 170/200\n",
      "612/612 [==============================] - 0s 550us/step - loss: 0.9768 - accuracy: 0.5283 - val_loss: 0.9883 - val_accuracy: 0.5191\n",
      "Epoch 171/200\n",
      "612/612 [==============================] - 0s 510us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9896 - val_accuracy: 0.5255\n",
      "Epoch 172/200\n",
      "612/612 [==============================] - 0s 542us/step - loss: 0.9770 - accuracy: 0.5274 - val_loss: 0.9833 - val_accuracy: 0.5255\n",
      "Epoch 173/200\n",
      "612/612 [==============================] - 0s 522us/step - loss: 0.9770 - accuracy: 0.5283 - val_loss: 0.9841 - val_accuracy: 0.5250\n",
      "Epoch 174/200\n",
      "612/612 [==============================] - 0s 540us/step - loss: 0.9768 - accuracy: 0.5288 - val_loss: 0.9852 - val_accuracy: 0.5237\n",
      "Epoch 175/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9859 - val_accuracy: 0.5246\n",
      "Epoch 176/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9833 - val_accuracy: 0.5278\n",
      "Epoch 177/200\n",
      "612/612 [==============================] - 0s 526us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9840 - val_accuracy: 0.5282\n",
      "Epoch 178/200\n",
      "612/612 [==============================] - 0s 511us/step - loss: 0.9772 - accuracy: 0.5296 - val_loss: 0.9824 - val_accuracy: 0.5278\n",
      "Epoch 179/200\n",
      "612/612 [==============================] - 0s 546us/step - loss: 0.9777 - accuracy: 0.5310 - val_loss: 0.9838 - val_accuracy: 0.5246\n",
      "Epoch 180/200\n",
      "612/612 [==============================] - 0s 516us/step - loss: 0.9764 - accuracy: 0.5309 - val_loss: 0.9859 - val_accuracy: 0.5241\n",
      "Epoch 181/200\n",
      "612/612 [==============================] - 0s 544us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9869 - val_accuracy: 0.5278\n",
      "Epoch 182/200\n",
      "612/612 [==============================] - 0s 518us/step - loss: 0.9779 - accuracy: 0.5298 - val_loss: 0.9850 - val_accuracy: 0.5227\n",
      "Epoch 183/200\n",
      "612/612 [==============================] - 0s 548us/step - loss: 0.9785 - accuracy: 0.5271 - val_loss: 0.9859 - val_accuracy: 0.5273\n",
      "Epoch 184/200\n",
      "612/612 [==============================] - 0s 510us/step - loss: 0.9792 - accuracy: 0.5253 - val_loss: 0.9871 - val_accuracy: 0.5227\n",
      "Epoch 185/200\n",
      "612/612 [==============================] - 0s 548us/step - loss: 0.9783 - accuracy: 0.5303 - val_loss: 0.9873 - val_accuracy: 0.5204\n",
      "Epoch 186/200\n",
      "612/612 [==============================] - 0s 514us/step - loss: 0.9776 - accuracy: 0.5293 - val_loss: 0.9950 - val_accuracy: 0.5067\n",
      "Epoch 187/200\n",
      "612/612 [==============================] - 0s 542us/step - loss: 0.9770 - accuracy: 0.5304 - val_loss: 0.9838 - val_accuracy: 0.5273\n",
      "Epoch 188/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9776 - accuracy: 0.5277 - val_loss: 0.9868 - val_accuracy: 0.5250\n",
      "Epoch 189/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9774 - accuracy: 0.5289 - val_loss: 0.9842 - val_accuracy: 0.5177\n",
      "Epoch 190/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9784 - accuracy: 0.5278 - val_loss: 0.9815 - val_accuracy: 0.5273\n",
      "Epoch 191/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9781 - accuracy: 0.5287 - val_loss: 0.9837 - val_accuracy: 0.5200\n",
      "Epoch 192/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9776 - accuracy: 0.5300 - val_loss: 0.9866 - val_accuracy: 0.5214\n",
      "Epoch 193/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9767 - accuracy: 0.5293 - val_loss: 0.9817 - val_accuracy: 0.5310\n",
      "Epoch 194/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9767 - accuracy: 0.5300 - val_loss: 0.9834 - val_accuracy: 0.5282\n",
      "Epoch 195/200\n",
      "612/612 [==============================] - 0s 543us/step - loss: 0.9773 - accuracy: 0.5273 - val_loss: 0.9846 - val_accuracy: 0.5227\n",
      "Epoch 196/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9769 - accuracy: 0.5286 - val_loss: 0.9822 - val_accuracy: 0.5287\n",
      "Epoch 197/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9768 - accuracy: 0.5287 - val_loss: 0.9823 - val_accuracy: 0.5292\n",
      "Epoch 198/200\n",
      "612/612 [==============================] - 0s 519us/step - loss: 0.9775 - accuracy: 0.5306 - val_loss: 0.9902 - val_accuracy: 0.5191\n",
      "Epoch 199/200\n",
      "612/612 [==============================] - 0s 517us/step - loss: 0.9782 - accuracy: 0.5280 - val_loss: 0.9839 - val_accuracy: 0.5241\n",
      "Epoch 200/200\n",
      "612/612 [==============================] - 0s 552us/step - loss: 0.9766 - accuracy: 0.5306 - val_loss: 0.9851 - val_accuracy: 0.5269\n",
      "\n",
      "Train split:\n",
      "612/612 [==============================] - 0s 571us/step - loss: 0.9772 - accuracy: 0.5301\n",
      "Accuracy : 0.5301266312599182\n",
      "\n",
      "Test split:\n",
      "69/69 - 0s - loss: 0.9851 - accuracy: 0.5269\n",
      "Accuracy : 0.5268718600273132\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "613/613 [==============================] - 0s 725us/step - loss: 1.0471 - accuracy: 0.4590 - val_loss: 1.0116 - val_accuracy: 0.4908\n",
      "Epoch 2/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9975 - accuracy: 0.5134 - val_loss: 0.9907 - val_accuracy: 0.5078\n",
      "Epoch 3/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9927 - accuracy: 0.5158 - val_loss: 0.9889 - val_accuracy: 0.5193\n",
      "Epoch 4/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9894 - accuracy: 0.5154 - val_loss: 0.9852 - val_accuracy: 0.5294\n",
      "Epoch 5/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9879 - accuracy: 0.5195 - val_loss: 0.9936 - val_accuracy: 0.5092\n",
      "Epoch 6/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9872 - accuracy: 0.5176 - val_loss: 0.9936 - val_accuracy: 0.4991\n",
      "Epoch 7/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9876 - accuracy: 0.5189 - val_loss: 0.9899 - val_accuracy: 0.5262\n",
      "Epoch 8/200\n",
      "613/613 [==============================] - 0s 580us/step - loss: 0.9865 - accuracy: 0.5196 - val_loss: 0.9807 - val_accuracy: 0.5294\n",
      "Epoch 9/200\n",
      "613/613 [==============================] - 0s 586us/step - loss: 0.9847 - accuracy: 0.5209 - val_loss: 0.9918 - val_accuracy: 0.5119\n",
      "Epoch 10/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9846 - accuracy: 0.5201 - val_loss: 0.9870 - val_accuracy: 0.5156\n",
      "Epoch 11/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9843 - accuracy: 0.5222 - val_loss: 0.9859 - val_accuracy: 0.5221\n",
      "Epoch 12/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9850 - accuracy: 0.5213 - val_loss: 0.9844 - val_accuracy: 0.5225\n",
      "Epoch 13/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9834 - accuracy: 0.5196 - val_loss: 0.9843 - val_accuracy: 0.5216\n",
      "Epoch 14/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9839 - accuracy: 0.5207 - val_loss: 0.9872 - val_accuracy: 0.5092\n",
      "Epoch 15/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9834 - accuracy: 0.5245 - val_loss: 0.9829 - val_accuracy: 0.5234\n",
      "Epoch 16/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9831 - accuracy: 0.5218 - val_loss: 0.9921 - val_accuracy: 0.5055\n",
      "Epoch 17/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9817 - accuracy: 0.5199 - val_loss: 0.9859 - val_accuracy: 0.5335\n",
      "Epoch 18/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9806 - accuracy: 0.5244 - val_loss: 0.9918 - val_accuracy: 0.5216\n",
      "Epoch 19/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9812 - accuracy: 0.5227 - val_loss: 0.9849 - val_accuracy: 0.5239\n",
      "Epoch 20/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9822 - accuracy: 0.5183 - val_loss: 0.9830 - val_accuracy: 0.5138\n",
      "Epoch 21/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9807 - accuracy: 0.5253 - val_loss: 0.9852 - val_accuracy: 0.5257\n",
      "Epoch 22/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9812 - accuracy: 0.5223 - val_loss: 0.9807 - val_accuracy: 0.5290\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 553us/step - loss: 0.9809 - accuracy: 0.5229 - val_loss: 0.9839 - val_accuracy: 0.5331\n",
      "Epoch 24/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9822 - accuracy: 0.5232 - val_loss: 0.9797 - val_accuracy: 0.5354\n",
      "Epoch 25/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9820 - accuracy: 0.5249 - val_loss: 0.9890 - val_accuracy: 0.5184\n",
      "Epoch 26/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9814 - accuracy: 0.5245 - val_loss: 0.9826 - val_accuracy: 0.5294\n",
      "Epoch 27/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9801 - accuracy: 0.5243 - val_loss: 0.9788 - val_accuracy: 0.5271\n",
      "Epoch 28/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9807 - accuracy: 0.5243 - val_loss: 0.9861 - val_accuracy: 0.5262\n",
      "Epoch 29/200\n",
      "613/613 [==============================] - 0s 549us/step - loss: 0.9795 - accuracy: 0.5241 - val_loss: 0.9801 - val_accuracy: 0.5257\n",
      "Epoch 30/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9801 - accuracy: 0.5241 - val_loss: 0.9822 - val_accuracy: 0.5198\n",
      "Epoch 31/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9784 - accuracy: 0.5251 - val_loss: 0.9829 - val_accuracy: 0.5257\n",
      "Epoch 32/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9792 - accuracy: 0.5240 - val_loss: 0.9810 - val_accuracy: 0.5280\n",
      "Epoch 33/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9799 - accuracy: 0.5262 - val_loss: 0.9815 - val_accuracy: 0.5308\n",
      "Epoch 34/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9802 - accuracy: 0.5254 - val_loss: 0.9833 - val_accuracy: 0.5239\n",
      "Epoch 35/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9807 - accuracy: 0.5225 - val_loss: 0.9791 - val_accuracy: 0.5253\n",
      "Epoch 36/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9786 - accuracy: 0.5263 - val_loss: 0.9839 - val_accuracy: 0.5257\n",
      "Epoch 37/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9804 - accuracy: 0.5260 - val_loss: 0.9823 - val_accuracy: 0.5299\n",
      "Epoch 38/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9809 - accuracy: 0.5226 - val_loss: 0.9800 - val_accuracy: 0.5308\n",
      "Epoch 39/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9795 - accuracy: 0.5235 - val_loss: 0.9805 - val_accuracy: 0.5335\n",
      "Epoch 40/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9803 - accuracy: 0.5223 - val_loss: 0.9801 - val_accuracy: 0.5358\n",
      "Epoch 41/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9821 - accuracy: 0.5256 - val_loss: 0.9897 - val_accuracy: 0.5239\n",
      "Epoch 42/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9809 - accuracy: 0.5209 - val_loss: 0.9789 - val_accuracy: 0.5358\n",
      "Epoch 43/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9801 - accuracy: 0.5226 - val_loss: 0.9820 - val_accuracy: 0.5211\n",
      "Epoch 44/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9799 - accuracy: 0.5220 - val_loss: 0.9812 - val_accuracy: 0.5299\n",
      "Epoch 45/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9802 - accuracy: 0.5271 - val_loss: 0.9850 - val_accuracy: 0.5262\n",
      "Epoch 46/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9786 - accuracy: 0.5273 - val_loss: 0.9791 - val_accuracy: 0.5326\n",
      "Epoch 47/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9784 - accuracy: 0.5245 - val_loss: 0.9796 - val_accuracy: 0.5290\n",
      "Epoch 48/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9795 - accuracy: 0.5264 - val_loss: 0.9814 - val_accuracy: 0.5225\n",
      "Epoch 49/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9807 - accuracy: 0.5251 - val_loss: 0.9844 - val_accuracy: 0.5239\n",
      "Epoch 50/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9796 - accuracy: 0.5258 - val_loss: 0.9841 - val_accuracy: 0.5267\n",
      "Epoch 51/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9784 - accuracy: 0.5274 - val_loss: 0.9820 - val_accuracy: 0.5225\n",
      "Epoch 52/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9777 - accuracy: 0.5267 - val_loss: 0.9817 - val_accuracy: 0.5225\n",
      "Epoch 53/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9788 - accuracy: 0.5266 - val_loss: 0.9863 - val_accuracy: 0.5253\n",
      "Epoch 54/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9790 - accuracy: 0.5230 - val_loss: 0.9902 - val_accuracy: 0.5170\n",
      "Epoch 55/200\n",
      "613/613 [==============================] - 0s 592us/step - loss: 0.9802 - accuracy: 0.5244 - val_loss: 0.9818 - val_accuracy: 0.5317\n",
      "Epoch 56/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9788 - accuracy: 0.5246 - val_loss: 0.9854 - val_accuracy: 0.5216\n",
      "Epoch 57/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9787 - accuracy: 0.5256 - val_loss: 0.9802 - val_accuracy: 0.5257\n",
      "Epoch 58/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9789 - accuracy: 0.5250 - val_loss: 0.9853 - val_accuracy: 0.5276\n",
      "Epoch 59/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9782 - accuracy: 0.5266 - val_loss: 0.9888 - val_accuracy: 0.5253\n",
      "Epoch 60/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9784 - accuracy: 0.5261 - val_loss: 0.9844 - val_accuracy: 0.5248\n",
      "Epoch 61/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9795 - accuracy: 0.5240 - val_loss: 0.9811 - val_accuracy: 0.5335\n",
      "Epoch 62/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9794 - accuracy: 0.5212 - val_loss: 0.9817 - val_accuracy: 0.5354\n",
      "Epoch 63/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9784 - accuracy: 0.5251 - val_loss: 0.9846 - val_accuracy: 0.5230\n",
      "Epoch 64/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9782 - accuracy: 0.5270 - val_loss: 0.9832 - val_accuracy: 0.5354\n",
      "Epoch 65/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9801 - accuracy: 0.5219 - val_loss: 0.9860 - val_accuracy: 0.5267\n",
      "Epoch 66/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9775 - accuracy: 0.5239 - val_loss: 0.9848 - val_accuracy: 0.5340\n",
      "Epoch 67/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9779 - accuracy: 0.5274 - val_loss: 0.9818 - val_accuracy: 0.5294\n",
      "Epoch 68/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9782 - accuracy: 0.5256 - val_loss: 0.9807 - val_accuracy: 0.5267\n",
      "Epoch 69/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9775 - accuracy: 0.5237 - val_loss: 0.9844 - val_accuracy: 0.5267\n",
      "Epoch 70/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9774 - accuracy: 0.5255 - val_loss: 0.9832 - val_accuracy: 0.5267\n",
      "Epoch 71/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9773 - accuracy: 0.5268 - val_loss: 0.9833 - val_accuracy: 0.5267\n",
      "Epoch 72/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9772 - accuracy: 0.5234 - val_loss: 0.9838 - val_accuracy: 0.5294\n",
      "Epoch 73/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9774 - accuracy: 0.5263 - val_loss: 0.9801 - val_accuracy: 0.5276\n",
      "Epoch 74/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9792 - accuracy: 0.5267 - val_loss: 0.9828 - val_accuracy: 0.5340\n",
      "Epoch 75/200\n",
      "613/613 [==============================] - 0s 533us/step - loss: 0.9786 - accuracy: 0.5250 - val_loss: 0.9829 - val_accuracy: 0.5349\n",
      "Epoch 76/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9790 - accuracy: 0.5264 - val_loss: 0.9807 - val_accuracy: 0.5312\n",
      "Epoch 77/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9783 - accuracy: 0.5275 - val_loss: 0.9815 - val_accuracy: 0.5303\n",
      "Epoch 78/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9780 - accuracy: 0.5260 - val_loss: 0.9828 - val_accuracy: 0.5354\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 570us/step - loss: 0.9795 - accuracy: 0.5286 - val_loss: 0.9808 - val_accuracy: 0.5303\n",
      "Epoch 80/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9787 - accuracy: 0.5270 - val_loss: 0.9807 - val_accuracy: 0.5299\n",
      "Epoch 81/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9788 - accuracy: 0.5255 - val_loss: 0.9801 - val_accuracy: 0.5317\n",
      "Epoch 82/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9787 - accuracy: 0.5273 - val_loss: 0.9854 - val_accuracy: 0.5221\n",
      "Epoch 83/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9789 - accuracy: 0.5270 - val_loss: 0.9799 - val_accuracy: 0.5308\n",
      "Epoch 84/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9785 - accuracy: 0.5264 - val_loss: 0.9810 - val_accuracy: 0.5308\n",
      "Epoch 85/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9773 - accuracy: 0.5278 - val_loss: 0.9827 - val_accuracy: 0.5290\n",
      "Epoch 86/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9784 - accuracy: 0.5247 - val_loss: 0.9825 - val_accuracy: 0.5285\n",
      "Epoch 87/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9791 - accuracy: 0.5258 - val_loss: 0.9831 - val_accuracy: 0.5285\n",
      "Epoch 88/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9791 - accuracy: 0.5283 - val_loss: 0.9868 - val_accuracy: 0.5041\n",
      "Epoch 89/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9786 - accuracy: 0.5259 - val_loss: 0.9815 - val_accuracy: 0.5303\n",
      "Epoch 90/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9782 - accuracy: 0.5272 - val_loss: 0.9818 - val_accuracy: 0.5326\n",
      "Epoch 91/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9784 - accuracy: 0.5249 - val_loss: 0.9810 - val_accuracy: 0.5335\n",
      "Epoch 92/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9788 - accuracy: 0.5272 - val_loss: 0.9846 - val_accuracy: 0.5207\n",
      "Epoch 93/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9797 - accuracy: 0.5204 - val_loss: 0.9846 - val_accuracy: 0.5184\n",
      "Epoch 94/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9785 - accuracy: 0.5275 - val_loss: 0.9817 - val_accuracy: 0.5257\n",
      "Epoch 95/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9779 - accuracy: 0.5275 - val_loss: 0.9818 - val_accuracy: 0.5280\n",
      "Epoch 96/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9780 - accuracy: 0.5251 - val_loss: 0.9772 - val_accuracy: 0.5340\n",
      "Epoch 97/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9783 - accuracy: 0.5230 - val_loss: 0.9798 - val_accuracy: 0.5285\n",
      "Epoch 98/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9780 - accuracy: 0.5250 - val_loss: 0.9820 - val_accuracy: 0.5280\n",
      "Epoch 99/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9775 - accuracy: 0.5266 - val_loss: 0.9823 - val_accuracy: 0.5331\n",
      "Epoch 100/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9772 - accuracy: 0.5277 - val_loss: 0.9812 - val_accuracy: 0.5207\n",
      "Epoch 101/200\n",
      "613/613 [==============================] - 0s 580us/step - loss: 0.9791 - accuracy: 0.5250 - val_loss: 0.9820 - val_accuracy: 0.5262\n",
      "Epoch 102/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9779 - accuracy: 0.5277 - val_loss: 0.9855 - val_accuracy: 0.5285\n",
      "Epoch 103/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9768 - accuracy: 0.5264 - val_loss: 0.9801 - val_accuracy: 0.5285\n",
      "Epoch 104/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9788 - accuracy: 0.5292 - val_loss: 0.9815 - val_accuracy: 0.5294\n",
      "Epoch 105/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9767 - accuracy: 0.5265 - val_loss: 0.9779 - val_accuracy: 0.5303\n",
      "Epoch 106/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9767 - accuracy: 0.5263 - val_loss: 0.9825 - val_accuracy: 0.5285\n",
      "Epoch 107/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9771 - accuracy: 0.5250 - val_loss: 0.9819 - val_accuracy: 0.5184\n",
      "Epoch 108/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9769 - accuracy: 0.5255 - val_loss: 0.9801 - val_accuracy: 0.5354\n",
      "Epoch 109/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9780 - accuracy: 0.5267 - val_loss: 0.9819 - val_accuracy: 0.5303\n",
      "Epoch 110/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9773 - accuracy: 0.5262 - val_loss: 0.9838 - val_accuracy: 0.5267\n",
      "Epoch 111/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9776 - accuracy: 0.5265 - val_loss: 0.9821 - val_accuracy: 0.5271\n",
      "Epoch 112/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9777 - accuracy: 0.5288 - val_loss: 0.9796 - val_accuracy: 0.5271\n",
      "Epoch 113/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9778 - accuracy: 0.5267 - val_loss: 0.9804 - val_accuracy: 0.5326\n",
      "Epoch 114/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9780 - accuracy: 0.5262 - val_loss: 0.9813 - val_accuracy: 0.5317\n",
      "Epoch 115/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9774 - accuracy: 0.5280 - val_loss: 0.9833 - val_accuracy: 0.5133\n",
      "Epoch 116/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9778 - accuracy: 0.5278 - val_loss: 0.9803 - val_accuracy: 0.5372\n",
      "Epoch 117/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9782 - accuracy: 0.5245 - val_loss: 0.9848 - val_accuracy: 0.5248\n",
      "Epoch 118/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9782 - accuracy: 0.5248 - val_loss: 0.9800 - val_accuracy: 0.5381\n",
      "Epoch 119/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9780 - accuracy: 0.5251 - val_loss: 0.9883 - val_accuracy: 0.5280\n",
      "Epoch 120/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9777 - accuracy: 0.5270 - val_loss: 0.9809 - val_accuracy: 0.5216\n",
      "Epoch 121/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9773 - accuracy: 0.5268 - val_loss: 0.9911 - val_accuracy: 0.5225\n",
      "Epoch 122/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9780 - accuracy: 0.5270 - val_loss: 0.9840 - val_accuracy: 0.5248\n",
      "Epoch 123/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9780 - accuracy: 0.5278 - val_loss: 0.9814 - val_accuracy: 0.5299\n",
      "Epoch 124/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9792 - accuracy: 0.5276 - val_loss: 0.9854 - val_accuracy: 0.5225\n",
      "Epoch 125/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9772 - accuracy: 0.5276 - val_loss: 0.9826 - val_accuracy: 0.5303\n",
      "Epoch 126/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9771 - accuracy: 0.5282 - val_loss: 0.9806 - val_accuracy: 0.5230\n",
      "Epoch 127/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9766 - accuracy: 0.5279 - val_loss: 0.9807 - val_accuracy: 0.5299\n",
      "Epoch 128/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9767 - accuracy: 0.5287 - val_loss: 0.9801 - val_accuracy: 0.5317\n",
      "Epoch 129/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9767 - accuracy: 0.5299 - val_loss: 0.9825 - val_accuracy: 0.5303\n",
      "Epoch 130/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9776 - accuracy: 0.5299 - val_loss: 0.9798 - val_accuracy: 0.5299\n",
      "Epoch 131/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9774 - accuracy: 0.5269 - val_loss: 0.9793 - val_accuracy: 0.5276\n",
      "Epoch 132/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9773 - accuracy: 0.5274 - val_loss: 0.9811 - val_accuracy: 0.5225\n",
      "Epoch 133/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9780 - accuracy: 0.5260 - val_loss: 0.9821 - val_accuracy: 0.5358\n",
      "Epoch 134/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9783 - accuracy: 0.5264 - val_loss: 0.9816 - val_accuracy: 0.5317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9766 - accuracy: 0.5277 - val_loss: 0.9842 - val_accuracy: 0.5253\n",
      "Epoch 136/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9768 - accuracy: 0.5280 - val_loss: 0.9823 - val_accuracy: 0.5248\n",
      "Epoch 137/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9773 - accuracy: 0.5297 - val_loss: 0.9810 - val_accuracy: 0.5271\n",
      "Epoch 138/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9779 - accuracy: 0.5283 - val_loss: 0.9803 - val_accuracy: 0.5294\n",
      "Epoch 139/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9774 - accuracy: 0.5287 - val_loss: 0.9817 - val_accuracy: 0.5257\n",
      "Epoch 140/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9775 - accuracy: 0.5288 - val_loss: 0.9794 - val_accuracy: 0.5280\n",
      "Epoch 141/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9789 - accuracy: 0.5236 - val_loss: 0.9808 - val_accuracy: 0.5285\n",
      "Epoch 142/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9785 - accuracy: 0.5252 - val_loss: 0.9809 - val_accuracy: 0.5294\n",
      "Epoch 143/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9771 - accuracy: 0.5271 - val_loss: 0.9811 - val_accuracy: 0.5276\n",
      "Epoch 144/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9784 - accuracy: 0.5256 - val_loss: 0.9815 - val_accuracy: 0.5335\n",
      "Epoch 145/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9779 - accuracy: 0.5258 - val_loss: 0.9812 - val_accuracy: 0.5276\n",
      "Epoch 146/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9774 - accuracy: 0.5282 - val_loss: 0.9813 - val_accuracy: 0.5317\n",
      "Epoch 147/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9777 - accuracy: 0.5297 - val_loss: 0.9892 - val_accuracy: 0.5276\n",
      "Epoch 148/200\n",
      "613/613 [==============================] - 0s 609us/step - loss: 0.9783 - accuracy: 0.5283 - val_loss: 0.9849 - val_accuracy: 0.5267\n",
      "Epoch 149/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9772 - accuracy: 0.5258 - val_loss: 0.9798 - val_accuracy: 0.5262\n",
      "Epoch 150/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9776 - accuracy: 0.5267 - val_loss: 0.9835 - val_accuracy: 0.5276\n",
      "Epoch 151/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9778 - accuracy: 0.5281 - val_loss: 0.9811 - val_accuracy: 0.5317\n",
      "Epoch 152/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9804 - val_accuracy: 0.5322\n",
      "Epoch 153/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9770 - accuracy: 0.5278 - val_loss: 0.9826 - val_accuracy: 0.5285\n",
      "Epoch 154/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9782 - accuracy: 0.5272 - val_loss: 0.9813 - val_accuracy: 0.5335\n",
      "Epoch 155/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9766 - accuracy: 0.5305 - val_loss: 0.9847 - val_accuracy: 0.5239\n",
      "Epoch 156/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9761 - accuracy: 0.5273 - val_loss: 0.9795 - val_accuracy: 0.5276\n",
      "Epoch 157/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9755 - accuracy: 0.5284 - val_loss: 0.9843 - val_accuracy: 0.5271\n",
      "Epoch 158/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9776 - accuracy: 0.5264 - val_loss: 0.9792 - val_accuracy: 0.5312\n",
      "Epoch 159/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9776 - accuracy: 0.5232 - val_loss: 0.9806 - val_accuracy: 0.5377\n",
      "Epoch 160/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9772 - accuracy: 0.5267 - val_loss: 0.9791 - val_accuracy: 0.5299\n",
      "Epoch 161/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9762 - accuracy: 0.5282 - val_loss: 0.9848 - val_accuracy: 0.5271\n",
      "Epoch 162/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9765 - accuracy: 0.5301 - val_loss: 0.9778 - val_accuracy: 0.5331\n",
      "Epoch 163/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9773 - accuracy: 0.5276 - val_loss: 0.9815 - val_accuracy: 0.5345\n",
      "Epoch 164/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9767 - accuracy: 0.5301 - val_loss: 0.9796 - val_accuracy: 0.5294\n",
      "Epoch 165/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9765 - accuracy: 0.5274 - val_loss: 0.9799 - val_accuracy: 0.5285\n",
      "Epoch 166/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9769 - accuracy: 0.5278 - val_loss: 0.9818 - val_accuracy: 0.5253\n",
      "Epoch 167/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9763 - accuracy: 0.5300 - val_loss: 0.9812 - val_accuracy: 0.5290\n",
      "Epoch 168/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9767 - accuracy: 0.5275 - val_loss: 0.9796 - val_accuracy: 0.5317\n",
      "Epoch 169/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9767 - accuracy: 0.5283 - val_loss: 0.9835 - val_accuracy: 0.5322\n",
      "Epoch 170/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9771 - accuracy: 0.5266 - val_loss: 0.9786 - val_accuracy: 0.5308\n",
      "Epoch 171/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9761 - accuracy: 0.5295 - val_loss: 0.9800 - val_accuracy: 0.5345\n",
      "Epoch 172/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9764 - accuracy: 0.5261 - val_loss: 0.9810 - val_accuracy: 0.5358\n",
      "Epoch 173/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9761 - accuracy: 0.5299 - val_loss: 0.9829 - val_accuracy: 0.5248\n",
      "Epoch 174/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9762 - accuracy: 0.5294 - val_loss: 0.9830 - val_accuracy: 0.5322\n",
      "Epoch 175/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9777 - accuracy: 0.5275 - val_loss: 0.9824 - val_accuracy: 0.5299\n",
      "Epoch 176/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9758 - accuracy: 0.5289 - val_loss: 0.9816 - val_accuracy: 0.5267\n",
      "Epoch 177/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9771 - accuracy: 0.5287 - val_loss: 0.9828 - val_accuracy: 0.5294\n",
      "Epoch 178/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9772 - accuracy: 0.5266 - val_loss: 0.9791 - val_accuracy: 0.5303\n",
      "Epoch 179/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9771 - accuracy: 0.5292 - val_loss: 0.9798 - val_accuracy: 0.5294\n",
      "Epoch 180/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9777 - accuracy: 0.5264 - val_loss: 0.9791 - val_accuracy: 0.5326\n",
      "Epoch 181/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9769 - accuracy: 0.5266 - val_loss: 0.9834 - val_accuracy: 0.5303\n",
      "Epoch 182/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9788 - accuracy: 0.5252 - val_loss: 0.9793 - val_accuracy: 0.5299\n",
      "Epoch 183/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9803 - val_accuracy: 0.5253\n",
      "Epoch 184/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9771 - accuracy: 0.5274 - val_loss: 0.9822 - val_accuracy: 0.5271\n",
      "Epoch 185/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9771 - accuracy: 0.5286 - val_loss: 0.9821 - val_accuracy: 0.5299\n",
      "Epoch 186/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9763 - accuracy: 0.5279 - val_loss: 0.9839 - val_accuracy: 0.5308\n",
      "Epoch 187/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9781 - accuracy: 0.5275 - val_loss: 0.9832 - val_accuracy: 0.5294\n",
      "Epoch 188/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9774 - accuracy: 0.5256 - val_loss: 0.9798 - val_accuracy: 0.5354\n",
      "Epoch 189/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9768 - accuracy: 0.5271 - val_loss: 0.9802 - val_accuracy: 0.5285\n",
      "Epoch 190/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9764 - accuracy: 0.5278 - val_loss: 0.9803 - val_accuracy: 0.5326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9768 - accuracy: 0.5261 - val_loss: 0.9818 - val_accuracy: 0.5303\n",
      "Epoch 192/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9780 - accuracy: 0.5283 - val_loss: 0.9781 - val_accuracy: 0.5326\n",
      "Epoch 193/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9768 - accuracy: 0.5260 - val_loss: 0.9781 - val_accuracy: 0.5308\n",
      "Epoch 194/200\n",
      "613/613 [==============================] - 0s 591us/step - loss: 0.9764 - accuracy: 0.5255 - val_loss: 0.9830 - val_accuracy: 0.5303\n",
      "Epoch 195/200\n",
      "613/613 [==============================] - 0s 590us/step - loss: 0.9776 - accuracy: 0.5279 - val_loss: 0.9797 - val_accuracy: 0.5326\n",
      "Epoch 196/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9771 - accuracy: 0.5277 - val_loss: 0.9794 - val_accuracy: 0.5326\n",
      "Epoch 197/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9775 - accuracy: 0.5279 - val_loss: 0.9805 - val_accuracy: 0.5276\n",
      "Epoch 198/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9777 - accuracy: 0.5264 - val_loss: 0.9794 - val_accuracy: 0.5358\n",
      "Epoch 199/200\n",
      "613/613 [==============================] - 0s 547us/step - loss: 0.9774 - accuracy: 0.5281 - val_loss: 0.9853 - val_accuracy: 0.5188\n",
      "Epoch 200/200\n",
      "613/613 [==============================] - 0s 595us/step - loss: 0.9771 - accuracy: 0.5274 - val_loss: 0.9804 - val_accuracy: 0.5322\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 589us/step - loss: 0.9755 - accuracy: 0.5286\n",
      "Accuracy : 0.5285677909851074\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9804 - accuracy: 0.5322\n",
      "Accuracy : 0.5321691036224365\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "613/613 [==============================] - 0s 730us/step - loss: 1.0495 - accuracy: 0.4637 - val_loss: 1.0257 - val_accuracy: 0.5032\n",
      "Epoch 2/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 1.0013 - accuracy: 0.5128 - val_loss: 1.0209 - val_accuracy: 0.4954\n",
      "Epoch 3/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9909 - accuracy: 0.5188 - val_loss: 1.0293 - val_accuracy: 0.5064\n",
      "Epoch 4/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9895 - accuracy: 0.5165 - val_loss: 1.0326 - val_accuracy: 0.4789\n",
      "Epoch 5/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9863 - accuracy: 0.5191 - val_loss: 1.0189 - val_accuracy: 0.4949\n",
      "Epoch 6/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9853 - accuracy: 0.5226 - val_loss: 1.0115 - val_accuracy: 0.5115\n",
      "Epoch 7/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9858 - accuracy: 0.5231 - val_loss: 1.0163 - val_accuracy: 0.5078\n",
      "Epoch 8/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9859 - accuracy: 0.5191 - val_loss: 1.0140 - val_accuracy: 0.5060\n",
      "Epoch 9/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9840 - accuracy: 0.5234 - val_loss: 1.0099 - val_accuracy: 0.5106\n",
      "Epoch 10/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9830 - accuracy: 0.5247 - val_loss: 1.0274 - val_accuracy: 0.4986\n",
      "Epoch 11/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9823 - accuracy: 0.5229 - val_loss: 1.0175 - val_accuracy: 0.5101\n",
      "Epoch 12/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9834 - accuracy: 0.5212 - val_loss: 1.0213 - val_accuracy: 0.4991\n",
      "Epoch 13/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9807 - accuracy: 0.5203 - val_loss: 1.0132 - val_accuracy: 0.5046\n",
      "Epoch 14/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9804 - accuracy: 0.5256 - val_loss: 1.0167 - val_accuracy: 0.5009\n",
      "Epoch 15/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9818 - accuracy: 0.5218 - val_loss: 1.0173 - val_accuracy: 0.5005\n",
      "Epoch 16/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9785 - accuracy: 0.5246 - val_loss: 1.0192 - val_accuracy: 0.4954\n",
      "Epoch 17/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9818 - accuracy: 0.5244 - val_loss: 1.0068 - val_accuracy: 0.5165\n",
      "Epoch 18/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9797 - accuracy: 0.5226 - val_loss: 1.0129 - val_accuracy: 0.5009\n",
      "Epoch 19/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9801 - accuracy: 0.5215 - val_loss: 1.0170 - val_accuracy: 0.5216\n",
      "Epoch 20/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9814 - accuracy: 0.5256 - val_loss: 1.0123 - val_accuracy: 0.5165\n",
      "Epoch 21/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9812 - accuracy: 0.5242 - val_loss: 1.0175 - val_accuracy: 0.5129\n",
      "Epoch 22/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9828 - accuracy: 0.5245 - val_loss: 1.0084 - val_accuracy: 0.5152\n",
      "Epoch 23/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9810 - accuracy: 0.5280 - val_loss: 1.0118 - val_accuracy: 0.5175\n",
      "Epoch 24/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9817 - accuracy: 0.5225 - val_loss: 1.0159 - val_accuracy: 0.5097\n",
      "Epoch 25/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9803 - accuracy: 0.5233 - val_loss: 1.0207 - val_accuracy: 0.4867\n",
      "Epoch 26/200\n",
      "613/613 [==============================] - 0s 580us/step - loss: 0.9801 - accuracy: 0.5227 - val_loss: 1.0132 - val_accuracy: 0.5124\n",
      "Epoch 27/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9829 - accuracy: 0.5250 - val_loss: 1.0110 - val_accuracy: 0.5152\n",
      "Epoch 28/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9813 - accuracy: 0.5246 - val_loss: 1.0056 - val_accuracy: 0.5202\n",
      "Epoch 29/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9807 - accuracy: 0.5261 - val_loss: 1.0167 - val_accuracy: 0.4986\n",
      "Epoch 30/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9805 - accuracy: 0.5250 - val_loss: 1.0147 - val_accuracy: 0.5175\n",
      "Epoch 31/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9802 - accuracy: 0.5260 - val_loss: 1.0085 - val_accuracy: 0.5129\n",
      "Epoch 32/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9788 - accuracy: 0.5227 - val_loss: 1.0135 - val_accuracy: 0.5170\n",
      "Epoch 33/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9795 - accuracy: 0.5261 - val_loss: 1.0166 - val_accuracy: 0.4986\n",
      "Epoch 34/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9780 - accuracy: 0.5271 - val_loss: 1.0091 - val_accuracy: 0.5193\n",
      "Epoch 35/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9793 - accuracy: 0.5258 - val_loss: 1.0084 - val_accuracy: 0.5083\n",
      "Epoch 36/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9799 - accuracy: 0.5255 - val_loss: 1.0075 - val_accuracy: 0.5175\n",
      "Epoch 37/200\n",
      "613/613 [==============================] - 0s 602us/step - loss: 0.9773 - accuracy: 0.5284 - val_loss: 1.0258 - val_accuracy: 0.5018\n",
      "Epoch 38/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9802 - accuracy: 0.5239 - val_loss: 1.0156 - val_accuracy: 0.5069\n",
      "Epoch 39/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9782 - accuracy: 0.5231 - val_loss: 1.0114 - val_accuracy: 0.5106\n",
      "Epoch 40/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9807 - accuracy: 0.5209 - val_loss: 1.0043 - val_accuracy: 0.5211\n",
      "Epoch 41/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9788 - accuracy: 0.5274 - val_loss: 1.0104 - val_accuracy: 0.5179\n",
      "Epoch 42/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9781 - accuracy: 0.5281 - val_loss: 1.0032 - val_accuracy: 0.5230\n",
      "Epoch 43/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9817 - accuracy: 0.5197 - val_loss: 1.0101 - val_accuracy: 0.5069\n",
      "Epoch 44/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9778 - accuracy: 0.5264 - val_loss: 1.0137 - val_accuracy: 0.4940\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 563us/step - loss: 0.9791 - accuracy: 0.5221 - val_loss: 1.0064 - val_accuracy: 0.5230\n",
      "Epoch 46/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9767 - accuracy: 0.5274 - val_loss: 1.0073 - val_accuracy: 0.5202\n",
      "Epoch 47/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9783 - accuracy: 0.5266 - val_loss: 1.0062 - val_accuracy: 0.5193\n",
      "Epoch 48/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9771 - accuracy: 0.5255 - val_loss: 1.0058 - val_accuracy: 0.5060\n",
      "Epoch 49/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9777 - accuracy: 0.5277 - val_loss: 1.0073 - val_accuracy: 0.5211\n",
      "Epoch 50/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9801 - accuracy: 0.5249 - val_loss: 1.0062 - val_accuracy: 0.5207\n",
      "Epoch 51/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9778 - accuracy: 0.5289 - val_loss: 1.0048 - val_accuracy: 0.5211\n",
      "Epoch 52/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9786 - accuracy: 0.5280 - val_loss: 1.0075 - val_accuracy: 0.5198\n",
      "Epoch 53/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9782 - accuracy: 0.5257 - val_loss: 1.0140 - val_accuracy: 0.5152\n",
      "Epoch 54/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9785 - accuracy: 0.5291 - val_loss: 1.0140 - val_accuracy: 0.5074\n",
      "Epoch 55/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9780 - accuracy: 0.5265 - val_loss: 1.0094 - val_accuracy: 0.5225\n",
      "Epoch 56/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9798 - accuracy: 0.5289 - val_loss: 1.0150 - val_accuracy: 0.5055\n",
      "Epoch 57/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9800 - accuracy: 0.5241 - val_loss: 1.0085 - val_accuracy: 0.5106\n",
      "Epoch 58/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9773 - accuracy: 0.5260 - val_loss: 1.0095 - val_accuracy: 0.5152\n",
      "Epoch 59/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9779 - accuracy: 0.5262 - val_loss: 1.0099 - val_accuracy: 0.5092\n",
      "Epoch 60/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9779 - accuracy: 0.5268 - val_loss: 1.0063 - val_accuracy: 0.5165\n",
      "Epoch 61/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9769 - accuracy: 0.5264 - val_loss: 1.0097 - val_accuracy: 0.5184\n",
      "Epoch 62/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9779 - accuracy: 0.5248 - val_loss: 1.0116 - val_accuracy: 0.5101\n",
      "Epoch 63/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9788 - accuracy: 0.5265 - val_loss: 1.0036 - val_accuracy: 0.5156\n",
      "Epoch 64/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9778 - accuracy: 0.5278 - val_loss: 1.0097 - val_accuracy: 0.5193\n",
      "Epoch 65/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9782 - accuracy: 0.5250 - val_loss: 1.0060 - val_accuracy: 0.5184\n",
      "Epoch 66/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9778 - accuracy: 0.5233 - val_loss: 1.0129 - val_accuracy: 0.5110\n",
      "Epoch 67/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9784 - accuracy: 0.5274 - val_loss: 1.0071 - val_accuracy: 0.5124\n",
      "Epoch 68/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9776 - accuracy: 0.5258 - val_loss: 1.0087 - val_accuracy: 0.5244\n",
      "Epoch 69/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9770 - accuracy: 0.5277 - val_loss: 1.0064 - val_accuracy: 0.5165\n",
      "Epoch 70/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9766 - accuracy: 0.5250 - val_loss: 1.0088 - val_accuracy: 0.5106\n",
      "Epoch 71/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9756 - accuracy: 0.5280 - val_loss: 1.0043 - val_accuracy: 0.5170\n",
      "Epoch 72/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9760 - accuracy: 0.5264 - val_loss: 1.0106 - val_accuracy: 0.5161\n",
      "Epoch 73/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9764 - accuracy: 0.5240 - val_loss: 1.0141 - val_accuracy: 0.5133\n",
      "Epoch 74/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9760 - accuracy: 0.5263 - val_loss: 1.0077 - val_accuracy: 0.5092\n",
      "Epoch 75/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9772 - accuracy: 0.5265 - val_loss: 1.0088 - val_accuracy: 0.5188\n",
      "Epoch 76/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9757 - accuracy: 0.5263 - val_loss: 1.0100 - val_accuracy: 0.5101\n",
      "Epoch 77/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9765 - accuracy: 0.5281 - val_loss: 1.0086 - val_accuracy: 0.5193\n",
      "Epoch 78/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 1.0054 - val_accuracy: 0.5179\n",
      "Epoch 79/200\n",
      "613/613 [==============================] - 0s 546us/step - loss: 0.9762 - accuracy: 0.5281 - val_loss: 1.0183 - val_accuracy: 0.4876\n",
      "Epoch 80/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9750 - accuracy: 0.5281 - val_loss: 1.0062 - val_accuracy: 0.5216\n",
      "Epoch 81/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9750 - accuracy: 0.5291 - val_loss: 1.0061 - val_accuracy: 0.5198\n",
      "Epoch 82/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9764 - accuracy: 0.5282 - val_loss: 1.0051 - val_accuracy: 0.5202\n",
      "Epoch 83/200\n",
      "613/613 [==============================] - 0s 582us/step - loss: 0.9759 - accuracy: 0.5276 - val_loss: 1.0068 - val_accuracy: 0.5234\n",
      "Epoch 84/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9771 - accuracy: 0.5279 - val_loss: 1.0112 - val_accuracy: 0.5110\n",
      "Epoch 85/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9765 - accuracy: 0.5292 - val_loss: 1.0116 - val_accuracy: 0.5133\n",
      "Epoch 86/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9762 - accuracy: 0.5264 - val_loss: 1.0056 - val_accuracy: 0.5234\n",
      "Epoch 87/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9767 - accuracy: 0.5303 - val_loss: 1.0112 - val_accuracy: 0.5051\n",
      "Epoch 88/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9774 - accuracy: 0.5268 - val_loss: 1.0099 - val_accuracy: 0.5129\n",
      "Epoch 89/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9760 - accuracy: 0.5280 - val_loss: 1.0093 - val_accuracy: 0.5138\n",
      "Epoch 90/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 1.0062 - val_accuracy: 0.5253\n",
      "Epoch 91/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9757 - accuracy: 0.5285 - val_loss: 1.0075 - val_accuracy: 0.5239\n",
      "Epoch 92/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9759 - accuracy: 0.5288 - val_loss: 1.0099 - val_accuracy: 0.5198\n",
      "Epoch 93/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9772 - accuracy: 0.5269 - val_loss: 1.0146 - val_accuracy: 0.5207\n",
      "Epoch 94/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 1.0111 - val_accuracy: 0.5221\n",
      "Epoch 95/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9772 - accuracy: 0.5274 - val_loss: 1.0144 - val_accuracy: 0.4922\n",
      "Epoch 96/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9776 - accuracy: 0.5269 - val_loss: 1.0089 - val_accuracy: 0.5147\n",
      "Epoch 97/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9760 - accuracy: 0.5326 - val_loss: 1.0095 - val_accuracy: 0.5239\n",
      "Epoch 98/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9764 - accuracy: 0.5300 - val_loss: 1.0133 - val_accuracy: 0.5074\n",
      "Epoch 99/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9756 - accuracy: 0.5284 - val_loss: 1.0130 - val_accuracy: 0.5147\n",
      "Epoch 100/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9763 - accuracy: 0.5309 - val_loss: 1.0080 - val_accuracy: 0.5138\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 563us/step - loss: 0.9762 - accuracy: 0.5290 - val_loss: 1.0068 - val_accuracy: 0.5202\n",
      "Epoch 102/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9754 - accuracy: 0.5306 - val_loss: 1.0065 - val_accuracy: 0.5211\n",
      "Epoch 103/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9761 - accuracy: 0.5292 - val_loss: 1.0071 - val_accuracy: 0.5230\n",
      "Epoch 104/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9768 - accuracy: 0.5268 - val_loss: 1.0119 - val_accuracy: 0.5124\n",
      "Epoch 105/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9750 - accuracy: 0.5295 - val_loss: 1.0096 - val_accuracy: 0.5069\n",
      "Epoch 106/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9767 - accuracy: 0.5263 - val_loss: 1.0032 - val_accuracy: 0.5216\n",
      "Epoch 107/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9758 - accuracy: 0.5280 - val_loss: 1.0064 - val_accuracy: 0.5244\n",
      "Epoch 108/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9755 - accuracy: 0.5272 - val_loss: 1.0107 - val_accuracy: 0.5097\n",
      "Epoch 109/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9759 - accuracy: 0.5281 - val_loss: 1.0081 - val_accuracy: 0.5055\n",
      "Epoch 110/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9768 - accuracy: 0.5250 - val_loss: 1.0057 - val_accuracy: 0.5188\n",
      "Epoch 111/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 1.0064 - val_accuracy: 0.5152\n",
      "Epoch 112/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9775 - accuracy: 0.5218 - val_loss: 1.0066 - val_accuracy: 0.5234\n",
      "Epoch 113/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9751 - accuracy: 0.5286 - val_loss: 1.0066 - val_accuracy: 0.5179\n",
      "Epoch 114/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9758 - accuracy: 0.5270 - val_loss: 1.0097 - val_accuracy: 0.5142\n",
      "Epoch 115/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9756 - accuracy: 0.5322 - val_loss: 1.0046 - val_accuracy: 0.5188\n",
      "Epoch 116/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9755 - accuracy: 0.5310 - val_loss: 1.0065 - val_accuracy: 0.5198\n",
      "Epoch 117/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9763 - accuracy: 0.5288 - val_loss: 1.0097 - val_accuracy: 0.5147\n",
      "Epoch 118/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9771 - accuracy: 0.5243 - val_loss: 1.0074 - val_accuracy: 0.5124\n",
      "Epoch 119/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9753 - accuracy: 0.5287 - val_loss: 1.0051 - val_accuracy: 0.5188\n",
      "Epoch 120/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9756 - accuracy: 0.5282 - val_loss: 1.0142 - val_accuracy: 0.5032\n",
      "Epoch 121/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9760 - accuracy: 0.5290 - val_loss: 1.0065 - val_accuracy: 0.5207\n",
      "Epoch 122/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9761 - accuracy: 0.5306 - val_loss: 1.0054 - val_accuracy: 0.5156\n",
      "Epoch 123/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9759 - accuracy: 0.5272 - val_loss: 1.0053 - val_accuracy: 0.5179\n",
      "Epoch 124/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9756 - accuracy: 0.5265 - val_loss: 1.0136 - val_accuracy: 0.5028\n",
      "Epoch 125/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9767 - accuracy: 0.5244 - val_loss: 1.0050 - val_accuracy: 0.5156\n",
      "Epoch 126/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9759 - accuracy: 0.5275 - val_loss: 1.0089 - val_accuracy: 0.5188\n",
      "Epoch 127/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9755 - accuracy: 0.5271 - val_loss: 1.0054 - val_accuracy: 0.5198\n",
      "Epoch 128/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9757 - accuracy: 0.5283 - val_loss: 1.0055 - val_accuracy: 0.5175\n",
      "Epoch 129/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9759 - accuracy: 0.5274 - val_loss: 1.0090 - val_accuracy: 0.5170\n",
      "Epoch 130/200\n",
      "613/613 [==============================] - 0s 590us/step - loss: 0.9763 - accuracy: 0.5299 - val_loss: 1.0062 - val_accuracy: 0.5147\n",
      "Epoch 131/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9762 - accuracy: 0.5296 - val_loss: 1.0061 - val_accuracy: 0.5207\n",
      "Epoch 132/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9759 - accuracy: 0.5294 - val_loss: 1.0098 - val_accuracy: 0.5110\n",
      "Epoch 133/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9758 - accuracy: 0.5297 - val_loss: 1.0117 - val_accuracy: 0.5216\n",
      "Epoch 134/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9750 - accuracy: 0.5321 - val_loss: 1.0042 - val_accuracy: 0.5165\n",
      "Epoch 135/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9755 - accuracy: 0.5275 - val_loss: 1.0037 - val_accuracy: 0.5221\n",
      "Epoch 136/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9762 - accuracy: 0.5268 - val_loss: 1.0059 - val_accuracy: 0.5161\n",
      "Epoch 137/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9758 - accuracy: 0.5302 - val_loss: 1.0078 - val_accuracy: 0.5188\n",
      "Epoch 138/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9761 - accuracy: 0.5269 - val_loss: 1.0077 - val_accuracy: 0.5087\n",
      "Epoch 139/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9755 - accuracy: 0.5288 - val_loss: 1.0056 - val_accuracy: 0.5221\n",
      "Epoch 140/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9749 - accuracy: 0.5287 - val_loss: 1.0128 - val_accuracy: 0.5198\n",
      "Epoch 141/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9748 - accuracy: 0.5303 - val_loss: 1.0088 - val_accuracy: 0.5230\n",
      "Epoch 142/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9758 - accuracy: 0.5319 - val_loss: 1.0125 - val_accuracy: 0.5000\n",
      "Epoch 143/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9770 - accuracy: 0.5274 - val_loss: 1.0081 - val_accuracy: 0.5138\n",
      "Epoch 144/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9768 - accuracy: 0.5262 - val_loss: 1.0074 - val_accuracy: 0.5230\n",
      "Epoch 145/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9767 - accuracy: 0.5284 - val_loss: 1.0052 - val_accuracy: 0.5211\n",
      "Epoch 146/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9761 - accuracy: 0.5282 - val_loss: 1.0071 - val_accuracy: 0.5211\n",
      "Epoch 147/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9760 - accuracy: 0.5294 - val_loss: 1.0095 - val_accuracy: 0.5161\n",
      "Epoch 148/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9749 - accuracy: 0.5309 - val_loss: 1.0061 - val_accuracy: 0.5138\n",
      "Epoch 149/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9753 - accuracy: 0.5310 - val_loss: 1.0054 - val_accuracy: 0.5198\n",
      "Epoch 150/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9761 - accuracy: 0.5283 - val_loss: 1.0100 - val_accuracy: 0.5211\n",
      "Epoch 151/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9760 - accuracy: 0.5296 - val_loss: 1.0047 - val_accuracy: 0.5129\n",
      "Epoch 152/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9765 - accuracy: 0.5254 - val_loss: 1.0092 - val_accuracy: 0.5009\n",
      "Epoch 153/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 1.0099 - val_accuracy: 0.5193\n",
      "Epoch 154/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9763 - accuracy: 0.5274 - val_loss: 1.0071 - val_accuracy: 0.5207\n",
      "Epoch 155/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9764 - accuracy: 0.5259 - val_loss: 1.0104 - val_accuracy: 0.4936\n",
      "Epoch 156/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9760 - accuracy: 0.5216 - val_loss: 1.0147 - val_accuracy: 0.4885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9755 - accuracy: 0.5312 - val_loss: 1.0089 - val_accuracy: 0.5221\n",
      "Epoch 158/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9769 - accuracy: 0.5274 - val_loss: 1.0069 - val_accuracy: 0.5179\n",
      "Epoch 159/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9757 - accuracy: 0.5276 - val_loss: 1.0066 - val_accuracy: 0.5211\n",
      "Epoch 160/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9750 - accuracy: 0.5258 - val_loss: 1.0023 - val_accuracy: 0.5207\n",
      "Epoch 161/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9761 - accuracy: 0.5258 - val_loss: 1.0107 - val_accuracy: 0.4867\n",
      "Epoch 162/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9751 - accuracy: 0.5251 - val_loss: 1.0099 - val_accuracy: 0.5023\n",
      "Epoch 163/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9755 - accuracy: 0.5271 - val_loss: 1.0066 - val_accuracy: 0.5230\n",
      "Epoch 164/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9748 - accuracy: 0.5242 - val_loss: 1.0089 - val_accuracy: 0.4972\n",
      "Epoch 165/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9746 - accuracy: 0.5293 - val_loss: 1.0044 - val_accuracy: 0.5230\n",
      "Epoch 166/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9736 - accuracy: 0.5304 - val_loss: 1.0084 - val_accuracy: 0.5161\n",
      "Epoch 167/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9747 - accuracy: 0.5268 - val_loss: 1.0037 - val_accuracy: 0.5202\n",
      "Epoch 168/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9742 - accuracy: 0.5294 - val_loss: 1.0055 - val_accuracy: 0.5211\n",
      "Epoch 169/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9754 - accuracy: 0.5276 - val_loss: 1.0060 - val_accuracy: 0.5175\n",
      "Epoch 170/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9758 - accuracy: 0.5260 - val_loss: 1.0069 - val_accuracy: 0.5152\n",
      "Epoch 171/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9752 - accuracy: 0.5294 - val_loss: 1.0076 - val_accuracy: 0.5216\n",
      "Epoch 172/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9742 - accuracy: 0.5279 - val_loss: 1.0093 - val_accuracy: 0.4986\n",
      "Epoch 173/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9747 - accuracy: 0.5286 - val_loss: 1.0083 - val_accuracy: 0.5156\n",
      "Epoch 174/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9743 - accuracy: 0.5288 - val_loss: 1.0095 - val_accuracy: 0.5083\n",
      "Epoch 175/200\n",
      "613/613 [==============================] - 0s 581us/step - loss: 0.9756 - accuracy: 0.5290 - val_loss: 1.0038 - val_accuracy: 0.5170\n",
      "Epoch 176/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9748 - accuracy: 0.5266 - val_loss: 1.0066 - val_accuracy: 0.5152\n",
      "Epoch 177/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9761 - accuracy: 0.5248 - val_loss: 1.0119 - val_accuracy: 0.5225\n",
      "Epoch 178/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9753 - accuracy: 0.5262 - val_loss: 1.0097 - val_accuracy: 0.5152\n",
      "Epoch 179/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5303 - val_loss: 1.0089 - val_accuracy: 0.5170\n",
      "Epoch 180/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9762 - accuracy: 0.5268 - val_loss: 1.0114 - val_accuracy: 0.5064\n",
      "Epoch 181/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9759 - accuracy: 0.5273 - val_loss: 1.0088 - val_accuracy: 0.5147\n",
      "Epoch 182/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9752 - accuracy: 0.5293 - val_loss: 1.0066 - val_accuracy: 0.5198\n",
      "Epoch 183/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9747 - accuracy: 0.5300 - val_loss: 1.0091 - val_accuracy: 0.5069\n",
      "Epoch 184/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9754 - accuracy: 0.5272 - val_loss: 1.0069 - val_accuracy: 0.5142\n",
      "Epoch 185/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9747 - accuracy: 0.5273 - val_loss: 1.0061 - val_accuracy: 0.5188\n",
      "Epoch 186/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 1.0070 - val_accuracy: 0.5188\n",
      "Epoch 187/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9741 - accuracy: 0.5285 - val_loss: 1.0078 - val_accuracy: 0.5202\n",
      "Epoch 188/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9755 - accuracy: 0.5293 - val_loss: 1.0059 - val_accuracy: 0.5156\n",
      "Epoch 189/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9750 - accuracy: 0.5279 - val_loss: 1.0089 - val_accuracy: 0.5097\n",
      "Epoch 190/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9748 - accuracy: 0.5269 - val_loss: 1.0067 - val_accuracy: 0.5175\n",
      "Epoch 191/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9746 - accuracy: 0.5260 - val_loss: 1.0073 - val_accuracy: 0.5161\n",
      "Epoch 192/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9747 - accuracy: 0.5298 - val_loss: 1.0067 - val_accuracy: 0.5152\n",
      "Epoch 193/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9741 - accuracy: 0.5282 - val_loss: 1.0130 - val_accuracy: 0.4968\n",
      "Epoch 194/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9741 - accuracy: 0.5274 - val_loss: 1.0076 - val_accuracy: 0.5216\n",
      "Epoch 195/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9744 - accuracy: 0.5272 - val_loss: 1.0062 - val_accuracy: 0.5023\n",
      "Epoch 196/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9745 - accuracy: 0.5304 - val_loss: 1.0076 - val_accuracy: 0.5161\n",
      "Epoch 197/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9749 - accuracy: 0.5296 - val_loss: 1.0065 - val_accuracy: 0.5179\n",
      "Epoch 198/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9756 - accuracy: 0.5310 - val_loss: 1.0087 - val_accuracy: 0.5156\n",
      "Epoch 199/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9740 - accuracy: 0.5296 - val_loss: 1.0126 - val_accuracy: 0.5032\n",
      "Epoch 200/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9773 - accuracy: 0.5278 - val_loss: 1.0093 - val_accuracy: 0.5092\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 589us/step - loss: 0.9758 - accuracy: 0.5271\n",
      "Accuracy : 0.5271381139755249\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 1.0093 - accuracy: 0.5092\n",
      "Accuracy : 0.5091911554336548\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "613/613 [==============================] - 0s 705us/step - loss: 1.0395 - accuracy: 0.4703 - val_loss: 1.0362 - val_accuracy: 0.4766\n",
      "Epoch 2/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 1.0002 - accuracy: 0.5121 - val_loss: 1.0126 - val_accuracy: 0.5041\n",
      "Epoch 3/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9905 - accuracy: 0.5186 - val_loss: 1.0123 - val_accuracy: 0.4839\n",
      "Epoch 4/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9884 - accuracy: 0.5186 - val_loss: 1.0104 - val_accuracy: 0.5037\n",
      "Epoch 5/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9890 - accuracy: 0.5164 - val_loss: 1.0235 - val_accuracy: 0.4936\n",
      "Epoch 6/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9860 - accuracy: 0.5201 - val_loss: 1.0112 - val_accuracy: 0.5014\n",
      "Epoch 7/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9869 - accuracy: 0.5174 - val_loss: 1.0082 - val_accuracy: 0.5092\n",
      "Epoch 8/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9839 - accuracy: 0.5216 - val_loss: 1.0160 - val_accuracy: 0.4945\n",
      "Epoch 9/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9862 - accuracy: 0.5219 - val_loss: 1.0162 - val_accuracy: 0.5023\n",
      "Epoch 10/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9871 - accuracy: 0.5211 - val_loss: 1.0114 - val_accuracy: 0.5069\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 557us/step - loss: 0.9845 - accuracy: 0.5245 - val_loss: 1.0187 - val_accuracy: 0.5037\n",
      "Epoch 12/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9832 - accuracy: 0.5236 - val_loss: 1.0066 - val_accuracy: 0.5078\n",
      "Epoch 13/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9832 - accuracy: 0.5257 - val_loss: 1.0101 - val_accuracy: 0.5101\n",
      "Epoch 14/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9845 - accuracy: 0.5214 - val_loss: 1.0201 - val_accuracy: 0.5018\n",
      "Epoch 15/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9827 - accuracy: 0.5249 - val_loss: 1.0286 - val_accuracy: 0.4940\n",
      "Epoch 16/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9844 - accuracy: 0.5245 - val_loss: 1.0054 - val_accuracy: 0.5087\n",
      "Epoch 17/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9819 - accuracy: 0.5251 - val_loss: 1.0127 - val_accuracy: 0.5092\n",
      "Epoch 18/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9837 - accuracy: 0.5200 - val_loss: 1.0171 - val_accuracy: 0.5064\n",
      "Epoch 19/200\n",
      "613/613 [==============================] - 0s 584us/step - loss: 0.9833 - accuracy: 0.5266 - val_loss: 1.0117 - val_accuracy: 0.4982\n",
      "Epoch 20/200\n",
      "613/613 [==============================] - 0s 580us/step - loss: 0.9847 - accuracy: 0.5248 - val_loss: 1.0083 - val_accuracy: 0.5046\n",
      "Epoch 21/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9803 - accuracy: 0.5288 - val_loss: 1.0076 - val_accuracy: 0.5037\n",
      "Epoch 22/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9805 - accuracy: 0.5257 - val_loss: 1.0126 - val_accuracy: 0.5060\n",
      "Epoch 23/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9814 - accuracy: 0.5229 - val_loss: 1.0074 - val_accuracy: 0.5055\n",
      "Epoch 24/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9793 - accuracy: 0.5262 - val_loss: 1.0062 - val_accuracy: 0.5069\n",
      "Epoch 25/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9812 - accuracy: 0.5254 - val_loss: 1.0177 - val_accuracy: 0.4747\n",
      "Epoch 26/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9800 - accuracy: 0.5249 - val_loss: 1.0109 - val_accuracy: 0.4986\n",
      "Epoch 27/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9796 - accuracy: 0.5262 - val_loss: 1.0063 - val_accuracy: 0.5106\n",
      "Epoch 28/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9802 - accuracy: 0.5272 - val_loss: 1.0070 - val_accuracy: 0.5051\n",
      "Epoch 29/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9786 - accuracy: 0.5254 - val_loss: 1.0087 - val_accuracy: 0.4995\n",
      "Epoch 30/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9787 - accuracy: 0.5255 - val_loss: 1.0074 - val_accuracy: 0.5078\n",
      "Epoch 31/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9778 - accuracy: 0.5274 - val_loss: 1.0062 - val_accuracy: 0.5014\n",
      "Epoch 32/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9792 - accuracy: 0.5251 - val_loss: 1.0139 - val_accuracy: 0.4844\n",
      "Epoch 33/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9788 - accuracy: 0.5270 - val_loss: 1.0069 - val_accuracy: 0.5069\n",
      "Epoch 34/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9780 - accuracy: 0.5279 - val_loss: 1.0067 - val_accuracy: 0.5115\n",
      "Epoch 35/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9777 - accuracy: 0.5290 - val_loss: 1.0078 - val_accuracy: 0.5041\n",
      "Epoch 36/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 1.0063 - val_accuracy: 0.5041\n",
      "Epoch 37/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9772 - accuracy: 0.5281 - val_loss: 1.0074 - val_accuracy: 0.5101\n",
      "Epoch 38/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9791 - accuracy: 0.5268 - val_loss: 1.0087 - val_accuracy: 0.5009\n",
      "Epoch 39/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9769 - accuracy: 0.5283 - val_loss: 1.0150 - val_accuracy: 0.4995\n",
      "Epoch 40/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9794 - accuracy: 0.5303 - val_loss: 1.0035 - val_accuracy: 0.4972\n",
      "Epoch 41/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9783 - accuracy: 0.5298 - val_loss: 1.0122 - val_accuracy: 0.4945\n",
      "Epoch 42/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9786 - accuracy: 0.5276 - val_loss: 1.0145 - val_accuracy: 0.4936\n",
      "Epoch 43/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9801 - accuracy: 0.5258 - val_loss: 1.0102 - val_accuracy: 0.4977\n",
      "Epoch 44/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9808 - accuracy: 0.5243 - val_loss: 1.0148 - val_accuracy: 0.5087\n",
      "Epoch 45/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9795 - accuracy: 0.5220 - val_loss: 1.0120 - val_accuracy: 0.4908\n",
      "Epoch 46/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9794 - accuracy: 0.5260 - val_loss: 1.0159 - val_accuracy: 0.5028\n",
      "Epoch 47/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9822 - accuracy: 0.5250 - val_loss: 1.0131 - val_accuracy: 0.4968\n",
      "Epoch 48/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9794 - accuracy: 0.5258 - val_loss: 1.0096 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9782 - accuracy: 0.5241 - val_loss: 1.0100 - val_accuracy: 0.5064\n",
      "Epoch 50/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9776 - accuracy: 0.5288 - val_loss: 1.0058 - val_accuracy: 0.5060\n",
      "Epoch 51/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9786 - accuracy: 0.5263 - val_loss: 1.0102 - val_accuracy: 0.4931\n",
      "Epoch 52/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9783 - accuracy: 0.5279 - val_loss: 1.0183 - val_accuracy: 0.5129\n",
      "Epoch 53/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9778 - accuracy: 0.5274 - val_loss: 1.0062 - val_accuracy: 0.5129\n",
      "Epoch 54/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9781 - accuracy: 0.5277 - val_loss: 1.0111 - val_accuracy: 0.5101\n",
      "Epoch 55/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9784 - accuracy: 0.5295 - val_loss: 1.0112 - val_accuracy: 0.5078\n",
      "Epoch 56/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9767 - accuracy: 0.5303 - val_loss: 1.0056 - val_accuracy: 0.5119\n",
      "Epoch 57/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9779 - accuracy: 0.5280 - val_loss: 1.0101 - val_accuracy: 0.5110\n",
      "Epoch 58/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9775 - accuracy: 0.5277 - val_loss: 1.0074 - val_accuracy: 0.5097\n",
      "Epoch 59/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9773 - accuracy: 0.5307 - val_loss: 1.0117 - val_accuracy: 0.4894\n",
      "Epoch 60/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9785 - accuracy: 0.5293 - val_loss: 1.0088 - val_accuracy: 0.5055\n",
      "Epoch 61/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 0.9768 - accuracy: 0.5290 - val_loss: 1.0118 - val_accuracy: 0.5087\n",
      "Epoch 62/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9795 - accuracy: 0.5214 - val_loss: 1.0064 - val_accuracy: 0.5087\n",
      "Epoch 63/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9792 - accuracy: 0.5215 - val_loss: 1.0066 - val_accuracy: 0.5129\n",
      "Epoch 64/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9777 - accuracy: 0.5275 - val_loss: 1.0066 - val_accuracy: 0.5046\n",
      "Epoch 65/200\n",
      "613/613 [==============================] - 0s 594us/step - loss: 0.9782 - accuracy: 0.5281 - val_loss: 1.0027 - val_accuracy: 0.5124\n",
      "Epoch 66/200\n",
      "613/613 [==============================] - 0s 585us/step - loss: 0.9777 - accuracy: 0.5299 - val_loss: 1.0039 - val_accuracy: 0.5069\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 555us/step - loss: 0.9776 - accuracy: 0.5292 - val_loss: 1.0066 - val_accuracy: 0.5078\n",
      "Epoch 68/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9794 - accuracy: 0.5263 - val_loss: 1.0047 - val_accuracy: 0.5005\n",
      "Epoch 69/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 1.0062 - val_accuracy: 0.5014\n",
      "Epoch 70/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9770 - accuracy: 0.5281 - val_loss: 1.0087 - val_accuracy: 0.5018\n",
      "Epoch 71/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9780 - accuracy: 0.5263 - val_loss: 1.0072 - val_accuracy: 0.5055\n",
      "Epoch 72/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9775 - accuracy: 0.5259 - val_loss: 1.0035 - val_accuracy: 0.5087\n",
      "Epoch 73/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9760 - accuracy: 0.5279 - val_loss: 1.0057 - val_accuracy: 0.5051\n",
      "Epoch 74/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9767 - accuracy: 0.5289 - val_loss: 1.0031 - val_accuracy: 0.5083\n",
      "Epoch 75/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9759 - accuracy: 0.5291 - val_loss: 1.0047 - val_accuracy: 0.5023\n",
      "Epoch 76/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9767 - accuracy: 0.5254 - val_loss: 1.0095 - val_accuracy: 0.5046\n",
      "Epoch 77/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9776 - accuracy: 0.5303 - val_loss: 1.0032 - val_accuracy: 0.5115\n",
      "Epoch 78/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9775 - accuracy: 0.5254 - val_loss: 1.0042 - val_accuracy: 0.5092\n",
      "Epoch 79/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9771 - accuracy: 0.5298 - val_loss: 1.0073 - val_accuracy: 0.5101\n",
      "Epoch 80/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9779 - accuracy: 0.5260 - val_loss: 1.0028 - val_accuracy: 0.5133\n",
      "Epoch 81/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9781 - accuracy: 0.5273 - val_loss: 1.0028 - val_accuracy: 0.5083\n",
      "Epoch 82/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9780 - accuracy: 0.5270 - val_loss: 1.0072 - val_accuracy: 0.5119\n",
      "Epoch 83/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9783 - accuracy: 0.5262 - val_loss: 1.0112 - val_accuracy: 0.5115\n",
      "Epoch 84/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9770 - accuracy: 0.5269 - val_loss: 1.0049 - val_accuracy: 0.5023\n",
      "Epoch 85/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9774 - accuracy: 0.5292 - val_loss: 1.0071 - val_accuracy: 0.5119\n",
      "Epoch 86/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 1.0024 - val_accuracy: 0.5110\n",
      "Epoch 87/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9771 - accuracy: 0.5266 - val_loss: 1.0071 - val_accuracy: 0.5170\n",
      "Epoch 88/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9772 - accuracy: 0.5269 - val_loss: 1.0131 - val_accuracy: 0.5069\n",
      "Epoch 89/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9762 - accuracy: 0.5288 - val_loss: 1.0106 - val_accuracy: 0.5018\n",
      "Epoch 90/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9764 - accuracy: 0.5300 - val_loss: 1.0067 - val_accuracy: 0.4982\n",
      "Epoch 91/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9770 - accuracy: 0.5283 - val_loss: 1.0092 - val_accuracy: 0.5064\n",
      "Epoch 92/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9770 - accuracy: 0.5260 - val_loss: 1.0097 - val_accuracy: 0.5087\n",
      "Epoch 93/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9762 - accuracy: 0.5294 - val_loss: 1.0043 - val_accuracy: 0.5055\n",
      "Epoch 94/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9773 - accuracy: 0.5295 - val_loss: 1.0070 - val_accuracy: 0.5161\n",
      "Epoch 95/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 1.0045 - val_accuracy: 0.5110\n",
      "Epoch 96/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9776 - accuracy: 0.5258 - val_loss: 1.0071 - val_accuracy: 0.5087\n",
      "Epoch 97/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9768 - accuracy: 0.5297 - val_loss: 1.0054 - val_accuracy: 0.5097\n",
      "Epoch 98/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9758 - accuracy: 0.5285 - val_loss: 1.0077 - val_accuracy: 0.5133\n",
      "Epoch 99/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9757 - accuracy: 0.5307 - val_loss: 1.0083 - val_accuracy: 0.5138\n",
      "Epoch 100/200\n",
      "613/613 [==============================] - 0s 547us/step - loss: 0.9754 - accuracy: 0.5286 - val_loss: 1.0060 - val_accuracy: 0.5110\n",
      "Epoch 101/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9757 - accuracy: 0.5296 - val_loss: 1.0046 - val_accuracy: 0.5060\n",
      "Epoch 102/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9754 - accuracy: 0.5315 - val_loss: 1.0065 - val_accuracy: 0.5041\n",
      "Epoch 103/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9747 - accuracy: 0.5320 - val_loss: 1.0083 - val_accuracy: 0.5115\n",
      "Epoch 104/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9753 - accuracy: 0.5321 - val_loss: 1.0063 - val_accuracy: 0.5119\n",
      "Epoch 105/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9753 - accuracy: 0.5280 - val_loss: 1.0095 - val_accuracy: 0.4986\n",
      "Epoch 106/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9766 - accuracy: 0.5283 - val_loss: 1.0015 - val_accuracy: 0.5106\n",
      "Epoch 107/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9759 - accuracy: 0.5312 - val_loss: 1.0089 - val_accuracy: 0.5018\n",
      "Epoch 108/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9757 - accuracy: 0.5283 - val_loss: 1.0102 - val_accuracy: 0.4968\n",
      "Epoch 109/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 1.0226 - val_accuracy: 0.5032\n",
      "Epoch 110/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9759 - accuracy: 0.5321 - val_loss: 1.0122 - val_accuracy: 0.5101\n",
      "Epoch 111/200\n",
      "613/613 [==============================] - 0s 581us/step - loss: 0.9747 - accuracy: 0.5283 - val_loss: 1.0101 - val_accuracy: 0.4922\n",
      "Epoch 112/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 1.0058 - val_accuracy: 0.5110\n",
      "Epoch 113/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9768 - accuracy: 0.5300 - val_loss: 1.0029 - val_accuracy: 0.5083\n",
      "Epoch 114/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9763 - accuracy: 0.5282 - val_loss: 1.0071 - val_accuracy: 0.5018\n",
      "Epoch 115/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9764 - accuracy: 0.5297 - val_loss: 1.0057 - val_accuracy: 0.5129\n",
      "Epoch 116/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9755 - accuracy: 0.5313 - val_loss: 1.0108 - val_accuracy: 0.5110\n",
      "Epoch 117/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9759 - accuracy: 0.5281 - val_loss: 1.0072 - val_accuracy: 0.5041\n",
      "Epoch 118/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9755 - accuracy: 0.5293 - val_loss: 1.0068 - val_accuracy: 0.5110\n",
      "Epoch 119/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9750 - accuracy: 0.5306 - val_loss: 1.0105 - val_accuracy: 0.5069\n",
      "Epoch 120/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9757 - accuracy: 0.5311 - val_loss: 1.0039 - val_accuracy: 0.5133\n",
      "Epoch 121/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9745 - accuracy: 0.5292 - val_loss: 1.0049 - val_accuracy: 0.5051\n",
      "Epoch 122/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9754 - accuracy: 0.5299 - val_loss: 1.0112 - val_accuracy: 0.5092\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 556us/step - loss: 0.9761 - accuracy: 0.5291 - val_loss: 1.0035 - val_accuracy: 0.5133\n",
      "Epoch 124/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 1.0053 - val_accuracy: 0.5037\n",
      "Epoch 125/200\n",
      "613/613 [==============================] - 0s 623us/step - loss: 0.9760 - accuracy: 0.5299 - val_loss: 1.0072 - val_accuracy: 0.5009\n",
      "Epoch 126/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9765 - accuracy: 0.5298 - val_loss: 1.0048 - val_accuracy: 0.5115\n",
      "Epoch 127/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9741 - accuracy: 0.5315 - val_loss: 1.0054 - val_accuracy: 0.5037\n",
      "Epoch 128/200\n",
      "613/613 [==============================] - 0s 585us/step - loss: 0.9753 - accuracy: 0.5297 - val_loss: 1.0097 - val_accuracy: 0.5051\n",
      "Epoch 129/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9749 - accuracy: 0.5290 - val_loss: 1.0104 - val_accuracy: 0.5037\n",
      "Epoch 130/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9745 - accuracy: 0.5312 - val_loss: 1.0068 - val_accuracy: 0.5161\n",
      "Epoch 131/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9747 - accuracy: 0.5295 - val_loss: 1.0053 - val_accuracy: 0.5083\n",
      "Epoch 132/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9755 - accuracy: 0.5310 - val_loss: 1.0044 - val_accuracy: 0.5069\n",
      "Epoch 133/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9745 - accuracy: 0.5289 - val_loss: 1.0065 - val_accuracy: 0.5138\n",
      "Epoch 134/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9737 - accuracy: 0.5318 - val_loss: 1.0040 - val_accuracy: 0.5142\n",
      "Epoch 135/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9758 - accuracy: 0.5285 - val_loss: 1.0055 - val_accuracy: 0.5101\n",
      "Epoch 136/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9760 - accuracy: 0.5306 - val_loss: 1.0042 - val_accuracy: 0.5124\n",
      "Epoch 137/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9750 - accuracy: 0.5296 - val_loss: 1.0062 - val_accuracy: 0.5032\n",
      "Epoch 138/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9749 - accuracy: 0.5300 - val_loss: 1.0056 - val_accuracy: 0.5106\n",
      "Epoch 139/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9737 - accuracy: 0.5322 - val_loss: 1.0073 - val_accuracy: 0.5018\n",
      "Epoch 140/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9738 - accuracy: 0.5332 - val_loss: 1.0084 - val_accuracy: 0.5055\n",
      "Epoch 141/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9750 - accuracy: 0.5304 - val_loss: 1.0086 - val_accuracy: 0.5032\n",
      "Epoch 142/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9764 - accuracy: 0.5290 - val_loss: 1.0097 - val_accuracy: 0.5055\n",
      "Epoch 143/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9750 - accuracy: 0.5288 - val_loss: 1.0089 - val_accuracy: 0.5009\n",
      "Epoch 144/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9751 - accuracy: 0.5281 - val_loss: 1.0056 - val_accuracy: 0.5051\n",
      "Epoch 145/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9758 - accuracy: 0.5281 - val_loss: 1.0044 - val_accuracy: 0.5060\n",
      "Epoch 146/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9769 - accuracy: 0.5300 - val_loss: 1.0038 - val_accuracy: 0.5119\n",
      "Epoch 147/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9770 - accuracy: 0.5311 - val_loss: 1.0113 - val_accuracy: 0.5055\n",
      "Epoch 148/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9770 - accuracy: 0.5313 - val_loss: 1.0066 - val_accuracy: 0.5092\n",
      "Epoch 149/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9758 - accuracy: 0.5303 - val_loss: 1.0073 - val_accuracy: 0.4931\n",
      "Epoch 150/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9766 - accuracy: 0.5269 - val_loss: 1.0053 - val_accuracy: 0.5000\n",
      "Epoch 151/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9769 - accuracy: 0.5280 - val_loss: 1.0158 - val_accuracy: 0.4917\n",
      "Epoch 152/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9762 - accuracy: 0.5274 - val_loss: 1.0062 - val_accuracy: 0.5097\n",
      "Epoch 153/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9762 - accuracy: 0.5275 - val_loss: 1.0072 - val_accuracy: 0.4986\n",
      "Epoch 154/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9763 - accuracy: 0.5293 - val_loss: 1.0111 - val_accuracy: 0.4917\n",
      "Epoch 155/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 1.0052 - val_accuracy: 0.5087\n",
      "Epoch 156/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9743 - accuracy: 0.5315 - val_loss: 1.0074 - val_accuracy: 0.5069\n",
      "Epoch 157/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9747 - accuracy: 0.5316 - val_loss: 1.0044 - val_accuracy: 0.5133\n",
      "Epoch 158/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9743 - accuracy: 0.5293 - val_loss: 1.0113 - val_accuracy: 0.5032\n",
      "Epoch 159/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9747 - accuracy: 0.5276 - val_loss: 1.0043 - val_accuracy: 0.5124\n",
      "Epoch 160/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9750 - accuracy: 0.5304 - val_loss: 1.0044 - val_accuracy: 0.5074\n",
      "Epoch 161/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9760 - accuracy: 0.5280 - val_loss: 1.0073 - val_accuracy: 0.4959\n",
      "Epoch 162/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9752 - accuracy: 0.5261 - val_loss: 1.0068 - val_accuracy: 0.4862\n",
      "Epoch 163/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9742 - accuracy: 0.5278 - val_loss: 1.0084 - val_accuracy: 0.5129\n",
      "Epoch 164/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9748 - accuracy: 0.5295 - val_loss: 1.0074 - val_accuracy: 0.4959\n",
      "Epoch 165/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9771 - accuracy: 0.5255 - val_loss: 1.0038 - val_accuracy: 0.5101\n",
      "Epoch 166/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 1.0071 - val_accuracy: 0.5106\n",
      "Epoch 167/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9742 - accuracy: 0.5321 - val_loss: 1.0114 - val_accuracy: 0.5005\n",
      "Epoch 168/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9750 - accuracy: 0.5320 - val_loss: 1.0103 - val_accuracy: 0.5165\n",
      "Epoch 169/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9754 - accuracy: 0.5280 - val_loss: 1.0091 - val_accuracy: 0.5083\n",
      "Epoch 170/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 1.0034 - val_accuracy: 0.5046\n",
      "Epoch 171/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9759 - accuracy: 0.5304 - val_loss: 1.0108 - val_accuracy: 0.4931\n",
      "Epoch 172/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9760 - accuracy: 0.5299 - val_loss: 1.0109 - val_accuracy: 0.5092\n",
      "Epoch 173/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9754 - accuracy: 0.5311 - val_loss: 1.0078 - val_accuracy: 0.5055\n",
      "Epoch 174/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9756 - accuracy: 0.5307 - val_loss: 1.0074 - val_accuracy: 0.5083\n",
      "Epoch 175/200\n",
      "613/613 [==============================] - 0s 589us/step - loss: 0.9749 - accuracy: 0.5266 - val_loss: 1.0051 - val_accuracy: 0.5005\n",
      "Epoch 176/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9744 - accuracy: 0.5310 - val_loss: 1.0073 - val_accuracy: 0.5101\n",
      "Epoch 177/200\n",
      "613/613 [==============================] - 0s 600us/step - loss: 0.9746 - accuracy: 0.5315 - val_loss: 1.0057 - val_accuracy: 0.5133\n",
      "Epoch 178/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9759 - accuracy: 0.5312 - val_loss: 1.0049 - val_accuracy: 0.5115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9749 - accuracy: 0.5293 - val_loss: 1.0041 - val_accuracy: 0.5037\n",
      "Epoch 180/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9752 - accuracy: 0.5299 - val_loss: 1.0066 - val_accuracy: 0.5028\n",
      "Epoch 181/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9751 - accuracy: 0.5318 - val_loss: 1.0068 - val_accuracy: 0.5005\n",
      "Epoch 182/200\n",
      "613/613 [==============================] - 0s 609us/step - loss: 0.9750 - accuracy: 0.5290 - val_loss: 1.0069 - val_accuracy: 0.5005\n",
      "Epoch 183/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9756 - accuracy: 0.5283 - val_loss: 1.0049 - val_accuracy: 0.5087\n",
      "Epoch 184/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9750 - accuracy: 0.5294 - val_loss: 1.0042 - val_accuracy: 0.5106\n",
      "Epoch 185/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9740 - accuracy: 0.5310 - val_loss: 1.0061 - val_accuracy: 0.5133\n",
      "Epoch 186/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9741 - accuracy: 0.5314 - val_loss: 1.0083 - val_accuracy: 0.5051\n",
      "Epoch 187/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9764 - accuracy: 0.5273 - val_loss: 1.0055 - val_accuracy: 0.5097\n",
      "Epoch 188/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9751 - accuracy: 0.5290 - val_loss: 1.0113 - val_accuracy: 0.5018\n",
      "Epoch 189/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9749 - accuracy: 0.5282 - val_loss: 1.0039 - val_accuracy: 0.5092\n",
      "Epoch 190/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9749 - accuracy: 0.5290 - val_loss: 1.0038 - val_accuracy: 0.5165\n",
      "Epoch 191/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9744 - accuracy: 0.5312 - val_loss: 1.0075 - val_accuracy: 0.5046\n",
      "Epoch 192/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9745 - accuracy: 0.5309 - val_loss: 1.0081 - val_accuracy: 0.5101\n",
      "Epoch 193/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9748 - accuracy: 0.5292 - val_loss: 1.0014 - val_accuracy: 0.5055\n",
      "Epoch 194/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9744 - accuracy: 0.5315 - val_loss: 1.0038 - val_accuracy: 0.5101\n",
      "Epoch 195/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9727 - accuracy: 0.5313 - val_loss: 1.0071 - val_accuracy: 0.5078\n",
      "Epoch 196/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9742 - accuracy: 0.5304 - val_loss: 1.0068 - val_accuracy: 0.5119\n",
      "Epoch 197/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9745 - accuracy: 0.5294 - val_loss: 1.0039 - val_accuracy: 0.5110\n",
      "Epoch 198/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 1.0090 - val_accuracy: 0.5023\n",
      "Epoch 199/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9752 - accuracy: 0.5278 - val_loss: 1.0078 - val_accuracy: 0.5087\n",
      "Epoch 200/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9741 - accuracy: 0.5272 - val_loss: 1.0053 - val_accuracy: 0.5115\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 585us/step - loss: 0.9730 - accuracy: 0.5322\n",
      "Accuracy : 0.5321930050849915\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 1.0053 - accuracy: 0.5115\n",
      "Accuracy : 0.5114889740943909\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "613/613 [==============================] - 0s 767us/step - loss: 1.0445 - accuracy: 0.4661 - val_loss: 1.0301 - val_accuracy: 0.4931\n",
      "Epoch 2/200\n",
      "613/613 [==============================] - 0s 797us/step - loss: 1.0007 - accuracy: 0.5137 - val_loss: 1.0020 - val_accuracy: 0.5106\n",
      "Epoch 3/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9920 - accuracy: 0.5157 - val_loss: 1.0073 - val_accuracy: 0.5060\n",
      "Epoch 4/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9905 - accuracy: 0.5165 - val_loss: 1.0013 - val_accuracy: 0.5023\n",
      "Epoch 5/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9896 - accuracy: 0.5216 - val_loss: 0.9988 - val_accuracy: 0.5156\n",
      "Epoch 6/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9874 - accuracy: 0.5197 - val_loss: 0.9940 - val_accuracy: 0.5234\n",
      "Epoch 7/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9867 - accuracy: 0.5206 - val_loss: 0.9947 - val_accuracy: 0.5055\n",
      "Epoch 8/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9862 - accuracy: 0.5202 - val_loss: 0.9916 - val_accuracy: 0.5184\n",
      "Epoch 9/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9832 - accuracy: 0.5247 - val_loss: 0.9999 - val_accuracy: 0.4885\n",
      "Epoch 10/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9839 - accuracy: 0.5214 - val_loss: 0.9925 - val_accuracy: 0.5119\n",
      "Epoch 11/200\n",
      "613/613 [==============================] - 0s 585us/step - loss: 0.9842 - accuracy: 0.5197 - val_loss: 0.9864 - val_accuracy: 0.5188\n",
      "Epoch 12/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9822 - accuracy: 0.5251 - val_loss: 0.9920 - val_accuracy: 0.5147\n",
      "Epoch 13/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9814 - accuracy: 0.5222 - val_loss: 0.9994 - val_accuracy: 0.4917\n",
      "Epoch 14/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9823 - accuracy: 0.5222 - val_loss: 0.9953 - val_accuracy: 0.5198\n",
      "Epoch 15/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9830 - accuracy: 0.5239 - val_loss: 0.9960 - val_accuracy: 0.5124\n",
      "Epoch 16/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9812 - accuracy: 0.5256 - val_loss: 0.9951 - val_accuracy: 0.5211\n",
      "Epoch 17/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9814 - accuracy: 0.5238 - val_loss: 0.9945 - val_accuracy: 0.5253\n",
      "Epoch 18/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9838 - accuracy: 0.5191 - val_loss: 0.9940 - val_accuracy: 0.5170\n",
      "Epoch 19/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9835 - accuracy: 0.5208 - val_loss: 0.9908 - val_accuracy: 0.5230\n",
      "Epoch 20/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9826 - accuracy: 0.5208 - val_loss: 0.9964 - val_accuracy: 0.5170\n",
      "Epoch 21/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9808 - accuracy: 0.5270 - val_loss: 0.9923 - val_accuracy: 0.5239\n",
      "Epoch 22/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9796 - accuracy: 0.5264 - val_loss: 0.9979 - val_accuracy: 0.5152\n",
      "Epoch 23/200\n",
      "613/613 [==============================] - 0s 538us/step - loss: 0.9841 - accuracy: 0.5211 - val_loss: 0.9928 - val_accuracy: 0.5193\n",
      "Epoch 24/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9838 - accuracy: 0.5186 - val_loss: 1.0000 - val_accuracy: 0.5014\n",
      "Epoch 25/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9819 - accuracy: 0.5229 - val_loss: 0.9900 - val_accuracy: 0.5156\n",
      "Epoch 26/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9819 - accuracy: 0.5247 - val_loss: 0.9962 - val_accuracy: 0.5142\n",
      "Epoch 27/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9806 - accuracy: 0.5246 - val_loss: 0.9873 - val_accuracy: 0.5248\n",
      "Epoch 28/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9814 - accuracy: 0.5235 - val_loss: 0.9936 - val_accuracy: 0.5216\n",
      "Epoch 29/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9803 - accuracy: 0.5256 - val_loss: 0.9887 - val_accuracy: 0.5198\n",
      "Epoch 30/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9799 - accuracy: 0.5260 - val_loss: 0.9969 - val_accuracy: 0.5216\n",
      "Epoch 31/200\n",
      "613/613 [==============================] - 0s 590us/step - loss: 0.9815 - accuracy: 0.5201 - val_loss: 0.9926 - val_accuracy: 0.5138\n",
      "Epoch 32/200\n",
      "613/613 [==============================] - 0s 546us/step - loss: 0.9801 - accuracy: 0.5255 - val_loss: 0.9958 - val_accuracy: 0.5202\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 583us/step - loss: 0.9797 - accuracy: 0.5255 - val_loss: 0.9953 - val_accuracy: 0.5267\n",
      "Epoch 34/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9799 - accuracy: 0.5246 - val_loss: 0.9915 - val_accuracy: 0.5267\n",
      "Epoch 35/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9797 - accuracy: 0.5245 - val_loss: 0.9897 - val_accuracy: 0.5239\n",
      "Epoch 36/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9798 - accuracy: 0.5235 - val_loss: 0.9951 - val_accuracy: 0.5165\n",
      "Epoch 37/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9826 - accuracy: 0.5225 - val_loss: 0.9951 - val_accuracy: 0.5156\n",
      "Epoch 38/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9832 - accuracy: 0.5223 - val_loss: 0.9963 - val_accuracy: 0.5115\n",
      "Epoch 39/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9807 - accuracy: 0.5270 - val_loss: 0.9913 - val_accuracy: 0.5193\n",
      "Epoch 40/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9793 - accuracy: 0.5240 - val_loss: 0.9972 - val_accuracy: 0.5170\n",
      "Epoch 41/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9786 - accuracy: 0.5280 - val_loss: 0.9941 - val_accuracy: 0.5234\n",
      "Epoch 42/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9793 - accuracy: 0.5242 - val_loss: 0.9931 - val_accuracy: 0.5179\n",
      "Epoch 43/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9830 - accuracy: 0.5226 - val_loss: 0.9945 - val_accuracy: 0.5198\n",
      "Epoch 44/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9805 - accuracy: 0.5263 - val_loss: 0.9895 - val_accuracy: 0.5193\n",
      "Epoch 45/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9801 - accuracy: 0.5283 - val_loss: 0.9880 - val_accuracy: 0.5184\n",
      "Epoch 46/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9799 - accuracy: 0.5264 - val_loss: 0.9911 - val_accuracy: 0.5207\n",
      "Epoch 47/200\n",
      "613/613 [==============================] - 0s 592us/step - loss: 0.9804 - accuracy: 0.5265 - val_loss: 0.9893 - val_accuracy: 0.5234\n",
      "Epoch 48/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9806 - accuracy: 0.5225 - val_loss: 0.9898 - val_accuracy: 0.5216\n",
      "Epoch 49/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9797 - accuracy: 0.5251 - val_loss: 0.9921 - val_accuracy: 0.4972\n",
      "Epoch 50/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9799 - accuracy: 0.5287 - val_loss: 0.9929 - val_accuracy: 0.5156\n",
      "Epoch 51/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9777 - accuracy: 0.5300 - val_loss: 0.9929 - val_accuracy: 0.5184\n",
      "Epoch 52/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9786 - accuracy: 0.5291 - val_loss: 0.9916 - val_accuracy: 0.5161\n",
      "Epoch 53/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9781 - accuracy: 0.5295 - val_loss: 0.9983 - val_accuracy: 0.5060\n",
      "Epoch 54/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9777 - accuracy: 0.5270 - val_loss: 0.9944 - val_accuracy: 0.5216\n",
      "Epoch 55/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9789 - accuracy: 0.5285 - val_loss: 0.9904 - val_accuracy: 0.5193\n",
      "Epoch 56/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9789 - accuracy: 0.5281 - val_loss: 0.9914 - val_accuracy: 0.5221\n",
      "Epoch 57/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9788 - accuracy: 0.5269 - val_loss: 0.9934 - val_accuracy: 0.5175\n",
      "Epoch 58/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9797 - accuracy: 0.5252 - val_loss: 0.9872 - val_accuracy: 0.5211\n",
      "Epoch 59/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9782 - accuracy: 0.5284 - val_loss: 0.9841 - val_accuracy: 0.5221\n",
      "Epoch 60/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9789 - accuracy: 0.5233 - val_loss: 0.9891 - val_accuracy: 0.5152\n",
      "Epoch 61/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9800 - accuracy: 0.5209 - val_loss: 0.9902 - val_accuracy: 0.5193\n",
      "Epoch 62/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9780 - accuracy: 0.5283 - val_loss: 0.9895 - val_accuracy: 0.5170\n",
      "Epoch 63/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9779 - accuracy: 0.5261 - val_loss: 0.9875 - val_accuracy: 0.5198\n",
      "Epoch 64/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9793 - accuracy: 0.5270 - val_loss: 1.0039 - val_accuracy: 0.4968\n",
      "Epoch 65/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9877 - val_accuracy: 0.5221\n",
      "Epoch 66/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9784 - accuracy: 0.5274 - val_loss: 0.9910 - val_accuracy: 0.5179\n",
      "Epoch 67/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9788 - accuracy: 0.5287 - val_loss: 0.9988 - val_accuracy: 0.5142\n",
      "Epoch 68/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9786 - accuracy: 0.5267 - val_loss: 0.9887 - val_accuracy: 0.5234\n",
      "Epoch 69/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9775 - accuracy: 0.5292 - val_loss: 0.9909 - val_accuracy: 0.5193\n",
      "Epoch 70/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9773 - accuracy: 0.5283 - val_loss: 0.9899 - val_accuracy: 0.5234\n",
      "Epoch 71/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9777 - accuracy: 0.5296 - val_loss: 0.9886 - val_accuracy: 0.5179\n",
      "Epoch 72/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9855 - val_accuracy: 0.5221\n",
      "Epoch 73/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9767 - accuracy: 0.5282 - val_loss: 0.9894 - val_accuracy: 0.5207\n",
      "Epoch 74/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9794 - accuracy: 0.5228 - val_loss: 0.9958 - val_accuracy: 0.5184\n",
      "Epoch 75/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9787 - accuracy: 0.5283 - val_loss: 0.9893 - val_accuracy: 0.5147\n",
      "Epoch 76/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9781 - accuracy: 0.5280 - val_loss: 0.9922 - val_accuracy: 0.5142\n",
      "Epoch 77/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9774 - accuracy: 0.5291 - val_loss: 0.9956 - val_accuracy: 0.5161\n",
      "Epoch 78/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9793 - accuracy: 0.5219 - val_loss: 0.9972 - val_accuracy: 0.5147\n",
      "Epoch 79/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9811 - accuracy: 0.5213 - val_loss: 0.9945 - val_accuracy: 0.5165\n",
      "Epoch 80/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9801 - accuracy: 0.5243 - val_loss: 1.0027 - val_accuracy: 0.4922\n",
      "Epoch 81/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9805 - accuracy: 0.5242 - val_loss: 0.9915 - val_accuracy: 0.5184\n",
      "Epoch 82/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9781 - accuracy: 0.5243 - val_loss: 0.9881 - val_accuracy: 0.5248\n",
      "Epoch 83/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9790 - accuracy: 0.5252 - val_loss: 0.9902 - val_accuracy: 0.5207\n",
      "Epoch 84/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9793 - accuracy: 0.5266 - val_loss: 0.9904 - val_accuracy: 0.5179\n",
      "Epoch 85/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9793 - accuracy: 0.5248 - val_loss: 0.9909 - val_accuracy: 0.5193\n",
      "Epoch 86/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9788 - accuracy: 0.5250 - val_loss: 0.9888 - val_accuracy: 0.5234\n",
      "Epoch 87/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9784 - accuracy: 0.5267 - val_loss: 0.9919 - val_accuracy: 0.5161\n",
      "Epoch 88/200\n",
      "613/613 [==============================] - 0s 585us/step - loss: 0.9784 - accuracy: 0.5261 - val_loss: 0.9938 - val_accuracy: 0.5257\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 565us/step - loss: 0.9788 - accuracy: 0.5260 - val_loss: 0.9871 - val_accuracy: 0.5234\n",
      "Epoch 90/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9780 - accuracy: 0.5283 - val_loss: 0.9972 - val_accuracy: 0.4779\n",
      "Epoch 91/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9789 - accuracy: 0.5283 - val_loss: 0.9886 - val_accuracy: 0.5161\n",
      "Epoch 92/200\n",
      "613/613 [==============================] - 0s 601us/step - loss: 0.9783 - accuracy: 0.5304 - val_loss: 0.9927 - val_accuracy: 0.5161\n",
      "Epoch 93/200\n",
      "613/613 [==============================] - 0s 582us/step - loss: 0.9789 - accuracy: 0.5295 - val_loss: 0.9940 - val_accuracy: 0.5179\n",
      "Epoch 94/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9784 - accuracy: 0.5302 - val_loss: 0.9921 - val_accuracy: 0.5078\n",
      "Epoch 95/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9785 - accuracy: 0.5296 - val_loss: 0.9907 - val_accuracy: 0.5115\n",
      "Epoch 96/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9798 - accuracy: 0.5259 - val_loss: 0.9929 - val_accuracy: 0.5276\n",
      "Epoch 97/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9782 - accuracy: 0.5261 - val_loss: 0.9893 - val_accuracy: 0.5119\n",
      "Epoch 98/200\n",
      "613/613 [==============================] - 0s 549us/step - loss: 0.9781 - accuracy: 0.5284 - val_loss: 0.9919 - val_accuracy: 0.4949\n",
      "Epoch 99/200\n",
      "613/613 [==============================] - 0s 590us/step - loss: 0.9792 - accuracy: 0.5254 - val_loss: 0.9913 - val_accuracy: 0.5211\n",
      "Epoch 100/200\n",
      "613/613 [==============================] - 0s 550us/step - loss: 0.9788 - accuracy: 0.5291 - val_loss: 0.9893 - val_accuracy: 0.5138\n",
      "Epoch 101/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9802 - accuracy: 0.5298 - val_loss: 0.9894 - val_accuracy: 0.5188\n",
      "Epoch 102/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9780 - accuracy: 0.5303 - val_loss: 0.9948 - val_accuracy: 0.5234\n",
      "Epoch 103/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9805 - accuracy: 0.5267 - val_loss: 0.9909 - val_accuracy: 0.5156\n",
      "Epoch 104/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9799 - accuracy: 0.5260 - val_loss: 0.9893 - val_accuracy: 0.5179\n",
      "Epoch 105/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9798 - accuracy: 0.5281 - val_loss: 0.9980 - val_accuracy: 0.5161\n",
      "Epoch 106/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9785 - accuracy: 0.5307 - val_loss: 0.9929 - val_accuracy: 0.5101\n",
      "Epoch 107/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9782 - accuracy: 0.5300 - val_loss: 0.9953 - val_accuracy: 0.5211\n",
      "Epoch 108/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9796 - accuracy: 0.5263 - val_loss: 0.9938 - val_accuracy: 0.5147\n",
      "Epoch 109/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9787 - accuracy: 0.5270 - val_loss: 0.9895 - val_accuracy: 0.5193\n",
      "Epoch 110/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9793 - accuracy: 0.5255 - val_loss: 0.9950 - val_accuracy: 0.4945\n",
      "Epoch 111/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9787 - accuracy: 0.5279 - val_loss: 0.9945 - val_accuracy: 0.5202\n",
      "Epoch 112/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9785 - accuracy: 0.5280 - val_loss: 0.9923 - val_accuracy: 0.5055\n",
      "Epoch 113/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9799 - accuracy: 0.5278 - val_loss: 0.9967 - val_accuracy: 0.5161\n",
      "Epoch 114/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9788 - accuracy: 0.5277 - val_loss: 0.9892 - val_accuracy: 0.5170\n",
      "Epoch 115/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9775 - accuracy: 0.5289 - val_loss: 0.9938 - val_accuracy: 0.5248\n",
      "Epoch 116/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9786 - accuracy: 0.5250 - val_loss: 0.9887 - val_accuracy: 0.5244\n",
      "Epoch 117/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9790 - accuracy: 0.5281 - val_loss: 0.9940 - val_accuracy: 0.5202\n",
      "Epoch 118/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9777 - accuracy: 0.5297 - val_loss: 0.9959 - val_accuracy: 0.5234\n",
      "Epoch 119/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9799 - accuracy: 0.5274 - val_loss: 0.9883 - val_accuracy: 0.5216\n",
      "Epoch 120/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9787 - accuracy: 0.5278 - val_loss: 0.9880 - val_accuracy: 0.5184\n",
      "Epoch 121/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9921 - val_accuracy: 0.5216\n",
      "Epoch 122/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9769 - accuracy: 0.5307 - val_loss: 0.9910 - val_accuracy: 0.5216\n",
      "Epoch 123/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9782 - accuracy: 0.5287 - val_loss: 0.9899 - val_accuracy: 0.5202\n",
      "Epoch 124/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9779 - accuracy: 0.5294 - val_loss: 0.9900 - val_accuracy: 0.5225\n",
      "Epoch 125/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9908 - val_accuracy: 0.5152\n",
      "Epoch 126/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9767 - accuracy: 0.5282 - val_loss: 0.9855 - val_accuracy: 0.5290\n",
      "Epoch 127/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9771 - accuracy: 0.5251 - val_loss: 0.9914 - val_accuracy: 0.5198\n",
      "Epoch 128/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9775 - accuracy: 0.5290 - val_loss: 0.9910 - val_accuracy: 0.5165\n",
      "Epoch 129/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9783 - accuracy: 0.5278 - val_loss: 0.9891 - val_accuracy: 0.5216\n",
      "Epoch 130/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9778 - accuracy: 0.5266 - val_loss: 0.9921 - val_accuracy: 0.5138\n",
      "Epoch 131/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9783 - accuracy: 0.5298 - val_loss: 0.9884 - val_accuracy: 0.5221\n",
      "Epoch 132/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9787 - accuracy: 0.5272 - val_loss: 0.9900 - val_accuracy: 0.5230\n",
      "Epoch 133/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9788 - accuracy: 0.5270 - val_loss: 0.9905 - val_accuracy: 0.5202\n",
      "Epoch 134/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9788 - accuracy: 0.5270 - val_loss: 0.9874 - val_accuracy: 0.5165\n",
      "Epoch 135/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9789 - accuracy: 0.5273 - val_loss: 0.9979 - val_accuracy: 0.5221\n",
      "Epoch 136/200\n",
      "613/613 [==============================] - 0s 550us/step - loss: 0.9777 - accuracy: 0.5296 - val_loss: 0.9933 - val_accuracy: 0.5198\n",
      "Epoch 137/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9786 - accuracy: 0.5282 - val_loss: 0.9875 - val_accuracy: 0.5221\n",
      "Epoch 138/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9780 - accuracy: 0.5294 - val_loss: 0.9899 - val_accuracy: 0.5225\n",
      "Epoch 139/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9775 - accuracy: 0.5292 - val_loss: 0.9950 - val_accuracy: 0.5064\n",
      "Epoch 140/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9769 - accuracy: 0.5299 - val_loss: 1.0033 - val_accuracy: 0.5074\n",
      "Epoch 141/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9792 - accuracy: 0.5261 - val_loss: 0.9914 - val_accuracy: 0.5193\n",
      "Epoch 142/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9791 - accuracy: 0.5200 - val_loss: 0.9951 - val_accuracy: 0.5101\n",
      "Epoch 143/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9780 - accuracy: 0.5294 - val_loss: 0.9915 - val_accuracy: 0.5202\n",
      "Epoch 144/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9777 - accuracy: 0.5265 - val_loss: 1.0000 - val_accuracy: 0.5152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9772 - accuracy: 0.5276 - val_loss: 0.9921 - val_accuracy: 0.5253\n",
      "Epoch 146/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9770 - accuracy: 0.5285 - val_loss: 0.9952 - val_accuracy: 0.5051\n",
      "Epoch 147/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9781 - accuracy: 0.5255 - val_loss: 0.9896 - val_accuracy: 0.5193\n",
      "Epoch 148/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9976 - val_accuracy: 0.5074\n",
      "Epoch 149/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9769 - accuracy: 0.5302 - val_loss: 0.9909 - val_accuracy: 0.5244\n",
      "Epoch 150/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9759 - accuracy: 0.5278 - val_loss: 0.9880 - val_accuracy: 0.5152\n",
      "Epoch 151/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9766 - accuracy: 0.5307 - val_loss: 0.9938 - val_accuracy: 0.5211\n",
      "Epoch 152/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9777 - accuracy: 0.5283 - val_loss: 0.9897 - val_accuracy: 0.5234\n",
      "Epoch 153/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9762 - accuracy: 0.5294 - val_loss: 0.9901 - val_accuracy: 0.5193\n",
      "Epoch 154/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9770 - accuracy: 0.5299 - val_loss: 0.9946 - val_accuracy: 0.5147\n",
      "Epoch 155/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9777 - accuracy: 0.5280 - val_loss: 0.9903 - val_accuracy: 0.5234\n",
      "Epoch 156/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9781 - accuracy: 0.5290 - val_loss: 0.9918 - val_accuracy: 0.5170\n",
      "Epoch 157/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9772 - accuracy: 0.5290 - val_loss: 0.9888 - val_accuracy: 0.5211\n",
      "Epoch 158/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9768 - accuracy: 0.5296 - val_loss: 0.9924 - val_accuracy: 0.5211\n",
      "Epoch 159/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9774 - accuracy: 0.5299 - val_loss: 1.0022 - val_accuracy: 0.5023\n",
      "Epoch 160/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9772 - accuracy: 0.5284 - val_loss: 0.9877 - val_accuracy: 0.5129\n",
      "Epoch 161/200\n",
      "613/613 [==============================] - 0s 599us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9915 - val_accuracy: 0.5060\n",
      "Epoch 162/200\n",
      "613/613 [==============================] - 0s 600us/step - loss: 0.9781 - accuracy: 0.5250 - val_loss: 0.9931 - val_accuracy: 0.5207\n",
      "Epoch 163/200\n",
      "613/613 [==============================] - 0s 597us/step - loss: 0.9780 - accuracy: 0.5258 - val_loss: 0.9893 - val_accuracy: 0.5216\n",
      "Epoch 164/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9771 - accuracy: 0.5284 - val_loss: 0.9983 - val_accuracy: 0.5234\n",
      "Epoch 165/200\n",
      "613/613 [==============================] - 0s 582us/step - loss: 0.9785 - accuracy: 0.5258 - val_loss: 0.9900 - val_accuracy: 0.5207\n",
      "Epoch 166/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9785 - accuracy: 0.5275 - val_loss: 0.9957 - val_accuracy: 0.5115\n",
      "Epoch 167/200\n",
      "613/613 [==============================] - 0s 597us/step - loss: 0.9770 - accuracy: 0.5289 - val_loss: 0.9898 - val_accuracy: 0.5244\n",
      "Epoch 168/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 0.9775 - accuracy: 0.5297 - val_loss: 0.9888 - val_accuracy: 0.5188\n",
      "Epoch 169/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9777 - accuracy: 0.5306 - val_loss: 0.9862 - val_accuracy: 0.5239\n",
      "Epoch 170/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9771 - accuracy: 0.5273 - val_loss: 0.9900 - val_accuracy: 0.5267\n",
      "Epoch 171/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9763 - accuracy: 0.5289 - val_loss: 0.9884 - val_accuracy: 0.5239\n",
      "Epoch 172/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9767 - accuracy: 0.5310 - val_loss: 0.9895 - val_accuracy: 0.5239\n",
      "Epoch 173/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9767 - accuracy: 0.5286 - val_loss: 0.9878 - val_accuracy: 0.5234\n",
      "Epoch 174/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9784 - accuracy: 0.5291 - val_loss: 0.9972 - val_accuracy: 0.5083\n",
      "Epoch 175/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9766 - accuracy: 0.5274 - val_loss: 0.9879 - val_accuracy: 0.5202\n",
      "Epoch 176/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9767 - accuracy: 0.5308 - val_loss: 0.9903 - val_accuracy: 0.5184\n",
      "Epoch 177/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9788 - accuracy: 0.5294 - val_loss: 0.9907 - val_accuracy: 0.5175\n",
      "Epoch 178/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9761 - accuracy: 0.5299 - val_loss: 0.9885 - val_accuracy: 0.5147\n",
      "Epoch 179/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9769 - accuracy: 0.5275 - val_loss: 0.9883 - val_accuracy: 0.5234\n",
      "Epoch 180/200\n",
      "613/613 [==============================] - 0s 584us/step - loss: 0.9779 - accuracy: 0.5266 - val_loss: 0.9920 - val_accuracy: 0.4954\n",
      "Epoch 181/200\n",
      "613/613 [==============================] - 0s 595us/step - loss: 0.9769 - accuracy: 0.5299 - val_loss: 0.9913 - val_accuracy: 0.5221\n",
      "Epoch 182/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9781 - accuracy: 0.5292 - val_loss: 0.9899 - val_accuracy: 0.5165\n",
      "Epoch 183/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9783 - accuracy: 0.5282 - val_loss: 0.9910 - val_accuracy: 0.5175\n",
      "Epoch 184/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9769 - accuracy: 0.5294 - val_loss: 0.9917 - val_accuracy: 0.5211\n",
      "Epoch 185/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9895 - val_accuracy: 0.5230\n",
      "Epoch 186/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9769 - accuracy: 0.5306 - val_loss: 0.9891 - val_accuracy: 0.5221\n",
      "Epoch 187/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9761 - accuracy: 0.5309 - val_loss: 0.9918 - val_accuracy: 0.5124\n",
      "Epoch 188/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9764 - accuracy: 0.5283 - val_loss: 0.9894 - val_accuracy: 0.5230\n",
      "Epoch 189/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9764 - accuracy: 0.5306 - val_loss: 0.9960 - val_accuracy: 0.4995\n",
      "Epoch 190/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9783 - accuracy: 0.5282 - val_loss: 0.9901 - val_accuracy: 0.5028\n",
      "Epoch 191/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9775 - accuracy: 0.5264 - val_loss: 0.9975 - val_accuracy: 0.5037\n",
      "Epoch 192/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9771 - accuracy: 0.5292 - val_loss: 0.9870 - val_accuracy: 0.5230\n",
      "Epoch 193/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9786 - accuracy: 0.5273 - val_loss: 0.9959 - val_accuracy: 0.5239\n",
      "Epoch 194/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9783 - accuracy: 0.5288 - val_loss: 0.9903 - val_accuracy: 0.5216\n",
      "Epoch 195/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9774 - accuracy: 0.5303 - val_loss: 0.9917 - val_accuracy: 0.5230\n",
      "Epoch 196/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9900 - val_accuracy: 0.5248\n",
      "Epoch 197/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9784 - accuracy: 0.5275 - val_loss: 0.9859 - val_accuracy: 0.5271\n",
      "Epoch 198/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9753 - accuracy: 0.5310 - val_loss: 0.9877 - val_accuracy: 0.5221\n",
      "Epoch 199/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9769 - accuracy: 0.5291 - val_loss: 0.9877 - val_accuracy: 0.5253\n",
      "Epoch 200/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9771 - accuracy: 0.5299 - val_loss: 0.9949 - val_accuracy: 0.5115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9773 - accuracy: 0.5305\n",
      "Accuracy : 0.5304569602012634\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9949 - accuracy: 0.5115\n",
      "Accuracy : 0.5114889740943909\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "613/613 [==============================] - 0s 705us/step - loss: 1.0447 - accuracy: 0.4655 - val_loss: 1.0215 - val_accuracy: 0.5060\n",
      "Epoch 2/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 1.0026 - accuracy: 0.5061 - val_loss: 1.0022 - val_accuracy: 0.5193\n",
      "Epoch 3/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9935 - accuracy: 0.5173 - val_loss: 0.9927 - val_accuracy: 0.5188\n",
      "Epoch 4/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9909 - accuracy: 0.5174 - val_loss: 0.9852 - val_accuracy: 0.5303\n",
      "Epoch 5/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9906 - accuracy: 0.5171 - val_loss: 0.9874 - val_accuracy: 0.5267\n",
      "Epoch 6/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9884 - accuracy: 0.5190 - val_loss: 0.9932 - val_accuracy: 0.5184\n",
      "Epoch 7/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9879 - accuracy: 0.5147 - val_loss: 0.9871 - val_accuracy: 0.5156\n",
      "Epoch 8/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9858 - accuracy: 0.5185 - val_loss: 0.9897 - val_accuracy: 0.5097\n",
      "Epoch 9/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9863 - accuracy: 0.5199 - val_loss: 0.9873 - val_accuracy: 0.5262\n",
      "Epoch 10/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9840 - accuracy: 0.5210 - val_loss: 0.9862 - val_accuracy: 0.5303\n",
      "Epoch 11/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9854 - accuracy: 0.5195 - val_loss: 0.9899 - val_accuracy: 0.5221\n",
      "Epoch 12/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9829 - accuracy: 0.5212 - val_loss: 0.9787 - val_accuracy: 0.5354\n",
      "Epoch 13/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9846 - accuracy: 0.5195 - val_loss: 0.9809 - val_accuracy: 0.5354\n",
      "Epoch 14/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9850 - accuracy: 0.5174 - val_loss: 0.9922 - val_accuracy: 0.5133\n",
      "Epoch 15/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9842 - accuracy: 0.5210 - val_loss: 0.9885 - val_accuracy: 0.5248\n",
      "Epoch 16/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9854 - accuracy: 0.5221 - val_loss: 0.9911 - val_accuracy: 0.5156\n",
      "Epoch 17/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9836 - accuracy: 0.5226 - val_loss: 0.9931 - val_accuracy: 0.5230\n",
      "Epoch 18/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9869 - accuracy: 0.5174 - val_loss: 0.9873 - val_accuracy: 0.5285\n",
      "Epoch 19/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9837 - accuracy: 0.5216 - val_loss: 0.9815 - val_accuracy: 0.5290\n",
      "Epoch 20/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9832 - accuracy: 0.5235 - val_loss: 0.9808 - val_accuracy: 0.5427\n",
      "Epoch 21/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9831 - accuracy: 0.5210 - val_loss: 0.9821 - val_accuracy: 0.5207\n",
      "Epoch 22/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9824 - accuracy: 0.5245 - val_loss: 0.9836 - val_accuracy: 0.5358\n",
      "Epoch 23/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9822 - accuracy: 0.5197 - val_loss: 0.9801 - val_accuracy: 0.5409\n",
      "Epoch 24/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9837 - accuracy: 0.5197 - val_loss: 0.9817 - val_accuracy: 0.5377\n",
      "Epoch 25/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9833 - accuracy: 0.5220 - val_loss: 0.9902 - val_accuracy: 0.5216\n",
      "Epoch 26/200\n",
      "613/613 [==============================] - 0s 589us/step - loss: 0.9820 - accuracy: 0.5216 - val_loss: 0.9790 - val_accuracy: 0.5395\n",
      "Epoch 27/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9820 - accuracy: 0.5240 - val_loss: 0.9770 - val_accuracy: 0.5409\n",
      "Epoch 28/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9824 - accuracy: 0.5219 - val_loss: 0.9756 - val_accuracy: 0.5395\n",
      "Epoch 29/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9817 - accuracy: 0.5221 - val_loss: 0.9852 - val_accuracy: 0.5368\n",
      "Epoch 30/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9824 - accuracy: 0.5235 - val_loss: 0.9962 - val_accuracy: 0.5005\n",
      "Epoch 31/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9818 - accuracy: 0.5247 - val_loss: 0.9833 - val_accuracy: 0.5363\n",
      "Epoch 32/200\n",
      "613/613 [==============================] - 0s 547us/step - loss: 0.9811 - accuracy: 0.5231 - val_loss: 0.9857 - val_accuracy: 0.5216\n",
      "Epoch 33/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9805 - accuracy: 0.5242 - val_loss: 0.9803 - val_accuracy: 0.5386\n",
      "Epoch 34/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9811 - accuracy: 0.5246 - val_loss: 0.9807 - val_accuracy: 0.5386\n",
      "Epoch 35/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9797 - accuracy: 0.5249 - val_loss: 0.9783 - val_accuracy: 0.5418\n",
      "Epoch 36/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9811 - accuracy: 0.5251 - val_loss: 0.9782 - val_accuracy: 0.5354\n",
      "Epoch 37/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9808 - accuracy: 0.5261 - val_loss: 0.9791 - val_accuracy: 0.5312\n",
      "Epoch 38/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9803 - accuracy: 0.5236 - val_loss: 0.9867 - val_accuracy: 0.5234\n",
      "Epoch 39/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9806 - accuracy: 0.5228 - val_loss: 0.9764 - val_accuracy: 0.5368\n",
      "Epoch 40/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9816 - accuracy: 0.5213 - val_loss: 0.9827 - val_accuracy: 0.5391\n",
      "Epoch 41/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9801 - accuracy: 0.5245 - val_loss: 0.9773 - val_accuracy: 0.5391\n",
      "Epoch 42/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9811 - accuracy: 0.5239 - val_loss: 0.9899 - val_accuracy: 0.5069\n",
      "Epoch 43/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9819 - accuracy: 0.5228 - val_loss: 0.9778 - val_accuracy: 0.5418\n",
      "Epoch 44/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9806 - accuracy: 0.5233 - val_loss: 0.9792 - val_accuracy: 0.5285\n",
      "Epoch 45/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9804 - accuracy: 0.5263 - val_loss: 0.9813 - val_accuracy: 0.5290\n",
      "Epoch 46/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9793 - accuracy: 0.5255 - val_loss: 0.9759 - val_accuracy: 0.5345\n",
      "Epoch 47/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9805 - accuracy: 0.5256 - val_loss: 0.9776 - val_accuracy: 0.5280\n",
      "Epoch 48/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9794 - accuracy: 0.5232 - val_loss: 0.9760 - val_accuracy: 0.5354\n",
      "Epoch 49/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9798 - accuracy: 0.5236 - val_loss: 0.9787 - val_accuracy: 0.5381\n",
      "Epoch 50/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9800 - accuracy: 0.5251 - val_loss: 0.9784 - val_accuracy: 0.5395\n",
      "Epoch 51/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9814 - accuracy: 0.5234 - val_loss: 0.9803 - val_accuracy: 0.5308\n",
      "Epoch 52/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9809 - accuracy: 0.5244 - val_loss: 0.9833 - val_accuracy: 0.5276\n",
      "Epoch 53/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9804 - accuracy: 0.5260 - val_loss: 0.9797 - val_accuracy: 0.5427\n",
      "Epoch 54/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9806 - accuracy: 0.5253 - val_loss: 0.9815 - val_accuracy: 0.5340\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 569us/step - loss: 0.9807 - accuracy: 0.5241 - val_loss: 0.9829 - val_accuracy: 0.5340\n",
      "Epoch 56/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9797 - accuracy: 0.5250 - val_loss: 0.9820 - val_accuracy: 0.5202\n",
      "Epoch 57/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9791 - accuracy: 0.5281 - val_loss: 0.9776 - val_accuracy: 0.5423\n",
      "Epoch 58/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9797 - accuracy: 0.5256 - val_loss: 0.9780 - val_accuracy: 0.5345\n",
      "Epoch 59/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9800 - accuracy: 0.5238 - val_loss: 0.9838 - val_accuracy: 0.5290\n",
      "Epoch 60/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9804 - accuracy: 0.5234 - val_loss: 0.9824 - val_accuracy: 0.5262\n",
      "Epoch 61/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9795 - accuracy: 0.5271 - val_loss: 0.9875 - val_accuracy: 0.5188\n",
      "Epoch 62/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9809 - accuracy: 0.5261 - val_loss: 0.9781 - val_accuracy: 0.5386\n",
      "Epoch 63/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9801 - accuracy: 0.5235 - val_loss: 0.9762 - val_accuracy: 0.5386\n",
      "Epoch 64/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9796 - accuracy: 0.5250 - val_loss: 0.9891 - val_accuracy: 0.5303\n",
      "Epoch 65/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9799 - accuracy: 0.5222 - val_loss: 0.9795 - val_accuracy: 0.5326\n",
      "Epoch 66/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9791 - accuracy: 0.5254 - val_loss: 0.9793 - val_accuracy: 0.5368\n",
      "Epoch 67/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9797 - accuracy: 0.5235 - val_loss: 0.9803 - val_accuracy: 0.5404\n",
      "Epoch 68/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9794 - accuracy: 0.5255 - val_loss: 0.9801 - val_accuracy: 0.5257\n",
      "Epoch 69/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9793 - accuracy: 0.5244 - val_loss: 0.9805 - val_accuracy: 0.5299\n",
      "Epoch 70/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9784 - accuracy: 0.5273 - val_loss: 0.9807 - val_accuracy: 0.5322\n",
      "Epoch 71/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9784 - accuracy: 0.5243 - val_loss: 0.9831 - val_accuracy: 0.5280\n",
      "Epoch 72/200\n",
      "613/613 [==============================] - 0s 590us/step - loss: 0.9797 - accuracy: 0.5241 - val_loss: 0.9786 - val_accuracy: 0.5455\n",
      "Epoch 73/200\n",
      "613/613 [==============================] - 0s 595us/step - loss: 0.9796 - accuracy: 0.5232 - val_loss: 0.9812 - val_accuracy: 0.5248\n",
      "Epoch 74/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9800 - accuracy: 0.5236 - val_loss: 0.9823 - val_accuracy: 0.5326\n",
      "Epoch 75/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9793 - accuracy: 0.5250 - val_loss: 0.9784 - val_accuracy: 0.5335\n",
      "Epoch 76/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9788 - accuracy: 0.5250 - val_loss: 0.9771 - val_accuracy: 0.5368\n",
      "Epoch 77/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9788 - accuracy: 0.5268 - val_loss: 0.9825 - val_accuracy: 0.5253\n",
      "Epoch 78/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9796 - accuracy: 0.5265 - val_loss: 0.9806 - val_accuracy: 0.5400\n",
      "Epoch 79/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9783 - accuracy: 0.5236 - val_loss: 0.9807 - val_accuracy: 0.5239\n",
      "Epoch 80/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9796 - accuracy: 0.5236 - val_loss: 0.9815 - val_accuracy: 0.5446\n",
      "Epoch 81/200\n",
      "613/613 [==============================] - 0s 582us/step - loss: 0.9802 - accuracy: 0.5247 - val_loss: 0.9765 - val_accuracy: 0.5446\n",
      "Epoch 82/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9790 - accuracy: 0.5235 - val_loss: 0.9794 - val_accuracy: 0.5354\n",
      "Epoch 83/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9791 - accuracy: 0.5237 - val_loss: 0.9761 - val_accuracy: 0.5427\n",
      "Epoch 84/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9781 - accuracy: 0.5258 - val_loss: 0.9757 - val_accuracy: 0.5340\n",
      "Epoch 85/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9786 - accuracy: 0.5246 - val_loss: 0.9779 - val_accuracy: 0.5450\n",
      "Epoch 86/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9776 - accuracy: 0.5239 - val_loss: 0.9874 - val_accuracy: 0.5115\n",
      "Epoch 87/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9783 - accuracy: 0.5241 - val_loss: 0.9782 - val_accuracy: 0.5308\n",
      "Epoch 88/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9792 - accuracy: 0.5259 - val_loss: 0.9803 - val_accuracy: 0.5377\n",
      "Epoch 89/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9800 - accuracy: 0.5219 - val_loss: 0.9756 - val_accuracy: 0.5368\n",
      "Epoch 90/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9781 - accuracy: 0.5287 - val_loss: 0.9795 - val_accuracy: 0.5221\n",
      "Epoch 91/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9788 - accuracy: 0.5263 - val_loss: 0.9741 - val_accuracy: 0.5414\n",
      "Epoch 92/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9787 - accuracy: 0.5279 - val_loss: 0.9743 - val_accuracy: 0.5437\n",
      "Epoch 93/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9793 - accuracy: 0.5234 - val_loss: 0.9803 - val_accuracy: 0.5363\n",
      "Epoch 94/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9797 - accuracy: 0.5224 - val_loss: 0.9739 - val_accuracy: 0.5446\n",
      "Epoch 95/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9799 - accuracy: 0.5286 - val_loss: 0.9781 - val_accuracy: 0.5349\n",
      "Epoch 96/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9801 - accuracy: 0.5244 - val_loss: 0.9785 - val_accuracy: 0.5349\n",
      "Epoch 97/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9801 - accuracy: 0.5267 - val_loss: 0.9774 - val_accuracy: 0.5377\n",
      "Epoch 98/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9787 - accuracy: 0.5271 - val_loss: 0.9783 - val_accuracy: 0.5290\n",
      "Epoch 99/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9790 - accuracy: 0.5257 - val_loss: 0.9771 - val_accuracy: 0.5294\n",
      "Epoch 100/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9775 - accuracy: 0.5283 - val_loss: 0.9782 - val_accuracy: 0.5294\n",
      "Epoch 101/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9807 - accuracy: 0.5239 - val_loss: 0.9780 - val_accuracy: 0.5381\n",
      "Epoch 102/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9792 - accuracy: 0.5252 - val_loss: 0.9766 - val_accuracy: 0.5386\n",
      "Epoch 103/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9794 - accuracy: 0.5255 - val_loss: 0.9760 - val_accuracy: 0.5409\n",
      "Epoch 104/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9776 - accuracy: 0.5267 - val_loss: 0.9804 - val_accuracy: 0.5211\n",
      "Epoch 105/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9785 - accuracy: 0.5258 - val_loss: 0.9768 - val_accuracy: 0.5414\n",
      "Epoch 106/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9789 - accuracy: 0.5252 - val_loss: 0.9752 - val_accuracy: 0.5391\n",
      "Epoch 107/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9777 - accuracy: 0.5274 - val_loss: 0.9800 - val_accuracy: 0.5211\n",
      "Epoch 108/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9790 - accuracy: 0.5274 - val_loss: 0.9784 - val_accuracy: 0.5294\n",
      "Epoch 109/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9777 - accuracy: 0.5267 - val_loss: 0.9764 - val_accuracy: 0.5409\n",
      "Epoch 110/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9787 - accuracy: 0.5259 - val_loss: 0.9809 - val_accuracy: 0.5391\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 585us/step - loss: 0.9784 - accuracy: 0.5277 - val_loss: 0.9762 - val_accuracy: 0.5404\n",
      "Epoch 112/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9772 - accuracy: 0.5259 - val_loss: 0.9827 - val_accuracy: 0.5207\n",
      "Epoch 113/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9797 - accuracy: 0.5231 - val_loss: 0.9800 - val_accuracy: 0.5294\n",
      "Epoch 114/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9783 - accuracy: 0.5256 - val_loss: 0.9769 - val_accuracy: 0.5395\n",
      "Epoch 115/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9780 - accuracy: 0.5273 - val_loss: 0.9786 - val_accuracy: 0.5372\n",
      "Epoch 116/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9782 - accuracy: 0.5265 - val_loss: 0.9766 - val_accuracy: 0.5340\n",
      "Epoch 117/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9781 - accuracy: 0.5267 - val_loss: 0.9746 - val_accuracy: 0.5358\n",
      "Epoch 118/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 0.9781 - accuracy: 0.5262 - val_loss: 0.9764 - val_accuracy: 0.5381\n",
      "Epoch 119/200\n",
      "613/613 [==============================] - 0s 581us/step - loss: 0.9782 - accuracy: 0.5290 - val_loss: 0.9780 - val_accuracy: 0.5345\n",
      "Epoch 120/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9788 - accuracy: 0.5266 - val_loss: 0.9776 - val_accuracy: 0.5377\n",
      "Epoch 121/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9784 - accuracy: 0.5267 - val_loss: 0.9769 - val_accuracy: 0.5418\n",
      "Epoch 122/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9777 - accuracy: 0.5256 - val_loss: 0.9772 - val_accuracy: 0.5464\n",
      "Epoch 123/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9782 - accuracy: 0.5256 - val_loss: 0.9828 - val_accuracy: 0.5152\n",
      "Epoch 124/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9783 - accuracy: 0.5282 - val_loss: 0.9794 - val_accuracy: 0.5290\n",
      "Epoch 125/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9788 - accuracy: 0.5279 - val_loss: 0.9769 - val_accuracy: 0.5377\n",
      "Epoch 126/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9780 - accuracy: 0.5257 - val_loss: 0.9767 - val_accuracy: 0.5427\n",
      "Epoch 127/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9782 - accuracy: 0.5239 - val_loss: 0.9747 - val_accuracy: 0.5391\n",
      "Epoch 128/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9783 - accuracy: 0.5223 - val_loss: 0.9764 - val_accuracy: 0.5372\n",
      "Epoch 129/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9771 - accuracy: 0.5277 - val_loss: 0.9755 - val_accuracy: 0.5326\n",
      "Epoch 130/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9768 - val_accuracy: 0.5391\n",
      "Epoch 131/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9782 - accuracy: 0.5279 - val_loss: 0.9758 - val_accuracy: 0.5391\n",
      "Epoch 132/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9781 - accuracy: 0.5276 - val_loss: 0.9818 - val_accuracy: 0.5335\n",
      "Epoch 133/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9779 - accuracy: 0.5281 - val_loss: 0.9764 - val_accuracy: 0.5363\n",
      "Epoch 134/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9771 - accuracy: 0.5278 - val_loss: 0.9737 - val_accuracy: 0.5395\n",
      "Epoch 135/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9782 - accuracy: 0.5278 - val_loss: 0.9748 - val_accuracy: 0.5381\n",
      "Epoch 136/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9763 - val_accuracy: 0.5395\n",
      "Epoch 137/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9785 - accuracy: 0.5261 - val_loss: 0.9759 - val_accuracy: 0.5381\n",
      "Epoch 138/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9773 - accuracy: 0.5271 - val_loss: 0.9767 - val_accuracy: 0.5331\n",
      "Epoch 139/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9777 - accuracy: 0.5277 - val_loss: 0.9832 - val_accuracy: 0.5354\n",
      "Epoch 140/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9771 - accuracy: 0.5267 - val_loss: 0.9762 - val_accuracy: 0.5455\n",
      "Epoch 141/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9787 - accuracy: 0.5269 - val_loss: 0.9721 - val_accuracy: 0.5381\n",
      "Epoch 142/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9779 - accuracy: 0.5257 - val_loss: 0.9759 - val_accuracy: 0.5391\n",
      "Epoch 143/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9778 - accuracy: 0.5276 - val_loss: 0.9724 - val_accuracy: 0.5368\n",
      "Epoch 144/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9770 - accuracy: 0.5286 - val_loss: 0.9813 - val_accuracy: 0.5381\n",
      "Epoch 145/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9778 - accuracy: 0.5264 - val_loss: 0.9754 - val_accuracy: 0.5354\n",
      "Epoch 146/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9772 - accuracy: 0.5271 - val_loss: 0.9795 - val_accuracy: 0.5372\n",
      "Epoch 147/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9781 - accuracy: 0.5274 - val_loss: 0.9745 - val_accuracy: 0.5395\n",
      "Epoch 148/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9769 - accuracy: 0.5262 - val_loss: 0.9792 - val_accuracy: 0.5322\n",
      "Epoch 149/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9786 - accuracy: 0.5262 - val_loss: 0.9761 - val_accuracy: 0.5349\n",
      "Epoch 150/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9774 - accuracy: 0.5271 - val_loss: 0.9753 - val_accuracy: 0.5312\n",
      "Epoch 151/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9781 - accuracy: 0.5273 - val_loss: 0.9802 - val_accuracy: 0.5395\n",
      "Epoch 152/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9778 - val_accuracy: 0.5404\n",
      "Epoch 153/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9785 - accuracy: 0.5258 - val_loss: 0.9825 - val_accuracy: 0.5280\n",
      "Epoch 154/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9784 - accuracy: 0.5271 - val_loss: 0.9808 - val_accuracy: 0.5349\n",
      "Epoch 155/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9792 - accuracy: 0.5230 - val_loss: 0.9731 - val_accuracy: 0.5460\n",
      "Epoch 156/200\n",
      "613/613 [==============================] - 0s 544us/step - loss: 0.9771 - accuracy: 0.5275 - val_loss: 0.9750 - val_accuracy: 0.5423\n",
      "Epoch 157/200\n",
      "613/613 [==============================] - 0s 584us/step - loss: 0.9784 - accuracy: 0.5275 - val_loss: 0.9767 - val_accuracy: 0.5404\n",
      "Epoch 158/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9765 - val_accuracy: 0.5414\n",
      "Epoch 159/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9780 - accuracy: 0.5273 - val_loss: 0.9786 - val_accuracy: 0.5400\n",
      "Epoch 160/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9771 - accuracy: 0.5258 - val_loss: 0.9760 - val_accuracy: 0.5414\n",
      "Epoch 161/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9772 - accuracy: 0.5278 - val_loss: 0.9739 - val_accuracy: 0.5381\n",
      "Epoch 162/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9769 - accuracy: 0.5250 - val_loss: 0.9745 - val_accuracy: 0.5414\n",
      "Epoch 163/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9777 - accuracy: 0.5290 - val_loss: 0.9762 - val_accuracy: 0.5363\n",
      "Epoch 164/200\n",
      "613/613 [==============================] - 0s 601us/step - loss: 0.9765 - accuracy: 0.5278 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 165/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9764 - val_accuracy: 0.5395\n",
      "Epoch 166/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9770 - accuracy: 0.5244 - val_loss: 0.9784 - val_accuracy: 0.5326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9778 - accuracy: 0.5238 - val_loss: 0.9760 - val_accuracy: 0.5404\n",
      "Epoch 168/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9773 - accuracy: 0.5264 - val_loss: 0.9794 - val_accuracy: 0.5363\n",
      "Epoch 169/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9779 - accuracy: 0.5278 - val_loss: 0.9740 - val_accuracy: 0.5400\n",
      "Epoch 170/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9760 - accuracy: 0.5282 - val_loss: 0.9779 - val_accuracy: 0.5354\n",
      "Epoch 171/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9768 - accuracy: 0.5283 - val_loss: 0.9756 - val_accuracy: 0.5354\n",
      "Epoch 172/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9776 - accuracy: 0.5281 - val_loss: 0.9787 - val_accuracy: 0.5354\n",
      "Epoch 173/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9791 - val_accuracy: 0.5386\n",
      "Epoch 174/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9759 - val_accuracy: 0.5427\n",
      "Epoch 175/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9768 - accuracy: 0.5278 - val_loss: 0.9773 - val_accuracy: 0.5372\n",
      "Epoch 176/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9765 - accuracy: 0.5282 - val_loss: 0.9788 - val_accuracy: 0.5303\n",
      "Epoch 177/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9777 - accuracy: 0.5274 - val_loss: 0.9761 - val_accuracy: 0.5372\n",
      "Epoch 178/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9777 - accuracy: 0.5243 - val_loss: 0.9786 - val_accuracy: 0.5391\n",
      "Epoch 179/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9774 - accuracy: 0.5277 - val_loss: 0.9777 - val_accuracy: 0.5386\n",
      "Epoch 180/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9780 - accuracy: 0.5268 - val_loss: 0.9740 - val_accuracy: 0.5423\n",
      "Epoch 181/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9735 - val_accuracy: 0.5473\n",
      "Epoch 182/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9766 - accuracy: 0.5272 - val_loss: 0.9750 - val_accuracy: 0.5427\n",
      "Epoch 183/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9772 - accuracy: 0.5251 - val_loss: 0.9784 - val_accuracy: 0.5280\n",
      "Epoch 184/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9767 - accuracy: 0.5266 - val_loss: 0.9806 - val_accuracy: 0.5285\n",
      "Epoch 185/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9768 - accuracy: 0.5262 - val_loss: 0.9735 - val_accuracy: 0.5418\n",
      "Epoch 186/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9766 - accuracy: 0.5286 - val_loss: 0.9767 - val_accuracy: 0.5381\n",
      "Epoch 187/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9768 - accuracy: 0.5278 - val_loss: 0.9760 - val_accuracy: 0.5386\n",
      "Epoch 188/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9776 - accuracy: 0.5272 - val_loss: 0.9754 - val_accuracy: 0.5391\n",
      "Epoch 189/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9774 - accuracy: 0.5280 - val_loss: 0.9743 - val_accuracy: 0.5450\n",
      "Epoch 190/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9775 - accuracy: 0.5266 - val_loss: 0.9753 - val_accuracy: 0.5322\n",
      "Epoch 191/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9765 - accuracy: 0.5270 - val_loss: 0.9754 - val_accuracy: 0.5409\n",
      "Epoch 192/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9774 - accuracy: 0.5258 - val_loss: 0.9744 - val_accuracy: 0.5391\n",
      "Epoch 193/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9769 - accuracy: 0.5259 - val_loss: 0.9801 - val_accuracy: 0.5354\n",
      "Epoch 194/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9773 - accuracy: 0.5265 - val_loss: 0.9760 - val_accuracy: 0.5423\n",
      "Epoch 195/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9767 - accuracy: 0.5297 - val_loss: 0.9816 - val_accuracy: 0.5354\n",
      "Epoch 196/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9775 - accuracy: 0.5282 - val_loss: 0.9768 - val_accuracy: 0.5437\n",
      "Epoch 197/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9766 - accuracy: 0.5279 - val_loss: 0.9785 - val_accuracy: 0.5418\n",
      "Epoch 198/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9772 - accuracy: 0.5267 - val_loss: 0.9754 - val_accuracy: 0.5372\n",
      "Epoch 199/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9787 - accuracy: 0.5272 - val_loss: 0.9737 - val_accuracy: 0.5441\n",
      "Epoch 200/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9781 - accuracy: 0.5221 - val_loss: 0.9773 - val_accuracy: 0.5404\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 590us/step - loss: 0.9785 - accuracy: 0.5259\n",
      "Accuracy : 0.5259127020835876\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9773 - accuracy: 0.5404\n",
      "Accuracy : 0.5404411554336548\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "613/613 [==============================] - 0s 713us/step - loss: 1.0500 - accuracy: 0.4598 - val_loss: 1.0103 - val_accuracy: 0.5064\n",
      "Epoch 2/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 1.0085 - accuracy: 0.5090 - val_loss: 0.9821 - val_accuracy: 0.5331\n",
      "Epoch 3/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9980 - accuracy: 0.5152 - val_loss: 0.9788 - val_accuracy: 0.5257\n",
      "Epoch 4/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9929 - accuracy: 0.5174 - val_loss: 0.9767 - val_accuracy: 0.5363\n",
      "Epoch 5/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9922 - accuracy: 0.5147 - val_loss: 0.9738 - val_accuracy: 0.5253\n",
      "Epoch 6/200\n",
      "613/613 [==============================] - 0s 591us/step - loss: 0.9897 - accuracy: 0.5173 - val_loss: 0.9731 - val_accuracy: 0.5404\n",
      "Epoch 7/200\n",
      "613/613 [==============================] - 0s 606us/step - loss: 0.9938 - accuracy: 0.5183 - val_loss: 0.9755 - val_accuracy: 0.5395\n",
      "Epoch 8/200\n",
      "613/613 [==============================] - 0s 580us/step - loss: 0.9906 - accuracy: 0.5191 - val_loss: 0.9763 - val_accuracy: 0.5340\n",
      "Epoch 9/200\n",
      "613/613 [==============================] - 0s 547us/step - loss: 0.9904 - accuracy: 0.5187 - val_loss: 0.9752 - val_accuracy: 0.5317\n",
      "Epoch 10/200\n",
      "613/613 [==============================] - 0s 595us/step - loss: 0.9892 - accuracy: 0.5192 - val_loss: 0.9809 - val_accuracy: 0.5257\n",
      "Epoch 11/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9887 - accuracy: 0.5225 - val_loss: 0.9746 - val_accuracy: 0.5363\n",
      "Epoch 12/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9883 - accuracy: 0.5180 - val_loss: 0.9772 - val_accuracy: 0.5253\n",
      "Epoch 13/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9901 - accuracy: 0.5144 - val_loss: 0.9738 - val_accuracy: 0.5363\n",
      "Epoch 14/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 0.9880 - accuracy: 0.5180 - val_loss: 0.9718 - val_accuracy: 0.5290\n",
      "Epoch 15/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9886 - accuracy: 0.5140 - val_loss: 0.9735 - val_accuracy: 0.5299\n",
      "Epoch 16/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9874 - accuracy: 0.5220 - val_loss: 0.9657 - val_accuracy: 0.5354\n",
      "Epoch 17/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9879 - accuracy: 0.5144 - val_loss: 0.9738 - val_accuracy: 0.5322\n",
      "Epoch 18/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9867 - accuracy: 0.5199 - val_loss: 0.9759 - val_accuracy: 0.5202\n",
      "Epoch 19/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9863 - accuracy: 0.5145 - val_loss: 0.9694 - val_accuracy: 0.5349\n",
      "Epoch 20/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9859 - accuracy: 0.5198 - val_loss: 0.9757 - val_accuracy: 0.5234\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 554us/step - loss: 0.9859 - accuracy: 0.5173 - val_loss: 0.9671 - val_accuracy: 0.5345\n",
      "Epoch 22/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9867 - accuracy: 0.5172 - val_loss: 0.9723 - val_accuracy: 0.5322\n",
      "Epoch 23/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9872 - accuracy: 0.5219 - val_loss: 0.9693 - val_accuracy: 0.5349\n",
      "Epoch 24/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9855 - accuracy: 0.5201 - val_loss: 0.9704 - val_accuracy: 0.5404\n",
      "Epoch 25/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9881 - accuracy: 0.5188 - val_loss: 0.9679 - val_accuracy: 0.5363\n",
      "Epoch 26/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9864 - accuracy: 0.5211 - val_loss: 0.9707 - val_accuracy: 0.5326\n",
      "Epoch 27/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9857 - accuracy: 0.5216 - val_loss: 0.9687 - val_accuracy: 0.5391\n",
      "Epoch 28/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9860 - accuracy: 0.5197 - val_loss: 0.9630 - val_accuracy: 0.5372\n",
      "Epoch 29/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9845 - accuracy: 0.5200 - val_loss: 0.9683 - val_accuracy: 0.5294\n",
      "Epoch 30/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9875 - accuracy: 0.5218 - val_loss: 0.9785 - val_accuracy: 0.5271\n",
      "Epoch 31/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9867 - accuracy: 0.5161 - val_loss: 0.9699 - val_accuracy: 0.5418\n",
      "Epoch 32/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9846 - accuracy: 0.5219 - val_loss: 0.9681 - val_accuracy: 0.5271\n",
      "Epoch 33/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9850 - accuracy: 0.5182 - val_loss: 0.9728 - val_accuracy: 0.5294\n",
      "Epoch 34/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9829 - accuracy: 0.5202 - val_loss: 0.9683 - val_accuracy: 0.5326\n",
      "Epoch 35/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9836 - accuracy: 0.5231 - val_loss: 0.9705 - val_accuracy: 0.5322\n",
      "Epoch 36/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9831 - accuracy: 0.5239 - val_loss: 0.9735 - val_accuracy: 0.5290\n",
      "Epoch 37/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9833 - accuracy: 0.5232 - val_loss: 0.9666 - val_accuracy: 0.5312\n",
      "Epoch 38/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9829 - accuracy: 0.5247 - val_loss: 0.9672 - val_accuracy: 0.5391\n",
      "Epoch 39/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9835 - accuracy: 0.5221 - val_loss: 0.9678 - val_accuracy: 0.5400\n",
      "Epoch 40/200\n",
      "613/613 [==============================] - 0s 592us/step - loss: 0.9838 - accuracy: 0.5220 - val_loss: 0.9779 - val_accuracy: 0.5087\n",
      "Epoch 41/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9880 - accuracy: 0.5161 - val_loss: 0.9723 - val_accuracy: 0.5363\n",
      "Epoch 42/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9849 - accuracy: 0.5242 - val_loss: 0.9646 - val_accuracy: 0.5386\n",
      "Epoch 43/200\n",
      "613/613 [==============================] - 0s 586us/step - loss: 0.9843 - accuracy: 0.5214 - val_loss: 0.9674 - val_accuracy: 0.5400\n",
      "Epoch 44/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9851 - accuracy: 0.5213 - val_loss: 0.9659 - val_accuracy: 0.5349\n",
      "Epoch 45/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 0.9851 - accuracy: 0.5183 - val_loss: 0.9643 - val_accuracy: 0.5377\n",
      "Epoch 46/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9821 - accuracy: 0.5237 - val_loss: 0.9657 - val_accuracy: 0.5303\n",
      "Epoch 47/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9837 - accuracy: 0.5223 - val_loss: 0.9728 - val_accuracy: 0.5372\n",
      "Epoch 48/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9828 - accuracy: 0.5223 - val_loss: 0.9634 - val_accuracy: 0.5381\n",
      "Epoch 49/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9819 - accuracy: 0.5214 - val_loss: 0.9650 - val_accuracy: 0.5368\n",
      "Epoch 50/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9817 - accuracy: 0.5233 - val_loss: 0.9695 - val_accuracy: 0.5349\n",
      "Epoch 51/200\n",
      "613/613 [==============================] - 0s 582us/step - loss: 0.9827 - accuracy: 0.5255 - val_loss: 0.9649 - val_accuracy: 0.5409\n",
      "Epoch 52/200\n",
      "613/613 [==============================] - 0s 609us/step - loss: 0.9817 - accuracy: 0.5221 - val_loss: 0.9642 - val_accuracy: 0.5395\n",
      "Epoch 53/200\n",
      "613/613 [==============================] - 0s 588us/step - loss: 0.9822 - accuracy: 0.5203 - val_loss: 0.9647 - val_accuracy: 0.5368\n",
      "Epoch 54/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9814 - accuracy: 0.5202 - val_loss: 0.9670 - val_accuracy: 0.5363\n",
      "Epoch 55/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9808 - accuracy: 0.5242 - val_loss: 0.9687 - val_accuracy: 0.5409\n",
      "Epoch 56/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9827 - accuracy: 0.5225 - val_loss: 0.9667 - val_accuracy: 0.5386\n",
      "Epoch 57/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9807 - accuracy: 0.5224 - val_loss: 0.9653 - val_accuracy: 0.5404\n",
      "Epoch 58/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9840 - accuracy: 0.5228 - val_loss: 0.9663 - val_accuracy: 0.5358\n",
      "Epoch 59/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9847 - accuracy: 0.5221 - val_loss: 0.9663 - val_accuracy: 0.5345\n",
      "Epoch 60/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9820 - accuracy: 0.5250 - val_loss: 0.9676 - val_accuracy: 0.5335\n",
      "Epoch 61/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9812 - accuracy: 0.5259 - val_loss: 0.9693 - val_accuracy: 0.5368\n",
      "Epoch 62/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9824 - accuracy: 0.5249 - val_loss: 0.9632 - val_accuracy: 0.5404\n",
      "Epoch 63/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9811 - accuracy: 0.5234 - val_loss: 0.9675 - val_accuracy: 0.5349\n",
      "Epoch 64/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9817 - accuracy: 0.5237 - val_loss: 0.9695 - val_accuracy: 0.5345\n",
      "Epoch 65/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9828 - accuracy: 0.5237 - val_loss: 0.9693 - val_accuracy: 0.5363\n",
      "Epoch 66/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9811 - accuracy: 0.5234 - val_loss: 0.9631 - val_accuracy: 0.5331\n",
      "Epoch 67/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9831 - accuracy: 0.5202 - val_loss: 0.9624 - val_accuracy: 0.5381\n",
      "Epoch 68/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9810 - accuracy: 0.5249 - val_loss: 0.9629 - val_accuracy: 0.5381\n",
      "Epoch 69/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9825 - accuracy: 0.5253 - val_loss: 0.9652 - val_accuracy: 0.5386\n",
      "Epoch 70/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9806 - accuracy: 0.5246 - val_loss: 0.9663 - val_accuracy: 0.5363\n",
      "Epoch 71/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9818 - accuracy: 0.5261 - val_loss: 0.9680 - val_accuracy: 0.5312\n",
      "Epoch 72/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9811 - accuracy: 0.5258 - val_loss: 0.9652 - val_accuracy: 0.5349\n",
      "Epoch 73/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9806 - accuracy: 0.5244 - val_loss: 0.9687 - val_accuracy: 0.5381\n",
      "Epoch 74/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9809 - accuracy: 0.5220 - val_loss: 0.9691 - val_accuracy: 0.5340\n",
      "Epoch 75/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9799 - accuracy: 0.5259 - val_loss: 0.9641 - val_accuracy: 0.5414\n",
      "Epoch 76/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9809 - accuracy: 0.5240 - val_loss: 0.9664 - val_accuracy: 0.5358\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 571us/step - loss: 0.9805 - accuracy: 0.5260 - val_loss: 0.9649 - val_accuracy: 0.5414\n",
      "Epoch 78/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9812 - accuracy: 0.5243 - val_loss: 0.9633 - val_accuracy: 0.5368\n",
      "Epoch 79/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9807 - accuracy: 0.5264 - val_loss: 0.9638 - val_accuracy: 0.5354\n",
      "Epoch 80/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9797 - accuracy: 0.5268 - val_loss: 0.9591 - val_accuracy: 0.5372\n",
      "Epoch 81/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9805 - accuracy: 0.5255 - val_loss: 0.9709 - val_accuracy: 0.5363\n",
      "Epoch 82/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9791 - accuracy: 0.5269 - val_loss: 0.9657 - val_accuracy: 0.5423\n",
      "Epoch 83/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9820 - accuracy: 0.5216 - val_loss: 0.9651 - val_accuracy: 0.5414\n",
      "Epoch 84/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9811 - accuracy: 0.5250 - val_loss: 0.9672 - val_accuracy: 0.5368\n",
      "Epoch 85/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9827 - accuracy: 0.5246 - val_loss: 0.9668 - val_accuracy: 0.5363\n",
      "Epoch 86/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9820 - accuracy: 0.5242 - val_loss: 0.9671 - val_accuracy: 0.5257\n",
      "Epoch 87/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9823 - accuracy: 0.5224 - val_loss: 0.9659 - val_accuracy: 0.5400\n",
      "Epoch 88/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9803 - accuracy: 0.5221 - val_loss: 0.9727 - val_accuracy: 0.5230\n",
      "Epoch 89/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9798 - accuracy: 0.5222 - val_loss: 0.9722 - val_accuracy: 0.5432\n",
      "Epoch 90/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9795 - accuracy: 0.5249 - val_loss: 0.9723 - val_accuracy: 0.5294\n",
      "Epoch 91/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9805 - accuracy: 0.5231 - val_loss: 0.9654 - val_accuracy: 0.5331\n",
      "Epoch 92/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9807 - accuracy: 0.5267 - val_loss: 0.9632 - val_accuracy: 0.5363\n",
      "Epoch 93/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9815 - accuracy: 0.5242 - val_loss: 0.9638 - val_accuracy: 0.5349\n",
      "Epoch 94/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9805 - accuracy: 0.5252 - val_loss: 0.9656 - val_accuracy: 0.5294\n",
      "Epoch 95/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9816 - accuracy: 0.5236 - val_loss: 0.9623 - val_accuracy: 0.5345\n",
      "Epoch 96/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9813 - accuracy: 0.5264 - val_loss: 0.9653 - val_accuracy: 0.5404\n",
      "Epoch 97/200\n",
      "613/613 [==============================] - 0s 600us/step - loss: 0.9801 - accuracy: 0.5266 - val_loss: 0.9671 - val_accuracy: 0.5299\n",
      "Epoch 98/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9818 - accuracy: 0.5251 - val_loss: 0.9678 - val_accuracy: 0.5257\n",
      "Epoch 99/200\n",
      "613/613 [==============================] - 0s 592us/step - loss: 0.9795 - accuracy: 0.5266 - val_loss: 0.9677 - val_accuracy: 0.5381\n",
      "Epoch 100/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9801 - accuracy: 0.5251 - val_loss: 0.9676 - val_accuracy: 0.5372\n",
      "Epoch 101/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9800 - accuracy: 0.5252 - val_loss: 0.9680 - val_accuracy: 0.5322\n",
      "Epoch 102/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9812 - accuracy: 0.5254 - val_loss: 0.9682 - val_accuracy: 0.5409\n",
      "Epoch 103/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9808 - accuracy: 0.5257 - val_loss: 0.9696 - val_accuracy: 0.5308\n",
      "Epoch 104/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9810 - accuracy: 0.5266 - val_loss: 0.9702 - val_accuracy: 0.5391\n",
      "Epoch 105/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9810 - accuracy: 0.5260 - val_loss: 0.9674 - val_accuracy: 0.5377\n",
      "Epoch 106/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9813 - accuracy: 0.5265 - val_loss: 0.9634 - val_accuracy: 0.5414\n",
      "Epoch 107/200\n",
      "613/613 [==============================] - 0s 580us/step - loss: 0.9813 - accuracy: 0.5243 - val_loss: 0.9714 - val_accuracy: 0.5400\n",
      "Epoch 108/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9809 - accuracy: 0.5249 - val_loss: 0.9692 - val_accuracy: 0.5368\n",
      "Epoch 109/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9807 - accuracy: 0.5245 - val_loss: 0.9674 - val_accuracy: 0.5294\n",
      "Epoch 110/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9799 - accuracy: 0.5239 - val_loss: 0.9669 - val_accuracy: 0.5391\n",
      "Epoch 111/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9810 - accuracy: 0.5270 - val_loss: 0.9652 - val_accuracy: 0.5418\n",
      "Epoch 112/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9798 - accuracy: 0.5283 - val_loss: 0.9682 - val_accuracy: 0.5381\n",
      "Epoch 113/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9801 - accuracy: 0.5273 - val_loss: 0.9645 - val_accuracy: 0.5404\n",
      "Epoch 114/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9802 - accuracy: 0.5252 - val_loss: 0.9646 - val_accuracy: 0.5418\n",
      "Epoch 115/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9799 - accuracy: 0.5262 - val_loss: 0.9733 - val_accuracy: 0.5391\n",
      "Epoch 116/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9800 - accuracy: 0.5263 - val_loss: 0.9681 - val_accuracy: 0.5303\n",
      "Epoch 117/200\n",
      "613/613 [==============================] - 0s 548us/step - loss: 0.9804 - accuracy: 0.5276 - val_loss: 0.9733 - val_accuracy: 0.5340\n",
      "Epoch 118/200\n",
      "613/613 [==============================] - 0s 592us/step - loss: 0.9805 - accuracy: 0.5270 - val_loss: 0.9644 - val_accuracy: 0.5414\n",
      "Epoch 119/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9815 - accuracy: 0.5258 - val_loss: 0.9702 - val_accuracy: 0.5308\n",
      "Epoch 120/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9793 - accuracy: 0.5289 - val_loss: 0.9694 - val_accuracy: 0.5418\n",
      "Epoch 121/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9813 - accuracy: 0.5275 - val_loss: 0.9661 - val_accuracy: 0.5381\n",
      "Epoch 122/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9810 - accuracy: 0.5261 - val_loss: 0.9648 - val_accuracy: 0.5446\n",
      "Epoch 123/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9807 - accuracy: 0.5270 - val_loss: 0.9646 - val_accuracy: 0.5335\n",
      "Epoch 124/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9816 - accuracy: 0.5259 - val_loss: 0.9634 - val_accuracy: 0.5354\n",
      "Epoch 125/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9807 - accuracy: 0.5271 - val_loss: 0.9675 - val_accuracy: 0.5331\n",
      "Epoch 126/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9822 - accuracy: 0.5245 - val_loss: 0.9657 - val_accuracy: 0.5335\n",
      "Epoch 127/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9795 - accuracy: 0.5284 - val_loss: 0.9604 - val_accuracy: 0.5381\n",
      "Epoch 128/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9795 - accuracy: 0.5288 - val_loss: 0.9692 - val_accuracy: 0.5294\n",
      "Epoch 129/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9801 - accuracy: 0.5270 - val_loss: 0.9679 - val_accuracy: 0.5345\n",
      "Epoch 130/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9794 - accuracy: 0.5277 - val_loss: 0.9665 - val_accuracy: 0.5358\n",
      "Epoch 131/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9805 - accuracy: 0.5267 - val_loss: 0.9651 - val_accuracy: 0.5391\n",
      "Epoch 132/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9802 - accuracy: 0.5271 - val_loss: 0.9714 - val_accuracy: 0.5294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9799 - accuracy: 0.5271 - val_loss: 0.9736 - val_accuracy: 0.5294\n",
      "Epoch 134/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9802 - accuracy: 0.5270 - val_loss: 0.9669 - val_accuracy: 0.5358\n",
      "Epoch 135/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9802 - accuracy: 0.5272 - val_loss: 0.9665 - val_accuracy: 0.5400\n",
      "Epoch 136/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9803 - accuracy: 0.5271 - val_loss: 0.9650 - val_accuracy: 0.5400\n",
      "Epoch 137/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9800 - accuracy: 0.5266 - val_loss: 0.9670 - val_accuracy: 0.5308\n",
      "Epoch 138/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9798 - accuracy: 0.5290 - val_loss: 0.9669 - val_accuracy: 0.5368\n",
      "Epoch 139/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9802 - accuracy: 0.5258 - val_loss: 0.9627 - val_accuracy: 0.5381\n",
      "Epoch 140/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9806 - accuracy: 0.5233 - val_loss: 0.9702 - val_accuracy: 0.5165\n",
      "Epoch 141/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9801 - accuracy: 0.5291 - val_loss: 0.9658 - val_accuracy: 0.5418\n",
      "Epoch 142/200\n",
      "613/613 [==============================] - 0s 604us/step - loss: 0.9796 - accuracy: 0.5248 - val_loss: 0.9721 - val_accuracy: 0.5391\n",
      "Epoch 143/200\n",
      "613/613 [==============================] - 0s 612us/step - loss: 0.9808 - accuracy: 0.5262 - val_loss: 0.9698 - val_accuracy: 0.5211\n",
      "Epoch 144/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9795 - accuracy: 0.5252 - val_loss: 0.9653 - val_accuracy: 0.5363\n",
      "Epoch 145/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9811 - accuracy: 0.5256 - val_loss: 0.9684 - val_accuracy: 0.5340\n",
      "Epoch 146/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9798 - accuracy: 0.5279 - val_loss: 0.9667 - val_accuracy: 0.5285\n",
      "Epoch 147/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9793 - accuracy: 0.5268 - val_loss: 0.9694 - val_accuracy: 0.5395\n",
      "Epoch 148/200\n",
      "613/613 [==============================] - 0s 597us/step - loss: 0.9801 - accuracy: 0.5293 - val_loss: 0.9678 - val_accuracy: 0.5395\n",
      "Epoch 149/200\n",
      "613/613 [==============================] - 0s 592us/step - loss: 0.9800 - accuracy: 0.5287 - val_loss: 0.9667 - val_accuracy: 0.5381\n",
      "Epoch 150/200\n",
      "613/613 [==============================] - 0s 546us/step - loss: 0.9810 - accuracy: 0.5259 - val_loss: 0.9682 - val_accuracy: 0.5358\n",
      "Epoch 151/200\n",
      "613/613 [==============================] - 0s 599us/step - loss: 0.9797 - accuracy: 0.5235 - val_loss: 0.9711 - val_accuracy: 0.5372\n",
      "Epoch 152/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9808 - accuracy: 0.5274 - val_loss: 0.9691 - val_accuracy: 0.5391\n",
      "Epoch 153/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9813 - accuracy: 0.5266 - val_loss: 0.9640 - val_accuracy: 0.5335\n",
      "Epoch 154/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9808 - accuracy: 0.5231 - val_loss: 0.9638 - val_accuracy: 0.5414\n",
      "Epoch 155/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9798 - accuracy: 0.5244 - val_loss: 0.9659 - val_accuracy: 0.5409\n",
      "Epoch 156/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9790 - accuracy: 0.5280 - val_loss: 0.9639 - val_accuracy: 0.5404\n",
      "Epoch 157/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9799 - accuracy: 0.5268 - val_loss: 0.9653 - val_accuracy: 0.5358\n",
      "Epoch 158/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9795 - accuracy: 0.5245 - val_loss: 0.9667 - val_accuracy: 0.5414\n",
      "Epoch 159/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9803 - accuracy: 0.5276 - val_loss: 0.9634 - val_accuracy: 0.5368\n",
      "Epoch 160/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9796 - accuracy: 0.5272 - val_loss: 0.9692 - val_accuracy: 0.5354\n",
      "Epoch 161/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9798 - accuracy: 0.5258 - val_loss: 0.9689 - val_accuracy: 0.5395\n",
      "Epoch 162/200\n",
      "613/613 [==============================] - 0s 580us/step - loss: 0.9804 - accuracy: 0.5257 - val_loss: 0.9664 - val_accuracy: 0.5308\n",
      "Epoch 163/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9810 - accuracy: 0.5255 - val_loss: 0.9680 - val_accuracy: 0.5377\n",
      "Epoch 164/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9813 - accuracy: 0.5265 - val_loss: 0.9656 - val_accuracy: 0.5372\n",
      "Epoch 165/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9811 - accuracy: 0.5259 - val_loss: 0.9674 - val_accuracy: 0.5395\n",
      "Epoch 166/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9807 - accuracy: 0.5286 - val_loss: 0.9679 - val_accuracy: 0.5363\n",
      "Epoch 167/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9808 - accuracy: 0.5279 - val_loss: 0.9690 - val_accuracy: 0.5363\n",
      "Epoch 168/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9801 - accuracy: 0.5297 - val_loss: 0.9674 - val_accuracy: 0.5372\n",
      "Epoch 169/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9799 - accuracy: 0.5274 - val_loss: 0.9652 - val_accuracy: 0.5368\n",
      "Epoch 170/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9827 - accuracy: 0.5254 - val_loss: 0.9707 - val_accuracy: 0.5363\n",
      "Epoch 171/200\n",
      "613/613 [==============================] - 0s 582us/step - loss: 0.9805 - accuracy: 0.5298 - val_loss: 0.9649 - val_accuracy: 0.5381\n",
      "Epoch 172/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9797 - accuracy: 0.5281 - val_loss: 0.9670 - val_accuracy: 0.5372\n",
      "Epoch 173/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9798 - accuracy: 0.5279 - val_loss: 0.9705 - val_accuracy: 0.5400\n",
      "Epoch 174/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9808 - accuracy: 0.5282 - val_loss: 0.9708 - val_accuracy: 0.5345\n",
      "Epoch 175/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9788 - accuracy: 0.5280 - val_loss: 0.9652 - val_accuracy: 0.5400\n",
      "Epoch 176/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9785 - accuracy: 0.5270 - val_loss: 0.9644 - val_accuracy: 0.5414\n",
      "Epoch 177/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9791 - accuracy: 0.5261 - val_loss: 0.9654 - val_accuracy: 0.5377\n",
      "Epoch 178/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9798 - accuracy: 0.5228 - val_loss: 0.9653 - val_accuracy: 0.5262\n",
      "Epoch 179/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9790 - accuracy: 0.5217 - val_loss: 0.9631 - val_accuracy: 0.5404\n",
      "Epoch 180/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9786 - accuracy: 0.5271 - val_loss: 0.9670 - val_accuracy: 0.5377\n",
      "Epoch 181/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9797 - accuracy: 0.5272 - val_loss: 0.9671 - val_accuracy: 0.5358\n",
      "Epoch 182/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9805 - accuracy: 0.5289 - val_loss: 0.9639 - val_accuracy: 0.5368\n",
      "Epoch 183/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9803 - accuracy: 0.5242 - val_loss: 0.9640 - val_accuracy: 0.5377\n",
      "Epoch 184/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9797 - accuracy: 0.5261 - val_loss: 0.9671 - val_accuracy: 0.5299\n",
      "Epoch 185/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9794 - accuracy: 0.5262 - val_loss: 0.9667 - val_accuracy: 0.5349\n",
      "Epoch 186/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9804 - accuracy: 0.5247 - val_loss: 0.9662 - val_accuracy: 0.5354\n",
      "Epoch 187/200\n",
      "613/613 [==============================] - 0s 600us/step - loss: 0.9793 - accuracy: 0.5291 - val_loss: 0.9675 - val_accuracy: 0.5363\n",
      "Epoch 188/200\n",
      "613/613 [==============================] - 0s 613us/step - loss: 0.9792 - accuracy: 0.5291 - val_loss: 0.9663 - val_accuracy: 0.5404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9794 - accuracy: 0.5281 - val_loss: 0.9680 - val_accuracy: 0.5386\n",
      "Epoch 190/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9803 - accuracy: 0.5245 - val_loss: 0.9672 - val_accuracy: 0.5349\n",
      "Epoch 191/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9792 - accuracy: 0.5274 - val_loss: 0.9694 - val_accuracy: 0.5381\n",
      "Epoch 192/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9800 - accuracy: 0.5275 - val_loss: 0.9672 - val_accuracy: 0.5391\n",
      "Epoch 193/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9803 - accuracy: 0.5268 - val_loss: 0.9660 - val_accuracy: 0.5377\n",
      "Epoch 194/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9788 - accuracy: 0.5271 - val_loss: 0.9675 - val_accuracy: 0.5368\n",
      "Epoch 195/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9809 - accuracy: 0.5213 - val_loss: 0.9688 - val_accuracy: 0.5257\n",
      "Epoch 196/200\n",
      "613/613 [==============================] - 0s 545us/step - loss: 0.9802 - accuracy: 0.5278 - val_loss: 0.9668 - val_accuracy: 0.5372\n",
      "Epoch 197/200\n",
      "613/613 [==============================] - 0s 602us/step - loss: 0.9784 - accuracy: 0.5294 - val_loss: 0.9677 - val_accuracy: 0.5340\n",
      "Epoch 198/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9815 - accuracy: 0.5208 - val_loss: 0.9653 - val_accuracy: 0.5391\n",
      "Epoch 199/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9804 - accuracy: 0.5269 - val_loss: 0.9629 - val_accuracy: 0.5414\n",
      "Epoch 200/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9783 - accuracy: 0.5283 - val_loss: 0.9647 - val_accuracy: 0.5368\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 590us/step - loss: 0.9795 - accuracy: 0.5290\n",
      "Accuracy : 0.5290273427963257\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9647 - accuracy: 0.5368\n",
      "Accuracy : 0.5367646813392639\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "613/613 [==============================] - 0s 729us/step - loss: 1.0490 - accuracy: 0.4618 - val_loss: 1.0134 - val_accuracy: 0.5009\n",
      "Epoch 2/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 1.0023 - accuracy: 0.5129 - val_loss: 0.9596 - val_accuracy: 0.5358\n",
      "Epoch 3/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9949 - accuracy: 0.5154 - val_loss: 0.9788 - val_accuracy: 0.5041\n",
      "Epoch 4/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9930 - accuracy: 0.5171 - val_loss: 0.9554 - val_accuracy: 0.5381\n",
      "Epoch 5/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9934 - accuracy: 0.5156 - val_loss: 0.9555 - val_accuracy: 0.5404\n",
      "Epoch 6/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9912 - accuracy: 0.5187 - val_loss: 0.9526 - val_accuracy: 0.5395\n",
      "Epoch 7/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9910 - accuracy: 0.5175 - val_loss: 0.9578 - val_accuracy: 0.5198\n",
      "Epoch 8/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9912 - accuracy: 0.5196 - val_loss: 0.9498 - val_accuracy: 0.5455\n",
      "Epoch 9/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9904 - accuracy: 0.5190 - val_loss: 0.9591 - val_accuracy: 0.5404\n",
      "Epoch 10/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9890 - accuracy: 0.5191 - val_loss: 0.9481 - val_accuracy: 0.5404\n",
      "Epoch 11/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9898 - accuracy: 0.5201 - val_loss: 0.9519 - val_accuracy: 0.5492\n",
      "Epoch 12/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9926 - accuracy: 0.5173 - val_loss: 0.9631 - val_accuracy: 0.5299\n",
      "Epoch 13/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9891 - accuracy: 0.5168 - val_loss: 0.9509 - val_accuracy: 0.5432\n",
      "Epoch 14/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9878 - accuracy: 0.5214 - val_loss: 0.9486 - val_accuracy: 0.5437\n",
      "Epoch 15/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9870 - accuracy: 0.5224 - val_loss: 0.9513 - val_accuracy: 0.5299\n",
      "Epoch 16/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9893 - accuracy: 0.5194 - val_loss: 0.9560 - val_accuracy: 0.5404\n",
      "Epoch 17/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9885 - accuracy: 0.5209 - val_loss: 0.9479 - val_accuracy: 0.5450\n",
      "Epoch 18/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9873 - accuracy: 0.5218 - val_loss: 0.9475 - val_accuracy: 0.5427\n",
      "Epoch 19/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9873 - accuracy: 0.5230 - val_loss: 0.9494 - val_accuracy: 0.5400\n",
      "Epoch 20/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9881 - accuracy: 0.5222 - val_loss: 0.9506 - val_accuracy: 0.5409\n",
      "Epoch 21/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9897 - accuracy: 0.5194 - val_loss: 0.9453 - val_accuracy: 0.5496\n",
      "Epoch 22/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9866 - accuracy: 0.5215 - val_loss: 0.9484 - val_accuracy: 0.5404\n",
      "Epoch 23/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9880 - accuracy: 0.5232 - val_loss: 0.9524 - val_accuracy: 0.5441\n",
      "Epoch 24/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9872 - accuracy: 0.5238 - val_loss: 0.9453 - val_accuracy: 0.5446\n",
      "Epoch 25/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9891 - accuracy: 0.5201 - val_loss: 0.9470 - val_accuracy: 0.5437\n",
      "Epoch 26/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9884 - accuracy: 0.5244 - val_loss: 0.9528 - val_accuracy: 0.5432\n",
      "Epoch 27/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9868 - accuracy: 0.5222 - val_loss: 0.9519 - val_accuracy: 0.5423\n",
      "Epoch 28/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9876 - accuracy: 0.5209 - val_loss: 0.9447 - val_accuracy: 0.5386\n",
      "Epoch 29/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9871 - accuracy: 0.5221 - val_loss: 0.9515 - val_accuracy: 0.5423\n",
      "Epoch 30/200\n",
      "613/613 [==============================] - 0s 594us/step - loss: 0.9874 - accuracy: 0.5221 - val_loss: 0.9488 - val_accuracy: 0.5386\n",
      "Epoch 31/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9866 - accuracy: 0.5230 - val_loss: 0.9461 - val_accuracy: 0.5432\n",
      "Epoch 32/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9865 - accuracy: 0.5246 - val_loss: 0.9466 - val_accuracy: 0.5450\n",
      "Epoch 33/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9857 - accuracy: 0.5254 - val_loss: 0.9433 - val_accuracy: 0.5483\n",
      "Epoch 34/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9855 - accuracy: 0.5235 - val_loss: 0.9459 - val_accuracy: 0.5418\n",
      "Epoch 35/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9858 - accuracy: 0.5212 - val_loss: 0.9456 - val_accuracy: 0.5395\n",
      "Epoch 36/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9862 - accuracy: 0.5219 - val_loss: 0.9487 - val_accuracy: 0.5437\n",
      "Epoch 37/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9873 - accuracy: 0.5233 - val_loss: 0.9540 - val_accuracy: 0.5478\n",
      "Epoch 38/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9868 - accuracy: 0.5245 - val_loss: 0.9490 - val_accuracy: 0.5427\n",
      "Epoch 39/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9873 - accuracy: 0.5212 - val_loss: 0.9490 - val_accuracy: 0.5464\n",
      "Epoch 40/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9870 - accuracy: 0.5239 - val_loss: 0.9571 - val_accuracy: 0.5492\n",
      "Epoch 41/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9879 - accuracy: 0.5231 - val_loss: 0.9501 - val_accuracy: 0.5437\n",
      "Epoch 42/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9869 - accuracy: 0.5226 - val_loss: 0.9532 - val_accuracy: 0.5368\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 561us/step - loss: 0.9884 - accuracy: 0.5228 - val_loss: 0.9542 - val_accuracy: 0.5400\n",
      "Epoch 44/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9875 - accuracy: 0.5249 - val_loss: 0.9597 - val_accuracy: 0.5409\n",
      "Epoch 45/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9864 - accuracy: 0.5268 - val_loss: 0.9504 - val_accuracy: 0.5386\n",
      "Epoch 46/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9863 - accuracy: 0.5228 - val_loss: 0.9477 - val_accuracy: 0.5340\n",
      "Epoch 47/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9863 - accuracy: 0.5214 - val_loss: 0.9471 - val_accuracy: 0.5391\n",
      "Epoch 48/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9846 - accuracy: 0.5239 - val_loss: 0.9509 - val_accuracy: 0.5450\n",
      "Epoch 49/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9862 - accuracy: 0.5210 - val_loss: 0.9470 - val_accuracy: 0.5423\n",
      "Epoch 50/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9862 - accuracy: 0.5236 - val_loss: 0.9485 - val_accuracy: 0.5473\n",
      "Epoch 51/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9850 - accuracy: 0.5245 - val_loss: 0.9533 - val_accuracy: 0.5441\n",
      "Epoch 52/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9874 - accuracy: 0.5214 - val_loss: 0.9472 - val_accuracy: 0.5377\n",
      "Epoch 53/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9855 - accuracy: 0.5246 - val_loss: 0.9473 - val_accuracy: 0.5414\n",
      "Epoch 54/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9838 - accuracy: 0.5225 - val_loss: 0.9447 - val_accuracy: 0.5450\n",
      "Epoch 55/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9849 - accuracy: 0.5244 - val_loss: 0.9551 - val_accuracy: 0.5391\n",
      "Epoch 56/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9863 - accuracy: 0.5232 - val_loss: 0.9598 - val_accuracy: 0.5423\n",
      "Epoch 57/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9871 - accuracy: 0.5232 - val_loss: 0.9570 - val_accuracy: 0.5423\n",
      "Epoch 58/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9857 - accuracy: 0.5239 - val_loss: 0.9463 - val_accuracy: 0.5432\n",
      "Epoch 59/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9860 - accuracy: 0.5225 - val_loss: 0.9438 - val_accuracy: 0.5469\n",
      "Epoch 60/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9846 - accuracy: 0.5234 - val_loss: 0.9491 - val_accuracy: 0.5303\n",
      "Epoch 61/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9849 - accuracy: 0.5171 - val_loss: 0.9471 - val_accuracy: 0.5418\n",
      "Epoch 62/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9864 - accuracy: 0.5214 - val_loss: 0.9446 - val_accuracy: 0.5404\n",
      "Epoch 63/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9853 - accuracy: 0.5234 - val_loss: 0.9505 - val_accuracy: 0.5446\n",
      "Epoch 64/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9853 - accuracy: 0.5249 - val_loss: 0.9498 - val_accuracy: 0.5427\n",
      "Epoch 65/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9848 - accuracy: 0.5232 - val_loss: 0.9457 - val_accuracy: 0.5354\n",
      "Epoch 66/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9859 - accuracy: 0.5227 - val_loss: 0.9520 - val_accuracy: 0.5358\n",
      "Epoch 67/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9861 - accuracy: 0.5247 - val_loss: 0.9484 - val_accuracy: 0.5368\n",
      "Epoch 68/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9843 - accuracy: 0.5250 - val_loss: 0.9473 - val_accuracy: 0.5409\n",
      "Epoch 69/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9860 - accuracy: 0.5251 - val_loss: 0.9455 - val_accuracy: 0.5381\n",
      "Epoch 70/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9848 - accuracy: 0.5251 - val_loss: 0.9483 - val_accuracy: 0.5409\n",
      "Epoch 71/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9851 - accuracy: 0.5244 - val_loss: 0.9421 - val_accuracy: 0.5450\n",
      "Epoch 72/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9873 - accuracy: 0.5219 - val_loss: 0.9457 - val_accuracy: 0.5404\n",
      "Epoch 73/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9851 - accuracy: 0.5243 - val_loss: 0.9535 - val_accuracy: 0.5381\n",
      "Epoch 74/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9842 - accuracy: 0.5262 - val_loss: 0.9433 - val_accuracy: 0.5450\n",
      "Epoch 75/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9838 - accuracy: 0.5268 - val_loss: 0.9414 - val_accuracy: 0.5464\n",
      "Epoch 76/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9840 - accuracy: 0.5251 - val_loss: 0.9440 - val_accuracy: 0.5368\n",
      "Epoch 77/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 0.9839 - accuracy: 0.5268 - val_loss: 0.9439 - val_accuracy: 0.5450\n",
      "Epoch 78/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9845 - accuracy: 0.5237 - val_loss: 0.9488 - val_accuracy: 0.5400\n",
      "Epoch 79/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9843 - accuracy: 0.5260 - val_loss: 0.9451 - val_accuracy: 0.5506\n",
      "Epoch 80/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9846 - accuracy: 0.5226 - val_loss: 0.9434 - val_accuracy: 0.5473\n",
      "Epoch 81/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9843 - accuracy: 0.5243 - val_loss: 0.9476 - val_accuracy: 0.5363\n",
      "Epoch 82/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9851 - accuracy: 0.5239 - val_loss: 0.9529 - val_accuracy: 0.5418\n",
      "Epoch 83/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9845 - accuracy: 0.5213 - val_loss: 0.9434 - val_accuracy: 0.5441\n",
      "Epoch 84/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9830 - accuracy: 0.5238 - val_loss: 0.9492 - val_accuracy: 0.5432\n",
      "Epoch 85/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9836 - accuracy: 0.5246 - val_loss: 0.9465 - val_accuracy: 0.5414\n",
      "Epoch 86/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9848 - accuracy: 0.5266 - val_loss: 0.9433 - val_accuracy: 0.5455\n",
      "Epoch 87/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9829 - accuracy: 0.5257 - val_loss: 0.9499 - val_accuracy: 0.5409\n",
      "Epoch 88/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9844 - accuracy: 0.5250 - val_loss: 0.9508 - val_accuracy: 0.5418\n",
      "Epoch 89/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9841 - accuracy: 0.5263 - val_loss: 0.9434 - val_accuracy: 0.5437\n",
      "Epoch 90/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9835 - accuracy: 0.5275 - val_loss: 0.9643 - val_accuracy: 0.5391\n",
      "Epoch 91/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9840 - accuracy: 0.5254 - val_loss: 0.9505 - val_accuracy: 0.5423\n",
      "Epoch 92/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9853 - accuracy: 0.5263 - val_loss: 0.9493 - val_accuracy: 0.5404\n",
      "Epoch 93/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9843 - accuracy: 0.5271 - val_loss: 0.9475 - val_accuracy: 0.5386\n",
      "Epoch 94/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9839 - accuracy: 0.5300 - val_loss: 0.9476 - val_accuracy: 0.5446\n",
      "Epoch 95/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9831 - accuracy: 0.5273 - val_loss: 0.9483 - val_accuracy: 0.5432\n",
      "Epoch 96/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9833 - accuracy: 0.5287 - val_loss: 0.9470 - val_accuracy: 0.5469\n",
      "Epoch 97/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9834 - accuracy: 0.5281 - val_loss: 0.9447 - val_accuracy: 0.5450\n",
      "Epoch 98/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9828 - accuracy: 0.5261 - val_loss: 0.9440 - val_accuracy: 0.5414\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 562us/step - loss: 0.9831 - accuracy: 0.5267 - val_loss: 0.9488 - val_accuracy: 0.5432\n",
      "Epoch 100/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9833 - accuracy: 0.5254 - val_loss: 0.9458 - val_accuracy: 0.5460\n",
      "Epoch 101/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9839 - accuracy: 0.5241 - val_loss: 0.9461 - val_accuracy: 0.5432\n",
      "Epoch 102/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9843 - accuracy: 0.5267 - val_loss: 0.9467 - val_accuracy: 0.5455\n",
      "Epoch 103/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9841 - accuracy: 0.5254 - val_loss: 0.9464 - val_accuracy: 0.5437\n",
      "Epoch 104/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9850 - accuracy: 0.5218 - val_loss: 0.9466 - val_accuracy: 0.5423\n",
      "Epoch 105/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9832 - accuracy: 0.5257 - val_loss: 0.9443 - val_accuracy: 0.5473\n",
      "Epoch 106/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9841 - accuracy: 0.5272 - val_loss: 0.9464 - val_accuracy: 0.5418\n",
      "Epoch 107/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9833 - accuracy: 0.5258 - val_loss: 0.9471 - val_accuracy: 0.5418\n",
      "Epoch 108/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9835 - accuracy: 0.5250 - val_loss: 0.9478 - val_accuracy: 0.5377\n",
      "Epoch 109/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9834 - accuracy: 0.5259 - val_loss: 0.9442 - val_accuracy: 0.5473\n",
      "Epoch 110/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9831 - accuracy: 0.5258 - val_loss: 0.9472 - val_accuracy: 0.5400\n",
      "Epoch 111/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9843 - accuracy: 0.5241 - val_loss: 0.9413 - val_accuracy: 0.5441\n",
      "Epoch 112/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9834 - accuracy: 0.5231 - val_loss: 0.9460 - val_accuracy: 0.5404\n",
      "Epoch 113/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9841 - accuracy: 0.5227 - val_loss: 0.9355 - val_accuracy: 0.5446\n",
      "Epoch 114/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9835 - accuracy: 0.5202 - val_loss: 0.9459 - val_accuracy: 0.5391\n",
      "Epoch 115/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9825 - accuracy: 0.5259 - val_loss: 0.9500 - val_accuracy: 0.5441\n",
      "Epoch 116/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9842 - accuracy: 0.5238 - val_loss: 0.9458 - val_accuracy: 0.5450\n",
      "Epoch 117/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9845 - accuracy: 0.5257 - val_loss: 0.9499 - val_accuracy: 0.5437\n",
      "Epoch 118/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9848 - accuracy: 0.5215 - val_loss: 0.9483 - val_accuracy: 0.5386\n",
      "Epoch 119/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9845 - accuracy: 0.5234 - val_loss: 0.9605 - val_accuracy: 0.5432\n",
      "Epoch 120/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9857 - accuracy: 0.5258 - val_loss: 0.9476 - val_accuracy: 0.5400\n",
      "Epoch 121/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9839 - accuracy: 0.5259 - val_loss: 0.9476 - val_accuracy: 0.5469\n",
      "Epoch 122/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9840 - accuracy: 0.5250 - val_loss: 0.9436 - val_accuracy: 0.5450\n",
      "Epoch 123/200\n",
      "613/613 [==============================] - 0s 581us/step - loss: 0.9827 - accuracy: 0.5229 - val_loss: 0.9498 - val_accuracy: 0.5464\n",
      "Epoch 124/200\n",
      "613/613 [==============================] - 0s 580us/step - loss: 0.9835 - accuracy: 0.5251 - val_loss: 0.9454 - val_accuracy: 0.5501\n",
      "Epoch 125/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9825 - accuracy: 0.5265 - val_loss: 0.9424 - val_accuracy: 0.5423\n",
      "Epoch 126/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9828 - accuracy: 0.5255 - val_loss: 0.9427 - val_accuracy: 0.5455\n",
      "Epoch 127/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9826 - accuracy: 0.5254 - val_loss: 0.9452 - val_accuracy: 0.5432\n",
      "Epoch 128/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9834 - accuracy: 0.5244 - val_loss: 0.9375 - val_accuracy: 0.5464\n",
      "Epoch 129/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9817 - accuracy: 0.5264 - val_loss: 0.9465 - val_accuracy: 0.5391\n",
      "Epoch 130/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9840 - accuracy: 0.5244 - val_loss: 0.9458 - val_accuracy: 0.5427\n",
      "Epoch 131/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9825 - accuracy: 0.5263 - val_loss: 0.9449 - val_accuracy: 0.5455\n",
      "Epoch 132/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9833 - accuracy: 0.5256 - val_loss: 0.9443 - val_accuracy: 0.5184\n",
      "Epoch 133/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9834 - accuracy: 0.5241 - val_loss: 0.9476 - val_accuracy: 0.5423\n",
      "Epoch 134/200\n",
      "613/613 [==============================] - 0s 547us/step - loss: 0.9827 - accuracy: 0.5260 - val_loss: 0.9393 - val_accuracy: 0.5437\n",
      "Epoch 135/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9825 - accuracy: 0.5264 - val_loss: 0.9449 - val_accuracy: 0.5450\n",
      "Epoch 136/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9828 - accuracy: 0.5289 - val_loss: 0.9445 - val_accuracy: 0.5437\n",
      "Epoch 137/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9830 - accuracy: 0.5268 - val_loss: 0.9498 - val_accuracy: 0.5432\n",
      "Epoch 138/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9823 - accuracy: 0.5298 - val_loss: 0.9443 - val_accuracy: 0.5455\n",
      "Epoch 139/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9820 - accuracy: 0.5284 - val_loss: 0.9425 - val_accuracy: 0.5455\n",
      "Epoch 140/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9823 - accuracy: 0.5269 - val_loss: 0.9466 - val_accuracy: 0.5391\n",
      "Epoch 141/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9834 - accuracy: 0.5256 - val_loss: 0.9529 - val_accuracy: 0.5404\n",
      "Epoch 142/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9823 - accuracy: 0.5278 - val_loss: 0.9484 - val_accuracy: 0.5280\n",
      "Epoch 143/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9844 - accuracy: 0.5239 - val_loss: 0.9435 - val_accuracy: 0.5423\n",
      "Epoch 144/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9827 - accuracy: 0.5276 - val_loss: 0.9436 - val_accuracy: 0.5418\n",
      "Epoch 145/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9825 - accuracy: 0.5263 - val_loss: 0.9479 - val_accuracy: 0.5312\n",
      "Epoch 146/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9824 - accuracy: 0.5270 - val_loss: 0.9440 - val_accuracy: 0.5290\n",
      "Epoch 147/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9839 - accuracy: 0.5212 - val_loss: 0.9443 - val_accuracy: 0.5460\n",
      "Epoch 148/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9825 - accuracy: 0.5261 - val_loss: 0.9459 - val_accuracy: 0.5427\n",
      "Epoch 149/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9818 - accuracy: 0.5282 - val_loss: 0.9447 - val_accuracy: 0.5404\n",
      "Epoch 150/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9834 - accuracy: 0.5269 - val_loss: 0.9475 - val_accuracy: 0.5368\n",
      "Epoch 151/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9825 - accuracy: 0.5270 - val_loss: 0.9425 - val_accuracy: 0.5446\n",
      "Epoch 152/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9828 - accuracy: 0.5278 - val_loss: 0.9436 - val_accuracy: 0.5427\n",
      "Epoch 153/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9829 - accuracy: 0.5257 - val_loss: 0.9460 - val_accuracy: 0.5400\n",
      "Epoch 154/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9840 - accuracy: 0.5278 - val_loss: 0.9455 - val_accuracy: 0.5446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9828 - accuracy: 0.5263 - val_loss: 0.9519 - val_accuracy: 0.5418\n",
      "Epoch 156/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9831 - accuracy: 0.5271 - val_loss: 0.9489 - val_accuracy: 0.5400\n",
      "Epoch 157/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9841 - accuracy: 0.5285 - val_loss: 0.9462 - val_accuracy: 0.5450\n",
      "Epoch 158/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9840 - accuracy: 0.5248 - val_loss: 0.9482 - val_accuracy: 0.5441\n",
      "Epoch 159/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9851 - accuracy: 0.5241 - val_loss: 0.9483 - val_accuracy: 0.5294\n",
      "Epoch 160/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9831 - accuracy: 0.5254 - val_loss: 0.9443 - val_accuracy: 0.5501\n",
      "Epoch 161/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9829 - accuracy: 0.5279 - val_loss: 0.9446 - val_accuracy: 0.5478\n",
      "Epoch 162/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9845 - accuracy: 0.5219 - val_loss: 0.9442 - val_accuracy: 0.5450\n",
      "Epoch 163/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9834 - accuracy: 0.5261 - val_loss: 0.9448 - val_accuracy: 0.5432\n",
      "Epoch 164/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9841 - accuracy: 0.5240 - val_loss: 0.9479 - val_accuracy: 0.5446\n",
      "Epoch 165/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9828 - accuracy: 0.5261 - val_loss: 0.9468 - val_accuracy: 0.5478\n",
      "Epoch 166/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9823 - accuracy: 0.5269 - val_loss: 0.9451 - val_accuracy: 0.5437\n",
      "Epoch 167/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9831 - accuracy: 0.5273 - val_loss: 0.9447 - val_accuracy: 0.5450\n",
      "Epoch 168/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9833 - accuracy: 0.5256 - val_loss: 0.9460 - val_accuracy: 0.5391\n",
      "Epoch 169/200\n",
      "613/613 [==============================] - 0s 600us/step - loss: 0.9833 - accuracy: 0.5250 - val_loss: 0.9488 - val_accuracy: 0.5308\n",
      "Epoch 170/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9820 - accuracy: 0.5275 - val_loss: 0.9509 - val_accuracy: 0.5216\n",
      "Epoch 171/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9850 - accuracy: 0.5262 - val_loss: 0.9451 - val_accuracy: 0.5469\n",
      "Epoch 172/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9841 - accuracy: 0.5250 - val_loss: 0.9435 - val_accuracy: 0.5469\n",
      "Epoch 173/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9829 - accuracy: 0.5260 - val_loss: 0.9421 - val_accuracy: 0.5377\n",
      "Epoch 174/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9839 - accuracy: 0.5260 - val_loss: 0.9400 - val_accuracy: 0.5469\n",
      "Epoch 175/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9843 - accuracy: 0.5250 - val_loss: 0.9426 - val_accuracy: 0.5441\n",
      "Epoch 176/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9826 - accuracy: 0.5273 - val_loss: 0.9431 - val_accuracy: 0.5400\n",
      "Epoch 177/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9831 - accuracy: 0.5239 - val_loss: 0.9450 - val_accuracy: 0.5460\n",
      "Epoch 178/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9832 - accuracy: 0.5283 - val_loss: 0.9480 - val_accuracy: 0.5464\n",
      "Epoch 179/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9815 - accuracy: 0.5266 - val_loss: 0.9481 - val_accuracy: 0.5460\n",
      "Epoch 180/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9820 - accuracy: 0.5266 - val_loss: 0.9427 - val_accuracy: 0.5473\n",
      "Epoch 181/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9825 - accuracy: 0.5273 - val_loss: 0.9454 - val_accuracy: 0.5483\n",
      "Epoch 182/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9822 - accuracy: 0.5259 - val_loss: 0.9416 - val_accuracy: 0.5464\n",
      "Epoch 183/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9823 - accuracy: 0.5269 - val_loss: 0.9487 - val_accuracy: 0.5414\n",
      "Epoch 184/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9831 - accuracy: 0.5280 - val_loss: 0.9392 - val_accuracy: 0.5460\n",
      "Epoch 185/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9827 - accuracy: 0.5222 - val_loss: 0.9490 - val_accuracy: 0.5450\n",
      "Epoch 186/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9837 - accuracy: 0.5281 - val_loss: 0.9421 - val_accuracy: 0.5483\n",
      "Epoch 187/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9842 - accuracy: 0.5285 - val_loss: 0.9492 - val_accuracy: 0.5446\n",
      "Epoch 188/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9824 - accuracy: 0.5279 - val_loss: 0.9424 - val_accuracy: 0.5464\n",
      "Epoch 189/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9829 - accuracy: 0.5266 - val_loss: 0.9482 - val_accuracy: 0.5446\n",
      "Epoch 190/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9843 - accuracy: 0.5272 - val_loss: 0.9482 - val_accuracy: 0.5400\n",
      "Epoch 191/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9823 - accuracy: 0.5243 - val_loss: 0.9430 - val_accuracy: 0.5478\n",
      "Epoch 192/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9828 - accuracy: 0.5271 - val_loss: 0.9536 - val_accuracy: 0.5473\n",
      "Epoch 193/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9837 - accuracy: 0.5269 - val_loss: 0.9461 - val_accuracy: 0.5473\n",
      "Epoch 194/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9840 - accuracy: 0.5234 - val_loss: 0.9468 - val_accuracy: 0.5441\n",
      "Epoch 195/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9823 - accuracy: 0.5264 - val_loss: 0.9434 - val_accuracy: 0.5446\n",
      "Epoch 196/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9813 - accuracy: 0.5301 - val_loss: 0.9482 - val_accuracy: 0.5446\n",
      "Epoch 197/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9832 - accuracy: 0.5256 - val_loss: 0.9527 - val_accuracy: 0.5418\n",
      "Epoch 198/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9826 - accuracy: 0.5265 - val_loss: 0.9475 - val_accuracy: 0.5450\n",
      "Epoch 199/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9825 - accuracy: 0.5259 - val_loss: 0.9416 - val_accuracy: 0.5473\n",
      "Epoch 200/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9818 - accuracy: 0.5244 - val_loss: 0.9476 - val_accuracy: 0.5437\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 592us/step - loss: 0.9808 - accuracy: 0.5293\n",
      "Accuracy : 0.5292826294898987\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9476 - accuracy: 0.5437\n",
      "Accuracy : 0.5436580777168274\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "613/613 [==============================] - 0s 707us/step - loss: 1.0398 - accuracy: 0.4734 - val_loss: 1.0131 - val_accuracy: 0.5060\n",
      "Epoch 2/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9991 - accuracy: 0.5112 - val_loss: 0.9975 - val_accuracy: 0.5097\n",
      "Epoch 3/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9920 - accuracy: 0.5187 - val_loss: 0.9939 - val_accuracy: 0.5069\n",
      "Epoch 4/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9884 - accuracy: 0.5213 - val_loss: 0.9904 - val_accuracy: 0.5041\n",
      "Epoch 5/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9889 - accuracy: 0.5188 - val_loss: 0.9896 - val_accuracy: 0.5211\n",
      "Epoch 6/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9872 - accuracy: 0.5209 - val_loss: 0.9884 - val_accuracy: 0.5129\n",
      "Epoch 7/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9887 - accuracy: 0.5168 - val_loss: 0.9920 - val_accuracy: 0.5175\n",
      "Epoch 8/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9863 - accuracy: 0.5198 - val_loss: 0.9924 - val_accuracy: 0.5142\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 558us/step - loss: 0.9849 - accuracy: 0.5214 - val_loss: 0.9894 - val_accuracy: 0.5161\n",
      "Epoch 10/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9826 - accuracy: 0.5254 - val_loss: 0.9918 - val_accuracy: 0.5156\n",
      "Epoch 11/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9840 - accuracy: 0.5224 - val_loss: 0.9868 - val_accuracy: 0.5101\n",
      "Epoch 12/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9825 - accuracy: 0.5240 - val_loss: 0.9919 - val_accuracy: 0.5009\n",
      "Epoch 13/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9827 - accuracy: 0.5230 - val_loss: 0.9912 - val_accuracy: 0.5060\n",
      "Epoch 14/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9828 - accuracy: 0.5212 - val_loss: 0.9961 - val_accuracy: 0.5207\n",
      "Epoch 15/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9811 - accuracy: 0.5259 - val_loss: 0.9905 - val_accuracy: 0.5161\n",
      "Epoch 16/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9827 - accuracy: 0.5225 - val_loss: 0.9897 - val_accuracy: 0.5161\n",
      "Epoch 17/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9823 - accuracy: 0.5231 - val_loss: 0.9921 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9807 - accuracy: 0.5229 - val_loss: 0.9913 - val_accuracy: 0.5041\n",
      "Epoch 19/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9837 - accuracy: 0.5239 - val_loss: 0.9853 - val_accuracy: 0.5133\n",
      "Epoch 20/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9832 - accuracy: 0.5231 - val_loss: 0.9887 - val_accuracy: 0.5152\n",
      "Epoch 21/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9808 - accuracy: 0.5249 - val_loss: 0.9829 - val_accuracy: 0.5221\n",
      "Epoch 22/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9816 - accuracy: 0.5246 - val_loss: 0.9816 - val_accuracy: 0.5211\n",
      "Epoch 23/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9812 - accuracy: 0.5243 - val_loss: 0.9912 - val_accuracy: 0.5055\n",
      "Epoch 24/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9847 - accuracy: 0.5248 - val_loss: 0.9804 - val_accuracy: 0.5188\n",
      "Epoch 25/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9830 - accuracy: 0.5220 - val_loss: 0.9864 - val_accuracy: 0.5110\n",
      "Epoch 26/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9815 - accuracy: 0.5245 - val_loss: 0.9822 - val_accuracy: 0.5156\n",
      "Epoch 27/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9813 - accuracy: 0.5260 - val_loss: 0.9896 - val_accuracy: 0.5101\n",
      "Epoch 28/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9825 - accuracy: 0.5246 - val_loss: 0.9840 - val_accuracy: 0.5253\n",
      "Epoch 29/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9806 - accuracy: 0.5242 - val_loss: 0.9854 - val_accuracy: 0.5221\n",
      "Epoch 30/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9804 - accuracy: 0.5239 - val_loss: 0.9880 - val_accuracy: 0.5147\n",
      "Epoch 31/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9804 - accuracy: 0.5263 - val_loss: 0.9841 - val_accuracy: 0.5188\n",
      "Epoch 32/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9790 - accuracy: 0.5261 - val_loss: 0.9834 - val_accuracy: 0.5244\n",
      "Epoch 33/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9794 - accuracy: 0.5247 - val_loss: 0.9849 - val_accuracy: 0.5170\n",
      "Epoch 34/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9809 - accuracy: 0.5260 - val_loss: 0.9911 - val_accuracy: 0.5184\n",
      "Epoch 35/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9814 - accuracy: 0.5259 - val_loss: 0.9844 - val_accuracy: 0.5175\n",
      "Epoch 36/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9811 - accuracy: 0.5250 - val_loss: 0.9809 - val_accuracy: 0.5244\n",
      "Epoch 37/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9830 - accuracy: 0.5249 - val_loss: 0.9853 - val_accuracy: 0.5179\n",
      "Epoch 38/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9804 - accuracy: 0.5252 - val_loss: 0.9863 - val_accuracy: 0.5225\n",
      "Epoch 39/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9800 - accuracy: 0.5233 - val_loss: 0.9860 - val_accuracy: 0.5179\n",
      "Epoch 40/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9783 - accuracy: 0.5294 - val_loss: 0.9855 - val_accuracy: 0.5184\n",
      "Epoch 41/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9796 - accuracy: 0.5252 - val_loss: 0.9861 - val_accuracy: 0.5170\n",
      "Epoch 42/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9789 - accuracy: 0.5275 - val_loss: 0.9829 - val_accuracy: 0.5170\n",
      "Epoch 43/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9803 - accuracy: 0.5236 - val_loss: 0.9800 - val_accuracy: 0.5165\n",
      "Epoch 44/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9795 - accuracy: 0.5274 - val_loss: 0.9839 - val_accuracy: 0.5184\n",
      "Epoch 45/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9797 - accuracy: 0.5261 - val_loss: 0.9871 - val_accuracy: 0.5023\n",
      "Epoch 46/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9797 - accuracy: 0.5237 - val_loss: 0.9795 - val_accuracy: 0.5248\n",
      "Epoch 47/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9792 - accuracy: 0.5249 - val_loss: 0.9907 - val_accuracy: 0.5078\n",
      "Epoch 48/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9791 - accuracy: 0.5264 - val_loss: 0.9878 - val_accuracy: 0.5055\n",
      "Epoch 49/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9803 - accuracy: 0.5249 - val_loss: 0.9829 - val_accuracy: 0.5202\n",
      "Epoch 50/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9803 - accuracy: 0.5284 - val_loss: 0.9886 - val_accuracy: 0.5129\n",
      "Epoch 51/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9791 - accuracy: 0.5262 - val_loss: 0.9825 - val_accuracy: 0.5211\n",
      "Epoch 52/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9793 - accuracy: 0.5257 - val_loss: 0.9875 - val_accuracy: 0.5216\n",
      "Epoch 53/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9820 - accuracy: 0.5234 - val_loss: 0.9855 - val_accuracy: 0.5234\n",
      "Epoch 54/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9798 - accuracy: 0.5261 - val_loss: 0.9813 - val_accuracy: 0.5198\n",
      "Epoch 55/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9789 - accuracy: 0.5263 - val_loss: 0.9855 - val_accuracy: 0.5156\n",
      "Epoch 56/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9790 - accuracy: 0.5289 - val_loss: 0.9841 - val_accuracy: 0.5211\n",
      "Epoch 57/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9797 - accuracy: 0.5251 - val_loss: 0.9820 - val_accuracy: 0.5221\n",
      "Epoch 58/200\n",
      "613/613 [==============================] - 0s 589us/step - loss: 0.9809 - accuracy: 0.5275 - val_loss: 0.9914 - val_accuracy: 0.5051\n",
      "Epoch 59/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9795 - accuracy: 0.5261 - val_loss: 0.9883 - val_accuracy: 0.5074\n",
      "Epoch 60/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9785 - accuracy: 0.5272 - val_loss: 0.9870 - val_accuracy: 0.5147\n",
      "Epoch 61/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9796 - accuracy: 0.5254 - val_loss: 0.9798 - val_accuracy: 0.5239\n",
      "Epoch 62/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9782 - accuracy: 0.5285 - val_loss: 0.9797 - val_accuracy: 0.5248\n",
      "Epoch 63/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9783 - accuracy: 0.5292 - val_loss: 0.9868 - val_accuracy: 0.5124\n",
      "Epoch 64/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9783 - accuracy: 0.5278 - val_loss: 0.9832 - val_accuracy: 0.5207\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 555us/step - loss: 0.9783 - accuracy: 0.5290 - val_loss: 0.9834 - val_accuracy: 0.5230\n",
      "Epoch 66/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9797 - accuracy: 0.5284 - val_loss: 0.9810 - val_accuracy: 0.5276\n",
      "Epoch 67/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9798 - accuracy: 0.5269 - val_loss: 0.9825 - val_accuracy: 0.5211\n",
      "Epoch 68/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9783 - accuracy: 0.5255 - val_loss: 0.9828 - val_accuracy: 0.5198\n",
      "Epoch 69/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9797 - accuracy: 0.5288 - val_loss: 0.9907 - val_accuracy: 0.5087\n",
      "Epoch 70/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9802 - accuracy: 0.5265 - val_loss: 0.9851 - val_accuracy: 0.5152\n",
      "Epoch 71/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9784 - accuracy: 0.5276 - val_loss: 0.9820 - val_accuracy: 0.5244\n",
      "Epoch 72/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9791 - accuracy: 0.5282 - val_loss: 0.9861 - val_accuracy: 0.5211\n",
      "Epoch 73/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9796 - accuracy: 0.5302 - val_loss: 0.9824 - val_accuracy: 0.5175\n",
      "Epoch 74/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9784 - accuracy: 0.5270 - val_loss: 0.9867 - val_accuracy: 0.5074\n",
      "Epoch 75/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9783 - accuracy: 0.5263 - val_loss: 0.9862 - val_accuracy: 0.5221\n",
      "Epoch 76/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9793 - accuracy: 0.5270 - val_loss: 0.9785 - val_accuracy: 0.5225\n",
      "Epoch 77/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9789 - accuracy: 0.5257 - val_loss: 0.9821 - val_accuracy: 0.5225\n",
      "Epoch 78/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9789 - accuracy: 0.5270 - val_loss: 0.9813 - val_accuracy: 0.5225\n",
      "Epoch 79/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9802 - accuracy: 0.5270 - val_loss: 0.9819 - val_accuracy: 0.5244\n",
      "Epoch 80/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9805 - accuracy: 0.5249 - val_loss: 0.9834 - val_accuracy: 0.5271\n",
      "Epoch 81/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9789 - accuracy: 0.5261 - val_loss: 0.9818 - val_accuracy: 0.5221\n",
      "Epoch 82/200\n",
      "613/613 [==============================] - 0s 589us/step - loss: 0.9796 - accuracy: 0.5276 - val_loss: 0.9837 - val_accuracy: 0.5225\n",
      "Epoch 83/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9785 - accuracy: 0.5247 - val_loss: 0.9871 - val_accuracy: 0.5193\n",
      "Epoch 84/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9796 - accuracy: 0.5267 - val_loss: 0.9856 - val_accuracy: 0.5119\n",
      "Epoch 85/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9793 - accuracy: 0.5238 - val_loss: 0.9866 - val_accuracy: 0.5276\n",
      "Epoch 86/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9797 - accuracy: 0.5250 - val_loss: 0.9831 - val_accuracy: 0.5152\n",
      "Epoch 87/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9806 - accuracy: 0.5269 - val_loss: 0.9811 - val_accuracy: 0.5253\n",
      "Epoch 88/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9789 - accuracy: 0.5247 - val_loss: 0.9828 - val_accuracy: 0.5188\n",
      "Epoch 89/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9804 - accuracy: 0.5258 - val_loss: 0.9847 - val_accuracy: 0.5230\n",
      "Epoch 90/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9788 - accuracy: 0.5272 - val_loss: 0.9803 - val_accuracy: 0.5248\n",
      "Epoch 91/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9783 - accuracy: 0.5274 - val_loss: 0.9823 - val_accuracy: 0.5248\n",
      "Epoch 92/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9777 - accuracy: 0.5262 - val_loss: 0.9813 - val_accuracy: 0.5216\n",
      "Epoch 93/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9785 - accuracy: 0.5284 - val_loss: 0.9793 - val_accuracy: 0.5221\n",
      "Epoch 94/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9775 - accuracy: 0.5264 - val_loss: 0.9842 - val_accuracy: 0.5211\n",
      "Epoch 95/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9786 - accuracy: 0.5268 - val_loss: 0.9870 - val_accuracy: 0.5230\n",
      "Epoch 96/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9772 - accuracy: 0.5279 - val_loss: 0.9781 - val_accuracy: 0.5179\n",
      "Epoch 97/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9770 - accuracy: 0.5296 - val_loss: 0.9881 - val_accuracy: 0.5221\n",
      "Epoch 98/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9778 - accuracy: 0.5282 - val_loss: 0.9913 - val_accuracy: 0.5083\n",
      "Epoch 99/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9782 - accuracy: 0.5291 - val_loss: 0.9786 - val_accuracy: 0.5262\n",
      "Epoch 100/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9825 - val_accuracy: 0.5244\n",
      "Epoch 101/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9781 - accuracy: 0.5284 - val_loss: 0.9870 - val_accuracy: 0.5239\n",
      "Epoch 102/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9795 - accuracy: 0.5285 - val_loss: 0.9832 - val_accuracy: 0.5152\n",
      "Epoch 103/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9772 - accuracy: 0.5259 - val_loss: 0.9812 - val_accuracy: 0.5110\n",
      "Epoch 104/200\n",
      "613/613 [==============================] - 0s 581us/step - loss: 0.9777 - accuracy: 0.5283 - val_loss: 0.9838 - val_accuracy: 0.5239\n",
      "Epoch 105/200\n",
      "613/613 [==============================] - 0s 596us/step - loss: 0.9789 - accuracy: 0.5265 - val_loss: 0.9833 - val_accuracy: 0.5165\n",
      "Epoch 106/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9798 - accuracy: 0.5264 - val_loss: 0.9877 - val_accuracy: 0.5253\n",
      "Epoch 107/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9780 - accuracy: 0.5270 - val_loss: 0.9894 - val_accuracy: 0.5060\n",
      "Epoch 108/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9795 - accuracy: 0.5262 - val_loss: 0.9807 - val_accuracy: 0.5299\n",
      "Epoch 109/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9760 - accuracy: 0.5244 - val_loss: 0.9848 - val_accuracy: 0.5230\n",
      "Epoch 110/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9767 - accuracy: 0.5267 - val_loss: 0.9844 - val_accuracy: 0.5211\n",
      "Epoch 111/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9789 - accuracy: 0.5283 - val_loss: 0.9810 - val_accuracy: 0.5202\n",
      "Epoch 112/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9772 - accuracy: 0.5265 - val_loss: 0.9828 - val_accuracy: 0.5285\n",
      "Epoch 113/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9771 - accuracy: 0.5275 - val_loss: 0.9875 - val_accuracy: 0.5101\n",
      "Epoch 114/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9779 - accuracy: 0.5263 - val_loss: 0.9826 - val_accuracy: 0.5216\n",
      "Epoch 115/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9776 - accuracy: 0.5272 - val_loss: 0.9787 - val_accuracy: 0.5142\n",
      "Epoch 116/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9785 - accuracy: 0.5285 - val_loss: 0.9811 - val_accuracy: 0.5211\n",
      "Epoch 117/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9781 - accuracy: 0.5270 - val_loss: 0.9808 - val_accuracy: 0.5216\n",
      "Epoch 118/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9786 - accuracy: 0.5259 - val_loss: 0.9802 - val_accuracy: 0.5225\n",
      "Epoch 119/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9793 - accuracy: 0.5270 - val_loss: 0.9789 - val_accuracy: 0.5207\n",
      "Epoch 120/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9842 - val_accuracy: 0.5248\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 555us/step - loss: 0.9786 - accuracy: 0.5251 - val_loss: 0.9860 - val_accuracy: 0.5239\n",
      "Epoch 122/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9793 - accuracy: 0.5267 - val_loss: 0.9843 - val_accuracy: 0.5234\n",
      "Epoch 123/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9774 - accuracy: 0.5290 - val_loss: 0.9853 - val_accuracy: 0.5092\n",
      "Epoch 124/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9775 - accuracy: 0.5250 - val_loss: 0.9789 - val_accuracy: 0.5152\n",
      "Epoch 125/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9776 - accuracy: 0.5282 - val_loss: 0.9858 - val_accuracy: 0.5211\n",
      "Epoch 126/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9775 - accuracy: 0.5268 - val_loss: 0.9833 - val_accuracy: 0.5239\n",
      "Epoch 127/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9778 - accuracy: 0.5268 - val_loss: 0.9887 - val_accuracy: 0.5234\n",
      "Epoch 128/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9788 - accuracy: 0.5272 - val_loss: 0.9828 - val_accuracy: 0.5170\n",
      "Epoch 129/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9782 - accuracy: 0.5262 - val_loss: 0.9824 - val_accuracy: 0.5184\n",
      "Epoch 130/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9800 - val_accuracy: 0.5244\n",
      "Epoch 131/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9765 - accuracy: 0.5267 - val_loss: 0.9870 - val_accuracy: 0.5119\n",
      "Epoch 132/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9771 - accuracy: 0.5269 - val_loss: 0.9805 - val_accuracy: 0.5257\n",
      "Epoch 133/200\n",
      "613/613 [==============================] - 0s 552us/step - loss: 0.9772 - accuracy: 0.5290 - val_loss: 0.9818 - val_accuracy: 0.5170\n",
      "Epoch 134/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9760 - accuracy: 0.5251 - val_loss: 0.9844 - val_accuracy: 0.5119\n",
      "Epoch 135/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9758 - accuracy: 0.5282 - val_loss: 0.9833 - val_accuracy: 0.5244\n",
      "Epoch 136/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9764 - accuracy: 0.5297 - val_loss: 0.9861 - val_accuracy: 0.5234\n",
      "Epoch 137/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9763 - accuracy: 0.5266 - val_loss: 0.9824 - val_accuracy: 0.5092\n",
      "Epoch 138/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9782 - accuracy: 0.5282 - val_loss: 0.9801 - val_accuracy: 0.5244\n",
      "Epoch 139/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9765 - accuracy: 0.5274 - val_loss: 0.9863 - val_accuracy: 0.5193\n",
      "Epoch 140/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9771 - accuracy: 0.5249 - val_loss: 0.9821 - val_accuracy: 0.5147\n",
      "Epoch 141/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9764 - accuracy: 0.5288 - val_loss: 0.9823 - val_accuracy: 0.5152\n",
      "Epoch 142/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9782 - accuracy: 0.5295 - val_loss: 0.9842 - val_accuracy: 0.5290\n",
      "Epoch 143/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9763 - accuracy: 0.5273 - val_loss: 0.9813 - val_accuracy: 0.5234\n",
      "Epoch 144/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9786 - accuracy: 0.5273 - val_loss: 0.9852 - val_accuracy: 0.5069\n",
      "Epoch 145/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9768 - accuracy: 0.5258 - val_loss: 0.9820 - val_accuracy: 0.5216\n",
      "Epoch 146/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9788 - accuracy: 0.5245 - val_loss: 0.9808 - val_accuracy: 0.5179\n",
      "Epoch 147/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9764 - accuracy: 0.5295 - val_loss: 0.9840 - val_accuracy: 0.5087\n",
      "Epoch 148/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9780 - accuracy: 0.5260 - val_loss: 0.9836 - val_accuracy: 0.5225\n",
      "Epoch 149/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9784 - accuracy: 0.5282 - val_loss: 0.9833 - val_accuracy: 0.5188\n",
      "Epoch 150/200\n",
      "613/613 [==============================] - 0s 585us/step - loss: 0.9764 - accuracy: 0.5260 - val_loss: 0.9950 - val_accuracy: 0.4862\n",
      "Epoch 151/200\n",
      "613/613 [==============================] - 0s 595us/step - loss: 0.9787 - accuracy: 0.5248 - val_loss: 0.9821 - val_accuracy: 0.5216\n",
      "Epoch 152/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9784 - accuracy: 0.5288 - val_loss: 0.9821 - val_accuracy: 0.5165\n",
      "Epoch 153/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9776 - accuracy: 0.5260 - val_loss: 0.9830 - val_accuracy: 0.5211\n",
      "Epoch 154/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9768 - accuracy: 0.5289 - val_loss: 0.9903 - val_accuracy: 0.5188\n",
      "Epoch 155/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9773 - accuracy: 0.5248 - val_loss: 0.9786 - val_accuracy: 0.5285\n",
      "Epoch 156/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9771 - accuracy: 0.5259 - val_loss: 0.9834 - val_accuracy: 0.5230\n",
      "Epoch 157/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9779 - accuracy: 0.5250 - val_loss: 0.9836 - val_accuracy: 0.5175\n",
      "Epoch 158/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9759 - accuracy: 0.5281 - val_loss: 0.9840 - val_accuracy: 0.4922\n",
      "Epoch 159/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9766 - accuracy: 0.5269 - val_loss: 0.9810 - val_accuracy: 0.5221\n",
      "Epoch 160/200\n",
      "613/613 [==============================] - 0s 533us/step - loss: 0.9764 - accuracy: 0.5251 - val_loss: 0.9798 - val_accuracy: 0.5193\n",
      "Epoch 161/200\n",
      "613/613 [==============================] - 0s 543us/step - loss: 0.9763 - accuracy: 0.5297 - val_loss: 0.9803 - val_accuracy: 0.5257\n",
      "Epoch 162/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9770 - accuracy: 0.5294 - val_loss: 0.9805 - val_accuracy: 0.5257\n",
      "Epoch 163/200\n",
      "613/613 [==============================] - 0s 536us/step - loss: 0.9765 - accuracy: 0.5283 - val_loss: 0.9837 - val_accuracy: 0.5101\n",
      "Epoch 164/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 0.9767 - accuracy: 0.5289 - val_loss: 0.9802 - val_accuracy: 0.5276\n",
      "Epoch 165/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9768 - accuracy: 0.5292 - val_loss: 0.9769 - val_accuracy: 0.5262\n",
      "Epoch 166/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9771 - accuracy: 0.5278 - val_loss: 0.9793 - val_accuracy: 0.5202\n",
      "Epoch 167/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9768 - accuracy: 0.5283 - val_loss: 0.9800 - val_accuracy: 0.5285\n",
      "Epoch 168/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9812 - val_accuracy: 0.5322\n",
      "Epoch 169/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9769 - accuracy: 0.5285 - val_loss: 0.9816 - val_accuracy: 0.5216\n",
      "Epoch 170/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9771 - accuracy: 0.5295 - val_loss: 0.9813 - val_accuracy: 0.5230\n",
      "Epoch 171/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9774 - accuracy: 0.5276 - val_loss: 0.9830 - val_accuracy: 0.5253\n",
      "Epoch 172/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9791 - accuracy: 0.5254 - val_loss: 0.9826 - val_accuracy: 0.5179\n",
      "Epoch 173/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9779 - accuracy: 0.5268 - val_loss: 0.9825 - val_accuracy: 0.5083\n",
      "Epoch 174/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9778 - accuracy: 0.5254 - val_loss: 0.9782 - val_accuracy: 0.5184\n",
      "Epoch 175/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9765 - accuracy: 0.5291 - val_loss: 0.9819 - val_accuracy: 0.5216\n",
      "Epoch 176/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9760 - accuracy: 0.5306 - val_loss: 0.9807 - val_accuracy: 0.5156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9757 - accuracy: 0.5293 - val_loss: 0.9815 - val_accuracy: 0.5322\n",
      "Epoch 178/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9757 - accuracy: 0.5283 - val_loss: 0.9831 - val_accuracy: 0.5239\n",
      "Epoch 179/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9776 - accuracy: 0.5304 - val_loss: 0.9804 - val_accuracy: 0.5262\n",
      "Epoch 180/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9769 - accuracy: 0.5296 - val_loss: 0.9810 - val_accuracy: 0.5230\n",
      "Epoch 181/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9760 - accuracy: 0.5296 - val_loss: 0.9814 - val_accuracy: 0.5285\n",
      "Epoch 182/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5306 - val_loss: 0.9815 - val_accuracy: 0.5253\n",
      "Epoch 183/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9811 - val_accuracy: 0.5225\n",
      "Epoch 184/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9763 - accuracy: 0.5264 - val_loss: 0.9799 - val_accuracy: 0.5221\n",
      "Epoch 185/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9767 - accuracy: 0.5297 - val_loss: 0.9804 - val_accuracy: 0.5262\n",
      "Epoch 186/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9765 - accuracy: 0.5278 - val_loss: 0.9801 - val_accuracy: 0.5326\n",
      "Epoch 187/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9767 - accuracy: 0.5293 - val_loss: 0.9819 - val_accuracy: 0.5198\n",
      "Epoch 188/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9781 - accuracy: 0.5301 - val_loss: 0.9810 - val_accuracy: 0.5221\n",
      "Epoch 189/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9779 - accuracy: 0.5294 - val_loss: 0.9787 - val_accuracy: 0.5244\n",
      "Epoch 190/200\n",
      "613/613 [==============================] - 0s 556us/step - loss: 0.9797 - accuracy: 0.5287 - val_loss: 0.9815 - val_accuracy: 0.5184\n",
      "Epoch 191/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9783 - accuracy: 0.5263 - val_loss: 0.9805 - val_accuracy: 0.5188\n",
      "Epoch 192/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9789 - accuracy: 0.5220 - val_loss: 0.9777 - val_accuracy: 0.5198\n",
      "Epoch 193/200\n",
      "613/613 [==============================] - 0s 555us/step - loss: 0.9778 - accuracy: 0.5272 - val_loss: 0.9839 - val_accuracy: 0.5244\n",
      "Epoch 194/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9779 - accuracy: 0.5279 - val_loss: 0.9896 - val_accuracy: 0.4982\n",
      "Epoch 195/200\n",
      "613/613 [==============================] - 0s 557us/step - loss: 0.9778 - accuracy: 0.5282 - val_loss: 0.9793 - val_accuracy: 0.5285\n",
      "Epoch 196/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9797 - accuracy: 0.5268 - val_loss: 0.9766 - val_accuracy: 0.5262\n",
      "Epoch 197/200\n",
      "613/613 [==============================] - 0s 581us/step - loss: 0.9790 - accuracy: 0.5252 - val_loss: 0.9812 - val_accuracy: 0.5239\n",
      "Epoch 198/200\n",
      "613/613 [==============================] - 0s 589us/step - loss: 0.9782 - accuracy: 0.5313 - val_loss: 0.9836 - val_accuracy: 0.5032\n",
      "Epoch 199/200\n",
      "613/613 [==============================] - 0s 549us/step - loss: 0.9792 - accuracy: 0.5251 - val_loss: 0.9800 - val_accuracy: 0.5216\n",
      "Epoch 200/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9783 - accuracy: 0.5261 - val_loss: 0.9782 - val_accuracy: 0.5230\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 589us/step - loss: 0.9767 - accuracy: 0.5303\n",
      "Accuracy : 0.5303037762641907\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9782 - accuracy: 0.5230\n",
      "Accuracy : 0.5229779481887817\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      "613/613 [==============================] - 0s 706us/step - loss: 1.0390 - accuracy: 0.4694 - val_loss: 0.9964 - val_accuracy: 0.5207\n",
      "Epoch 2/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 1.0028 - accuracy: 0.5073 - val_loss: 0.9738 - val_accuracy: 0.5345\n",
      "Epoch 3/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 1.0004 - accuracy: 0.5109 - val_loss: 0.9749 - val_accuracy: 0.5253\n",
      "Epoch 4/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9944 - accuracy: 0.5148 - val_loss: 0.9760 - val_accuracy: 0.5326\n",
      "Epoch 5/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9914 - accuracy: 0.5161 - val_loss: 0.9731 - val_accuracy: 0.5230\n",
      "Epoch 6/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9915 - accuracy: 0.5137 - val_loss: 0.9676 - val_accuracy: 0.5340\n",
      "Epoch 7/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9912 - accuracy: 0.5169 - val_loss: 0.9769 - val_accuracy: 0.5299\n",
      "Epoch 8/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9893 - accuracy: 0.5191 - val_loss: 0.9638 - val_accuracy: 0.5317\n",
      "Epoch 9/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9893 - accuracy: 0.5183 - val_loss: 0.9700 - val_accuracy: 0.5395\n",
      "Epoch 10/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9877 - accuracy: 0.5214 - val_loss: 0.9640 - val_accuracy: 0.5299\n",
      "Epoch 11/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9879 - accuracy: 0.5208 - val_loss: 0.9632 - val_accuracy: 0.5299\n",
      "Epoch 12/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9889 - accuracy: 0.5185 - val_loss: 0.9803 - val_accuracy: 0.5267\n",
      "Epoch 13/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9888 - accuracy: 0.5199 - val_loss: 0.9638 - val_accuracy: 0.5290\n",
      "Epoch 14/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9847 - accuracy: 0.5250 - val_loss: 0.9721 - val_accuracy: 0.5276\n",
      "Epoch 15/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9862 - accuracy: 0.5190 - val_loss: 0.9923 - val_accuracy: 0.5276\n",
      "Epoch 16/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9852 - accuracy: 0.5231 - val_loss: 0.9700 - val_accuracy: 0.5018\n",
      "Epoch 17/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9851 - accuracy: 0.5197 - val_loss: 0.9696 - val_accuracy: 0.5358\n",
      "Epoch 18/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9845 - accuracy: 0.5244 - val_loss: 0.9632 - val_accuracy: 0.5276\n",
      "Epoch 19/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9845 - accuracy: 0.5230 - val_loss: 0.9580 - val_accuracy: 0.5290\n",
      "Epoch 20/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9859 - accuracy: 0.5224 - val_loss: 0.9610 - val_accuracy: 0.5317\n",
      "Epoch 21/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9844 - accuracy: 0.5253 - val_loss: 0.9735 - val_accuracy: 0.5340\n",
      "Epoch 22/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9842 - accuracy: 0.5244 - val_loss: 0.9620 - val_accuracy: 0.5303\n",
      "Epoch 23/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9844 - accuracy: 0.5257 - val_loss: 0.9753 - val_accuracy: 0.5239\n",
      "Epoch 24/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9852 - accuracy: 0.5264 - val_loss: 0.9593 - val_accuracy: 0.5340\n",
      "Epoch 25/200\n",
      "613/613 [==============================] - 0s 591us/step - loss: 0.9856 - accuracy: 0.5217 - val_loss: 0.9602 - val_accuracy: 0.5221\n",
      "Epoch 26/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9843 - accuracy: 0.5234 - val_loss: 0.9604 - val_accuracy: 0.5345\n",
      "Epoch 27/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9852 - accuracy: 0.5225 - val_loss: 0.9670 - val_accuracy: 0.5046\n",
      "Epoch 28/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9850 - accuracy: 0.5215 - val_loss: 0.9598 - val_accuracy: 0.5317\n",
      "Epoch 29/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9841 - accuracy: 0.5215 - val_loss: 0.9692 - val_accuracy: 0.5326\n",
      "Epoch 30/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9837 - accuracy: 0.5232 - val_loss: 0.9660 - val_accuracy: 0.5299\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 560us/step - loss: 0.9839 - accuracy: 0.5254 - val_loss: 0.9588 - val_accuracy: 0.5331\n",
      "Epoch 32/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9843 - accuracy: 0.5235 - val_loss: 0.9700 - val_accuracy: 0.5244\n",
      "Epoch 33/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9856 - accuracy: 0.5225 - val_loss: 0.9716 - val_accuracy: 0.5345\n",
      "Epoch 34/200\n",
      "613/613 [==============================] - 0s 554us/step - loss: 0.9862 - accuracy: 0.5202 - val_loss: 0.9657 - val_accuracy: 0.5299\n",
      "Epoch 35/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9863 - accuracy: 0.5216 - val_loss: 0.9608 - val_accuracy: 0.5345\n",
      "Epoch 36/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9836 - accuracy: 0.5213 - val_loss: 0.9610 - val_accuracy: 0.5312\n",
      "Epoch 37/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9855 - accuracy: 0.5241 - val_loss: 0.9608 - val_accuracy: 0.5276\n",
      "Epoch 38/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9831 - accuracy: 0.5192 - val_loss: 0.9647 - val_accuracy: 0.5308\n",
      "Epoch 39/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9854 - accuracy: 0.5215 - val_loss: 0.9598 - val_accuracy: 0.5404\n",
      "Epoch 40/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9832 - accuracy: 0.5201 - val_loss: 0.9611 - val_accuracy: 0.5290\n",
      "Epoch 41/200\n",
      "613/613 [==============================] - 0s 598us/step - loss: 0.9851 - accuracy: 0.5244 - val_loss: 0.9622 - val_accuracy: 0.5349\n",
      "Epoch 42/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9848 - accuracy: 0.5217 - val_loss: 0.9648 - val_accuracy: 0.5303\n",
      "Epoch 43/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9855 - accuracy: 0.5240 - val_loss: 0.9611 - val_accuracy: 0.5340\n",
      "Epoch 44/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9835 - accuracy: 0.5262 - val_loss: 0.9646 - val_accuracy: 0.5322\n",
      "Epoch 45/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9830 - accuracy: 0.5269 - val_loss: 0.9591 - val_accuracy: 0.5358\n",
      "Epoch 46/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9857 - accuracy: 0.5240 - val_loss: 0.9678 - val_accuracy: 0.5312\n",
      "Epoch 47/200\n",
      "613/613 [==============================] - 0s 558us/step - loss: 0.9827 - accuracy: 0.5258 - val_loss: 0.9591 - val_accuracy: 0.5349\n",
      "Epoch 48/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9838 - accuracy: 0.5248 - val_loss: 0.9588 - val_accuracy: 0.5303\n",
      "Epoch 49/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9825 - accuracy: 0.5268 - val_loss: 0.9617 - val_accuracy: 0.5340\n",
      "Epoch 50/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9831 - accuracy: 0.5252 - val_loss: 0.9604 - val_accuracy: 0.5276\n",
      "Epoch 51/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9827 - accuracy: 0.5255 - val_loss: 0.9632 - val_accuracy: 0.5331\n",
      "Epoch 52/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9820 - accuracy: 0.5263 - val_loss: 0.9633 - val_accuracy: 0.5340\n",
      "Epoch 53/200\n",
      "613/613 [==============================] - 0s 559us/step - loss: 0.9803 - accuracy: 0.5259 - val_loss: 0.9620 - val_accuracy: 0.5326\n",
      "Epoch 54/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9823 - accuracy: 0.5283 - val_loss: 0.9643 - val_accuracy: 0.5322\n",
      "Epoch 55/200\n",
      "613/613 [==============================] - 0s 534us/step - loss: 0.9826 - accuracy: 0.5256 - val_loss: 0.9590 - val_accuracy: 0.5331\n",
      "Epoch 56/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9834 - accuracy: 0.5245 - val_loss: 0.9604 - val_accuracy: 0.5345\n",
      "Epoch 57/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9830 - accuracy: 0.5255 - val_loss: 0.9725 - val_accuracy: 0.5317\n",
      "Epoch 58/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9827 - accuracy: 0.5257 - val_loss: 0.9556 - val_accuracy: 0.5326\n",
      "Epoch 59/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9829 - accuracy: 0.5273 - val_loss: 0.9605 - val_accuracy: 0.5322\n",
      "Epoch 60/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9822 - accuracy: 0.5253 - val_loss: 0.9619 - val_accuracy: 0.5331\n",
      "Epoch 61/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9820 - accuracy: 0.5266 - val_loss: 0.9668 - val_accuracy: 0.5349\n",
      "Epoch 62/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9809 - accuracy: 0.5270 - val_loss: 0.9581 - val_accuracy: 0.5317\n",
      "Epoch 63/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9822 - accuracy: 0.5263 - val_loss: 0.9591 - val_accuracy: 0.5326\n",
      "Epoch 64/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9817 - accuracy: 0.5252 - val_loss: 0.9621 - val_accuracy: 0.5322\n",
      "Epoch 65/200\n",
      "613/613 [==============================] - 0s 585us/step - loss: 0.9826 - accuracy: 0.5269 - val_loss: 0.9645 - val_accuracy: 0.5303\n",
      "Epoch 66/200\n",
      "613/613 [==============================] - 0s 589us/step - loss: 0.9827 - accuracy: 0.5263 - val_loss: 0.9638 - val_accuracy: 0.5331\n",
      "Epoch 67/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9851 - accuracy: 0.5264 - val_loss: 0.9644 - val_accuracy: 0.5326\n",
      "Epoch 68/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9829 - accuracy: 0.5258 - val_loss: 0.9645 - val_accuracy: 0.5326\n",
      "Epoch 69/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9816 - accuracy: 0.5281 - val_loss: 0.9575 - val_accuracy: 0.5326\n",
      "Epoch 70/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9833 - accuracy: 0.5239 - val_loss: 0.9607 - val_accuracy: 0.5335\n",
      "Epoch 71/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9825 - accuracy: 0.5221 - val_loss: 0.9608 - val_accuracy: 0.5381\n",
      "Epoch 72/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9831 - accuracy: 0.5223 - val_loss: 0.9748 - val_accuracy: 0.5248\n",
      "Epoch 73/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9820 - accuracy: 0.5292 - val_loss: 0.9654 - val_accuracy: 0.5308\n",
      "Epoch 74/200\n",
      "613/613 [==============================] - 0s 582us/step - loss: 0.9814 - accuracy: 0.5269 - val_loss: 0.9608 - val_accuracy: 0.5308\n",
      "Epoch 75/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9824 - accuracy: 0.5247 - val_loss: 0.9586 - val_accuracy: 0.5303\n",
      "Epoch 76/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9820 - accuracy: 0.5269 - val_loss: 0.9603 - val_accuracy: 0.5299\n",
      "Epoch 77/200\n",
      "613/613 [==============================] - 0s 579us/step - loss: 0.9813 - accuracy: 0.5242 - val_loss: 0.9563 - val_accuracy: 0.5303\n",
      "Epoch 78/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9817 - accuracy: 0.5272 - val_loss: 0.9607 - val_accuracy: 0.5308\n",
      "Epoch 79/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9818 - accuracy: 0.5241 - val_loss: 0.9569 - val_accuracy: 0.5354\n",
      "Epoch 80/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9811 - accuracy: 0.5271 - val_loss: 0.9623 - val_accuracy: 0.5317\n",
      "Epoch 81/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9819 - accuracy: 0.5286 - val_loss: 0.9625 - val_accuracy: 0.5317\n",
      "Epoch 82/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9819 - accuracy: 0.5284 - val_loss: 0.9581 - val_accuracy: 0.5322\n",
      "Epoch 83/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9819 - accuracy: 0.5280 - val_loss: 0.9560 - val_accuracy: 0.5317\n",
      "Epoch 84/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9810 - accuracy: 0.5282 - val_loss: 0.9606 - val_accuracy: 0.5317\n",
      "Epoch 85/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9816 - accuracy: 0.5263 - val_loss: 0.9543 - val_accuracy: 0.5285\n",
      "Epoch 86/200\n",
      "613/613 [==============================] - 0s 614us/step - loss: 0.9812 - accuracy: 0.5260 - val_loss: 0.9583 - val_accuracy: 0.5331\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613/613 [==============================] - 0s 579us/step - loss: 0.9814 - accuracy: 0.5264 - val_loss: 0.9695 - val_accuracy: 0.5317\n",
      "Epoch 88/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9818 - accuracy: 0.5259 - val_loss: 0.9578 - val_accuracy: 0.5303\n",
      "Epoch 89/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9848 - accuracy: 0.5204 - val_loss: 0.9624 - val_accuracy: 0.5207\n",
      "Epoch 90/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9830 - accuracy: 0.5254 - val_loss: 0.9620 - val_accuracy: 0.5303\n",
      "Epoch 91/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9809 - accuracy: 0.5242 - val_loss: 0.9633 - val_accuracy: 0.5290\n",
      "Epoch 92/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9825 - accuracy: 0.5258 - val_loss: 0.9600 - val_accuracy: 0.5354\n",
      "Epoch 93/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9810 - accuracy: 0.5284 - val_loss: 0.9642 - val_accuracy: 0.5340\n",
      "Epoch 94/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9808 - accuracy: 0.5243 - val_loss: 0.9589 - val_accuracy: 0.5308\n",
      "Epoch 95/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9820 - accuracy: 0.5274 - val_loss: 0.9600 - val_accuracy: 0.5317\n",
      "Epoch 96/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9807 - accuracy: 0.5273 - val_loss: 0.9661 - val_accuracy: 0.5335\n",
      "Epoch 97/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9814 - accuracy: 0.5274 - val_loss: 0.9603 - val_accuracy: 0.5326\n",
      "Epoch 98/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9824 - accuracy: 0.5263 - val_loss: 0.9567 - val_accuracy: 0.5349\n",
      "Epoch 99/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9815 - accuracy: 0.5289 - val_loss: 0.9636 - val_accuracy: 0.5009\n",
      "Epoch 100/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9814 - accuracy: 0.5254 - val_loss: 0.9636 - val_accuracy: 0.5317\n",
      "Epoch 101/200\n",
      "613/613 [==============================] - 0s 551us/step - loss: 0.9809 - accuracy: 0.5290 - val_loss: 0.9600 - val_accuracy: 0.5322\n",
      "Epoch 102/200\n",
      "613/613 [==============================] - 0s 584us/step - loss: 0.9818 - accuracy: 0.5260 - val_loss: 0.9591 - val_accuracy: 0.5345\n",
      "Epoch 103/200\n",
      "613/613 [==============================] - 0s 581us/step - loss: 0.9808 - accuracy: 0.5289 - val_loss: 0.9580 - val_accuracy: 0.5290\n",
      "Epoch 104/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 0.9813 - accuracy: 0.5261 - val_loss: 0.9579 - val_accuracy: 0.5317\n",
      "Epoch 105/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9806 - accuracy: 0.5267 - val_loss: 0.9573 - val_accuracy: 0.5285\n",
      "Epoch 106/200\n",
      "613/613 [==============================] - 0s 585us/step - loss: 0.9821 - accuracy: 0.5257 - val_loss: 0.9583 - val_accuracy: 0.5326\n",
      "Epoch 107/200\n",
      "613/613 [==============================] - 0s 545us/step - loss: 0.9798 - accuracy: 0.5290 - val_loss: 0.9583 - val_accuracy: 0.5312\n",
      "Epoch 108/200\n",
      "613/613 [==============================] - 0s 582us/step - loss: 0.9809 - accuracy: 0.5266 - val_loss: 0.9564 - val_accuracy: 0.5303\n",
      "Epoch 109/200\n",
      "613/613 [==============================] - 0s 584us/step - loss: 0.9807 - accuracy: 0.5261 - val_loss: 0.9563 - val_accuracy: 0.5354\n",
      "Epoch 110/200\n",
      "613/613 [==============================] - 0s 639us/step - loss: 0.9803 - accuracy: 0.5273 - val_loss: 0.9598 - val_accuracy: 0.5322\n",
      "Epoch 111/200\n",
      "613/613 [==============================] - 0s 582us/step - loss: 0.9802 - accuracy: 0.5266 - val_loss: 0.9557 - val_accuracy: 0.5358\n",
      "Epoch 112/200\n",
      "613/613 [==============================] - 0s 586us/step - loss: 0.9822 - accuracy: 0.5263 - val_loss: 0.9575 - val_accuracy: 0.5303\n",
      "Epoch 113/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9814 - accuracy: 0.5253 - val_loss: 0.9655 - val_accuracy: 0.5312\n",
      "Epoch 114/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9809 - accuracy: 0.5283 - val_loss: 0.9586 - val_accuracy: 0.5294\n",
      "Epoch 115/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9806 - accuracy: 0.5265 - val_loss: 0.9536 - val_accuracy: 0.5322\n",
      "Epoch 116/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9819 - accuracy: 0.5251 - val_loss: 0.9676 - val_accuracy: 0.5335\n",
      "Epoch 117/200\n",
      "613/613 [==============================] - 0s 545us/step - loss: 0.9822 - accuracy: 0.5246 - val_loss: 0.9597 - val_accuracy: 0.5290\n",
      "Epoch 118/200\n",
      "613/613 [==============================] - 0s 569us/step - loss: 0.9810 - accuracy: 0.5243 - val_loss: 0.9583 - val_accuracy: 0.5322\n",
      "Epoch 119/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9809 - accuracy: 0.5268 - val_loss: 0.9662 - val_accuracy: 0.5335\n",
      "Epoch 120/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9824 - accuracy: 0.5244 - val_loss: 0.9593 - val_accuracy: 0.5340\n",
      "Epoch 121/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9809 - accuracy: 0.5266 - val_loss: 0.9573 - val_accuracy: 0.5345\n",
      "Epoch 122/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9806 - accuracy: 0.5273 - val_loss: 0.9656 - val_accuracy: 0.5358\n",
      "Epoch 123/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9797 - accuracy: 0.5296 - val_loss: 0.9592 - val_accuracy: 0.5331\n",
      "Epoch 124/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9817 - accuracy: 0.5258 - val_loss: 0.9581 - val_accuracy: 0.5349\n",
      "Epoch 125/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9800 - accuracy: 0.5277 - val_loss: 0.9579 - val_accuracy: 0.5299\n",
      "Epoch 126/200\n",
      "613/613 [==============================] - 0s 587us/step - loss: 0.9794 - accuracy: 0.5285 - val_loss: 0.9608 - val_accuracy: 0.5340\n",
      "Epoch 127/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9812 - accuracy: 0.5290 - val_loss: 0.9576 - val_accuracy: 0.5179\n",
      "Epoch 128/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9809 - accuracy: 0.5260 - val_loss: 0.9562 - val_accuracy: 0.5322\n",
      "Epoch 129/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9800 - accuracy: 0.5273 - val_loss: 0.9593 - val_accuracy: 0.5322\n",
      "Epoch 130/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9804 - accuracy: 0.5256 - val_loss: 0.9604 - val_accuracy: 0.5317\n",
      "Epoch 131/200\n",
      "613/613 [==============================] - 0s 597us/step - loss: 0.9808 - accuracy: 0.5270 - val_loss: 0.9652 - val_accuracy: 0.5331\n",
      "Epoch 132/200\n",
      "613/613 [==============================] - 0s 585us/step - loss: 0.9813 - accuracy: 0.5255 - val_loss: 0.9602 - val_accuracy: 0.5345\n",
      "Epoch 133/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9804 - accuracy: 0.5225 - val_loss: 0.9577 - val_accuracy: 0.5331\n",
      "Epoch 134/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9812 - accuracy: 0.5283 - val_loss: 0.9587 - val_accuracy: 0.5326\n",
      "Epoch 135/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9798 - accuracy: 0.5271 - val_loss: 0.9576 - val_accuracy: 0.5331\n",
      "Epoch 136/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9809 - accuracy: 0.5262 - val_loss: 0.9603 - val_accuracy: 0.5294\n",
      "Epoch 137/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9812 - accuracy: 0.5251 - val_loss: 0.9576 - val_accuracy: 0.5345\n",
      "Epoch 138/200\n",
      "613/613 [==============================] - 0s 581us/step - loss: 0.9818 - accuracy: 0.5254 - val_loss: 0.9696 - val_accuracy: 0.5312\n",
      "Epoch 139/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9823 - accuracy: 0.5254 - val_loss: 0.9542 - val_accuracy: 0.5294\n",
      "Epoch 140/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9798 - accuracy: 0.5280 - val_loss: 0.9613 - val_accuracy: 0.5326\n",
      "Epoch 141/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9792 - accuracy: 0.5298 - val_loss: 0.9624 - val_accuracy: 0.5326\n",
      "Epoch 142/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9805 - accuracy: 0.5274 - val_loss: 0.9609 - val_accuracy: 0.5326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9818 - accuracy: 0.5278 - val_loss: 0.9598 - val_accuracy: 0.5368\n",
      "Epoch 144/200\n",
      "613/613 [==============================] - 0s 578us/step - loss: 0.9800 - accuracy: 0.5261 - val_loss: 0.9590 - val_accuracy: 0.5331\n",
      "Epoch 145/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9823 - accuracy: 0.5216 - val_loss: 0.9582 - val_accuracy: 0.5331\n",
      "Epoch 146/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9804 - accuracy: 0.5268 - val_loss: 0.9591 - val_accuracy: 0.5331\n",
      "Epoch 147/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9814 - accuracy: 0.5233 - val_loss: 0.9585 - val_accuracy: 0.5331\n",
      "Epoch 148/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9806 - accuracy: 0.5250 - val_loss: 0.9576 - val_accuracy: 0.5308\n",
      "Epoch 149/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9803 - accuracy: 0.5301 - val_loss: 0.9645 - val_accuracy: 0.5322\n",
      "Epoch 150/200\n",
      "613/613 [==============================] - 0s 553us/step - loss: 0.9827 - accuracy: 0.5278 - val_loss: 0.9636 - val_accuracy: 0.5331\n",
      "Epoch 151/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9808 - accuracy: 0.5271 - val_loss: 0.9646 - val_accuracy: 0.5322\n",
      "Epoch 152/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9799 - accuracy: 0.5292 - val_loss: 0.9650 - val_accuracy: 0.5299\n",
      "Epoch 153/200\n",
      "613/613 [==============================] - 0s 588us/step - loss: 0.9811 - accuracy: 0.5264 - val_loss: 0.9618 - val_accuracy: 0.5331\n",
      "Epoch 154/200\n",
      "613/613 [==============================] - 0s 541us/step - loss: 0.9800 - accuracy: 0.5291 - val_loss: 0.9650 - val_accuracy: 0.5322\n",
      "Epoch 155/200\n",
      "613/613 [==============================] - 0s 583us/step - loss: 0.9811 - accuracy: 0.5284 - val_loss: 0.9632 - val_accuracy: 0.5340\n",
      "Epoch 156/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9811 - accuracy: 0.5270 - val_loss: 0.9595 - val_accuracy: 0.5317\n",
      "Epoch 157/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9813 - accuracy: 0.5302 - val_loss: 0.9632 - val_accuracy: 0.5340\n",
      "Epoch 158/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9810 - accuracy: 0.5248 - val_loss: 0.9564 - val_accuracy: 0.5312\n",
      "Epoch 159/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9801 - accuracy: 0.5277 - val_loss: 0.9587 - val_accuracy: 0.5322\n",
      "Epoch 160/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9806 - accuracy: 0.5267 - val_loss: 0.9591 - val_accuracy: 0.5349\n",
      "Epoch 161/200\n",
      "613/613 [==============================] - 0s 562us/step - loss: 0.9803 - accuracy: 0.5259 - val_loss: 0.9584 - val_accuracy: 0.5322\n",
      "Epoch 162/200\n",
      "613/613 [==============================] - 0s 566us/step - loss: 0.9790 - accuracy: 0.5279 - val_loss: 0.9592 - val_accuracy: 0.5299\n",
      "Epoch 163/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9806 - accuracy: 0.5280 - val_loss: 0.9573 - val_accuracy: 0.5317\n",
      "Epoch 164/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9810 - accuracy: 0.5278 - val_loss: 0.9610 - val_accuracy: 0.5326\n",
      "Epoch 165/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9807 - accuracy: 0.5274 - val_loss: 0.9542 - val_accuracy: 0.5331\n",
      "Epoch 166/200\n",
      "613/613 [==============================] - 0s 564us/step - loss: 0.9804 - accuracy: 0.5274 - val_loss: 0.9567 - val_accuracy: 0.5331\n",
      "Epoch 167/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9807 - accuracy: 0.5281 - val_loss: 0.9590 - val_accuracy: 0.5317\n",
      "Epoch 168/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9813 - accuracy: 0.5280 - val_loss: 0.9590 - val_accuracy: 0.5294\n",
      "Epoch 169/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9800 - accuracy: 0.5273 - val_loss: 0.9559 - val_accuracy: 0.5308\n",
      "Epoch 170/200\n",
      "613/613 [==============================] - 0s 574us/step - loss: 0.9797 - accuracy: 0.5271 - val_loss: 0.9570 - val_accuracy: 0.5331\n",
      "Epoch 171/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9801 - accuracy: 0.5286 - val_loss: 0.9605 - val_accuracy: 0.5299\n",
      "Epoch 172/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9800 - accuracy: 0.5279 - val_loss: 0.9580 - val_accuracy: 0.5335\n",
      "Epoch 173/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9799 - accuracy: 0.5252 - val_loss: 0.9569 - val_accuracy: 0.5294\n",
      "Epoch 174/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9803 - accuracy: 0.5265 - val_loss: 0.9582 - val_accuracy: 0.5345\n",
      "Epoch 175/200\n",
      "613/613 [==============================] - 0s 577us/step - loss: 0.9802 - accuracy: 0.5286 - val_loss: 0.9563 - val_accuracy: 0.5312\n",
      "Epoch 176/200\n",
      "613/613 [==============================] - 0s 604us/step - loss: 0.9790 - accuracy: 0.5308 - val_loss: 0.9636 - val_accuracy: 0.5303\n",
      "Epoch 177/200\n",
      "613/613 [==============================] - 0s 599us/step - loss: 0.9801 - accuracy: 0.5287 - val_loss: 0.9557 - val_accuracy: 0.5290\n",
      "Epoch 178/200\n",
      "613/613 [==============================] - 0s 586us/step - loss: 0.9796 - accuracy: 0.5273 - val_loss: 0.9593 - val_accuracy: 0.5253\n",
      "Epoch 179/200\n",
      "613/613 [==============================] - 0s 585us/step - loss: 0.9809 - accuracy: 0.5261 - val_loss: 0.9607 - val_accuracy: 0.5345\n",
      "Epoch 180/200\n",
      "613/613 [==============================] - 0s 575us/step - loss: 0.9813 - accuracy: 0.5275 - val_loss: 0.9569 - val_accuracy: 0.5317\n",
      "Epoch 181/200\n",
      "613/613 [==============================] - 0s 571us/step - loss: 0.9799 - accuracy: 0.5274 - val_loss: 0.9553 - val_accuracy: 0.5331\n",
      "Epoch 182/200\n",
      "613/613 [==============================] - 0s 572us/step - loss: 0.9801 - accuracy: 0.5289 - val_loss: 0.9600 - val_accuracy: 0.5317\n",
      "Epoch 183/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9802 - accuracy: 0.5286 - val_loss: 0.9597 - val_accuracy: 0.5335\n",
      "Epoch 184/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9805 - accuracy: 0.5295 - val_loss: 0.9596 - val_accuracy: 0.5340\n",
      "Epoch 185/200\n",
      "613/613 [==============================] - 0s 576us/step - loss: 0.9793 - accuracy: 0.5277 - val_loss: 0.9560 - val_accuracy: 0.5335\n",
      "Epoch 186/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9800 - accuracy: 0.5278 - val_loss: 0.9602 - val_accuracy: 0.5335\n",
      "Epoch 187/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9802 - accuracy: 0.5247 - val_loss: 0.9602 - val_accuracy: 0.5276\n",
      "Epoch 188/200\n",
      "613/613 [==============================] - 0s 573us/step - loss: 0.9800 - accuracy: 0.5274 - val_loss: 0.9589 - val_accuracy: 0.5303\n",
      "Epoch 189/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9797 - accuracy: 0.5294 - val_loss: 0.9599 - val_accuracy: 0.5285\n",
      "Epoch 190/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9795 - accuracy: 0.5281 - val_loss: 0.9626 - val_accuracy: 0.5331\n",
      "Epoch 191/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9798 - accuracy: 0.5282 - val_loss: 0.9586 - val_accuracy: 0.5326\n",
      "Epoch 192/200\n",
      "613/613 [==============================] - 0s 570us/step - loss: 0.9804 - accuracy: 0.5287 - val_loss: 0.9584 - val_accuracy: 0.5363\n",
      "Epoch 193/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9790 - accuracy: 0.5295 - val_loss: 0.9612 - val_accuracy: 0.5303\n",
      "Epoch 194/200\n",
      "613/613 [==============================] - 0s 565us/step - loss: 0.9802 - accuracy: 0.5298 - val_loss: 0.9615 - val_accuracy: 0.5354\n",
      "Epoch 195/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9801 - accuracy: 0.5267 - val_loss: 0.9566 - val_accuracy: 0.5340\n",
      "Epoch 196/200\n",
      "613/613 [==============================] - 0s 560us/step - loss: 0.9808 - accuracy: 0.5273 - val_loss: 0.9613 - val_accuracy: 0.5312\n",
      "Epoch 197/200\n",
      "613/613 [==============================] - 0s 567us/step - loss: 0.9808 - accuracy: 0.5283 - val_loss: 0.9579 - val_accuracy: 0.5331\n",
      "Epoch 198/200\n",
      "613/613 [==============================] - 0s 561us/step - loss: 0.9801 - accuracy: 0.5285 - val_loss: 0.9591 - val_accuracy: 0.5340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200\n",
      "613/613 [==============================] - 0s 563us/step - loss: 0.9804 - accuracy: 0.5296 - val_loss: 0.9602 - val_accuracy: 0.5331\n",
      "Epoch 200/200\n",
      "613/613 [==============================] - 0s 568us/step - loss: 0.9803 - accuracy: 0.5273 - val_loss: 0.9625 - val_accuracy: 0.5303\n",
      "\n",
      "Train split:\n",
      "613/613 [==============================] - 0s 591us/step - loss: 0.9845 - accuracy: 0.5266\n",
      "Accuracy : 0.5265764594078064\n",
      "\n",
      "Test split:\n",
      "68/68 - 0s - loss: 0.9625 - accuracy: 0.5303\n",
      "Accuracy : 0.5303308963775635\n",
      "\n",
      "The final train accuracy is:0.5289585411548614 \n",
      "\n",
      "The final test accuracy is:0.5265382826328278 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data_3.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data = np.array(df.iloc[:,0:28])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "    \n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "    \n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (28,1)),\n",
    "        keras.layers.Dense(28,activation='sigmoid'),\n",
    "        keras.layers.Dense(28,activation='sigmoid'),\n",
    "        keras.layers.Dense(3,activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confident-invalid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "promising-nursing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legal-jersey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-closer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
