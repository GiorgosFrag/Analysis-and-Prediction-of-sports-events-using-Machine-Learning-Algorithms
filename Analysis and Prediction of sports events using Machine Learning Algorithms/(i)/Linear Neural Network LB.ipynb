{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heated-singing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1.7813 - accuracy: 0.3803 - val_loss: 1.6377 - val_accuracy: 0.3504\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 651us/step - loss: 1.5306 - accuracy: 0.3355 - val_loss: 1.4195 - val_accuracy: 0.3314\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 1.3337 - accuracy: 0.3483 - val_loss: 1.2535 - val_accuracy: 0.3558\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.1967 - accuracy: 0.3887 - val_loss: 1.1502 - val_accuracy: 0.4146\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.1171 - accuracy: 0.4544 - val_loss: 1.0908 - val_accuracy: 0.4929\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 1.0685 - accuracy: 0.5190 - val_loss: 1.0524 - val_accuracy: 0.5150\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 1.0343 - accuracy: 0.5309 - val_loss: 1.0264 - val_accuracy: 0.5261\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0114 - accuracy: 0.5313 - val_loss: 1.0113 - val_accuracy: 0.5288\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9988 - accuracy: 0.5299 - val_loss: 1.0028 - val_accuracy: 0.5279\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9920 - accuracy: 0.5290 - val_loss: 0.9981 - val_accuracy: 0.5279\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9880 - accuracy: 0.5294 - val_loss: 0.9951 - val_accuracy: 0.5274\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9855 - accuracy: 0.5295 - val_loss: 0.9932 - val_accuracy: 0.5274\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9840 - accuracy: 0.5290 - val_loss: 0.9920 - val_accuracy: 0.5274\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9828 - accuracy: 0.5300 - val_loss: 0.9911 - val_accuracy: 0.5279\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9820 - accuracy: 0.5300 - val_loss: 0.9906 - val_accuracy: 0.5257\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9814 - accuracy: 0.5301 - val_loss: 0.9901 - val_accuracy: 0.5257\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9808 - accuracy: 0.5304 - val_loss: 0.9898 - val_accuracy: 0.5257\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 578us/step - loss: 0.9804 - accuracy: 0.5299 - val_loss: 0.9894 - val_accuracy: 0.5181\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9800 - accuracy: 0.5307 - val_loss: 0.9892 - val_accuracy: 0.5150\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9796 - accuracy: 0.5312 - val_loss: 0.9889 - val_accuracy: 0.5164\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9792 - accuracy: 0.5309 - val_loss: 0.9887 - val_accuracy: 0.5159\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9789 - accuracy: 0.5311 - val_loss: 0.9885 - val_accuracy: 0.5164\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9787 - accuracy: 0.5312 - val_loss: 0.9884 - val_accuracy: 0.5159\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9783 - accuracy: 0.5312 - val_loss: 0.9882 - val_accuracy: 0.5150\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9780 - accuracy: 0.5319 - val_loss: 0.9881 - val_accuracy: 0.5159\n",
      "Epoch 26/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9779 - accuracy: 0.5313 - val_loss: 0.9880 - val_accuracy: 0.5142\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9776 - accuracy: 0.5312 - val_loss: 0.9878 - val_accuracy: 0.5155\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9774 - accuracy: 0.5316 - val_loss: 0.9877 - val_accuracy: 0.5164\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9772 - accuracy: 0.5311 - val_loss: 0.9875 - val_accuracy: 0.5150\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9770 - accuracy: 0.5303 - val_loss: 0.9875 - val_accuracy: 0.5150\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9768 - accuracy: 0.5316 - val_loss: 0.9873 - val_accuracy: 0.5150\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9766 - accuracy: 0.5309 - val_loss: 0.9875 - val_accuracy: 0.5133\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9766 - accuracy: 0.5306 - val_loss: 0.9874 - val_accuracy: 0.5137\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9764 - accuracy: 0.5310 - val_loss: 0.9873 - val_accuracy: 0.5150\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9762 - accuracy: 0.5317 - val_loss: 0.9872 - val_accuracy: 0.5124\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9762 - accuracy: 0.5307 - val_loss: 0.9873 - val_accuracy: 0.5128\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9760 - accuracy: 0.5304 - val_loss: 0.9871 - val_accuracy: 0.5128\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9760 - accuracy: 0.5300 - val_loss: 0.9869 - val_accuracy: 0.5142\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9759 - accuracy: 0.5307 - val_loss: 0.9869 - val_accuracy: 0.5133\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9758 - accuracy: 0.5304 - val_loss: 0.9869 - val_accuracy: 0.5124\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9758 - accuracy: 0.5307 - val_loss: 0.9870 - val_accuracy: 0.5142\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5305 - val_loss: 0.9868 - val_accuracy: 0.5142\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9868 - val_accuracy: 0.5128\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9756 - accuracy: 0.5306 - val_loss: 0.9867 - val_accuracy: 0.5137\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9754 - accuracy: 0.5305 - val_loss: 0.9868 - val_accuracy: 0.5128\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9754 - accuracy: 0.5303 - val_loss: 0.9867 - val_accuracy: 0.5142\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9754 - accuracy: 0.5299 - val_loss: 0.9867 - val_accuracy: 0.5133\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9753 - accuracy: 0.5302 - val_loss: 0.9866 - val_accuracy: 0.5137\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9754 - accuracy: 0.5304 - val_loss: 0.9867 - val_accuracy: 0.5106\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9753 - accuracy: 0.5304 - val_loss: 0.9866 - val_accuracy: 0.5124\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9866 - val_accuracy: 0.5142\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9751 - accuracy: 0.5314 - val_loss: 0.9868 - val_accuracy: 0.5097\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9866 - val_accuracy: 0.5124\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9752 - accuracy: 0.5305 - val_loss: 0.9865 - val_accuracy: 0.5133\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9752 - accuracy: 0.5310 - val_loss: 0.9867 - val_accuracy: 0.5097\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 0.9868 - val_accuracy: 0.5155\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9752 - accuracy: 0.5313 - val_loss: 0.9865 - val_accuracy: 0.5133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9865 - val_accuracy: 0.5128\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9751 - accuracy: 0.5304 - val_loss: 0.9866 - val_accuracy: 0.5124\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9750 - accuracy: 0.5304 - val_loss: 0.9866 - val_accuracy: 0.5133\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9750 - accuracy: 0.5308 - val_loss: 0.9866 - val_accuracy: 0.5102\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9866 - val_accuracy: 0.5102\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9750 - accuracy: 0.5309 - val_loss: 0.9865 - val_accuracy: 0.5133\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 586us/step - loss: 0.9749 - accuracy: 0.5306 - val_loss: 0.9867 - val_accuracy: 0.5155\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9865 - val_accuracy: 0.5142\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 0.9865 - val_accuracy: 0.5137\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9865 - val_accuracy: 0.5128\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 595us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9864 - val_accuracy: 0.5133\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 575us/step - loss: 0.9748 - accuracy: 0.5302 - val_loss: 0.9865 - val_accuracy: 0.5142\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 0.9864 - val_accuracy: 0.5142\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9747 - accuracy: 0.5314 - val_loss: 0.9864 - val_accuracy: 0.5102\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 608us/step - loss: 0.9747 - accuracy: 0.5304 - val_loss: 0.9865 - val_accuracy: 0.5128\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 616us/step - loss: 0.9747 - accuracy: 0.5317 - val_loss: 0.9865 - val_accuracy: 0.5102\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 532us/step - loss: 0.9748 - accuracy: 0.5304 - val_loss: 0.9863 - val_accuracy: 0.5128\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 623us/step - loss: 0.9747 - accuracy: 0.5306 - val_loss: 0.9864 - val_accuracy: 0.5128\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 639us/step - loss: 0.9748 - accuracy: 0.5308 - val_loss: 0.9865 - val_accuracy: 0.5102\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 582us/step - loss: 0.9747 - accuracy: 0.5302 - val_loss: 0.9864 - val_accuracy: 0.5137\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 634us/step - loss: 0.9747 - accuracy: 0.5306 - val_loss: 0.9864 - val_accuracy: 0.5142\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9863 - val_accuracy: 0.5159\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9746 - accuracy: 0.5305 - val_loss: 0.9864 - val_accuracy: 0.5159\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9746 - accuracy: 0.5307 - val_loss: 0.9863 - val_accuracy: 0.5133\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 568us/step - loss: 0.9747 - accuracy: 0.5304 - val_loss: 0.9863 - val_accuracy: 0.5142\n",
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9746 - accuracy: 0.5309 - val_loss: 0.9862 - val_accuracy: 0.5142\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9745 - accuracy: 0.5304 - val_loss: 0.9863 - val_accuracy: 0.5133\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 448us/step - loss: 0.9746 - accuracy: 0.5310 - val_loss: 0.9863 - val_accuracy: 0.5133\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 656us/step - loss: 0.9745 - accuracy: 0.5314 - val_loss: 0.9863 - val_accuracy: 0.5142\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 420us/step - loss: 0.9745 - accuracy: 0.5303 - val_loss: 0.9865 - val_accuracy: 0.5128\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 694us/step - loss: 0.9745 - accuracy: 0.5311 - val_loss: 0.9862 - val_accuracy: 0.5159\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 575us/step - loss: 0.9745 - accuracy: 0.5315 - val_loss: 0.9862 - val_accuracy: 0.5159\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 570us/step - loss: 0.9745 - accuracy: 0.5317 - val_loss: 0.9862 - val_accuracy: 0.5159\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9743 - accuracy: 0.5316 - val_loss: 0.9863 - val_accuracy: 0.5128\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 529us/step - loss: 0.9744 - accuracy: 0.5307 - val_loss: 0.9863 - val_accuracy: 0.5133\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 524us/step - loss: 0.9743 - accuracy: 0.5311 - val_loss: 0.9862 - val_accuracy: 0.5159\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9744 - accuracy: 0.5309 - val_loss: 0.9863 - val_accuracy: 0.5159\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 676us/step - loss: 0.9743 - accuracy: 0.5305 - val_loss: 0.9864 - val_accuracy: 0.5137\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 584us/step - loss: 0.9744 - accuracy: 0.5312 - val_loss: 0.9864 - val_accuracy: 0.5142\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 579us/step - loss: 0.9743 - accuracy: 0.5304 - val_loss: 0.9863 - val_accuracy: 0.5137\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9745 - accuracy: 0.5309 - val_loss: 0.9862 - val_accuracy: 0.5133\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9744 - accuracy: 0.5308 - val_loss: 0.9861 - val_accuracy: 0.5128\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9743 - accuracy: 0.5317 - val_loss: 0.9862 - val_accuracy: 0.5133\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9744 - accuracy: 0.5301 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9744 - accuracy: 0.5312 - val_loss: 0.9861 - val_accuracy: 0.5146\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9742 - accuracy: 0.5310 - val_loss: 0.9861 - val_accuracy: 0.5159\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9743 - accuracy: 0.5315 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9742 - accuracy: 0.5309 - val_loss: 0.9862 - val_accuracy: 0.5128\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9742 - accuracy: 0.5313 - val_loss: 0.9862 - val_accuracy: 0.5159\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9743 - accuracy: 0.5313 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9741 - accuracy: 0.5315 - val_loss: 0.9860 - val_accuracy: 0.5133\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9742 - accuracy: 0.5310 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9741 - accuracy: 0.5309 - val_loss: 0.9860 - val_accuracy: 0.5159\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9741 - accuracy: 0.5317 - val_loss: 0.9862 - val_accuracy: 0.5142\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9741 - accuracy: 0.5311 - val_loss: 0.9860 - val_accuracy: 0.5137\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9741 - accuracy: 0.5325 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9742 - accuracy: 0.5308 - val_loss: 0.9861 - val_accuracy: 0.5133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9741 - accuracy: 0.5314 - val_loss: 0.9860 - val_accuracy: 0.5137\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9741 - accuracy: 0.5311 - val_loss: 0.9861 - val_accuracy: 0.5133\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9741 - accuracy: 0.5303 - val_loss: 0.9863 - val_accuracy: 0.5146\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9741 - accuracy: 0.5319 - val_loss: 0.9861 - val_accuracy: 0.5142\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5310 - val_loss: 0.9863 - val_accuracy: 0.5142\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9740 - accuracy: 0.5311 - val_loss: 0.9860 - val_accuracy: 0.5133\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 0.9861 - val_accuracy: 0.5133\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5317 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 0.9863 - val_accuracy: 0.5142\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.9741 - accuracy: 0.5314 - val_loss: 0.9861 - val_accuracy: 0.5133\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9740 - accuracy: 0.5312 - val_loss: 0.9860 - val_accuracy: 0.5133\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9740 - accuracy: 0.5319 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9739 - accuracy: 0.5310 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5316 - val_loss: 0.9860 - val_accuracy: 0.5159\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9739 - accuracy: 0.5316 - val_loss: 0.9860 - val_accuracy: 0.5146\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9740 - accuracy: 0.5311 - val_loss: 0.9863 - val_accuracy: 0.5155\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9739 - accuracy: 0.5312 - val_loss: 0.9862 - val_accuracy: 0.5150\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9741 - accuracy: 0.5319 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 580us/step - loss: 0.9740 - accuracy: 0.5314 - val_loss: 0.9860 - val_accuracy: 0.5146\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9739 - accuracy: 0.5307 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 414us/step - loss: 0.9739 - accuracy: 0.5310 - val_loss: 0.9860 - val_accuracy: 0.5133\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 698us/step - loss: 0.9739 - accuracy: 0.5309 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 0.9739 - accuracy: 0.5314 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9738 - accuracy: 0.5314 - val_loss: 0.9860 - val_accuracy: 0.5137\n",
      "Epoch 139/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9739 - accuracy: 0.5317 - val_loss: 0.9862 - val_accuracy: 0.5137\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9738 - accuracy: 0.5319 - val_loss: 0.9861 - val_accuracy: 0.5133\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9738 - accuracy: 0.5314 - val_loss: 0.9861 - val_accuracy: 0.5142\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 0.9862 - val_accuracy: 0.5133\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9738 - accuracy: 0.5320 - val_loss: 0.9859 - val_accuracy: 0.5150\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9738 - accuracy: 0.5317 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9738 - accuracy: 0.5317 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 563us/step - loss: 0.9738 - accuracy: 0.5313 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 0.9860 - val_accuracy: 0.5133\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 0.9863 - val_accuracy: 0.5142\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9739 - accuracy: 0.5308 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 423us/step - loss: 0.9738 - accuracy: 0.5320 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 747us/step - loss: 0.9738 - accuracy: 0.5317 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9738 - accuracy: 0.5311 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9738 - accuracy: 0.5321 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9737 - accuracy: 0.5318 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9863 - val_accuracy: 0.5150\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9738 - accuracy: 0.5319 - val_loss: 0.9862 - val_accuracy: 0.5150\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9738 - accuracy: 0.5312 - val_loss: 0.9861 - val_accuracy: 0.5146\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9737 - accuracy: 0.5312 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9737 - accuracy: 0.5316 - val_loss: 0.9859 - val_accuracy: 0.5150\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9737 - accuracy: 0.5320 - val_loss: 0.9859 - val_accuracy: 0.5150\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9737 - accuracy: 0.5317 - val_loss: 0.9859 - val_accuracy: 0.5150\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9737 - accuracy: 0.5319 - val_loss: 0.9863 - val_accuracy: 0.5150\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 481us/step - loss: 0.9737 - accuracy: 0.5318 - val_loss: 0.9860 - val_accuracy: 0.5146\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 617us/step - loss: 0.9737 - accuracy: 0.5316 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 497us/step - loss: 0.9737 - accuracy: 0.5318 - val_loss: 0.9859 - val_accuracy: 0.5150\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 666us/step - loss: 0.9737 - accuracy: 0.5313 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9736 - accuracy: 0.5319 - val_loss: 0.9859 - val_accuracy: 0.5150\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9737 - accuracy: 0.5316 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9860 - val_accuracy: 0.5146\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 587us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9867 - val_accuracy: 0.5133\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9737 - accuracy: 0.5314 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9737 - accuracy: 0.5312 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9736 - accuracy: 0.5316 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9735 - accuracy: 0.5318 - val_loss: 0.9864 - val_accuracy: 0.5155\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9737 - accuracy: 0.5317 - val_loss: 0.9861 - val_accuracy: 0.5137\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 0.9860 - val_accuracy: 0.5137\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9736 - accuracy: 0.5322 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9736 - accuracy: 0.5318 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9736 - accuracy: 0.5318 - val_loss: 0.9864 - val_accuracy: 0.5133\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9737 - accuracy: 0.5320 - val_loss: 0.9862 - val_accuracy: 0.5137\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9736 - accuracy: 0.5317 - val_loss: 0.9860 - val_accuracy: 0.5137\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9736 - accuracy: 0.5317 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 422us/step - loss: 0.9735 - accuracy: 0.5320 - val_loss: 0.9861 - val_accuracy: 0.5133\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 720us/step - loss: 0.9735 - accuracy: 0.5316 - val_loss: 0.9860 - val_accuracy: 0.5146\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 0.9735 - accuracy: 0.5312 - val_loss: 0.9860 - val_accuracy: 0.5128\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9736 - accuracy: 0.5316 - val_loss: 0.9864 - val_accuracy: 0.5142\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 461us/step - loss: 0.9736 - accuracy: 0.5321 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 669us/step - loss: 0.9736 - accuracy: 0.5316 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 564us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9867 - val_accuracy: 0.5128\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 445us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9860 - val_accuracy: 0.5150\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 686us/step - loss: 0.9735 - accuracy: 0.5321 - val_loss: 0.9859 - val_accuracy: 0.5146\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9736 - accuracy: 0.5323 - val_loss: 0.9866 - val_accuracy: 0.5150\n",
      "Epoch 195/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9736 - accuracy: 0.5316 - val_loss: 0.9861 - val_accuracy: 0.5128\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 475us/step - loss: 0.9734 - accuracy: 0.5317 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 626us/step - loss: 0.9734 - accuracy: 0.5319 - val_loss: 0.9863 - val_accuracy: 0.5142\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9735 - accuracy: 0.5311 - val_loss: 0.9861 - val_accuracy: 0.5133\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9736 - accuracy: 0.5322 - val_loss: 0.9861 - val_accuracy: 0.5150\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 572us/step - loss: 0.9734 - accuracy: 0.5312 - val_loss: 0.9865 - val_accuracy: 0.5128\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 340us/step - loss: 0.9736 - accuracy: 0.5318\n",
      "Accuracy : 0.5317725539207458\n",
      "\n",
      "Test split:\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "71/71 - 0s - loss: 0.9865 - accuracy: 0.5128\n",
      "Accuracy : 0.5128318667411804\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1.0153 - accuracy: 0.5096 - val_loss: 0.9879 - val_accuracy: 0.5305\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9796 - accuracy: 0.5289 - val_loss: 0.9793 - val_accuracy: 0.5358\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9769 - accuracy: 0.5300 - val_loss: 0.9769 - val_accuracy: 0.5358\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9763 - accuracy: 0.5303 - val_loss: 0.9761 - val_accuracy: 0.5350\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9762 - accuracy: 0.5299 - val_loss: 0.9755 - val_accuracy: 0.5358\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9756 - val_accuracy: 0.5350\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 506us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9755 - val_accuracy: 0.5354\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 464us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9753 - val_accuracy: 0.5358\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 689us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9760 - accuracy: 0.5303 - val_loss: 0.9754 - val_accuracy: 0.5354\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9762 - accuracy: 0.5302 - val_loss: 0.9759 - val_accuracy: 0.5332\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9761 - accuracy: 0.5304 - val_loss: 0.9755 - val_accuracy: 0.5358\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.9761 - accuracy: 0.5300 - val_loss: 0.9758 - val_accuracy: 0.5358\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 547us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9753 - val_accuracy: 0.5354\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9759 - accuracy: 0.5296 - val_loss: 0.9768 - val_accuracy: 0.5319\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 460us/step - loss: 0.9762 - accuracy: 0.5292 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9763 - accuracy: 0.5301 - val_loss: 0.9757 - val_accuracy: 0.5336\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9760 - accuracy: 0.5291 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 0.9760 - accuracy: 0.5296 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9759 - accuracy: 0.5296 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9755 - val_accuracy: 0.5358\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9760 - accuracy: 0.5300 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 396us/step - loss: 0.9760 - accuracy: 0.5293 - val_loss: 0.9755 - val_accuracy: 0.5358\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 494us/step - loss: 0.9763 - accuracy: 0.5300 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 26/200\n",
      "92/92 [==============================] - 0s 451us/step - loss: 0.9759 - accuracy: 0.5300 - val_loss: 0.9756 - val_accuracy: 0.5358\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 467us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9755 - val_accuracy: 0.5354\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9760 - accuracy: 0.5299 - val_loss: 0.9756 - val_accuracy: 0.5341\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9761 - accuracy: 0.5295 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9757 - val_accuracy: 0.5363\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9759 - accuracy: 0.5295 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9753 - val_accuracy: 0.5358\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 452us/step - loss: 0.9760 - accuracy: 0.5292 - val_loss: 0.9755 - val_accuracy: 0.5363\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 677us/step - loss: 0.9759 - accuracy: 0.5298 - val_loss: 0.9757 - val_accuracy: 0.5358\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 388us/step - loss: 0.9759 - accuracy: 0.5300 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 575us/step - loss: 0.9759 - accuracy: 0.5304 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9759 - accuracy: 0.5302 - val_loss: 0.9757 - val_accuracy: 0.5332\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9759 - accuracy: 0.5289 - val_loss: 0.9758 - val_accuracy: 0.5358\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9756 - val_accuracy: 0.5363\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9760 - accuracy: 0.5295 - val_loss: 0.9755 - val_accuracy: 0.5363\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9757 - val_accuracy: 0.5336\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9759 - accuracy: 0.5295 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9759 - accuracy: 0.5301 - val_loss: 0.9755 - val_accuracy: 0.5345\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9759 - accuracy: 0.5293 - val_loss: 0.9755 - val_accuracy: 0.5363\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9759 - accuracy: 0.5301 - val_loss: 0.9756 - val_accuracy: 0.5358\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9760 - accuracy: 0.5288 - val_loss: 0.9756 - val_accuracy: 0.5358\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 507us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9757 - val_accuracy: 0.5345\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 502us/step - loss: 0.9760 - accuracy: 0.5296 - val_loss: 0.9758 - val_accuracy: 0.5363\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 660us/step - loss: 0.9759 - accuracy: 0.5300 - val_loss: 0.9755 - val_accuracy: 0.5358\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 446us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5294 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9762 - val_accuracy: 0.5336\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 608us/step - loss: 0.9760 - accuracy: 0.5302 - val_loss: 0.9755 - val_accuracy: 0.5363\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 479us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9755 - val_accuracy: 0.5358\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 656us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 0.9758 - val_accuracy: 0.5345\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 602us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9756 - val_accuracy: 0.5358\n",
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 563us/step - loss: 0.9758 - accuracy: 0.5306 - val_loss: 0.9755 - val_accuracy: 0.5363\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 522us/step - loss: 0.9758 - accuracy: 0.5298 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 669us/step - loss: 0.9760 - accuracy: 0.5287 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 415us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 542us/step - loss: 0.9758 - accuracy: 0.5297 - val_loss: 0.9759 - val_accuracy: 0.5332\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9758 - accuracy: 0.5297 - val_loss: 0.9757 - val_accuracy: 0.5363\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9758 - accuracy: 0.5294 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 0.9758 - val_accuracy: 0.5363\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 525us/step - loss: 0.9759 - accuracy: 0.5295 - val_loss: 0.9755 - val_accuracy: 0.5358\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 599us/step - loss: 0.9758 - accuracy: 0.5298 - val_loss: 0.9755 - val_accuracy: 0.5336\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 491us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 625us/step - loss: 0.9759 - accuracy: 0.5293 - val_loss: 0.9754 - val_accuracy: 0.5367\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 465us/step - loss: 0.9758 - accuracy: 0.5287 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 634us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 456us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9756 - val_accuracy: 0.5363\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 541us/step - loss: 0.9757 - accuracy: 0.5288 - val_loss: 0.9756 - val_accuracy: 0.5363\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 525us/step - loss: 0.9757 - accuracy: 0.5296 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9758 - accuracy: 0.5296 - val_loss: 0.9755 - val_accuracy: 0.5354\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 519us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 635us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9756 - val_accuracy: 0.5358\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9757 - accuracy: 0.5291 - val_loss: 0.9754 - val_accuracy: 0.5354\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9756 - val_accuracy: 0.5336\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 400us/step - loss: 0.9758 - accuracy: 0.5300 - val_loss: 0.9753 - val_accuracy: 0.5358\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 536us/step - loss: 0.9758 - accuracy: 0.5290 - val_loss: 0.9754 - val_accuracy: 0.5363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 528us/step - loss: 0.9758 - accuracy: 0.5296 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 606us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 496us/step - loss: 0.9757 - accuracy: 0.5297 - val_loss: 0.9756 - val_accuracy: 0.5332\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 652us/step - loss: 0.9757 - accuracy: 0.5292 - val_loss: 0.9755 - val_accuracy: 0.5354\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 603us/step - loss: 0.9757 - accuracy: 0.5292 - val_loss: 0.9755 - val_accuracy: 0.5350\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9757 - accuracy: 0.5289 - val_loss: 0.9752 - val_accuracy: 0.5358\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9756 - val_accuracy: 0.5350\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9759 - val_accuracy: 0.5345\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9753 - val_accuracy: 0.5358\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9760 - accuracy: 0.5289 - val_loss: 0.9753 - val_accuracy: 0.5367\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9758 - accuracy: 0.5298 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9751 - val_accuracy: 0.5354\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9751 - val_accuracy: 0.5363\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5294 - val_loss: 0.9754 - val_accuracy: 0.5354\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9757 - accuracy: 0.5293 - val_loss: 0.9753 - val_accuracy: 0.5367\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9758 - accuracy: 0.5297 - val_loss: 0.9752 - val_accuracy: 0.5358\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 490us/step - loss: 0.9756 - accuracy: 0.5291 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 646us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9754 - val_accuracy: 0.5367\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 546us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 0.9756 - val_accuracy: 0.5332\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9756 - accuracy: 0.5287 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9756 - val_accuracy: 0.5358\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 529us/step - loss: 0.9755 - accuracy: 0.5301 - val_loss: 0.9754 - val_accuracy: 0.5336\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 628us/step - loss: 0.9758 - accuracy: 0.5288 - val_loss: 0.9753 - val_accuracy: 0.5345\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 0.9757 - accuracy: 0.5284 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9758 - accuracy: 0.5296 - val_loss: 0.9756 - val_accuracy: 0.5363\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 391us/step - loss: 0.9757 - accuracy: 0.5293 - val_loss: 0.9756 - val_accuracy: 0.5354\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 619us/step - loss: 0.9757 - accuracy: 0.5296 - val_loss: 0.9752 - val_accuracy: 0.5354\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9756 - accuracy: 0.5289 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9762 - val_accuracy: 0.5341\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9757 - accuracy: 0.5296 - val_loss: 0.9751 - val_accuracy: 0.5363\n",
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9754 - val_accuracy: 0.5354\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 482us/step - loss: 0.9757 - accuracy: 0.5287 - val_loss: 0.9754 - val_accuracy: 0.5332\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9757 - accuracy: 0.5294 - val_loss: 0.9750 - val_accuracy: 0.5358\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 603us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 0.9751 - val_accuracy: 0.5367\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 487us/step - loss: 0.9757 - accuracy: 0.5286 - val_loss: 0.9752 - val_accuracy: 0.5367\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 662us/step - loss: 0.9756 - accuracy: 0.5297 - val_loss: 0.9754 - val_accuracy: 0.5336\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 641us/step - loss: 0.9756 - accuracy: 0.5295 - val_loss: 0.9759 - val_accuracy: 0.5332\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9758 - accuracy: 0.5285 - val_loss: 0.9754 - val_accuracy: 0.5354\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9757 - accuracy: 0.5304 - val_loss: 0.9752 - val_accuracy: 0.5354\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5292 - val_loss: 0.9751 - val_accuracy: 0.5363\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9756 - accuracy: 0.5306 - val_loss: 0.9754 - val_accuracy: 0.5363\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 0.9755 - val_accuracy: 0.5319\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9758 - accuracy: 0.5289 - val_loss: 0.9755 - val_accuracy: 0.5336\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9757 - accuracy: 0.5297 - val_loss: 0.9752 - val_accuracy: 0.5354\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9757 - accuracy: 0.5287 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 0.9751 - val_accuracy: 0.5367\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9755 - val_accuracy: 0.5354\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9758 - accuracy: 0.5293 - val_loss: 0.9751 - val_accuracy: 0.5363\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9756 - val_accuracy: 0.5323\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9750 - val_accuracy: 0.5367\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9758 - accuracy: 0.5284 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 648us/step - loss: 0.9758 - accuracy: 0.5287 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5295 - val_loss: 0.9750 - val_accuracy: 0.5363\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 464us/step - loss: 0.9756 - accuracy: 0.5297 - val_loss: 0.9751 - val_accuracy: 0.5363\n",
      "Epoch 139/200\n",
      "92/92 [==============================] - 0s 716us/step - loss: 0.9755 - accuracy: 0.5298 - val_loss: 0.9755 - val_accuracy: 0.5332\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9754 - accuracy: 0.5279 - val_loss: 0.9751 - val_accuracy: 0.5358\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9752 - val_accuracy: 0.5354\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9751 - val_accuracy: 0.5363\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9756 - accuracy: 0.5291 - val_loss: 0.9752 - val_accuracy: 0.5358\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9756 - accuracy: 0.5296 - val_loss: 0.9753 - val_accuracy: 0.5336\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9752 - val_accuracy: 0.5358\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 0.9755 - val_accuracy: 0.5363\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5297 - val_loss: 0.9758 - val_accuracy: 0.5319\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9750 - val_accuracy: 0.5363\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9755 - accuracy: 0.5289 - val_loss: 0.9751 - val_accuracy: 0.5358\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9757 - accuracy: 0.5293 - val_loss: 0.9750 - val_accuracy: 0.5354\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9754 - val_accuracy: 0.5332\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9757 - accuracy: 0.5294 - val_loss: 0.9751 - val_accuracy: 0.5367\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9757 - accuracy: 0.5292 - val_loss: 0.9749 - val_accuracy: 0.5363\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5297 - val_loss: 0.9755 - val_accuracy: 0.5336\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9756 - accuracy: 0.5296 - val_loss: 0.9752 - val_accuracy: 0.5345\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 613us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 0.9753 - val_accuracy: 0.5332\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9756 - accuracy: 0.5287 - val_loss: 0.9751 - val_accuracy: 0.5358\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.9755 - accuracy: 0.5298 - val_loss: 0.9753 - val_accuracy: 0.5332\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9753 - val_accuracy: 0.5363\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 511us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9752 - val_accuracy: 0.5332\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 710us/step - loss: 0.9756 - accuracy: 0.5287 - val_loss: 0.9756 - val_accuracy: 0.5319\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 478us/step - loss: 0.9757 - accuracy: 0.5297 - val_loss: 0.9754 - val_accuracy: 0.5332\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 690us/step - loss: 0.9756 - accuracy: 0.5303 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 606us/step - loss: 0.9757 - accuracy: 0.5290 - val_loss: 0.9749 - val_accuracy: 0.5363\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 573us/step - loss: 0.9756 - accuracy: 0.5287 - val_loss: 0.9749 - val_accuracy: 0.5367\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 482us/step - loss: 0.9755 - accuracy: 0.5283 - val_loss: 0.9753 - val_accuracy: 0.5354\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 636us/step - loss: 0.9755 - accuracy: 0.5294 - val_loss: 0.9752 - val_accuracy: 0.5367\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9749 - val_accuracy: 0.5367\n",
      "Epoch 171/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5288 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 0.9756 - accuracy: 0.5294 - val_loss: 0.9750 - val_accuracy: 0.5354\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9755 - accuracy: 0.5302 - val_loss: 0.9752 - val_accuracy: 0.5345\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5292 - val_loss: 0.9756 - val_accuracy: 0.5350\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9754 - val_accuracy: 0.5354\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9751 - val_accuracy: 0.5363\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9749 - val_accuracy: 0.5363\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5291 - val_loss: 0.9753 - val_accuracy: 0.5332\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9756 - accuracy: 0.5296 - val_loss: 0.9751 - val_accuracy: 0.5358\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 436us/step - loss: 0.9757 - accuracy: 0.5289 - val_loss: 0.9752 - val_accuracy: 0.5354\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 691us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 0.9749 - val_accuracy: 0.5367\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9757 - accuracy: 0.5289 - val_loss: 0.9749 - val_accuracy: 0.5367\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 459us/step - loss: 0.9755 - accuracy: 0.5290 - val_loss: 0.9750 - val_accuracy: 0.5350\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 652us/step - loss: 0.9756 - accuracy: 0.5297 - val_loss: 0.9749 - val_accuracy: 0.5367\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5291 - val_loss: 0.9748 - val_accuracy: 0.5354\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9758 - accuracy: 0.5290 - val_loss: 0.9751 - val_accuracy: 0.5345\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5290 - val_loss: 0.9748 - val_accuracy: 0.5358\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9756 - accuracy: 0.5296 - val_loss: 0.9751 - val_accuracy: 0.5350\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 580us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9750 - val_accuracy: 0.5367\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9756 - accuracy: 0.5289 - val_loss: 0.9750 - val_accuracy: 0.5363\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 603us/step - loss: 0.9755 - accuracy: 0.5296 - val_loss: 0.9753 - val_accuracy: 0.5332\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9757 - accuracy: 0.5288 - val_loss: 0.9748 - val_accuracy: 0.5363\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9756 - accuracy: 0.5304 - val_loss: 0.9752 - val_accuracy: 0.5358\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 518us/step - loss: 0.9755 - accuracy: 0.5294 - val_loss: 0.9749 - val_accuracy: 0.5363\n",
      "Epoch 195/200\n",
      "92/92 [==============================] - 0s 509us/step - loss: 0.9756 - accuracy: 0.5289 - val_loss: 0.9749 - val_accuracy: 0.5358\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9757 - accuracy: 0.5290 - val_loss: 0.9760 - val_accuracy: 0.5319\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5290 - val_loss: 0.9756 - val_accuracy: 0.5363\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 451us/step - loss: 0.9757 - accuracy: 0.5290 - val_loss: 0.9749 - val_accuracy: 0.5363\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9757 - accuracy: 0.5294 - val_loss: 0.9751 - val_accuracy: 0.5350\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 459us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9756 - val_accuracy: 0.5332\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 324us/step - loss: 0.9756 - accuracy: 0.5279\n",
      "Accuracy : 0.5278870463371277\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9756 - accuracy: 0.5332\n",
      "Accuracy : 0.5331858396530151\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.1651 - accuracy: 0.4590 - val_loss: 1.0707 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 1.0342 - accuracy: 0.5025 - val_loss: 1.0242 - val_accuracy: 0.4931\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 1.0038 - accuracy: 0.5267 - val_loss: 1.0135 - val_accuracy: 0.5113\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 541us/step - loss: 0.9881 - accuracy: 0.5274 - val_loss: 1.0078 - val_accuracy: 0.5153\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9794 - accuracy: 0.5311 - val_loss: 1.0058 - val_accuracy: 0.5206\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9754 - accuracy: 0.5318 - val_loss: 1.0052 - val_accuracy: 0.5210\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 543us/step - loss: 0.9746 - accuracy: 0.5316 - val_loss: 1.0049 - val_accuracy: 0.5197\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9740 - accuracy: 0.5315 - val_loss: 1.0056 - val_accuracy: 0.5201\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9740 - accuracy: 0.5319 - val_loss: 1.0052 - val_accuracy: 0.5201\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9739 - accuracy: 0.5315 - val_loss: 1.0049 - val_accuracy: 0.5197\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9739 - accuracy: 0.5318 - val_loss: 1.0050 - val_accuracy: 0.5197\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9740 - accuracy: 0.5320 - val_loss: 1.0049 - val_accuracy: 0.5197\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 517us/step - loss: 0.9737 - accuracy: 0.5319 - val_loss: 1.0052 - val_accuracy: 0.5197\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9736 - accuracy: 0.5317 - val_loss: 1.0056 - val_accuracy: 0.5197\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 555us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 1.0054 - val_accuracy: 0.5197\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 521us/step - loss: 0.9739 - accuracy: 0.5308 - val_loss: 1.0048 - val_accuracy: 0.5197\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9738 - accuracy: 0.5302 - val_loss: 1.0051 - val_accuracy: 0.5201\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9735 - accuracy: 0.5316 - val_loss: 1.0049 - val_accuracy: 0.5197\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9735 - accuracy: 0.5311 - val_loss: 1.0059 - val_accuracy: 0.5197\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9737 - accuracy: 0.5317 - val_loss: 1.0049 - val_accuracy: 0.5201\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 568us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 1.0046 - val_accuracy: 0.5197\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 1.0043 - val_accuracy: 0.5197\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 1.0049 - val_accuracy: 0.5197\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 1.0044 - val_accuracy: 0.5206\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9733 - accuracy: 0.5314 - val_loss: 1.0044 - val_accuracy: 0.5206\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 494us/step - loss: 0.9733 - accuracy: 0.5310 - val_loss: 1.0046 - val_accuracy: 0.5197\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9732 - accuracy: 0.5317 - val_loss: 1.0043 - val_accuracy: 0.5206\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9735 - accuracy: 0.5312 - val_loss: 1.0044 - val_accuracy: 0.5197\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9737 - accuracy: 0.5309 - val_loss: 1.0053 - val_accuracy: 0.5197\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9733 - accuracy: 0.5311 - val_loss: 1.0050 - val_accuracy: 0.5206\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9733 - accuracy: 0.5306 - val_loss: 1.0049 - val_accuracy: 0.5206\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9736 - accuracy: 0.5316 - val_loss: 1.0053 - val_accuracy: 0.5206\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9734 - accuracy: 0.5316 - val_loss: 1.0051 - val_accuracy: 0.5206\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9732 - accuracy: 0.5317 - val_loss: 1.0046 - val_accuracy: 0.5197\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 493us/step - loss: 0.9732 - accuracy: 0.5312 - val_loss: 1.0054 - val_accuracy: 0.5206\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 545us/step - loss: 0.9734 - accuracy: 0.5313 - val_loss: 1.0045 - val_accuracy: 0.5197\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 531us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 1.0039 - val_accuracy: 0.5201\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9734 - accuracy: 0.5311 - val_loss: 1.0041 - val_accuracy: 0.5197\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9732 - accuracy: 0.5315 - val_loss: 1.0048 - val_accuracy: 0.5206\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 477us/step - loss: 0.9733 - accuracy: 0.5318 - val_loss: 1.0048 - val_accuracy: 0.5210\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 1.0050 - val_accuracy: 0.5197\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9733 - accuracy: 0.5316 - val_loss: 1.0044 - val_accuracy: 0.5206\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9732 - accuracy: 0.5321 - val_loss: 1.0043 - val_accuracy: 0.5197\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9732 - accuracy: 0.5316 - val_loss: 1.0049 - val_accuracy: 0.5206\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 539us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 1.0042 - val_accuracy: 0.5201\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 521us/step - loss: 0.9732 - accuracy: 0.5303 - val_loss: 1.0043 - val_accuracy: 0.5197\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9732 - accuracy: 0.5319 - val_loss: 1.0054 - val_accuracy: 0.5206\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 569us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 1.0047 - val_accuracy: 0.5197\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 507us/step - loss: 0.9730 - accuracy: 0.5316 - val_loss: 1.0043 - val_accuracy: 0.5197\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9732 - accuracy: 0.5324 - val_loss: 1.0045 - val_accuracy: 0.5206\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 558us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 1.0043 - val_accuracy: 0.5197\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9731 - accuracy: 0.5317 - val_loss: 1.0047 - val_accuracy: 0.5210\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 1.0050 - val_accuracy: 0.5201\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9732 - accuracy: 0.5302 - val_loss: 1.0057 - val_accuracy: 0.5197\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 1.0050 - val_accuracy: 0.5206\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9732 - accuracy: 0.5295 - val_loss: 1.0050 - val_accuracy: 0.5206\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9730 - accuracy: 0.5304 - val_loss: 1.0049 - val_accuracy: 0.5201\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 476us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 1.0052 - val_accuracy: 0.5197\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 540us/step - loss: 0.9733 - accuracy: 0.5313 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 1.0046 - val_accuracy: 0.5206\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 1.0045 - val_accuracy: 0.5206\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9730 - accuracy: 0.5317 - val_loss: 1.0045 - val_accuracy: 0.5206\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9729 - accuracy: 0.5303 - val_loss: 1.0045 - val_accuracy: 0.5201\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 1.0045 - val_accuracy: 0.5210\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9731 - accuracy: 0.5295 - val_loss: 1.0052 - val_accuracy: 0.5210\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 1.0042 - val_accuracy: 0.5197\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 491us/step - loss: 0.9731 - accuracy: 0.5312 - val_loss: 1.0052 - val_accuracy: 0.5206\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 533us/step - loss: 0.9733 - accuracy: 0.5313 - val_loss: 1.0046 - val_accuracy: 0.5206\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 541us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 1.0045 - val_accuracy: 0.5206\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9732 - accuracy: 0.5301 - val_loss: 1.0043 - val_accuracy: 0.5206\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 1.0041 - val_accuracy: 0.5206\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9729 - accuracy: 0.5314 - val_loss: 1.0051 - val_accuracy: 0.5210\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9730 - accuracy: 0.5295 - val_loss: 1.0039 - val_accuracy: 0.5206\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9732 - accuracy: 0.5317 - val_loss: 1.0047 - val_accuracy: 0.5206\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9728 - accuracy: 0.5299 - val_loss: 1.0045 - val_accuracy: 0.5197\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 501us/step - loss: 0.9729 - accuracy: 0.5319 - val_loss: 1.0042 - val_accuracy: 0.5201\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9730 - accuracy: 0.5314 - val_loss: 1.0049 - val_accuracy: 0.5201\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 565us/step - loss: 0.9735 - accuracy: 0.5315 - val_loss: 1.0044 - val_accuracy: 0.5215\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9733 - accuracy: 0.5311 - val_loss: 1.0050 - val_accuracy: 0.5206\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 1.0047 - val_accuracy: 0.5206\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9729 - accuracy: 0.5289 - val_loss: 1.0044 - val_accuracy: 0.5206\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9728 - accuracy: 0.5316 - val_loss: 1.0048 - val_accuracy: 0.5175\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9732 - accuracy: 0.5301 - val_loss: 1.0053 - val_accuracy: 0.5197\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9732 - accuracy: 0.5318 - val_loss: 1.0052 - val_accuracy: 0.5201\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9731 - accuracy: 0.5315 - val_loss: 1.0050 - val_accuracy: 0.5206\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9729 - accuracy: 0.5304 - val_loss: 1.0043 - val_accuracy: 0.5206\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 473us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 1.0042 - val_accuracy: 0.5201\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 457us/step - loss: 0.9731 - accuracy: 0.5312 - val_loss: 1.0044 - val_accuracy: 0.5197\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 453us/step - loss: 0.9729 - accuracy: 0.5324 - val_loss: 1.0042 - val_accuracy: 0.5206\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 1.0057 - val_accuracy: 0.5201\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 541us/step - loss: 0.9733 - accuracy: 0.5305 - val_loss: 1.0043 - val_accuracy: 0.5201\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9730 - accuracy: 0.5317 - val_loss: 1.0042 - val_accuracy: 0.5201\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 524us/step - loss: 0.9729 - accuracy: 0.5304 - val_loss: 1.0040 - val_accuracy: 0.5197\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 551us/step - loss: 0.9731 - accuracy: 0.5315 - val_loss: 1.0048 - val_accuracy: 0.5206\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 1.0046 - val_accuracy: 0.5201\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9729 - accuracy: 0.5316 - val_loss: 1.0042 - val_accuracy: 0.5215\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9732 - accuracy: 0.5313 - val_loss: 1.0046 - val_accuracy: 0.5206\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 485us/step - loss: 0.9729 - accuracy: 0.5298 - val_loss: 1.0046 - val_accuracy: 0.5201\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 1.0046 - val_accuracy: 0.5201\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 551us/step - loss: 0.9731 - accuracy: 0.5316 - val_loss: 1.0046 - val_accuracy: 0.5197\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 523us/step - loss: 0.9727 - accuracy: 0.5303 - val_loss: 1.0042 - val_accuracy: 0.5201\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 529us/step - loss: 0.9729 - accuracy: 0.5297 - val_loss: 1.0047 - val_accuracy: 0.5201\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 545us/step - loss: 0.9729 - accuracy: 0.5314 - val_loss: 1.0040 - val_accuracy: 0.5215\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9733 - accuracy: 0.5306 - val_loss: 1.0046 - val_accuracy: 0.5201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9731 - accuracy: 0.5315 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 1.0045 - val_accuracy: 0.5206\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 1.0049 - val_accuracy: 0.5206\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 508us/step - loss: 0.9731 - accuracy: 0.5293 - val_loss: 1.0044 - val_accuracy: 0.5206\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 742us/step - loss: 0.9730 - accuracy: 0.5288 - val_loss: 1.0048 - val_accuracy: 0.5206\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 499us/step - loss: 0.9727 - accuracy: 0.5315 - val_loss: 1.0041 - val_accuracy: 0.5206\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9732 - accuracy: 0.5310 - val_loss: 1.0045 - val_accuracy: 0.5206\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9729 - accuracy: 0.5312 - val_loss: 1.0048 - val_accuracy: 0.5201\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 534us/step - loss: 0.9728 - accuracy: 0.5294 - val_loss: 1.0045 - val_accuracy: 0.5206\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 484us/step - loss: 0.9729 - accuracy: 0.5318 - val_loss: 1.0040 - val_accuracy: 0.5201\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9728 - accuracy: 0.5299 - val_loss: 1.0039 - val_accuracy: 0.5201\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9729 - accuracy: 0.5318 - val_loss: 1.0047 - val_accuracy: 0.5206\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 499us/step - loss: 0.9729 - accuracy: 0.5315 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9734 - accuracy: 0.5282 - val_loss: 1.0047 - val_accuracy: 0.5206\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9739 - accuracy: 0.5305 - val_loss: 1.0055 - val_accuracy: 0.5197\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9732 - accuracy: 0.5288 - val_loss: 1.0054 - val_accuracy: 0.5210\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9728 - accuracy: 0.5290 - val_loss: 1.0053 - val_accuracy: 0.5206\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9731 - accuracy: 0.5312 - val_loss: 1.0044 - val_accuracy: 0.5206\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9730 - accuracy: 0.5311 - val_loss: 1.0043 - val_accuracy: 0.5201\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9728 - accuracy: 0.5305 - val_loss: 1.0043 - val_accuracy: 0.5210\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9729 - accuracy: 0.5303 - val_loss: 1.0051 - val_accuracy: 0.5201\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9728 - accuracy: 0.5291 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 562us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 1.0049 - val_accuracy: 0.5206\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 517us/step - loss: 0.9732 - accuracy: 0.5301 - val_loss: 1.0044 - val_accuracy: 0.5197\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9728 - accuracy: 0.5298 - val_loss: 1.0047 - val_accuracy: 0.5206\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 546us/step - loss: 0.9730 - accuracy: 0.5314 - val_loss: 1.0048 - val_accuracy: 0.5206\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 530us/step - loss: 0.9733 - accuracy: 0.5313 - val_loss: 1.0043 - val_accuracy: 0.5197\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 1.0047 - val_accuracy: 0.5201\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 660us/step - loss: 0.9730 - accuracy: 0.5316 - val_loss: 1.0042 - val_accuracy: 0.5206\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 1.0044 - val_accuracy: 0.5197\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 1.0042 - val_accuracy: 0.5206\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 501us/step - loss: 0.9729 - accuracy: 0.5313 - val_loss: 1.0048 - val_accuracy: 0.5201\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9730 - accuracy: 0.5289 - val_loss: 1.0046 - val_accuracy: 0.5201\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 542us/step - loss: 0.9728 - accuracy: 0.5318 - val_loss: 1.0047 - val_accuracy: 0.5188\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 536us/step - loss: 0.9728 - accuracy: 0.5290 - val_loss: 1.0049 - val_accuracy: 0.5201\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 672us/step - loss: 0.9729 - accuracy: 0.5289 - val_loss: 1.0049 - val_accuracy: 0.5201\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9727 - accuracy: 0.5300 - val_loss: 1.0046 - val_accuracy: 0.5201\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9729 - accuracy: 0.5314 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9728 - accuracy: 0.5302 - val_loss: 1.0049 - val_accuracy: 0.5206\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 549us/step - loss: 0.9728 - accuracy: 0.5317 - val_loss: 1.0043 - val_accuracy: 0.5201\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 530us/step - loss: 0.9728 - accuracy: 0.5302 - val_loss: 1.0046 - val_accuracy: 0.5197\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 1.0048 - val_accuracy: 0.5206\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 542us/step - loss: 0.9730 - accuracy: 0.5306 - val_loss: 1.0049 - val_accuracy: 0.5201\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 533us/step - loss: 0.9728 - accuracy: 0.5291 - val_loss: 1.0039 - val_accuracy: 0.5201\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 1.0042 - val_accuracy: 0.5206\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 1.0048 - val_accuracy: 0.5201\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9733 - accuracy: 0.5317 - val_loss: 1.0047 - val_accuracy: 0.5197\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9730 - accuracy: 0.5307 - val_loss: 1.0048 - val_accuracy: 0.5175\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 546us/step - loss: 0.9728 - accuracy: 0.5310 - val_loss: 1.0042 - val_accuracy: 0.5206\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 530us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 1.0040 - val_accuracy: 0.5201\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 742us/step - loss: 0.9726 - accuracy: 0.5312 - val_loss: 1.0045 - val_accuracy: 0.5201\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 551us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 1.0045 - val_accuracy: 0.5197\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 524us/step - loss: 0.9732 - accuracy: 0.5313 - val_loss: 1.0041 - val_accuracy: 0.5206\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 760us/step - loss: 0.9730 - accuracy: 0.5312 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 485us/step - loss: 0.9729 - accuracy: 0.5309 - val_loss: 1.0044 - val_accuracy: 0.5197\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9727 - accuracy: 0.5315 - val_loss: 1.0042 - val_accuracy: 0.5215\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 1.0040 - val_accuracy: 0.5206\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9732 - accuracy: 0.5278 - val_loss: 1.0046 - val_accuracy: 0.5197\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 466us/step - loss: 0.9729 - accuracy: 0.5307 - val_loss: 1.0045 - val_accuracy: 0.5206\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9730 - accuracy: 0.5300 - val_loss: 1.0043 - val_accuracy: 0.5206\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 554us/step - loss: 0.9726 - accuracy: 0.5295 - val_loss: 1.0050 - val_accuracy: 0.5197\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 520us/step - loss: 0.9728 - accuracy: 0.5313 - val_loss: 1.0045 - val_accuracy: 0.5201\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9729 - accuracy: 0.5314 - val_loss: 1.0046 - val_accuracy: 0.5201\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9727 - accuracy: 0.5306 - val_loss: 1.0050 - val_accuracy: 0.5201\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 522us/step - loss: 0.9727 - accuracy: 0.5294 - val_loss: 1.0045 - val_accuracy: 0.5206\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9727 - accuracy: 0.5305 - val_loss: 1.0043 - val_accuracy: 0.5201\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 1.0041 - val_accuracy: 0.5201\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9729 - accuracy: 0.5315 - val_loss: 1.0038 - val_accuracy: 0.5215\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9729 - accuracy: 0.5314 - val_loss: 1.0047 - val_accuracy: 0.5206\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 567us/step - loss: 0.9731 - accuracy: 0.5312 - val_loss: 1.0037 - val_accuracy: 0.5206\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9728 - accuracy: 0.5312 - val_loss: 1.0038 - val_accuracy: 0.5206\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 1.0044 - val_accuracy: 0.5206\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9728 - accuracy: 0.5316 - val_loss: 1.0044 - val_accuracy: 0.5197\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9729 - accuracy: 0.5282 - val_loss: 1.0039 - val_accuracy: 0.5201\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9732 - accuracy: 0.5312 - val_loss: 1.0045 - val_accuracy: 0.5206\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9733 - accuracy: 0.5313 - val_loss: 1.0053 - val_accuracy: 0.5175\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9728 - accuracy: 0.5302 - val_loss: 1.0046 - val_accuracy: 0.5197\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9727 - accuracy: 0.5311 - val_loss: 1.0050 - val_accuracy: 0.5206\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 1.0045 - val_accuracy: 0.5193\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9731 - accuracy: 0.5304 - val_loss: 1.0044 - val_accuracy: 0.5206\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9727 - accuracy: 0.5319 - val_loss: 1.0052 - val_accuracy: 0.5201\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 672us/step - loss: 0.9728 - accuracy: 0.5307 - val_loss: 1.0048 - val_accuracy: 0.5206\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9729 - accuracy: 0.5315 - val_loss: 1.0040 - val_accuracy: 0.5206\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9728 - accuracy: 0.5304 - val_loss: 1.0048 - val_accuracy: 0.5201\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9728 - accuracy: 0.5308 - val_loss: 1.0047 - val_accuracy: 0.5206\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9726 - accuracy: 0.5305 - val_loss: 1.0053 - val_accuracy: 0.5197\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9726 - accuracy: 0.5310 - val_loss: 1.0043 - val_accuracy: 0.5206\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9728 - accuracy: 0.5313 - val_loss: 1.0044 - val_accuracy: 0.5201\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9728 - accuracy: 0.5317 - val_loss: 1.0046 - val_accuracy: 0.5201\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9726 - accuracy: 0.5313 - val_loss: 1.0050 - val_accuracy: 0.5197\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9725 - accuracy: 0.5315 - val_loss: 1.0056 - val_accuracy: 0.5201\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9726 - accuracy: 0.5309 - val_loss: 1.0049 - val_accuracy: 0.5201\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 329us/step - loss: 0.9725 - accuracy: 0.5316\n",
      "Accuracy : 0.5316480398178101\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0049 - accuracy: 0.5201\n",
      "Accuracy : 0.5201416611671448\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.8639 - accuracy: 0.4580 - val_loss: 1.6940 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 1.5676 - accuracy: 0.4578 - val_loss: 1.3909 - val_accuracy: 0.4582\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.2517 - accuracy: 0.4580 - val_loss: 1.1302 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 1.0582 - accuracy: 0.4816 - val_loss: 1.0446 - val_accuracy: 0.4892\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0088 - accuracy: 0.5172 - val_loss: 1.0311 - val_accuracy: 0.4847\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9977 - accuracy: 0.5169 - val_loss: 1.0274 - val_accuracy: 0.4714\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9935 - accuracy: 0.5195 - val_loss: 1.0246 - val_accuracy: 0.4785\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9911 - accuracy: 0.5217 - val_loss: 1.0232 - val_accuracy: 0.4821\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9893 - accuracy: 0.5237 - val_loss: 1.0222 - val_accuracy: 0.4816\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9881 - accuracy: 0.5247 - val_loss: 1.0215 - val_accuracy: 0.4852\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9873 - accuracy: 0.5245 - val_loss: 1.0207 - val_accuracy: 0.4865\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9864 - accuracy: 0.5239 - val_loss: 1.0199 - val_accuracy: 0.4949\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9858 - accuracy: 0.5273 - val_loss: 1.0195 - val_accuracy: 0.4949\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9853 - accuracy: 0.5277 - val_loss: 1.0192 - val_accuracy: 0.4985\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9848 - accuracy: 0.5271 - val_loss: 1.0187 - val_accuracy: 0.5024\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9841 - accuracy: 0.5284 - val_loss: 1.0183 - val_accuracy: 0.5024\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 624us/step - loss: 0.9838 - accuracy: 0.5267 - val_loss: 1.0192 - val_accuracy: 0.4847\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9841 - accuracy: 0.5248 - val_loss: 1.0178 - val_accuracy: 0.5029\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9830 - accuracy: 0.5294 - val_loss: 1.0174 - val_accuracy: 0.5033\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 566us/step - loss: 0.9827 - accuracy: 0.5271 - val_loss: 1.0170 - val_accuracy: 0.5069\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 737us/step - loss: 0.9824 - accuracy: 0.5309 - val_loss: 1.0169 - val_accuracy: 0.5011\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9839 - accuracy: 0.5299 - val_loss: 1.0162 - val_accuracy: 0.5060\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9817 - accuracy: 0.5309 - val_loss: 1.0163 - val_accuracy: 0.5038\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9812 - accuracy: 0.5312 - val_loss: 1.0159 - val_accuracy: 0.5064\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9809 - accuracy: 0.5285 - val_loss: 1.0154 - val_accuracy: 0.5069\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9807 - accuracy: 0.5298 - val_loss: 1.0153 - val_accuracy: 0.5060\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9804 - accuracy: 0.5293 - val_loss: 1.0150 - val_accuracy: 0.5064\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9800 - accuracy: 0.5317 - val_loss: 1.0144 - val_accuracy: 0.5064\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9796 - accuracy: 0.5311 - val_loss: 1.0147 - val_accuracy: 0.5064\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9794 - accuracy: 0.5297 - val_loss: 1.0140 - val_accuracy: 0.5060\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9794 - accuracy: 0.5310 - val_loss: 1.0141 - val_accuracy: 0.5064\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9792 - accuracy: 0.5299 - val_loss: 1.0135 - val_accuracy: 0.5060\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9788 - accuracy: 0.5317 - val_loss: 1.0133 - val_accuracy: 0.5060\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9785 - accuracy: 0.5302 - val_loss: 1.0133 - val_accuracy: 0.5060\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9782 - accuracy: 0.5321 - val_loss: 1.0128 - val_accuracy: 0.5069\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9779 - accuracy: 0.5311 - val_loss: 1.0133 - val_accuracy: 0.5064\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9780 - accuracy: 0.5310 - val_loss: 1.0122 - val_accuracy: 0.5069\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9775 - accuracy: 0.5303 - val_loss: 1.0129 - val_accuracy: 0.5077\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9773 - accuracy: 0.5311 - val_loss: 1.0123 - val_accuracy: 0.5064\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9772 - accuracy: 0.5316 - val_loss: 1.0119 - val_accuracy: 0.5069\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9769 - accuracy: 0.5320 - val_loss: 1.0115 - val_accuracy: 0.5069\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9783 - accuracy: 0.5316 - val_loss: 1.0113 - val_accuracy: 0.5069\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5328 - val_loss: 1.0111 - val_accuracy: 0.5073\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9767 - accuracy: 0.5307 - val_loss: 1.0113 - val_accuracy: 0.5077\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5306 - val_loss: 1.0108 - val_accuracy: 0.5069\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9763 - accuracy: 0.5323 - val_loss: 1.0106 - val_accuracy: 0.5069\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9763 - accuracy: 0.5325 - val_loss: 1.0102 - val_accuracy: 0.5064\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 715us/step - loss: 0.9760 - accuracy: 0.5308 - val_loss: 1.0106 - val_accuracy: 0.5069\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9761 - accuracy: 0.5313 - val_loss: 1.0101 - val_accuracy: 0.5069\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9757 - accuracy: 0.5324 - val_loss: 1.0104 - val_accuracy: 0.5073\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9757 - accuracy: 0.5322 - val_loss: 1.0096 - val_accuracy: 0.5064\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9755 - accuracy: 0.5319 - val_loss: 1.0097 - val_accuracy: 0.5060\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9754 - accuracy: 0.5324 - val_loss: 1.0097 - val_accuracy: 0.5064\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9753 - accuracy: 0.5326 - val_loss: 1.0098 - val_accuracy: 0.5069\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9751 - accuracy: 0.5329 - val_loss: 1.0099 - val_accuracy: 0.5082\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9751 - accuracy: 0.5326 - val_loss: 1.0093 - val_accuracy: 0.5064\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9752 - accuracy: 0.5322 - val_loss: 1.0094 - val_accuracy: 0.5064\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9751 - accuracy: 0.5323 - val_loss: 1.0089 - val_accuracy: 0.5064\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9751 - accuracy: 0.5308 - val_loss: 1.0092 - val_accuracy: 0.5069\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9750 - accuracy: 0.5315 - val_loss: 1.0091 - val_accuracy: 0.5064\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9748 - accuracy: 0.5327 - val_loss: 1.0089 - val_accuracy: 0.5064\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 660us/step - loss: 0.9752 - accuracy: 0.5323 - val_loss: 1.0092 - val_accuracy: 0.5073\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9746 - accuracy: 0.5323 - val_loss: 1.0087 - val_accuracy: 0.5064\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9746 - accuracy: 0.5327 - val_loss: 1.0093 - val_accuracy: 0.5064\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9748 - accuracy: 0.5316 - val_loss: 1.0092 - val_accuracy: 0.5064\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 664us/step - loss: 0.9745 - accuracy: 0.5316 - val_loss: 1.0085 - val_accuracy: 0.5064\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9744 - accuracy: 0.5316 - val_loss: 1.0082 - val_accuracy: 0.5064\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9744 - accuracy: 0.5310 - val_loss: 1.0082 - val_accuracy: 0.5064\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9743 - accuracy: 0.5311 - val_loss: 1.0080 - val_accuracy: 0.5064\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 748us/step - loss: 0.9744 - accuracy: 0.5326 - val_loss: 1.0082 - val_accuracy: 0.5064\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9743 - accuracy: 0.5317 - val_loss: 1.0083 - val_accuracy: 0.5077\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9743 - accuracy: 0.5326 - val_loss: 1.0082 - val_accuracy: 0.5064\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 664us/step - loss: 0.9741 - accuracy: 0.5315 - val_loss: 1.0079 - val_accuracy: 0.5064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9740 - accuracy: 0.5312 - val_loss: 1.0082 - val_accuracy: 0.5064\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9742 - accuracy: 0.5313 - val_loss: 1.0080 - val_accuracy: 0.5064\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9739 - accuracy: 0.5312 - val_loss: 1.0076 - val_accuracy: 0.5069\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9738 - accuracy: 0.5311 - val_loss: 1.0087 - val_accuracy: 0.5064\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9741 - accuracy: 0.5318 - val_loss: 1.0077 - val_accuracy: 0.5064\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9742 - accuracy: 0.5319 - val_loss: 1.0074 - val_accuracy: 0.5064\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9738 - accuracy: 0.5321 - val_loss: 1.0080 - val_accuracy: 0.5082\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9738 - accuracy: 0.5321 - val_loss: 1.0072 - val_accuracy: 0.5069\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9741 - accuracy: 0.5321 - val_loss: 1.0075 - val_accuracy: 0.5073\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9740 - accuracy: 0.5308 - val_loss: 1.0084 - val_accuracy: 0.5064\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9744 - accuracy: 0.5318 - val_loss: 1.0074 - val_accuracy: 0.5064\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9742 - accuracy: 0.5332 - val_loss: 1.0073 - val_accuracy: 0.5077\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9739 - accuracy: 0.5310 - val_loss: 1.0070 - val_accuracy: 0.5060\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 1.0072 - val_accuracy: 0.5064\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9737 - accuracy: 0.5313 - val_loss: 1.0073 - val_accuracy: 0.5064\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 1.0072 - val_accuracy: 0.5060\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9738 - accuracy: 0.5318 - val_loss: 1.0073 - val_accuracy: 0.5064\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9734 - accuracy: 0.5311 - val_loss: 1.0070 - val_accuracy: 0.5064\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 1.0070 - val_accuracy: 0.5073\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9736 - accuracy: 0.5313 - val_loss: 1.0069 - val_accuracy: 0.5077\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9741 - accuracy: 0.5328 - val_loss: 1.0069 - val_accuracy: 0.5073\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9735 - accuracy: 0.5321 - val_loss: 1.0072 - val_accuracy: 0.5064\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9738 - accuracy: 0.5318 - val_loss: 1.0067 - val_accuracy: 0.5073\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9737 - accuracy: 0.5316 - val_loss: 1.0069 - val_accuracy: 0.5064\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9734 - accuracy: 0.5317 - val_loss: 1.0068 - val_accuracy: 0.5060\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9737 - accuracy: 0.5320 - val_loss: 1.0068 - val_accuracy: 0.5055\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9736 - accuracy: 0.5307 - val_loss: 1.0067 - val_accuracy: 0.5055\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9737 - accuracy: 0.5316 - val_loss: 1.0065 - val_accuracy: 0.5073\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9735 - accuracy: 0.5303 - val_loss: 1.0065 - val_accuracy: 0.5060\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9734 - accuracy: 0.5319 - val_loss: 1.0066 - val_accuracy: 0.5073\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9733 - accuracy: 0.5314 - val_loss: 1.0065 - val_accuracy: 0.5073\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9736 - accuracy: 0.5299 - val_loss: 1.0063 - val_accuracy: 0.5060\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 1.0068 - val_accuracy: 0.5073\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 1.0063 - val_accuracy: 0.5060\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9735 - accuracy: 0.5308 - val_loss: 1.0064 - val_accuracy: 0.5082\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9735 - accuracy: 0.5315 - val_loss: 1.0064 - val_accuracy: 0.5073\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 1.0064 - val_accuracy: 0.5082\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 1.0063 - val_accuracy: 0.5055\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9733 - accuracy: 0.5314 - val_loss: 1.0065 - val_accuracy: 0.5086\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 1.0062 - val_accuracy: 0.5073\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9733 - accuracy: 0.5314 - val_loss: 1.0061 - val_accuracy: 0.5073\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9731 - accuracy: 0.5319 - val_loss: 1.0064 - val_accuracy: 0.5073\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9733 - accuracy: 0.5307 - val_loss: 1.0068 - val_accuracy: 0.5073\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9738 - accuracy: 0.5312 - val_loss: 1.0059 - val_accuracy: 0.5069\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9732 - accuracy: 0.5320 - val_loss: 1.0066 - val_accuracy: 0.5069\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 1.0060 - val_accuracy: 0.5077\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 1.0064 - val_accuracy: 0.5055\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9732 - accuracy: 0.5317 - val_loss: 1.0061 - val_accuracy: 0.5069\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9732 - accuracy: 0.5313 - val_loss: 1.0060 - val_accuracy: 0.5073\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9734 - accuracy: 0.5302 - val_loss: 1.0059 - val_accuracy: 0.5060\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9732 - accuracy: 0.5304 - val_loss: 1.0064 - val_accuracy: 0.5073\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9735 - accuracy: 0.5314 - val_loss: 1.0057 - val_accuracy: 0.5073\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9732 - accuracy: 0.5321 - val_loss: 1.0061 - val_accuracy: 0.5073\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9734 - accuracy: 0.5319 - val_loss: 1.0059 - val_accuracy: 0.5055\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9733 - accuracy: 0.5311 - val_loss: 1.0057 - val_accuracy: 0.5077\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9734 - accuracy: 0.5315 - val_loss: 1.0059 - val_accuracy: 0.5077\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9731 - accuracy: 0.5311 - val_loss: 1.0057 - val_accuracy: 0.5073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 705us/step - loss: 0.9730 - accuracy: 0.5302 - val_loss: 1.0059 - val_accuracy: 0.5077\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 1.0056 - val_accuracy: 0.5073\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9730 - accuracy: 0.5326 - val_loss: 1.0056 - val_accuracy: 0.5073\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9732 - accuracy: 0.5313 - val_loss: 1.0056 - val_accuracy: 0.5069\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9730 - accuracy: 0.5316 - val_loss: 1.0055 - val_accuracy: 0.5073\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9731 - accuracy: 0.5322 - val_loss: 1.0057 - val_accuracy: 0.5069\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9732 - accuracy: 0.5312 - val_loss: 1.0058 - val_accuracy: 0.5055\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9733 - accuracy: 0.5316 - val_loss: 1.0056 - val_accuracy: 0.5073\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9730 - accuracy: 0.5321 - val_loss: 1.0058 - val_accuracy: 0.5060\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9736 - accuracy: 0.5319 - val_loss: 1.0054 - val_accuracy: 0.5077\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 660us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 1.0057 - val_accuracy: 0.5055\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9730 - accuracy: 0.5301 - val_loss: 1.0055 - val_accuracy: 0.5060\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9732 - accuracy: 0.5322 - val_loss: 1.0055 - val_accuracy: 0.5077\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9732 - accuracy: 0.5322 - val_loss: 1.0053 - val_accuracy: 0.5077\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9731 - accuracy: 0.5317 - val_loss: 1.0052 - val_accuracy: 0.5069\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9730 - accuracy: 0.5311 - val_loss: 1.0053 - val_accuracy: 0.5069\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9732 - accuracy: 0.5312 - val_loss: 1.0051 - val_accuracy: 0.5073\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9730 - accuracy: 0.5314 - val_loss: 1.0052 - val_accuracy: 0.5073\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9731 - accuracy: 0.5326 - val_loss: 1.0055 - val_accuracy: 0.5064\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9732 - accuracy: 0.5320 - val_loss: 1.0057 - val_accuracy: 0.5060\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 1.0052 - val_accuracy: 0.5077\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9732 - accuracy: 0.5307 - val_loss: 1.0051 - val_accuracy: 0.5073\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9732 - accuracy: 0.5316 - val_loss: 1.0050 - val_accuracy: 0.5069\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9730 - accuracy: 0.5323 - val_loss: 1.0050 - val_accuracy: 0.5073\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9730 - accuracy: 0.5310 - val_loss: 1.0052 - val_accuracy: 0.5073\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9730 - accuracy: 0.5327 - val_loss: 1.0050 - val_accuracy: 0.5073\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9729 - accuracy: 0.5324 - val_loss: 1.0054 - val_accuracy: 0.5069\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 1.0050 - val_accuracy: 0.5073\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9731 - accuracy: 0.5315 - val_loss: 1.0051 - val_accuracy: 0.5073\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 1.0053 - val_accuracy: 0.5073\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9729 - accuracy: 0.5321 - val_loss: 1.0051 - val_accuracy: 0.5064\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 1.0055 - val_accuracy: 0.5073\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9732 - accuracy: 0.5321 - val_loss: 1.0050 - val_accuracy: 0.5073\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 1.0049 - val_accuracy: 0.5077\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 1.0053 - val_accuracy: 0.5073\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9728 - accuracy: 0.5305 - val_loss: 1.0049 - val_accuracy: 0.5073\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9729 - accuracy: 0.5312 - val_loss: 1.0050 - val_accuracy: 0.5073\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9730 - accuracy: 0.5310 - val_loss: 1.0047 - val_accuracy: 0.5073\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9730 - accuracy: 0.5332 - val_loss: 1.0052 - val_accuracy: 0.5073\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9730 - accuracy: 0.5321 - val_loss: 1.0049 - val_accuracy: 0.5064\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9728 - accuracy: 0.5321 - val_loss: 1.0048 - val_accuracy: 0.5069\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9731 - accuracy: 0.5324 - val_loss: 1.0047 - val_accuracy: 0.5077\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9729 - accuracy: 0.5322 - val_loss: 1.0050 - val_accuracy: 0.5055\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9730 - accuracy: 0.5324 - val_loss: 1.0047 - val_accuracy: 0.5086\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9729 - accuracy: 0.5325 - val_loss: 1.0049 - val_accuracy: 0.5069\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9728 - accuracy: 0.5320 - val_loss: 1.0048 - val_accuracy: 0.5069\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9728 - accuracy: 0.5313 - val_loss: 1.0048 - val_accuracy: 0.5069\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9730 - accuracy: 0.5314 - val_loss: 1.0046 - val_accuracy: 0.5069\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9727 - accuracy: 0.5323 - val_loss: 1.0049 - val_accuracy: 0.5086\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9731 - accuracy: 0.5312 - val_loss: 1.0055 - val_accuracy: 0.5069\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9728 - accuracy: 0.5321 - val_loss: 1.0046 - val_accuracy: 0.5064\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9729 - accuracy: 0.5323 - val_loss: 1.0048 - val_accuracy: 0.5086\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9729 - accuracy: 0.5330 - val_loss: 1.0047 - val_accuracy: 0.5069\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 563us/step - loss: 0.9728 - accuracy: 0.5324 - val_loss: 1.0053 - val_accuracy: 0.5077\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9728 - accuracy: 0.5318 - val_loss: 1.0045 - val_accuracy: 0.5073\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9729 - accuracy: 0.5318 - val_loss: 1.0046 - val_accuracy: 0.5073\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 610us/step - loss: 0.9728 - accuracy: 0.5317 - val_loss: 1.0047 - val_accuracy: 0.5069\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9728 - accuracy: 0.5321 - val_loss: 1.0046 - val_accuracy: 0.5069\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9729 - accuracy: 0.5317 - val_loss: 1.0045 - val_accuracy: 0.5069\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9729 - accuracy: 0.5319 - val_loss: 1.0046 - val_accuracy: 0.5069\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9729 - accuracy: 0.5307 - val_loss: 1.0044 - val_accuracy: 0.5086\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 660us/step - loss: 0.9732 - accuracy: 0.5328 - val_loss: 1.0042 - val_accuracy: 0.5086\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9729 - accuracy: 0.5325 - val_loss: 1.0049 - val_accuracy: 0.5077\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9729 - accuracy: 0.5304 - val_loss: 1.0049 - val_accuracy: 0.5069\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9731 - accuracy: 0.5317 - val_loss: 1.0047 - val_accuracy: 0.5082\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9727 - accuracy: 0.5314 - val_loss: 1.0046 - val_accuracy: 0.5069\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9727 - accuracy: 0.5312 - val_loss: 1.0043 - val_accuracy: 0.5069\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9729 - accuracy: 0.5315 - val_loss: 1.0045 - val_accuracy: 0.5064\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9728 - accuracy: 0.5312 - val_loss: 1.0049 - val_accuracy: 0.5069\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9731 - accuracy: 0.5323 - val_loss: 1.0045 - val_accuracy: 0.5064\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 339us/step - loss: 0.9725 - accuracy: 0.5318\n",
      "Accuracy : 0.5317956209182739\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0045 - accuracy: 0.5064\n",
      "Accuracy : 0.506418764591217\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0795 - accuracy: 0.4589 - val_loss: 1.0728 - val_accuracy: 0.4599\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 729us/step - loss: 1.0641 - accuracy: 0.4584 - val_loss: 1.0521 - val_accuracy: 0.4595\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0279 - accuracy: 0.4588 - val_loss: 1.0184 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0106 - accuracy: 0.4591 - val_loss: 1.0155 - val_accuracy: 0.4591\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0078 - accuracy: 0.4591 - val_loss: 1.0138 - val_accuracy: 0.4591\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 1.0057 - accuracy: 0.4638 - val_loss: 1.0122 - val_accuracy: 0.4763\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0027 - accuracy: 0.4927 - val_loss: 1.0081 - val_accuracy: 0.5108\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9930 - accuracy: 0.5243 - val_loss: 1.0000 - val_accuracy: 0.5268\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9883 - accuracy: 0.5305 - val_loss: 0.9983 - val_accuracy: 0.5286\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9874 - accuracy: 0.5304 - val_loss: 0.9973 - val_accuracy: 0.5277\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9863 - accuracy: 0.5300 - val_loss: 0.9966 - val_accuracy: 0.5272\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9855 - accuracy: 0.5301 - val_loss: 0.9959 - val_accuracy: 0.5294\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9847 - accuracy: 0.5303 - val_loss: 0.9951 - val_accuracy: 0.5286\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9841 - accuracy: 0.5303 - val_loss: 0.9945 - val_accuracy: 0.5286\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9831 - accuracy: 0.5304 - val_loss: 0.9936 - val_accuracy: 0.5290\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9824 - accuracy: 0.5305 - val_loss: 0.9927 - val_accuracy: 0.5281\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9818 - accuracy: 0.5302 - val_loss: 0.9920 - val_accuracy: 0.5290\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9814 - accuracy: 0.5307 - val_loss: 0.9912 - val_accuracy: 0.5303\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9806 - accuracy: 0.5308 - val_loss: 0.9906 - val_accuracy: 0.5281\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9800 - accuracy: 0.5301 - val_loss: 0.9899 - val_accuracy: 0.5299\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9793 - accuracy: 0.5302 - val_loss: 0.9893 - val_accuracy: 0.5286\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9788 - accuracy: 0.5301 - val_loss: 0.9888 - val_accuracy: 0.5281\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9785 - accuracy: 0.5301 - val_loss: 0.9883 - val_accuracy: 0.5303\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9782 - accuracy: 0.5302 - val_loss: 0.9881 - val_accuracy: 0.5286\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9782 - accuracy: 0.5308 - val_loss: 0.9877 - val_accuracy: 0.5299\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9777 - accuracy: 0.5302 - val_loss: 0.9874 - val_accuracy: 0.5303\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9775 - accuracy: 0.5299 - val_loss: 0.9872 - val_accuracy: 0.5294\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9776 - accuracy: 0.5299 - val_loss: 0.9872 - val_accuracy: 0.5294\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9775 - accuracy: 0.5307 - val_loss: 0.9868 - val_accuracy: 0.5303\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9771 - accuracy: 0.5303 - val_loss: 0.9866 - val_accuracy: 0.5303\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9770 - accuracy: 0.5302 - val_loss: 0.9864 - val_accuracy: 0.5303\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9768 - accuracy: 0.5307 - val_loss: 0.9862 - val_accuracy: 0.5299\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9767 - accuracy: 0.5302 - val_loss: 0.9861 - val_accuracy: 0.5290\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9767 - accuracy: 0.5302 - val_loss: 0.9861 - val_accuracy: 0.5294\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9767 - accuracy: 0.5318 - val_loss: 0.9859 - val_accuracy: 0.5272\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9765 - accuracy: 0.5305 - val_loss: 0.9858 - val_accuracy: 0.5290\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9764 - accuracy: 0.5303 - val_loss: 0.9857 - val_accuracy: 0.5303\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9763 - accuracy: 0.5303 - val_loss: 0.9857 - val_accuracy: 0.5290\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9764 - accuracy: 0.5301 - val_loss: 0.9856 - val_accuracy: 0.5290\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9764 - accuracy: 0.5305 - val_loss: 0.9855 - val_accuracy: 0.5290\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9763 - accuracy: 0.5303 - val_loss: 0.9855 - val_accuracy: 0.5290\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 571us/step - loss: 0.9762 - accuracy: 0.5305 - val_loss: 0.9855 - val_accuracy: 0.5294\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9764 - accuracy: 0.5303 - val_loss: 0.9855 - val_accuracy: 0.5290\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9770 - accuracy: 0.5302 - val_loss: 0.9855 - val_accuracy: 0.5263\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9762 - accuracy: 0.5298 - val_loss: 0.9852 - val_accuracy: 0.5294\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9761 - accuracy: 0.5295 - val_loss: 0.9852 - val_accuracy: 0.5290\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5303 - val_loss: 0.9852 - val_accuracy: 0.5290\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9850 - val_accuracy: 0.5272\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9760 - accuracy: 0.5303 - val_loss: 0.9851 - val_accuracy: 0.5272\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9851 - val_accuracy: 0.5303\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9763 - accuracy: 0.5298 - val_loss: 0.9850 - val_accuracy: 0.5303\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9760 - accuracy: 0.5295 - val_loss: 0.9850 - val_accuracy: 0.5272\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9759 - accuracy: 0.5300 - val_loss: 0.9851 - val_accuracy: 0.5263\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9760 - accuracy: 0.5302 - val_loss: 0.9850 - val_accuracy: 0.5290\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9761 - accuracy: 0.5306 - val_loss: 0.9850 - val_accuracy: 0.5290\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9760 - accuracy: 0.5312 - val_loss: 0.9850 - val_accuracy: 0.5277\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9760 - accuracy: 0.5301 - val_loss: 0.9850 - val_accuracy: 0.5277\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9759 - accuracy: 0.5293 - val_loss: 0.9850 - val_accuracy: 0.5303\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9760 - accuracy: 0.5292 - val_loss: 0.9851 - val_accuracy: 0.5290\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9763 - accuracy: 0.5300 - val_loss: 0.9850 - val_accuracy: 0.5272\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9760 - accuracy: 0.5284 - val_loss: 0.9850 - val_accuracy: 0.5272\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9759 - accuracy: 0.5301 - val_loss: 0.9849 - val_accuracy: 0.5272\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9766 - accuracy: 0.5274 - val_loss: 0.9851 - val_accuracy: 0.5281\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9762 - accuracy: 0.5295 - val_loss: 0.9851 - val_accuracy: 0.5263\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9760 - accuracy: 0.5293 - val_loss: 0.9852 - val_accuracy: 0.5272\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9759 - accuracy: 0.5295 - val_loss: 0.9850 - val_accuracy: 0.5263\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9757 - accuracy: 0.5296 - val_loss: 0.9850 - val_accuracy: 0.5268\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9758 - accuracy: 0.5296 - val_loss: 0.9850 - val_accuracy: 0.5290\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9760 - accuracy: 0.5306 - val_loss: 0.9850 - val_accuracy: 0.5286\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 0.9850 - val_accuracy: 0.5290\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9757 - accuracy: 0.5302 - val_loss: 0.9851 - val_accuracy: 0.5290\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9851 - val_accuracy: 0.5272\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9756 - accuracy: 0.5290 - val_loss: 0.9851 - val_accuracy: 0.5299\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9760 - accuracy: 0.5301 - val_loss: 0.9850 - val_accuracy: 0.5299\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9756 - accuracy: 0.5304 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9756 - accuracy: 0.5289 - val_loss: 0.9849 - val_accuracy: 0.5272\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9756 - accuracy: 0.5288 - val_loss: 0.9850 - val_accuracy: 0.5268\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9849 - val_accuracy: 0.5272\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9755 - accuracy: 0.5302 - val_loss: 0.9851 - val_accuracy: 0.5286\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9850 - val_accuracy: 0.5277\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9755 - accuracy: 0.5293 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9755 - accuracy: 0.5294 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9757 - accuracy: 0.5281 - val_loss: 0.9848 - val_accuracy: 0.5281\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9754 - accuracy: 0.5292 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9754 - accuracy: 0.5294 - val_loss: 0.9849 - val_accuracy: 0.5272\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 696us/step - loss: 0.9753 - accuracy: 0.5293 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9755 - accuracy: 0.5296 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9754 - accuracy: 0.5290 - val_loss: 0.9849 - val_accuracy: 0.5272\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9753 - accuracy: 0.5293 - val_loss: 0.9849 - val_accuracy: 0.5272\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9755 - accuracy: 0.5294 - val_loss: 0.9848 - val_accuracy: 0.5272\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9753 - accuracy: 0.5290 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9754 - accuracy: 0.5300 - val_loss: 0.9849 - val_accuracy: 0.5294\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9753 - accuracy: 0.5296 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9753 - accuracy: 0.5293 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9753 - accuracy: 0.5291 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9754 - accuracy: 0.5280 - val_loss: 0.9847 - val_accuracy: 0.5277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9754 - accuracy: 0.5294 - val_loss: 0.9847 - val_accuracy: 0.5277\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9752 - accuracy: 0.5297 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9752 - accuracy: 0.5304 - val_loss: 0.9849 - val_accuracy: 0.5286\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9752 - accuracy: 0.5303 - val_loss: 0.9848 - val_accuracy: 0.5272\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9756 - accuracy: 0.5301 - val_loss: 0.9847 - val_accuracy: 0.5277\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9847 - val_accuracy: 0.5272\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9753 - accuracy: 0.5287 - val_loss: 0.9847 - val_accuracy: 0.5281\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9751 - accuracy: 0.5295 - val_loss: 0.9847 - val_accuracy: 0.5299\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9754 - accuracy: 0.5301 - val_loss: 0.9848 - val_accuracy: 0.5272\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9752 - accuracy: 0.5284 - val_loss: 0.9848 - val_accuracy: 0.5272\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9758 - accuracy: 0.5290 - val_loss: 0.9848 - val_accuracy: 0.5272\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9751 - accuracy: 0.5297 - val_loss: 0.9847 - val_accuracy: 0.5272\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9753 - accuracy: 0.5292 - val_loss: 0.9847 - val_accuracy: 0.5290\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9752 - accuracy: 0.5286 - val_loss: 0.9847 - val_accuracy: 0.5272\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9752 - accuracy: 0.5294 - val_loss: 0.9847 - val_accuracy: 0.5272\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9847 - val_accuracy: 0.5272\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9751 - accuracy: 0.5287 - val_loss: 0.9846 - val_accuracy: 0.5272\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9750 - accuracy: 0.5294 - val_loss: 0.9847 - val_accuracy: 0.5277\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9750 - accuracy: 0.5303 - val_loss: 0.9847 - val_accuracy: 0.5281\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9749 - accuracy: 0.5296 - val_loss: 0.9847 - val_accuracy: 0.5277\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9750 - accuracy: 0.5287 - val_loss: 0.9846 - val_accuracy: 0.5277\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9750 - accuracy: 0.5291 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9847 - val_accuracy: 0.5277\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9749 - accuracy: 0.5300 - val_loss: 0.9848 - val_accuracy: 0.5281\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9752 - accuracy: 0.5315 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9749 - accuracy: 0.5289 - val_loss: 0.9849 - val_accuracy: 0.5303\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9752 - accuracy: 0.5311 - val_loss: 0.9848 - val_accuracy: 0.5281\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9751 - accuracy: 0.5286 - val_loss: 0.9847 - val_accuracy: 0.5277\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9748 - accuracy: 0.5291 - val_loss: 0.9847 - val_accuracy: 0.5281\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9748 - accuracy: 0.5295 - val_loss: 0.9849 - val_accuracy: 0.5303\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9751 - accuracy: 0.5310 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9749 - accuracy: 0.5296 - val_loss: 0.9848 - val_accuracy: 0.5281\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9748 - accuracy: 0.5302 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9747 - accuracy: 0.5301 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9851 - val_accuracy: 0.5299\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9749 - accuracy: 0.5300 - val_loss: 0.9850 - val_accuracy: 0.5281\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9747 - accuracy: 0.5310 - val_loss: 0.9853 - val_accuracy: 0.5277\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9750 - accuracy: 0.5300 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9748 - accuracy: 0.5299 - val_loss: 0.9850 - val_accuracy: 0.5299\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9750 - accuracy: 0.5302 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9747 - accuracy: 0.5299 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9747 - accuracy: 0.5296 - val_loss: 0.9850 - val_accuracy: 0.5303\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 694us/step - loss: 0.9748 - accuracy: 0.5314 - val_loss: 0.9850 - val_accuracy: 0.5277\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9748 - accuracy: 0.5290 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9851 - val_accuracy: 0.5277\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9750 - accuracy: 0.5297 - val_loss: 0.9850 - val_accuracy: 0.5277\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9747 - accuracy: 0.5303 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9746 - accuracy: 0.5298 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9748 - accuracy: 0.5302 - val_loss: 0.9849 - val_accuracy: 0.5286\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9747 - accuracy: 0.5297 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9749 - accuracy: 0.5301 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9850 - val_accuracy: 0.5277\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9745 - accuracy: 0.5299 - val_loss: 0.9849 - val_accuracy: 0.5299\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9747 - accuracy: 0.5295 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 603us/step - loss: 0.9746 - accuracy: 0.5304 - val_loss: 0.9853 - val_accuracy: 0.5290\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9748 - accuracy: 0.5299 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9745 - accuracy: 0.5301 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9746 - accuracy: 0.5293 - val_loss: 0.9848 - val_accuracy: 0.5272\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9745 - accuracy: 0.5304 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9850 - val_accuracy: 0.5281\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9746 - accuracy: 0.5299 - val_loss: 0.9850 - val_accuracy: 0.5277\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9745 - accuracy: 0.5292 - val_loss: 0.9850 - val_accuracy: 0.5290\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9744 - accuracy: 0.5299 - val_loss: 0.9851 - val_accuracy: 0.5290\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9746 - accuracy: 0.5300 - val_loss: 0.9849 - val_accuracy: 0.5290\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9745 - accuracy: 0.5297 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9751 - accuracy: 0.5305 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9746 - accuracy: 0.5298 - val_loss: 0.9848 - val_accuracy: 0.5281\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9744 - accuracy: 0.5298 - val_loss: 0.9848 - val_accuracy: 0.5277\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9743 - accuracy: 0.5304 - val_loss: 0.9850 - val_accuracy: 0.5281\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9744 - accuracy: 0.5293 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9745 - accuracy: 0.5297 - val_loss: 0.9850 - val_accuracy: 0.5281\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9745 - accuracy: 0.5301 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9744 - accuracy: 0.5300 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9745 - accuracy: 0.5299 - val_loss: 0.9849 - val_accuracy: 0.5290\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9750 - accuracy: 0.5308 - val_loss: 0.9849 - val_accuracy: 0.5281\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9743 - accuracy: 0.5303 - val_loss: 0.9850 - val_accuracy: 0.5290\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9749 - accuracy: 0.5301 - val_loss: 0.9848 - val_accuracy: 0.5281\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9748 - accuracy: 0.5285 - val_loss: 0.9849 - val_accuracy: 0.5290\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9748 - accuracy: 0.5274 - val_loss: 0.9849 - val_accuracy: 0.5299\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9744 - accuracy: 0.5298 - val_loss: 0.9849 - val_accuracy: 0.5277\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9744 - accuracy: 0.5300 - val_loss: 0.9850 - val_accuracy: 0.5281\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9743 - accuracy: 0.5305 - val_loss: 0.9851 - val_accuracy: 0.5277\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9747 - accuracy: 0.5299 - val_loss: 0.9854 - val_accuracy: 0.5281\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9853 - val_accuracy: 0.5277\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9745 - accuracy: 0.5303 - val_loss: 0.9853 - val_accuracy: 0.5281\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9744 - accuracy: 0.5288 - val_loss: 0.9851 - val_accuracy: 0.5281\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9742 - accuracy: 0.5305 - val_loss: 0.9851 - val_accuracy: 0.5281\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9742 - accuracy: 0.5300 - val_loss: 0.9852 - val_accuracy: 0.5281\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9742 - accuracy: 0.5296 - val_loss: 0.9851 - val_accuracy: 0.5281\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9743 - accuracy: 0.5291 - val_loss: 0.9850 - val_accuracy: 0.5290\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9742 - accuracy: 0.5301 - val_loss: 0.9852 - val_accuracy: 0.5290\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9742 - accuracy: 0.5301 - val_loss: 0.9851 - val_accuracy: 0.5281\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9851 - val_accuracy: 0.5277\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9742 - accuracy: 0.5299 - val_loss: 0.9852 - val_accuracy: 0.5281\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9743 - accuracy: 0.5299 - val_loss: 0.9850 - val_accuracy: 0.5281\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9743 - accuracy: 0.5303 - val_loss: 0.9850 - val_accuracy: 0.5277\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9743 - accuracy: 0.5301 - val_loss: 0.9851 - val_accuracy: 0.5290\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9741 - accuracy: 0.5300 - val_loss: 0.9851 - val_accuracy: 0.5277\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9742 - accuracy: 0.5297 - val_loss: 0.9851 - val_accuracy: 0.5281\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9742 - accuracy: 0.5296 - val_loss: 0.9853 - val_accuracy: 0.5290\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 331us/step - loss: 0.9741 - accuracy: 0.5300\n",
      "Accuracy : 0.530025064945221\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9853 - accuracy: 0.5290\n",
      "Accuracy : 0.528995156288147\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 2.8085 - accuracy: 0.2463 - val_loss: 2.3788 - val_accuracy: 0.2444\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 759us/step - loss: 2.2129 - accuracy: 0.2474 - val_loss: 1.8756 - val_accuracy: 0.2519\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.7806 - accuracy: 0.2510 - val_loss: 1.5446 - val_accuracy: 0.2603\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 1.5048 - accuracy: 0.2641 - val_loss: 1.3452 - val_accuracy: 0.2714\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 1.3354 - accuracy: 0.2788 - val_loss: 1.2285 - val_accuracy: 0.2807\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.2311 - accuracy: 0.2875 - val_loss: 1.1579 - val_accuracy: 0.2908\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.1689 - accuracy: 0.2888 - val_loss: 1.1161 - val_accuracy: 0.2922\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.1290 - accuracy: 0.2931 - val_loss: 1.0896 - val_accuracy: 0.2931\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 1.1032 - accuracy: 0.2957 - val_loss: 1.0725 - val_accuracy: 0.2948\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 599us/step - loss: 1.0856 - accuracy: 0.2929 - val_loss: 1.0621 - val_accuracy: 0.2966\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 1.0748 - accuracy: 0.3024 - val_loss: 1.0550 - val_accuracy: 0.3063\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0672 - accuracy: 0.3127 - val_loss: 1.0500 - val_accuracy: 0.3245\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0616 - accuracy: 0.3242 - val_loss: 1.0463 - val_accuracy: 0.3351\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0573 - accuracy: 0.3399 - val_loss: 1.0432 - val_accuracy: 0.3586\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0536 - accuracy: 0.3593 - val_loss: 1.0404 - val_accuracy: 0.3780\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 1.0505 - accuracy: 0.3720 - val_loss: 1.0383 - val_accuracy: 0.3966\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.0477 - accuracy: 0.3945 - val_loss: 1.0355 - val_accuracy: 0.4307\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0441 - accuracy: 0.4375 - val_loss: 1.0315 - val_accuracy: 0.4586\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0402 - accuracy: 0.4553 - val_loss: 1.0272 - val_accuracy: 0.4591\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 1.0336 - accuracy: 0.4585 - val_loss: 1.0196 - val_accuracy: 0.4591\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 1.0237 - accuracy: 0.4585 - val_loss: 1.0118 - val_accuracy: 0.4591\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.0138 - accuracy: 0.4585 - val_loss: 1.0078 - val_accuracy: 0.4591\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0091 - accuracy: 0.4585 - val_loss: 1.0058 - val_accuracy: 0.4591\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 1.0068 - accuracy: 0.4585 - val_loss: 1.0049 - val_accuracy: 0.4591\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0054 - accuracy: 0.4585 - val_loss: 1.0041 - val_accuracy: 0.4591\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0045 - accuracy: 0.4585 - val_loss: 1.0038 - val_accuracy: 0.4591\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0038 - accuracy: 0.4585 - val_loss: 1.0036 - val_accuracy: 0.4591\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0031 - accuracy: 0.4585 - val_loss: 1.0036 - val_accuracy: 0.4591\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 1.0028 - accuracy: 0.4585 - val_loss: 1.0032 - val_accuracy: 0.4591\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0024 - accuracy: 0.4588 - val_loss: 1.0030 - val_accuracy: 0.4595\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 1.0020 - accuracy: 0.4619 - val_loss: 1.0024 - val_accuracy: 0.4648\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 1.0015 - accuracy: 0.4757 - val_loss: 1.0021 - val_accuracy: 0.4790\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 1.0012 - accuracy: 0.4861 - val_loss: 1.0017 - val_accuracy: 0.4923\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 1.0008 - accuracy: 0.4929 - val_loss: 1.0012 - val_accuracy: 0.5011\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 1.0002 - accuracy: 0.5053 - val_loss: 1.0008 - val_accuracy: 0.5184\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9996 - accuracy: 0.5097 - val_loss: 0.9999 - val_accuracy: 0.5255\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9987 - accuracy: 0.5163 - val_loss: 0.9990 - val_accuracy: 0.5374\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9977 - accuracy: 0.5230 - val_loss: 0.9976 - val_accuracy: 0.5396\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9962 - accuracy: 0.5241 - val_loss: 0.9958 - val_accuracy: 0.5401\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9942 - accuracy: 0.5274 - val_loss: 0.9930 - val_accuracy: 0.5405\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9918 - accuracy: 0.5299 - val_loss: 0.9899 - val_accuracy: 0.5405\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9886 - accuracy: 0.5284 - val_loss: 0.9870 - val_accuracy: 0.5396\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9859 - accuracy: 0.5278 - val_loss: 0.9845 - val_accuracy: 0.5405\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9841 - accuracy: 0.5279 - val_loss: 0.9826 - val_accuracy: 0.5401\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9828 - accuracy: 0.5284 - val_loss: 0.9813 - val_accuracy: 0.5396\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9819 - accuracy: 0.5291 - val_loss: 0.9803 - val_accuracy: 0.5401\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9811 - accuracy: 0.5295 - val_loss: 0.9795 - val_accuracy: 0.5405\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9806 - accuracy: 0.5278 - val_loss: 0.9788 - val_accuracy: 0.5396\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9799 - accuracy: 0.5287 - val_loss: 0.9780 - val_accuracy: 0.5405\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9796 - accuracy: 0.5303 - val_loss: 0.9777 - val_accuracy: 0.5405\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9794 - accuracy: 0.5303 - val_loss: 0.9775 - val_accuracy: 0.5418\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9788 - accuracy: 0.5289 - val_loss: 0.9774 - val_accuracy: 0.5378\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9786 - accuracy: 0.5301 - val_loss: 0.9767 - val_accuracy: 0.5396\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9783 - accuracy: 0.5303 - val_loss: 0.9766 - val_accuracy: 0.5378\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9782 - accuracy: 0.5302 - val_loss: 0.9763 - val_accuracy: 0.5378\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9780 - accuracy: 0.5299 - val_loss: 0.9761 - val_accuracy: 0.5383\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9779 - accuracy: 0.5305 - val_loss: 0.9760 - val_accuracy: 0.5396\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9777 - accuracy: 0.5298 - val_loss: 0.9760 - val_accuracy: 0.5396\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9777 - accuracy: 0.5311 - val_loss: 0.9760 - val_accuracy: 0.5387\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9777 - accuracy: 0.5304 - val_loss: 0.9755 - val_accuracy: 0.5392\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 565us/step - loss: 0.9775 - accuracy: 0.5304 - val_loss: 0.9759 - val_accuracy: 0.5387\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5305 - val_loss: 0.9756 - val_accuracy: 0.5387\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9775 - accuracy: 0.5278 - val_loss: 0.9757 - val_accuracy: 0.5387\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5304 - val_loss: 0.9758 - val_accuracy: 0.5387\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9756 - val_accuracy: 0.5387\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9773 - accuracy: 0.5284 - val_loss: 0.9759 - val_accuracy: 0.5387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9771 - accuracy: 0.5297 - val_loss: 0.9754 - val_accuracy: 0.5387\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9772 - accuracy: 0.5293 - val_loss: 0.9752 - val_accuracy: 0.5387\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9772 - accuracy: 0.5305 - val_loss: 0.9755 - val_accuracy: 0.5392\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9774 - accuracy: 0.5302 - val_loss: 0.9753 - val_accuracy: 0.5392\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9772 - accuracy: 0.5299 - val_loss: 0.9752 - val_accuracy: 0.5392\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9775 - accuracy: 0.5302 - val_loss: 0.9750 - val_accuracy: 0.5392\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9772 - accuracy: 0.5304 - val_loss: 0.9756 - val_accuracy: 0.5392\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9770 - accuracy: 0.5295 - val_loss: 0.9754 - val_accuracy: 0.5392\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9770 - accuracy: 0.5296 - val_loss: 0.9752 - val_accuracy: 0.5405\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9769 - accuracy: 0.5301 - val_loss: 0.9755 - val_accuracy: 0.5392\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5298 - val_loss: 0.9757 - val_accuracy: 0.5387\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9755 - val_accuracy: 0.5387\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9770 - accuracy: 0.5293 - val_loss: 0.9755 - val_accuracy: 0.5387\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5304 - val_loss: 0.9750 - val_accuracy: 0.5392\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9770 - accuracy: 0.5303 - val_loss: 0.9746 - val_accuracy: 0.5405\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9770 - accuracy: 0.5295 - val_loss: 0.9751 - val_accuracy: 0.5405\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9772 - accuracy: 0.5305 - val_loss: 0.9749 - val_accuracy: 0.5401\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9770 - accuracy: 0.5307 - val_loss: 0.9746 - val_accuracy: 0.5383\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9768 - accuracy: 0.5301 - val_loss: 0.9745 - val_accuracy: 0.5401\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9772 - accuracy: 0.5309 - val_loss: 0.9750 - val_accuracy: 0.5401\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9771 - accuracy: 0.5299 - val_loss: 0.9747 - val_accuracy: 0.5405\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9769 - accuracy: 0.5302 - val_loss: 0.9747 - val_accuracy: 0.5392\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9768 - accuracy: 0.5287 - val_loss: 0.9748 - val_accuracy: 0.5392\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9770 - accuracy: 0.5309 - val_loss: 0.9748 - val_accuracy: 0.5392\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9768 - accuracy: 0.5310 - val_loss: 0.9746 - val_accuracy: 0.5405\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9771 - accuracy: 0.5303 - val_loss: 0.9746 - val_accuracy: 0.5383\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9774 - accuracy: 0.5268 - val_loss: 0.9754 - val_accuracy: 0.5387\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9770 - accuracy: 0.5300 - val_loss: 0.9749 - val_accuracy: 0.5392\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9769 - accuracy: 0.5277 - val_loss: 0.9749 - val_accuracy: 0.5392\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9768 - accuracy: 0.5291 - val_loss: 0.9748 - val_accuracy: 0.5387\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9767 - accuracy: 0.5281 - val_loss: 0.9748 - val_accuracy: 0.5387\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9768 - accuracy: 0.5294 - val_loss: 0.9748 - val_accuracy: 0.5383\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9769 - accuracy: 0.5302 - val_loss: 0.9748 - val_accuracy: 0.5387\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9769 - accuracy: 0.5299 - val_loss: 0.9753 - val_accuracy: 0.5401\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 0.9768 - accuracy: 0.5305 - val_loss: 0.9749 - val_accuracy: 0.5387\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9768 - accuracy: 0.5306 - val_loss: 0.9749 - val_accuracy: 0.5392\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9767 - accuracy: 0.5304 - val_loss: 0.9747 - val_accuracy: 0.5401\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9768 - accuracy: 0.5305 - val_loss: 0.9747 - val_accuracy: 0.5396\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9744 - val_accuracy: 0.5387\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9770 - accuracy: 0.5293 - val_loss: 0.9751 - val_accuracy: 0.5392\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9769 - accuracy: 0.5302 - val_loss: 0.9748 - val_accuracy: 0.5392\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9766 - accuracy: 0.5305 - val_loss: 0.9750 - val_accuracy: 0.5387\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9746 - val_accuracy: 0.5392\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9766 - accuracy: 0.5285 - val_loss: 0.9746 - val_accuracy: 0.5396\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9766 - accuracy: 0.5301 - val_loss: 0.9746 - val_accuracy: 0.5396\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9766 - accuracy: 0.5285 - val_loss: 0.9744 - val_accuracy: 0.5383\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9768 - accuracy: 0.5297 - val_loss: 0.9745 - val_accuracy: 0.5392\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9766 - accuracy: 0.5298 - val_loss: 0.9743 - val_accuracy: 0.5392\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9743 - val_accuracy: 0.5387\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9768 - accuracy: 0.5298 - val_loss: 0.9747 - val_accuracy: 0.5401\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9767 - accuracy: 0.5309 - val_loss: 0.9746 - val_accuracy: 0.5396\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9745 - val_accuracy: 0.5387\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9766 - accuracy: 0.5307 - val_loss: 0.9744 - val_accuracy: 0.5387\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9766 - accuracy: 0.5304 - val_loss: 0.9742 - val_accuracy: 0.5392\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9765 - accuracy: 0.5298 - val_loss: 0.9744 - val_accuracy: 0.5387\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9765 - accuracy: 0.5299 - val_loss: 0.9743 - val_accuracy: 0.5392\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9764 - accuracy: 0.5299 - val_loss: 0.9746 - val_accuracy: 0.5396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9766 - accuracy: 0.5301 - val_loss: 0.9744 - val_accuracy: 0.5387\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9765 - accuracy: 0.5286 - val_loss: 0.9744 - val_accuracy: 0.5392\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9765 - accuracy: 0.5311 - val_loss: 0.9742 - val_accuracy: 0.5383\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9764 - accuracy: 0.5288 - val_loss: 0.9742 - val_accuracy: 0.5396\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9766 - accuracy: 0.5303 - val_loss: 0.9744 - val_accuracy: 0.5396\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9765 - accuracy: 0.5300 - val_loss: 0.9745 - val_accuracy: 0.5396\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9764 - accuracy: 0.5301 - val_loss: 0.9741 - val_accuracy: 0.5396\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9765 - accuracy: 0.5299 - val_loss: 0.9742 - val_accuracy: 0.5396\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9765 - accuracy: 0.5285 - val_loss: 0.9742 - val_accuracy: 0.5383\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9763 - accuracy: 0.5297 - val_loss: 0.9741 - val_accuracy: 0.5387\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9764 - accuracy: 0.5282 - val_loss: 0.9741 - val_accuracy: 0.5392\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9764 - accuracy: 0.5298 - val_loss: 0.9743 - val_accuracy: 0.5387\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9745 - val_accuracy: 0.5387\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9764 - accuracy: 0.5299 - val_loss: 0.9742 - val_accuracy: 0.5396\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9763 - accuracy: 0.5295 - val_loss: 0.9742 - val_accuracy: 0.5387\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9763 - accuracy: 0.5305 - val_loss: 0.9738 - val_accuracy: 0.5392\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9764 - accuracy: 0.5314 - val_loss: 0.9739 - val_accuracy: 0.5392\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9763 - accuracy: 0.5287 - val_loss: 0.9739 - val_accuracy: 0.5387\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9763 - accuracy: 0.5302 - val_loss: 0.9740 - val_accuracy: 0.5396\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9762 - accuracy: 0.5298 - val_loss: 0.9741 - val_accuracy: 0.5392\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9763 - accuracy: 0.5302 - val_loss: 0.9743 - val_accuracy: 0.5396\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9762 - accuracy: 0.5287 - val_loss: 0.9743 - val_accuracy: 0.5396\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9763 - accuracy: 0.5310 - val_loss: 0.9739 - val_accuracy: 0.5392\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9763 - accuracy: 0.5289 - val_loss: 0.9739 - val_accuracy: 0.5383\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9766 - accuracy: 0.5272 - val_loss: 0.9741 - val_accuracy: 0.5387\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 660us/step - loss: 0.9762 - accuracy: 0.5291 - val_loss: 0.9741 - val_accuracy: 0.5387\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9762 - accuracy: 0.5289 - val_loss: 0.9741 - val_accuracy: 0.5396\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 673us/step - loss: 0.9762 - accuracy: 0.5306 - val_loss: 0.9738 - val_accuracy: 0.5387\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9762 - accuracy: 0.5288 - val_loss: 0.9740 - val_accuracy: 0.5383\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9764 - accuracy: 0.5309 - val_loss: 0.9740 - val_accuracy: 0.5392\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9764 - accuracy: 0.5306 - val_loss: 0.9735 - val_accuracy: 0.5392\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9764 - accuracy: 0.5292 - val_loss: 0.9741 - val_accuracy: 0.5387\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9763 - accuracy: 0.5287 - val_loss: 0.9738 - val_accuracy: 0.5392\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9763 - accuracy: 0.5294 - val_loss: 0.9739 - val_accuracy: 0.5396\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9761 - accuracy: 0.5290 - val_loss: 0.9736 - val_accuracy: 0.5392\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9761 - accuracy: 0.5286 - val_loss: 0.9738 - val_accuracy: 0.5405\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9762 - accuracy: 0.5295 - val_loss: 0.9736 - val_accuracy: 0.5392\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9762 - accuracy: 0.5298 - val_loss: 0.9739 - val_accuracy: 0.5392\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9765 - accuracy: 0.5273 - val_loss: 0.9744 - val_accuracy: 0.5405\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9737 - val_accuracy: 0.5405\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9760 - accuracy: 0.5293 - val_loss: 0.9738 - val_accuracy: 0.5392\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9761 - accuracy: 0.5287 - val_loss: 0.9736 - val_accuracy: 0.5405\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9762 - accuracy: 0.5289 - val_loss: 0.9737 - val_accuracy: 0.5396\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9761 - accuracy: 0.5273 - val_loss: 0.9738 - val_accuracy: 0.5392\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9761 - accuracy: 0.5289 - val_loss: 0.9734 - val_accuracy: 0.5405\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9761 - accuracy: 0.5285 - val_loss: 0.9736 - val_accuracy: 0.5401\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9761 - accuracy: 0.5281 - val_loss: 0.9739 - val_accuracy: 0.5396\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9765 - accuracy: 0.5296 - val_loss: 0.9740 - val_accuracy: 0.5392\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9763 - accuracy: 0.5293 - val_loss: 0.9737 - val_accuracy: 0.5387\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9763 - accuracy: 0.5292 - val_loss: 0.9735 - val_accuracy: 0.5405\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9760 - accuracy: 0.5289 - val_loss: 0.9735 - val_accuracy: 0.5392\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9763 - accuracy: 0.5294 - val_loss: 0.9735 - val_accuracy: 0.5396\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9761 - accuracy: 0.5288 - val_loss: 0.9737 - val_accuracy: 0.5401\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9761 - accuracy: 0.5292 - val_loss: 0.9737 - val_accuracy: 0.5396\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9761 - accuracy: 0.5287 - val_loss: 0.9736 - val_accuracy: 0.5396\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9761 - accuracy: 0.5291 - val_loss: 0.9736 - val_accuracy: 0.5387\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5292 - val_loss: 0.9736 - val_accuracy: 0.5405\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9759 - accuracy: 0.5288 - val_loss: 0.9736 - val_accuracy: 0.5401\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9763 - accuracy: 0.5299 - val_loss: 0.9737 - val_accuracy: 0.5396\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9765 - accuracy: 0.5264 - val_loss: 0.9740 - val_accuracy: 0.5401\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9761 - accuracy: 0.5283 - val_loss: 0.9739 - val_accuracy: 0.5396\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9760 - accuracy: 0.5282 - val_loss: 0.9738 - val_accuracy: 0.5396\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9761 - accuracy: 0.5295 - val_loss: 0.9737 - val_accuracy: 0.5392\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9759 - accuracy: 0.5274 - val_loss: 0.9738 - val_accuracy: 0.5396\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9760 - accuracy: 0.5294 - val_loss: 0.9738 - val_accuracy: 0.5401\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9761 - accuracy: 0.5292 - val_loss: 0.9739 - val_accuracy: 0.5396\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 563us/step - loss: 0.9761 - accuracy: 0.5288 - val_loss: 0.9740 - val_accuracy: 0.5401\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9763 - accuracy: 0.5296 - val_loss: 0.9743 - val_accuracy: 0.5405\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9762 - accuracy: 0.5294 - val_loss: 0.9743 - val_accuracy: 0.5392\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9760 - accuracy: 0.5296 - val_loss: 0.9738 - val_accuracy: 0.5405\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9758 - accuracy: 0.5289 - val_loss: 0.9735 - val_accuracy: 0.5401\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9764 - accuracy: 0.5286 - val_loss: 0.9735 - val_accuracy: 0.5401\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9762 - accuracy: 0.5307 - val_loss: 0.9735 - val_accuracy: 0.5387\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9759 - accuracy: 0.5293 - val_loss: 0.9737 - val_accuracy: 0.5396\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 568us/step - loss: 0.9760 - accuracy: 0.5291 - val_loss: 0.9734 - val_accuracy: 0.5401\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9761 - accuracy: 0.5288 - val_loss: 0.9735 - val_accuracy: 0.5392\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9732 - val_accuracy: 0.5401\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 335us/step - loss: 0.9757 - accuracy: 0.5291\n",
      "Accuracy : 0.5291398167610168\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9732 - accuracy: 0.5401\n",
      "Accuracy : 0.5400619506835938\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.8327 - accuracy: 0.3094 - val_loss: 1.7145 - val_accuracy: 0.2382\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 1.5713 - accuracy: 0.2580 - val_loss: 1.4879 - val_accuracy: 0.2103\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.3974 - accuracy: 0.2337 - val_loss: 1.3376 - val_accuracy: 0.2032\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.2847 - accuracy: 0.2190 - val_loss: 1.2391 - val_accuracy: 0.2067\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.2093 - accuracy: 0.2214 - val_loss: 1.1747 - val_accuracy: 0.2196\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.1604 - accuracy: 0.2274 - val_loss: 1.1346 - val_accuracy: 0.2306\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 1.1285 - accuracy: 0.2396 - val_loss: 1.1105 - val_accuracy: 0.2421\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.1083 - accuracy: 0.2538 - val_loss: 1.0960 - val_accuracy: 0.2638\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0960 - accuracy: 0.2666 - val_loss: 1.0875 - val_accuracy: 0.2802\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0883 - accuracy: 0.2806 - val_loss: 1.0819 - val_accuracy: 0.2886\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0830 - accuracy: 0.2887 - val_loss: 1.0779 - val_accuracy: 0.2895\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 1.0794 - accuracy: 0.2910 - val_loss: 1.0754 - val_accuracy: 0.2900\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0766 - accuracy: 0.2930 - val_loss: 1.0732 - val_accuracy: 0.2913\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 1.0744 - accuracy: 0.2940 - val_loss: 1.0713 - val_accuracy: 0.2913\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 1.0727 - accuracy: 0.2951 - val_loss: 1.0698 - val_accuracy: 0.2913\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0712 - accuracy: 0.2960 - val_loss: 1.0686 - val_accuracy: 0.2917\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 1.0701 - accuracy: 0.2966 - val_loss: 1.0675 - val_accuracy: 0.2917\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0691 - accuracy: 0.2982 - val_loss: 1.0667 - val_accuracy: 0.2944\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.0683 - accuracy: 0.3055 - val_loss: 1.0661 - val_accuracy: 0.3108\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 1.0676 - accuracy: 0.3302 - val_loss: 1.0653 - val_accuracy: 0.3528\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0669 - accuracy: 0.3588 - val_loss: 1.0647 - val_accuracy: 0.3931\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 1.0664 - accuracy: 0.3857 - val_loss: 1.0642 - val_accuracy: 0.4290\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0659 - accuracy: 0.4244 - val_loss: 1.0638 - val_accuracy: 0.4613\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 1.0652 - accuracy: 0.4521 - val_loss: 1.0632 - val_accuracy: 0.4874\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 1.0645 - accuracy: 0.4595 - val_loss: 1.0623 - val_accuracy: 0.5011\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.0636 - accuracy: 0.4823 - val_loss: 1.0618 - val_accuracy: 0.5153\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0625 - accuracy: 0.5019 - val_loss: 1.0605 - val_accuracy: 0.5356\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.0605 - accuracy: 0.5216 - val_loss: 1.0583 - val_accuracy: 0.5423\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 1.0568 - accuracy: 0.5273 - val_loss: 1.0534 - val_accuracy: 0.5347\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 1.0470 - accuracy: 0.5222 - val_loss: 1.0352 - val_accuracy: 0.5184\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 1.0149 - accuracy: 0.5132 - val_loss: 0.9846 - val_accuracy: 0.5166\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9909 - accuracy: 0.5190 - val_loss: 0.9729 - val_accuracy: 0.5321\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9870 - accuracy: 0.5233 - val_loss: 0.9702 - val_accuracy: 0.5290\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9854 - accuracy: 0.5235 - val_loss: 0.9687 - val_accuracy: 0.5356\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 584us/step - loss: 0.9846 - accuracy: 0.5256 - val_loss: 0.9672 - val_accuracy: 0.5370\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9837 - accuracy: 0.5266 - val_loss: 0.9664 - val_accuracy: 0.5365\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9833 - accuracy: 0.5238 - val_loss: 0.9659 - val_accuracy: 0.5343\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9827 - accuracy: 0.5253 - val_loss: 0.9658 - val_accuracy: 0.5356\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9823 - accuracy: 0.5259 - val_loss: 0.9654 - val_accuracy: 0.5303\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9819 - accuracy: 0.5288 - val_loss: 0.9648 - val_accuracy: 0.5343\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9819 - accuracy: 0.5284 - val_loss: 0.9644 - val_accuracy: 0.5365\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9814 - accuracy: 0.5285 - val_loss: 0.9644 - val_accuracy: 0.5343\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9812 - accuracy: 0.5279 - val_loss: 0.9642 - val_accuracy: 0.5334\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9811 - accuracy: 0.5261 - val_loss: 0.9641 - val_accuracy: 0.5330\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9810 - accuracy: 0.5268 - val_loss: 0.9639 - val_accuracy: 0.5378\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9807 - accuracy: 0.5268 - val_loss: 0.9638 - val_accuracy: 0.5343\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9807 - accuracy: 0.5285 - val_loss: 0.9637 - val_accuracy: 0.5370\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9805 - accuracy: 0.5285 - val_loss: 0.9634 - val_accuracy: 0.5374\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9804 - accuracy: 0.5291 - val_loss: 0.9634 - val_accuracy: 0.5378\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9804 - accuracy: 0.5294 - val_loss: 0.9632 - val_accuracy: 0.5374\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9802 - accuracy: 0.5291 - val_loss: 0.9629 - val_accuracy: 0.5370\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9802 - accuracy: 0.5296 - val_loss: 0.9631 - val_accuracy: 0.5378\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9802 - accuracy: 0.5293 - val_loss: 0.9626 - val_accuracy: 0.5370\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9802 - accuracy: 0.5277 - val_loss: 0.9630 - val_accuracy: 0.5356\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9800 - accuracy: 0.5295 - val_loss: 0.9627 - val_accuracy: 0.5374\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9801 - accuracy: 0.5287 - val_loss: 0.9627 - val_accuracy: 0.5374\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9802 - accuracy: 0.5296 - val_loss: 0.9628 - val_accuracy: 0.5374\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9799 - accuracy: 0.5296 - val_loss: 0.9627 - val_accuracy: 0.5374\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9800 - accuracy: 0.5287 - val_loss: 0.9626 - val_accuracy: 0.5370\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9799 - accuracy: 0.5295 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9799 - accuracy: 0.5294 - val_loss: 0.9630 - val_accuracy: 0.5370\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9800 - accuracy: 0.5296 - val_loss: 0.9626 - val_accuracy: 0.5370\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9797 - accuracy: 0.5296 - val_loss: 0.9625 - val_accuracy: 0.5370\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9797 - accuracy: 0.5288 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9797 - accuracy: 0.5296 - val_loss: 0.9626 - val_accuracy: 0.5370\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9798 - accuracy: 0.5289 - val_loss: 0.9625 - val_accuracy: 0.5383\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9796 - accuracy: 0.5294 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9796 - accuracy: 0.5294 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9797 - accuracy: 0.5296 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9798 - accuracy: 0.5283 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9795 - accuracy: 0.5296 - val_loss: 0.9625 - val_accuracy: 0.5370\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9798 - accuracy: 0.5298 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9797 - accuracy: 0.5286 - val_loss: 0.9623 - val_accuracy: 0.5365\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9795 - accuracy: 0.5293 - val_loss: 0.9623 - val_accuracy: 0.5370\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9795 - accuracy: 0.5292 - val_loss: 0.9624 - val_accuracy: 0.5374\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9795 - accuracy: 0.5293 - val_loss: 0.9624 - val_accuracy: 0.5383\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9794 - accuracy: 0.5296 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9793 - accuracy: 0.5293 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9794 - accuracy: 0.5297 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9795 - accuracy: 0.5298 - val_loss: 0.9623 - val_accuracy: 0.5370\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9795 - accuracy: 0.5294 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9793 - accuracy: 0.5295 - val_loss: 0.9620 - val_accuracy: 0.5392\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9795 - accuracy: 0.5289 - val_loss: 0.9619 - val_accuracy: 0.5383\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9793 - accuracy: 0.5295 - val_loss: 0.9621 - val_accuracy: 0.5392\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9794 - accuracy: 0.5286 - val_loss: 0.9624 - val_accuracy: 0.5387\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9797 - accuracy: 0.5293 - val_loss: 0.9627 - val_accuracy: 0.5387\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9793 - accuracy: 0.5284 - val_loss: 0.9623 - val_accuracy: 0.5370\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9792 - accuracy: 0.5295 - val_loss: 0.9623 - val_accuracy: 0.5370\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9791 - accuracy: 0.5300 - val_loss: 0.9623 - val_accuracy: 0.5387\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9793 - accuracy: 0.5294 - val_loss: 0.9621 - val_accuracy: 0.5374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9791 - accuracy: 0.5296 - val_loss: 0.9621 - val_accuracy: 0.5370\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9791 - accuracy: 0.5296 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9791 - accuracy: 0.5299 - val_loss: 0.9619 - val_accuracy: 0.5374\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9791 - accuracy: 0.5298 - val_loss: 0.9620 - val_accuracy: 0.5387\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9790 - accuracy: 0.5296 - val_loss: 0.9621 - val_accuracy: 0.5370\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9791 - accuracy: 0.5296 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9791 - accuracy: 0.5294 - val_loss: 0.9620 - val_accuracy: 0.5392\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9790 - accuracy: 0.5298 - val_loss: 0.9618 - val_accuracy: 0.5387\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9790 - accuracy: 0.5292 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9790 - accuracy: 0.5296 - val_loss: 0.9619 - val_accuracy: 0.5370\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9790 - accuracy: 0.5290 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9789 - accuracy: 0.5293 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9791 - accuracy: 0.5294 - val_loss: 0.9621 - val_accuracy: 0.5370\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9791 - accuracy: 0.5293 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9789 - accuracy: 0.5295 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9792 - accuracy: 0.5278 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9790 - accuracy: 0.5296 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9788 - accuracy: 0.5297 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9788 - accuracy: 0.5293 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9788 - accuracy: 0.5296 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9790 - accuracy: 0.5295 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9790 - accuracy: 0.5293 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9787 - accuracy: 0.5292 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9788 - accuracy: 0.5298 - val_loss: 0.9619 - val_accuracy: 0.5387\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9786 - accuracy: 0.5291 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9786 - accuracy: 0.5296 - val_loss: 0.9620 - val_accuracy: 0.5378\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9787 - accuracy: 0.5293 - val_loss: 0.9621 - val_accuracy: 0.5378\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9788 - accuracy: 0.5298 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9786 - accuracy: 0.5297 - val_loss: 0.9619 - val_accuracy: 0.5370\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9786 - accuracy: 0.5297 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9786 - accuracy: 0.5294 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9786 - accuracy: 0.5291 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9786 - accuracy: 0.5296 - val_loss: 0.9618 - val_accuracy: 0.5392\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9788 - accuracy: 0.5296 - val_loss: 0.9617 - val_accuracy: 0.5383\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9787 - accuracy: 0.5299 - val_loss: 0.9619 - val_accuracy: 0.5370\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9785 - accuracy: 0.5295 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9785 - accuracy: 0.5296 - val_loss: 0.9617 - val_accuracy: 0.5392\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9786 - accuracy: 0.5300 - val_loss: 0.9617 - val_accuracy: 0.5365\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9788 - accuracy: 0.5283 - val_loss: 0.9617 - val_accuracy: 0.5365\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9785 - accuracy: 0.5297 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9784 - accuracy: 0.5291 - val_loss: 0.9616 - val_accuracy: 0.5374\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9787 - accuracy: 0.5287 - val_loss: 0.9616 - val_accuracy: 0.5374\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9784 - accuracy: 0.5300 - val_loss: 0.9617 - val_accuracy: 0.5374\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9784 - accuracy: 0.5295 - val_loss: 0.9616 - val_accuracy: 0.5378\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9784 - accuracy: 0.5289 - val_loss: 0.9617 - val_accuracy: 0.5383\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9785 - accuracy: 0.5300 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9783 - accuracy: 0.5295 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9783 - accuracy: 0.5295 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9783 - accuracy: 0.5295 - val_loss: 0.9619 - val_accuracy: 0.5370\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9785 - accuracy: 0.5292 - val_loss: 0.9615 - val_accuracy: 0.5374\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9782 - accuracy: 0.5295 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9784 - accuracy: 0.5289 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9783 - accuracy: 0.5299 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9782 - accuracy: 0.5286 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9783 - accuracy: 0.5300 - val_loss: 0.9616 - val_accuracy: 0.5370\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9782 - accuracy: 0.5281 - val_loss: 0.9617 - val_accuracy: 0.5374\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 610us/step - loss: 0.9784 - accuracy: 0.5296 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9783 - accuracy: 0.5296 - val_loss: 0.9619 - val_accuracy: 0.5370\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9781 - accuracy: 0.5301 - val_loss: 0.9618 - val_accuracy: 0.5392\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9783 - accuracy: 0.5289 - val_loss: 0.9616 - val_accuracy: 0.5370\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9782 - accuracy: 0.5295 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9783 - accuracy: 0.5291 - val_loss: 0.9616 - val_accuracy: 0.5370\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9782 - accuracy: 0.5298 - val_loss: 0.9617 - val_accuracy: 0.5392\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9782 - accuracy: 0.5296 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9780 - accuracy: 0.5299 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9780 - accuracy: 0.5298 - val_loss: 0.9615 - val_accuracy: 0.5392\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9781 - accuracy: 0.5297 - val_loss: 0.9615 - val_accuracy: 0.5396\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9781 - accuracy: 0.5298 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9781 - accuracy: 0.5295 - val_loss: 0.9616 - val_accuracy: 0.5378\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9780 - accuracy: 0.5291 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9781 - accuracy: 0.5283 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9781 - accuracy: 0.5284 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9780 - accuracy: 0.5298 - val_loss: 0.9616 - val_accuracy: 0.5370\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9780 - accuracy: 0.5295 - val_loss: 0.9616 - val_accuracy: 0.5370\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9780 - accuracy: 0.5288 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9779 - accuracy: 0.5300 - val_loss: 0.9616 - val_accuracy: 0.5387\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9780 - accuracy: 0.5294 - val_loss: 0.9616 - val_accuracy: 0.5370\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9780 - accuracy: 0.5294 - val_loss: 0.9615 - val_accuracy: 0.5383\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9784 - accuracy: 0.5301 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9780 - accuracy: 0.5295 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9778 - accuracy: 0.5297 - val_loss: 0.9616 - val_accuracy: 0.5370\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9779 - accuracy: 0.5295 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9779 - accuracy: 0.5296 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9782 - accuracy: 0.5297 - val_loss: 0.9613 - val_accuracy: 0.5370\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9778 - accuracy: 0.5297 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9781 - accuracy: 0.5284 - val_loss: 0.9616 - val_accuracy: 0.5356\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9781 - accuracy: 0.5296 - val_loss: 0.9613 - val_accuracy: 0.5370\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9779 - accuracy: 0.5293 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9778 - accuracy: 0.5298 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9777 - accuracy: 0.5295 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9777 - accuracy: 0.5300 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9781 - accuracy: 0.5297 - val_loss: 0.9614 - val_accuracy: 0.5365\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9779 - accuracy: 0.5289 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9777 - accuracy: 0.5296 - val_loss: 0.9614 - val_accuracy: 0.5383\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9778 - accuracy: 0.5296 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9779 - accuracy: 0.5289 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9777 - accuracy: 0.5296 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9777 - accuracy: 0.5300 - val_loss: 0.9614 - val_accuracy: 0.5374\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9776 - accuracy: 0.5295 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9778 - accuracy: 0.5293 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9777 - accuracy: 0.5295 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9779 - accuracy: 0.5288 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9777 - accuracy: 0.5294 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9778 - accuracy: 0.5295 - val_loss: 0.9613 - val_accuracy: 0.5392\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9776 - accuracy: 0.5296 - val_loss: 0.9613 - val_accuracy: 0.5370\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9779 - accuracy: 0.5296 - val_loss: 0.9612 - val_accuracy: 0.5370\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9776 - accuracy: 0.5294 - val_loss: 0.9612 - val_accuracy: 0.5370\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9776 - accuracy: 0.5295 - val_loss: 0.9613 - val_accuracy: 0.5370\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9776 - accuracy: 0.5296 - val_loss: 0.9613 - val_accuracy: 0.5370\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 338us/step - loss: 0.9774 - accuracy: 0.5298\n",
      "Accuracy : 0.5297791957855225\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9613 - accuracy: 0.5370\n",
      "Accuracy : 0.5369632840156555\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.2630 - accuracy: 0.2475 - val_loss: 1.1818 - val_accuracy: 0.2351\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 1.1389 - accuracy: 0.2711 - val_loss: 1.1048 - val_accuracy: 0.2926\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 613us/step - loss: 1.0903 - accuracy: 0.3346 - val_loss: 1.0804 - val_accuracy: 0.3382\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0707 - accuracy: 0.3979 - val_loss: 1.0564 - val_accuracy: 0.4219\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 1.0483 - accuracy: 0.4703 - val_loss: 1.0205 - val_accuracy: 0.5356\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 1.0239 - accuracy: 0.5194 - val_loss: 0.9937 - val_accuracy: 0.5401\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 1.0023 - accuracy: 0.5229 - val_loss: 0.9663 - val_accuracy: 0.5396\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9879 - accuracy: 0.5263 - val_loss: 0.9514 - val_accuracy: 0.5418\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9831 - accuracy: 0.5280 - val_loss: 0.9470 - val_accuracy: 0.5414\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 0.9818 - accuracy: 0.5274 - val_loss: 0.9461 - val_accuracy: 0.5480\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 567us/step - loss: 0.9815 - accuracy: 0.5291 - val_loss: 0.9449 - val_accuracy: 0.5449\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9814 - accuracy: 0.5269 - val_loss: 0.9442 - val_accuracy: 0.5418\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9813 - accuracy: 0.5272 - val_loss: 0.9446 - val_accuracy: 0.5476\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9812 - accuracy: 0.5284 - val_loss: 0.9442 - val_accuracy: 0.5476\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9811 - accuracy: 0.5292 - val_loss: 0.9440 - val_accuracy: 0.5476\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9811 - accuracy: 0.5284 - val_loss: 0.9438 - val_accuracy: 0.5423\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9810 - accuracy: 0.5281 - val_loss: 0.9434 - val_accuracy: 0.5418\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9811 - accuracy: 0.5273 - val_loss: 0.9437 - val_accuracy: 0.5476\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9808 - accuracy: 0.5276 - val_loss: 0.9438 - val_accuracy: 0.5494\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9808 - accuracy: 0.5285 - val_loss: 0.9438 - val_accuracy: 0.5498\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9811 - accuracy: 0.5280 - val_loss: 0.9433 - val_accuracy: 0.5440\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9808 - accuracy: 0.5271 - val_loss: 0.9442 - val_accuracy: 0.5485\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9811 - accuracy: 0.5286 - val_loss: 0.9438 - val_accuracy: 0.5489\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9808 - accuracy: 0.5281 - val_loss: 0.9439 - val_accuracy: 0.5485\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9810 - accuracy: 0.5286 - val_loss: 0.9439 - val_accuracy: 0.5498\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9810 - accuracy: 0.5287 - val_loss: 0.9435 - val_accuracy: 0.5471\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9807 - accuracy: 0.5285 - val_loss: 0.9437 - val_accuracy: 0.5494\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9808 - accuracy: 0.5283 - val_loss: 0.9432 - val_accuracy: 0.5471\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9808 - accuracy: 0.5286 - val_loss: 0.9435 - val_accuracy: 0.5476\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9808 - accuracy: 0.5275 - val_loss: 0.9435 - val_accuracy: 0.5485\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9806 - accuracy: 0.5290 - val_loss: 0.9430 - val_accuracy: 0.5471\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9810 - accuracy: 0.5285 - val_loss: 0.9435 - val_accuracy: 0.5471\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9809 - accuracy: 0.5284 - val_loss: 0.9437 - val_accuracy: 0.5476\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9808 - accuracy: 0.5285 - val_loss: 0.9439 - val_accuracy: 0.5494\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9808 - accuracy: 0.5283 - val_loss: 0.9438 - val_accuracy: 0.5485\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9808 - accuracy: 0.5292 - val_loss: 0.9446 - val_accuracy: 0.5494\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9808 - accuracy: 0.5293 - val_loss: 0.9438 - val_accuracy: 0.5471\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9810 - accuracy: 0.5294 - val_loss: 0.9432 - val_accuracy: 0.5436\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9807 - accuracy: 0.5275 - val_loss: 0.9437 - val_accuracy: 0.5440\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9806 - accuracy: 0.5269 - val_loss: 0.9432 - val_accuracy: 0.5463\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 568us/step - loss: 0.9807 - accuracy: 0.5288 - val_loss: 0.9432 - val_accuracy: 0.5440\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9806 - accuracy: 0.5285 - val_loss: 0.9433 - val_accuracy: 0.5471\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9805 - accuracy: 0.5285 - val_loss: 0.9434 - val_accuracy: 0.5463\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9806 - accuracy: 0.5288 - val_loss: 0.9435 - val_accuracy: 0.5476\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9807 - accuracy: 0.5283 - val_loss: 0.9437 - val_accuracy: 0.5471\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9805 - accuracy: 0.5287 - val_loss: 0.9431 - val_accuracy: 0.5463\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9806 - accuracy: 0.5278 - val_loss: 0.9434 - val_accuracy: 0.5480\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9807 - accuracy: 0.5280 - val_loss: 0.9432 - val_accuracy: 0.5476\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9808 - accuracy: 0.5281 - val_loss: 0.9433 - val_accuracy: 0.5401\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9805 - accuracy: 0.5273 - val_loss: 0.9439 - val_accuracy: 0.5494\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9806 - accuracy: 0.5282 - val_loss: 0.9433 - val_accuracy: 0.5449\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9804 - accuracy: 0.5275 - val_loss: 0.9437 - val_accuracy: 0.5489\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9806 - accuracy: 0.5287 - val_loss: 0.9431 - val_accuracy: 0.5449\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9804 - accuracy: 0.5265 - val_loss: 0.9436 - val_accuracy: 0.5485\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9804 - accuracy: 0.5272 - val_loss: 0.9435 - val_accuracy: 0.5471\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9807 - accuracy: 0.5292 - val_loss: 0.9434 - val_accuracy: 0.5471\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9804 - accuracy: 0.5271 - val_loss: 0.9434 - val_accuracy: 0.5471\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9804 - accuracy: 0.5273 - val_loss: 0.9437 - val_accuracy: 0.5471\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9804 - accuracy: 0.5282 - val_loss: 0.9430 - val_accuracy: 0.5449\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 560us/step - loss: 0.9807 - accuracy: 0.5279 - val_loss: 0.9432 - val_accuracy: 0.5476\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9804 - accuracy: 0.5287 - val_loss: 0.9429 - val_accuracy: 0.5463\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9805 - accuracy: 0.5277 - val_loss: 0.9431 - val_accuracy: 0.5440\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9808 - accuracy: 0.5283 - val_loss: 0.9441 - val_accuracy: 0.5476\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9805 - accuracy: 0.5287 - val_loss: 0.9437 - val_accuracy: 0.5471\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9810 - accuracy: 0.5296 - val_loss: 0.9443 - val_accuracy: 0.5463\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9804 - accuracy: 0.5273 - val_loss: 0.9439 - val_accuracy: 0.5401\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9804 - accuracy: 0.5272 - val_loss: 0.9435 - val_accuracy: 0.5440\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9808 - accuracy: 0.5282 - val_loss: 0.9440 - val_accuracy: 0.5418\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9803 - accuracy: 0.5280 - val_loss: 0.9433 - val_accuracy: 0.5418\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9805 - accuracy: 0.5275 - val_loss: 0.9431 - val_accuracy: 0.5409\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9806 - accuracy: 0.5251 - val_loss: 0.9433 - val_accuracy: 0.5401\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9804 - accuracy: 0.5261 - val_loss: 0.9436 - val_accuracy: 0.5463\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9803 - accuracy: 0.5261 - val_loss: 0.9436 - val_accuracy: 0.5423\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9803 - accuracy: 0.5265 - val_loss: 0.9434 - val_accuracy: 0.5463\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9808 - accuracy: 0.5280 - val_loss: 0.9440 - val_accuracy: 0.5471\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9806 - accuracy: 0.5283 - val_loss: 0.9440 - val_accuracy: 0.5401\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9803 - accuracy: 0.5273 - val_loss: 0.9437 - val_accuracy: 0.5463\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9803 - accuracy: 0.5288 - val_loss: 0.9434 - val_accuracy: 0.5449\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9803 - accuracy: 0.5269 - val_loss: 0.9436 - val_accuracy: 0.5476\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9802 - accuracy: 0.5290 - val_loss: 0.9431 - val_accuracy: 0.5401\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9803 - accuracy: 0.5276 - val_loss: 0.9434 - val_accuracy: 0.5480\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9804 - accuracy: 0.5293 - val_loss: 0.9436 - val_accuracy: 0.5476\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9803 - accuracy: 0.5269 - val_loss: 0.9432 - val_accuracy: 0.5463\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9802 - accuracy: 0.5277 - val_loss: 0.9432 - val_accuracy: 0.5440\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9803 - accuracy: 0.5273 - val_loss: 0.9432 - val_accuracy: 0.5471\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9803 - accuracy: 0.5278 - val_loss: 0.9431 - val_accuracy: 0.5440\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9802 - accuracy: 0.5276 - val_loss: 0.9429 - val_accuracy: 0.5463\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9803 - accuracy: 0.5282 - val_loss: 0.9431 - val_accuracy: 0.5476\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9802 - accuracy: 0.5275 - val_loss: 0.9428 - val_accuracy: 0.5396\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9801 - accuracy: 0.5260 - val_loss: 0.9436 - val_accuracy: 0.5489\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9800 - accuracy: 0.5285 - val_loss: 0.9431 - val_accuracy: 0.5440\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9803 - accuracy: 0.5280 - val_loss: 0.9432 - val_accuracy: 0.5463\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9801 - accuracy: 0.5281 - val_loss: 0.9431 - val_accuracy: 0.5476\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9803 - accuracy: 0.5288 - val_loss: 0.9431 - val_accuracy: 0.5440\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9802 - accuracy: 0.5265 - val_loss: 0.9438 - val_accuracy: 0.5498\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9803 - accuracy: 0.5283 - val_loss: 0.9432 - val_accuracy: 0.5463\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9801 - accuracy: 0.5285 - val_loss: 0.9427 - val_accuracy: 0.5396\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9804 - accuracy: 0.5263 - val_loss: 0.9431 - val_accuracy: 0.5440\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9801 - accuracy: 0.5287 - val_loss: 0.9431 - val_accuracy: 0.5476\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9803 - accuracy: 0.5283 - val_loss: 0.9440 - val_accuracy: 0.5494\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9806 - accuracy: 0.5285 - val_loss: 0.9432 - val_accuracy: 0.5476\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9801 - accuracy: 0.5285 - val_loss: 0.9436 - val_accuracy: 0.5463\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9801 - accuracy: 0.5280 - val_loss: 0.9429 - val_accuracy: 0.5463\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9800 - accuracy: 0.5283 - val_loss: 0.9427 - val_accuracy: 0.5449\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9800 - accuracy: 0.5283 - val_loss: 0.9430 - val_accuracy: 0.5471\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9801 - accuracy: 0.5275 - val_loss: 0.9428 - val_accuracy: 0.5449\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9800 - accuracy: 0.5280 - val_loss: 0.9433 - val_accuracy: 0.5480\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9804 - accuracy: 0.5296 - val_loss: 0.9428 - val_accuracy: 0.5423\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9801 - accuracy: 0.5257 - val_loss: 0.9436 - val_accuracy: 0.5485\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9805 - accuracy: 0.5277 - val_loss: 0.9435 - val_accuracy: 0.5427\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9800 - accuracy: 0.5285 - val_loss: 0.9430 - val_accuracy: 0.5405\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9800 - accuracy: 0.5267 - val_loss: 0.9432 - val_accuracy: 0.5458\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9800 - accuracy: 0.5281 - val_loss: 0.9431 - val_accuracy: 0.5463\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9800 - accuracy: 0.5289 - val_loss: 0.9432 - val_accuracy: 0.5467\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9800 - accuracy: 0.5288 - val_loss: 0.9432 - val_accuracy: 0.5471\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9799 - accuracy: 0.5281 - val_loss: 0.9427 - val_accuracy: 0.5449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9799 - accuracy: 0.5288 - val_loss: 0.9427 - val_accuracy: 0.5427\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9799 - accuracy: 0.5269 - val_loss: 0.9437 - val_accuracy: 0.5480\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9807 - accuracy: 0.5280 - val_loss: 0.9436 - val_accuracy: 0.5480\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9807 - accuracy: 0.5279 - val_loss: 0.9427 - val_accuracy: 0.5409\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9800 - accuracy: 0.5285 - val_loss: 0.9427 - val_accuracy: 0.5405\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 568us/step - loss: 0.9801 - accuracy: 0.5267 - val_loss: 0.9428 - val_accuracy: 0.5449\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9799 - accuracy: 0.5264 - val_loss: 0.9428 - val_accuracy: 0.5427\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9799 - accuracy: 0.5280 - val_loss: 0.9430 - val_accuracy: 0.5449\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9800 - accuracy: 0.5284 - val_loss: 0.9432 - val_accuracy: 0.5463\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9801 - accuracy: 0.5278 - val_loss: 0.9431 - val_accuracy: 0.5427\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9798 - accuracy: 0.5269 - val_loss: 0.9434 - val_accuracy: 0.5471\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9801 - accuracy: 0.5286 - val_loss: 0.9436 - val_accuracy: 0.5471\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9800 - accuracy: 0.5289 - val_loss: 0.9429 - val_accuracy: 0.5405\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9800 - accuracy: 0.5268 - val_loss: 0.9430 - val_accuracy: 0.5449\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9798 - accuracy: 0.5272 - val_loss: 0.9429 - val_accuracy: 0.5458\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9798 - accuracy: 0.5277 - val_loss: 0.9427 - val_accuracy: 0.5405\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9799 - accuracy: 0.5285 - val_loss: 0.9428 - val_accuracy: 0.5449\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9800 - accuracy: 0.5268 - val_loss: 0.9426 - val_accuracy: 0.5427\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9799 - accuracy: 0.5260 - val_loss: 0.9429 - val_accuracy: 0.5427\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9797 - accuracy: 0.5269 - val_loss: 0.9431 - val_accuracy: 0.5463\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9799 - accuracy: 0.5290 - val_loss: 0.9432 - val_accuracy: 0.5458\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9800 - accuracy: 0.5290 - val_loss: 0.9428 - val_accuracy: 0.5449\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9799 - accuracy: 0.5282 - val_loss: 0.9427 - val_accuracy: 0.5449\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9798 - accuracy: 0.5275 - val_loss: 0.9432 - val_accuracy: 0.5480\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9800 - accuracy: 0.5285 - val_loss: 0.9433 - val_accuracy: 0.5476\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9797 - accuracy: 0.5289 - val_loss: 0.9434 - val_accuracy: 0.5480\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9797 - accuracy: 0.5288 - val_loss: 0.9430 - val_accuracy: 0.5463\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9798 - accuracy: 0.5281 - val_loss: 0.9428 - val_accuracy: 0.5449\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9798 - accuracy: 0.5280 - val_loss: 0.9429 - val_accuracy: 0.5463\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9797 - accuracy: 0.5282 - val_loss: 0.9430 - val_accuracy: 0.5463\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9798 - accuracy: 0.5286 - val_loss: 0.9430 - val_accuracy: 0.5476\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9797 - accuracy: 0.5290 - val_loss: 0.9429 - val_accuracy: 0.5467\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9801 - accuracy: 0.5282 - val_loss: 0.9428 - val_accuracy: 0.5471\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9797 - accuracy: 0.5269 - val_loss: 0.9430 - val_accuracy: 0.5449\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9798 - accuracy: 0.5276 - val_loss: 0.9429 - val_accuracy: 0.5427\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9798 - accuracy: 0.5277 - val_loss: 0.9429 - val_accuracy: 0.5449\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9796 - accuracy: 0.5281 - val_loss: 0.9429 - val_accuracy: 0.5471\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9797 - accuracy: 0.5294 - val_loss: 0.9426 - val_accuracy: 0.5445\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9797 - accuracy: 0.5268 - val_loss: 0.9428 - val_accuracy: 0.5463\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9797 - accuracy: 0.5269 - val_loss: 0.9431 - val_accuracy: 0.5471\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9798 - accuracy: 0.5284 - val_loss: 0.9428 - val_accuracy: 0.5471\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9797 - accuracy: 0.5280 - val_loss: 0.9427 - val_accuracy: 0.5463\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9796 - accuracy: 0.5278 - val_loss: 0.9427 - val_accuracy: 0.5463\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9799 - accuracy: 0.5280 - val_loss: 0.9429 - val_accuracy: 0.5476\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9800 - accuracy: 0.5289 - val_loss: 0.9434 - val_accuracy: 0.5449\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9798 - accuracy: 0.5268 - val_loss: 0.9428 - val_accuracy: 0.5427\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9797 - accuracy: 0.5261 - val_loss: 0.9428 - val_accuracy: 0.5445\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9795 - accuracy: 0.5284 - val_loss: 0.9428 - val_accuracy: 0.5463\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9795 - accuracy: 0.5284 - val_loss: 0.9425 - val_accuracy: 0.5449\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9795 - accuracy: 0.5285 - val_loss: 0.9433 - val_accuracy: 0.5476\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9798 - accuracy: 0.5283 - val_loss: 0.9427 - val_accuracy: 0.5463\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9796 - accuracy: 0.5285 - val_loss: 0.9426 - val_accuracy: 0.5471\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9795 - accuracy: 0.5278 - val_loss: 0.9428 - val_accuracy: 0.5480\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9795 - accuracy: 0.5286 - val_loss: 0.9424 - val_accuracy: 0.5458\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5282 - val_loss: 0.9423 - val_accuracy: 0.5458\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9805 - accuracy: 0.5287 - val_loss: 0.9434 - val_accuracy: 0.5449\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 592us/step - loss: 0.9797 - accuracy: 0.5282 - val_loss: 0.9430 - val_accuracy: 0.5449\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9795 - accuracy: 0.5278 - val_loss: 0.9429 - val_accuracy: 0.5387\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9797 - accuracy: 0.5272 - val_loss: 0.9425 - val_accuracy: 0.5405\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9796 - accuracy: 0.5273 - val_loss: 0.9425 - val_accuracy: 0.5445\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9794 - accuracy: 0.5282 - val_loss: 0.9425 - val_accuracy: 0.5458\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9793 - accuracy: 0.5278 - val_loss: 0.9427 - val_accuracy: 0.5471\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9794 - accuracy: 0.5283 - val_loss: 0.9428 - val_accuracy: 0.5471\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9795 - accuracy: 0.5289 - val_loss: 0.9425 - val_accuracy: 0.5449\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9794 - accuracy: 0.5283 - val_loss: 0.9422 - val_accuracy: 0.5449\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9794 - accuracy: 0.5279 - val_loss: 0.9422 - val_accuracy: 0.5445\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9795 - accuracy: 0.5278 - val_loss: 0.9425 - val_accuracy: 0.5449\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5271 - val_loss: 0.9427 - val_accuracy: 0.5476\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9795 - accuracy: 0.5283 - val_loss: 0.9424 - val_accuracy: 0.5449\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9793 - accuracy: 0.5273 - val_loss: 0.9430 - val_accuracy: 0.5480\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9795 - accuracy: 0.5280 - val_loss: 0.9428 - val_accuracy: 0.5476\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9792 - accuracy: 0.5284 - val_loss: 0.9425 - val_accuracy: 0.5471\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9793 - accuracy: 0.5280 - val_loss: 0.9427 - val_accuracy: 0.5476\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9792 - accuracy: 0.5285 - val_loss: 0.9428 - val_accuracy: 0.5476\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9792 - accuracy: 0.5284 - val_loss: 0.9426 - val_accuracy: 0.5480\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5277 - val_loss: 0.9426 - val_accuracy: 0.5476\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9794 - accuracy: 0.5285 - val_loss: 0.9425 - val_accuracy: 0.5476\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9793 - accuracy: 0.5285 - val_loss: 0.9428 - val_accuracy: 0.5476\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9794 - accuracy: 0.5286 - val_loss: 0.9427 - val_accuracy: 0.5480\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9792 - accuracy: 0.5285 - val_loss: 0.9426 - val_accuracy: 0.5471\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9792 - accuracy: 0.5282 - val_loss: 0.9426 - val_accuracy: 0.5476\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9792 - accuracy: 0.5284 - val_loss: 0.9426 - val_accuracy: 0.5467\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9794 - accuracy: 0.5270 - val_loss: 0.9424 - val_accuracy: 0.5449\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5273 - val_loss: 0.9423 - val_accuracy: 0.5405\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 332us/step - loss: 0.9791 - accuracy: 0.5273\n",
      "Accuracy : 0.5272709131240845\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9423 - accuracy: 0.5405\n",
      "Accuracy : 0.5405046343803406\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.7957 - accuracy: 0.2416 - val_loss: 1.5673 - val_accuracy: 0.2328\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 1.4700 - accuracy: 0.2395 - val_loss: 1.3358 - val_accuracy: 0.2342\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.2807 - accuracy: 0.2506 - val_loss: 1.2089 - val_accuracy: 0.2479\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 1.1832 - accuracy: 0.2661 - val_loss: 1.1470 - val_accuracy: 0.2882\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.1340 - accuracy: 0.2876 - val_loss: 1.1141 - val_accuracy: 0.2882\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.1058 - accuracy: 0.2876 - val_loss: 1.0920 - val_accuracy: 0.2882\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 1.0836 - accuracy: 0.3374 - val_loss: 1.0685 - val_accuracy: 0.5051\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 1.0459 - accuracy: 0.4946 - val_loss: 1.0194 - val_accuracy: 0.5055\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 1.0049 - accuracy: 0.5016 - val_loss: 0.9968 - val_accuracy: 0.5126\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9925 - accuracy: 0.5167 - val_loss: 0.9891 - val_accuracy: 0.5179\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9873 - accuracy: 0.5221 - val_loss: 0.9856 - val_accuracy: 0.5193\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9854 - accuracy: 0.5235 - val_loss: 0.9846 - val_accuracy: 0.5197\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9845 - accuracy: 0.5254 - val_loss: 0.9835 - val_accuracy: 0.5197\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9839 - accuracy: 0.5256 - val_loss: 0.9832 - val_accuracy: 0.5184\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9835 - accuracy: 0.5260 - val_loss: 0.9830 - val_accuracy: 0.5179\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9833 - accuracy: 0.5267 - val_loss: 0.9826 - val_accuracy: 0.5188\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9833 - accuracy: 0.5267 - val_loss: 0.9824 - val_accuracy: 0.5184\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9831 - accuracy: 0.5267 - val_loss: 0.9822 - val_accuracy: 0.5188\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9830 - accuracy: 0.5265 - val_loss: 0.9826 - val_accuracy: 0.5184\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9829 - accuracy: 0.5278 - val_loss: 0.9824 - val_accuracy: 0.5179\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9833 - accuracy: 0.5268 - val_loss: 0.9826 - val_accuracy: 0.5179\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9828 - accuracy: 0.5277 - val_loss: 0.9823 - val_accuracy: 0.5184\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9826 - accuracy: 0.5276 - val_loss: 0.9819 - val_accuracy: 0.5179\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9826 - accuracy: 0.5272 - val_loss: 0.9817 - val_accuracy: 0.5188\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9825 - accuracy: 0.5277 - val_loss: 0.9816 - val_accuracy: 0.5179\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9824 - accuracy: 0.5270 - val_loss: 0.9818 - val_accuracy: 0.5184\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9823 - accuracy: 0.5277 - val_loss: 0.9815 - val_accuracy: 0.5179\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 592us/step - loss: 0.9825 - accuracy: 0.5274 - val_loss: 0.9816 - val_accuracy: 0.5184\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9822 - accuracy: 0.5278 - val_loss: 0.9815 - val_accuracy: 0.5184\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9821 - accuracy: 0.5278 - val_loss: 0.9816 - val_accuracy: 0.5188\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9821 - accuracy: 0.5280 - val_loss: 0.9812 - val_accuracy: 0.5179\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9820 - accuracy: 0.5268 - val_loss: 0.9815 - val_accuracy: 0.5193\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9820 - accuracy: 0.5285 - val_loss: 0.9814 - val_accuracy: 0.5219\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9819 - accuracy: 0.5275 - val_loss: 0.9809 - val_accuracy: 0.5188\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9821 - accuracy: 0.5281 - val_loss: 0.9809 - val_accuracy: 0.5188\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9818 - accuracy: 0.5270 - val_loss: 0.9806 - val_accuracy: 0.5179\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9816 - accuracy: 0.5275 - val_loss: 0.9808 - val_accuracy: 0.5206\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9815 - accuracy: 0.5285 - val_loss: 0.9809 - val_accuracy: 0.5219\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9816 - accuracy: 0.5285 - val_loss: 0.9807 - val_accuracy: 0.5232\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9813 - accuracy: 0.5276 - val_loss: 0.9804 - val_accuracy: 0.5179\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9817 - accuracy: 0.5268 - val_loss: 0.9807 - val_accuracy: 0.5184\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9814 - accuracy: 0.5287 - val_loss: 0.9805 - val_accuracy: 0.5193\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9817 - accuracy: 0.5272 - val_loss: 0.9807 - val_accuracy: 0.5219\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9812 - accuracy: 0.5293 - val_loss: 0.9803 - val_accuracy: 0.5197\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9812 - accuracy: 0.5286 - val_loss: 0.9803 - val_accuracy: 0.5219\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9810 - accuracy: 0.5276 - val_loss: 0.9802 - val_accuracy: 0.5206\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9811 - accuracy: 0.5286 - val_loss: 0.9800 - val_accuracy: 0.5188\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9812 - accuracy: 0.5273 - val_loss: 0.9800 - val_accuracy: 0.5184\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9809 - accuracy: 0.5290 - val_loss: 0.9801 - val_accuracy: 0.5219\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9808 - accuracy: 0.5284 - val_loss: 0.9800 - val_accuracy: 0.5219\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9808 - accuracy: 0.5288 - val_loss: 0.9800 - val_accuracy: 0.5224\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9808 - accuracy: 0.5279 - val_loss: 0.9798 - val_accuracy: 0.5188\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9808 - accuracy: 0.5281 - val_loss: 0.9800 - val_accuracy: 0.5219\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9809 - accuracy: 0.5285 - val_loss: 0.9800 - val_accuracy: 0.5219\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9808 - accuracy: 0.5291 - val_loss: 0.9801 - val_accuracy: 0.5228\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9806 - accuracy: 0.5290 - val_loss: 0.9798 - val_accuracy: 0.5219\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9806 - accuracy: 0.5286 - val_loss: 0.9798 - val_accuracy: 0.5219\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9808 - accuracy: 0.5294 - val_loss: 0.9796 - val_accuracy: 0.5206\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9805 - accuracy: 0.5285 - val_loss: 0.9796 - val_accuracy: 0.5219\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9805 - accuracy: 0.5272 - val_loss: 0.9796 - val_accuracy: 0.5219\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9804 - accuracy: 0.5291 - val_loss: 0.9793 - val_accuracy: 0.5219\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9808 - accuracy: 0.5279 - val_loss: 0.9795 - val_accuracy: 0.5219\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9803 - accuracy: 0.5280 - val_loss: 0.9792 - val_accuracy: 0.5224\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9803 - accuracy: 0.5286 - val_loss: 0.9794 - val_accuracy: 0.5250\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9803 - accuracy: 0.5292 - val_loss: 0.9791 - val_accuracy: 0.5219\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9802 - accuracy: 0.5289 - val_loss: 0.9793 - val_accuracy: 0.5228\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9803 - accuracy: 0.5285 - val_loss: 0.9793 - val_accuracy: 0.5228\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9803 - accuracy: 0.5303 - val_loss: 0.9793 - val_accuracy: 0.5237\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9802 - accuracy: 0.5280 - val_loss: 0.9795 - val_accuracy: 0.5237\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9801 - accuracy: 0.5289 - val_loss: 0.9791 - val_accuracy: 0.5219\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9801 - accuracy: 0.5285 - val_loss: 0.9792 - val_accuracy: 0.5228\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9802 - accuracy: 0.5286 - val_loss: 0.9794 - val_accuracy: 0.5250\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9801 - accuracy: 0.5296 - val_loss: 0.9793 - val_accuracy: 0.5219\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 688us/step - loss: 0.9801 - accuracy: 0.5282 - val_loss: 0.9791 - val_accuracy: 0.5219\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9799 - accuracy: 0.5280 - val_loss: 0.9793 - val_accuracy: 0.5237\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9800 - accuracy: 0.5288 - val_loss: 0.9793 - val_accuracy: 0.5250\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9799 - accuracy: 0.5297 - val_loss: 0.9791 - val_accuracy: 0.5237\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9798 - accuracy: 0.5287 - val_loss: 0.9788 - val_accuracy: 0.5219\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9799 - accuracy: 0.5284 - val_loss: 0.9790 - val_accuracy: 0.5232\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9799 - accuracy: 0.5295 - val_loss: 0.9788 - val_accuracy: 0.5219\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9798 - accuracy: 0.5284 - val_loss: 0.9788 - val_accuracy: 0.5210\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9797 - accuracy: 0.5290 - val_loss: 0.9789 - val_accuracy: 0.5224\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9796 - accuracy: 0.5290 - val_loss: 0.9791 - val_accuracy: 0.5250\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9797 - accuracy: 0.5290 - val_loss: 0.9788 - val_accuracy: 0.5237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9796 - accuracy: 0.5284 - val_loss: 0.9788 - val_accuracy: 0.5241\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9797 - accuracy: 0.5281 - val_loss: 0.9785 - val_accuracy: 0.5210\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9795 - accuracy: 0.5285 - val_loss: 0.9788 - val_accuracy: 0.5241\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9796 - accuracy: 0.5282 - val_loss: 0.9788 - val_accuracy: 0.5228\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9796 - accuracy: 0.5279 - val_loss: 0.9785 - val_accuracy: 0.5210\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9796 - accuracy: 0.5280 - val_loss: 0.9788 - val_accuracy: 0.5224\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9797 - accuracy: 0.5286 - val_loss: 0.9786 - val_accuracy: 0.5210\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9796 - accuracy: 0.5282 - val_loss: 0.9787 - val_accuracy: 0.5241\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5276 - val_loss: 0.9785 - val_accuracy: 0.5219\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9793 - accuracy: 0.5276 - val_loss: 0.9784 - val_accuracy: 0.5210\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9794 - accuracy: 0.5282 - val_loss: 0.9785 - val_accuracy: 0.5219\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9792 - accuracy: 0.5278 - val_loss: 0.9788 - val_accuracy: 0.5250\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9803 - accuracy: 0.5283 - val_loss: 0.9788 - val_accuracy: 0.5250\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9782 - val_accuracy: 0.5210\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9794 - accuracy: 0.5277 - val_loss: 0.9786 - val_accuracy: 0.5241\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9793 - accuracy: 0.5294 - val_loss: 0.9787 - val_accuracy: 0.5250\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9793 - accuracy: 0.5295 - val_loss: 0.9784 - val_accuracy: 0.5241\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9790 - accuracy: 0.5277 - val_loss: 0.9781 - val_accuracy: 0.5210\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9791 - accuracy: 0.5286 - val_loss: 0.9786 - val_accuracy: 0.5250\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9790 - accuracy: 0.5276 - val_loss: 0.9783 - val_accuracy: 0.5219\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9789 - accuracy: 0.5283 - val_loss: 0.9781 - val_accuracy: 0.5210\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9791 - accuracy: 0.5274 - val_loss: 0.9785 - val_accuracy: 0.5237\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9797 - accuracy: 0.5286 - val_loss: 0.9785 - val_accuracy: 0.5219\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9793 - accuracy: 0.5299 - val_loss: 0.9783 - val_accuracy: 0.5219\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9789 - accuracy: 0.5273 - val_loss: 0.9780 - val_accuracy: 0.5210\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9790 - accuracy: 0.5282 - val_loss: 0.9781 - val_accuracy: 0.5228\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9788 - accuracy: 0.5290 - val_loss: 0.9781 - val_accuracy: 0.5250\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9789 - accuracy: 0.5287 - val_loss: 0.9779 - val_accuracy: 0.5224\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9788 - accuracy: 0.5302 - val_loss: 0.9778 - val_accuracy: 0.5210\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9788 - accuracy: 0.5282 - val_loss: 0.9780 - val_accuracy: 0.5228\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9789 - accuracy: 0.5297 - val_loss: 0.9783 - val_accuracy: 0.5255\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9793 - accuracy: 0.5297 - val_loss: 0.9782 - val_accuracy: 0.5237\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9789 - accuracy: 0.5289 - val_loss: 0.9780 - val_accuracy: 0.5219\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9787 - accuracy: 0.5282 - val_loss: 0.9780 - val_accuracy: 0.5228\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9787 - accuracy: 0.5272 - val_loss: 0.9780 - val_accuracy: 0.5237\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9787 - accuracy: 0.5283 - val_loss: 0.9779 - val_accuracy: 0.5237\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9786 - accuracy: 0.5283 - val_loss: 0.9778 - val_accuracy: 0.5228\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9786 - accuracy: 0.5278 - val_loss: 0.9777 - val_accuracy: 0.5228\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9786 - accuracy: 0.5282 - val_loss: 0.9778 - val_accuracy: 0.5228\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9785 - accuracy: 0.5280 - val_loss: 0.9780 - val_accuracy: 0.5250\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9786 - accuracy: 0.5296 - val_loss: 0.9777 - val_accuracy: 0.5228\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9786 - accuracy: 0.5281 - val_loss: 0.9776 - val_accuracy: 0.5219\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9785 - accuracy: 0.5296 - val_loss: 0.9781 - val_accuracy: 0.5263\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9789 - accuracy: 0.5294 - val_loss: 0.9780 - val_accuracy: 0.5250\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9784 - accuracy: 0.5275 - val_loss: 0.9780 - val_accuracy: 0.5250\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9784 - accuracy: 0.5303 - val_loss: 0.9776 - val_accuracy: 0.5237\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9784 - accuracy: 0.5277 - val_loss: 0.9775 - val_accuracy: 0.5241\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9784 - accuracy: 0.5290 - val_loss: 0.9776 - val_accuracy: 0.5237\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9784 - accuracy: 0.5285 - val_loss: 0.9774 - val_accuracy: 0.5219\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9784 - accuracy: 0.5276 - val_loss: 0.9774 - val_accuracy: 0.5210\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9787 - accuracy: 0.5268 - val_loss: 0.9777 - val_accuracy: 0.5210\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9784 - accuracy: 0.5275 - val_loss: 0.9779 - val_accuracy: 0.5224\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9783 - accuracy: 0.5274 - val_loss: 0.9777 - val_accuracy: 0.5219\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9784 - accuracy: 0.5288 - val_loss: 0.9780 - val_accuracy: 0.5250\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9782 - accuracy: 0.5288 - val_loss: 0.9777 - val_accuracy: 0.5250\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9782 - accuracy: 0.5280 - val_loss: 0.9775 - val_accuracy: 0.5224\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 656us/step - loss: 0.9781 - accuracy: 0.5283 - val_loss: 0.9773 - val_accuracy: 0.5219\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9781 - accuracy: 0.5279 - val_loss: 0.9774 - val_accuracy: 0.5224\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9780 - accuracy: 0.5284 - val_loss: 0.9774 - val_accuracy: 0.5224\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9782 - accuracy: 0.5285 - val_loss: 0.9772 - val_accuracy: 0.5210\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9780 - accuracy: 0.5294 - val_loss: 0.9776 - val_accuracy: 0.5255\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9780 - accuracy: 0.5284 - val_loss: 0.9774 - val_accuracy: 0.5237\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9781 - accuracy: 0.5293 - val_loss: 0.9771 - val_accuracy: 0.5241\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9779 - accuracy: 0.5285 - val_loss: 0.9774 - val_accuracy: 0.5250\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9779 - accuracy: 0.5282 - val_loss: 0.9775 - val_accuracy: 0.5255\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9782 - accuracy: 0.5291 - val_loss: 0.9776 - val_accuracy: 0.5255\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9781 - accuracy: 0.5298 - val_loss: 0.9774 - val_accuracy: 0.5237\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9779 - accuracy: 0.5278 - val_loss: 0.9776 - val_accuracy: 0.5255\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9779 - accuracy: 0.5296 - val_loss: 0.9771 - val_accuracy: 0.5237\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9779 - accuracy: 0.5283 - val_loss: 0.9770 - val_accuracy: 0.5228\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9779 - accuracy: 0.5279 - val_loss: 0.9770 - val_accuracy: 0.5219\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9778 - accuracy: 0.5284 - val_loss: 0.9770 - val_accuracy: 0.5224\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9777 - accuracy: 0.5291 - val_loss: 0.9772 - val_accuracy: 0.5255\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9778 - accuracy: 0.5294 - val_loss: 0.9770 - val_accuracy: 0.5250\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9778 - accuracy: 0.5284 - val_loss: 0.9774 - val_accuracy: 0.5259\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9778 - accuracy: 0.5306 - val_loss: 0.9770 - val_accuracy: 0.5237\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9778 - accuracy: 0.5281 - val_loss: 0.9772 - val_accuracy: 0.5255\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9776 - accuracy: 0.5294 - val_loss: 0.9770 - val_accuracy: 0.5250\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9777 - accuracy: 0.5285 - val_loss: 0.9769 - val_accuracy: 0.5237\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9777 - accuracy: 0.5295 - val_loss: 0.9771 - val_accuracy: 0.5263\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9778 - accuracy: 0.5300 - val_loss: 0.9771 - val_accuracy: 0.5255\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9776 - accuracy: 0.5287 - val_loss: 0.9771 - val_accuracy: 0.5263\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9778 - accuracy: 0.5294 - val_loss: 0.9771 - val_accuracy: 0.5255\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9776 - accuracy: 0.5302 - val_loss: 0.9768 - val_accuracy: 0.5237\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9769 - val_accuracy: 0.5250\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9775 - accuracy: 0.5292 - val_loss: 0.9770 - val_accuracy: 0.5237\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9772 - val_accuracy: 0.5255\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9777 - accuracy: 0.5289 - val_loss: 0.9773 - val_accuracy: 0.5263\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5289 - val_loss: 0.9771 - val_accuracy: 0.5255\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9774 - accuracy: 0.5297 - val_loss: 0.9767 - val_accuracy: 0.5250\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9768 - val_accuracy: 0.5250\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9774 - accuracy: 0.5284 - val_loss: 0.9770 - val_accuracy: 0.5255\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9774 - accuracy: 0.5296 - val_loss: 0.9772 - val_accuracy: 0.5263\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9779 - accuracy: 0.5300 - val_loss: 0.9772 - val_accuracy: 0.5250\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9769 - val_accuracy: 0.5237\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5277 - val_loss: 0.9770 - val_accuracy: 0.5250\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9773 - accuracy: 0.5290 - val_loss: 0.9767 - val_accuracy: 0.5250\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9772 - accuracy: 0.5297 - val_loss: 0.9768 - val_accuracy: 0.5250\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9774 - accuracy: 0.5301 - val_loss: 0.9770 - val_accuracy: 0.5250\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9771 - accuracy: 0.5292 - val_loss: 0.9768 - val_accuracy: 0.5228\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9766 - val_accuracy: 0.5219\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9773 - accuracy: 0.5284 - val_loss: 0.9766 - val_accuracy: 0.5228\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5282 - val_loss: 0.9766 - val_accuracy: 0.5237\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5292 - val_loss: 0.9769 - val_accuracy: 0.5250\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5308 - val_loss: 0.9771 - val_accuracy: 0.5263\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9775 - accuracy: 0.5291 - val_loss: 0.9772 - val_accuracy: 0.5255\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9772 - accuracy: 0.5289 - val_loss: 0.9769 - val_accuracy: 0.5250\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9773 - accuracy: 0.5290 - val_loss: 0.9769 - val_accuracy: 0.5250\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9770 - val_accuracy: 0.5255\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9773 - accuracy: 0.5290 - val_loss: 0.9769 - val_accuracy: 0.5228\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9773 - accuracy: 0.5280 - val_loss: 0.9769 - val_accuracy: 0.5250\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9770 - accuracy: 0.5290 - val_loss: 0.9767 - val_accuracy: 0.5237\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 594us/step - loss: 0.9771 - accuracy: 0.5288 - val_loss: 0.9765 - val_accuracy: 0.5237\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9772 - accuracy: 0.5288 - val_loss: 0.9767 - val_accuracy: 0.5255\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9770 - accuracy: 0.5296 - val_loss: 0.9768 - val_accuracy: 0.5263\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9775 - accuracy: 0.5294 - val_loss: 0.9768 - val_accuracy: 0.5250\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 336us/step - loss: 0.9768 - accuracy: 0.5293\n",
      "Accuracy : 0.5293365716934204\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9768 - accuracy: 0.5250\n",
      "Accuracy : 0.5250110626220703\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.6786 - accuracy: 0.4027 - val_loss: 1.4227 - val_accuracy: 0.4661\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 1.2874 - accuracy: 0.4719 - val_loss: 1.1749 - val_accuracy: 0.5042\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 1.1252 - accuracy: 0.4996 - val_loss: 1.0819 - val_accuracy: 0.5188\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0713 - accuracy: 0.5115 - val_loss: 1.0498 - val_accuracy: 0.5290\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 1.0484 - accuracy: 0.5159 - val_loss: 1.0287 - val_accuracy: 0.5303\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 1.0304 - accuracy: 0.5162 - val_loss: 1.0104 - val_accuracy: 0.5330\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 1.0147 - accuracy: 0.5238 - val_loss: 0.9953 - val_accuracy: 0.5343\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.0025 - accuracy: 0.5272 - val_loss: 0.9837 - val_accuracy: 0.5370\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9936 - accuracy: 0.5282 - val_loss: 0.9757 - val_accuracy: 0.5330\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9873 - accuracy: 0.5313 - val_loss: 0.9691 - val_accuracy: 0.5343\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9831 - accuracy: 0.5320 - val_loss: 0.9656 - val_accuracy: 0.5356\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9809 - accuracy: 0.5307 - val_loss: 0.9627 - val_accuracy: 0.5378\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9795 - accuracy: 0.5302 - val_loss: 0.9607 - val_accuracy: 0.5374\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9788 - accuracy: 0.5302 - val_loss: 0.9601 - val_accuracy: 0.5387\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9784 - accuracy: 0.5291 - val_loss: 0.9591 - val_accuracy: 0.5378\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9783 - accuracy: 0.5301 - val_loss: 0.9591 - val_accuracy: 0.5374\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9782 - accuracy: 0.5285 - val_loss: 0.9582 - val_accuracy: 0.5374\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9780 - accuracy: 0.5296 - val_loss: 0.9582 - val_accuracy: 0.5374\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9781 - accuracy: 0.5280 - val_loss: 0.9578 - val_accuracy: 0.5374\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9781 - accuracy: 0.5285 - val_loss: 0.9584 - val_accuracy: 0.5352\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9782 - accuracy: 0.5290 - val_loss: 0.9586 - val_accuracy: 0.5356\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9781 - accuracy: 0.5282 - val_loss: 0.9573 - val_accuracy: 0.5374\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9787 - accuracy: 0.5286 - val_loss: 0.9575 - val_accuracy: 0.5378\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9781 - accuracy: 0.5298 - val_loss: 0.9578 - val_accuracy: 0.5365\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9779 - accuracy: 0.5278 - val_loss: 0.9574 - val_accuracy: 0.5356\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9780 - accuracy: 0.5279 - val_loss: 0.9573 - val_accuracy: 0.5352\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9781 - accuracy: 0.5287 - val_loss: 0.9573 - val_accuracy: 0.5374\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9780 - accuracy: 0.5282 - val_loss: 0.9574 - val_accuracy: 0.5387\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9786 - accuracy: 0.5296 - val_loss: 0.9566 - val_accuracy: 0.5365\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9779 - accuracy: 0.5275 - val_loss: 0.9571 - val_accuracy: 0.5378\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9781 - accuracy: 0.5303 - val_loss: 0.9565 - val_accuracy: 0.5378\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9782 - accuracy: 0.5294 - val_loss: 0.9576 - val_accuracy: 0.5365\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9781 - accuracy: 0.5298 - val_loss: 0.9575 - val_accuracy: 0.5356\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9781 - accuracy: 0.5285 - val_loss: 0.9570 - val_accuracy: 0.5352\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9781 - accuracy: 0.5285 - val_loss: 0.9578 - val_accuracy: 0.5352\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9781 - accuracy: 0.5276 - val_loss: 0.9568 - val_accuracy: 0.5356\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9781 - accuracy: 0.5285 - val_loss: 0.9571 - val_accuracy: 0.5352\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9780 - accuracy: 0.5278 - val_loss: 0.9568 - val_accuracy: 0.5352\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9779 - accuracy: 0.5285 - val_loss: 0.9567 - val_accuracy: 0.5374\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9778 - accuracy: 0.5293 - val_loss: 0.9575 - val_accuracy: 0.5352\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9778 - accuracy: 0.5276 - val_loss: 0.9566 - val_accuracy: 0.5387\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9782 - accuracy: 0.5287 - val_loss: 0.9571 - val_accuracy: 0.5365\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9780 - accuracy: 0.5280 - val_loss: 0.9572 - val_accuracy: 0.5374\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9780 - accuracy: 0.5284 - val_loss: 0.9573 - val_accuracy: 0.5352\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9780 - accuracy: 0.5279 - val_loss: 0.9574 - val_accuracy: 0.5374\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9779 - accuracy: 0.5298 - val_loss: 0.9586 - val_accuracy: 0.5347\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9782 - accuracy: 0.5272 - val_loss: 0.9567 - val_accuracy: 0.5374\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9781 - accuracy: 0.5286 - val_loss: 0.9568 - val_accuracy: 0.5374\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9779 - accuracy: 0.5293 - val_loss: 0.9571 - val_accuracy: 0.5365\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9785 - accuracy: 0.5293 - val_loss: 0.9555 - val_accuracy: 0.5352\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9779 - accuracy: 0.5273 - val_loss: 0.9558 - val_accuracy: 0.5374\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 598us/step - loss: 0.9790 - accuracy: 0.5289 - val_loss: 0.9568 - val_accuracy: 0.5365\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9778 - accuracy: 0.5294 - val_loss: 0.9573 - val_accuracy: 0.5352\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9778 - accuracy: 0.5285 - val_loss: 0.9581 - val_accuracy: 0.5365\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9779 - accuracy: 0.5282 - val_loss: 0.9568 - val_accuracy: 0.5374\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9778 - accuracy: 0.5284 - val_loss: 0.9568 - val_accuracy: 0.5347\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9778 - accuracy: 0.5270 - val_loss: 0.9571 - val_accuracy: 0.5374\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9779 - accuracy: 0.5279 - val_loss: 0.9567 - val_accuracy: 0.5378\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9780 - accuracy: 0.5293 - val_loss: 0.9569 - val_accuracy: 0.5352\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9779 - accuracy: 0.5284 - val_loss: 0.9569 - val_accuracy: 0.5352\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9783 - accuracy: 0.5270 - val_loss: 0.9569 - val_accuracy: 0.5356\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9778 - accuracy: 0.5288 - val_loss: 0.9569 - val_accuracy: 0.5356\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9776 - accuracy: 0.5284 - val_loss: 0.9568 - val_accuracy: 0.5378\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9779 - accuracy: 0.5295 - val_loss: 0.9591 - val_accuracy: 0.5352\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9781 - accuracy: 0.5285 - val_loss: 0.9567 - val_accuracy: 0.5378\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9779 - accuracy: 0.5290 - val_loss: 0.9570 - val_accuracy: 0.5374\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9777 - accuracy: 0.5294 - val_loss: 0.9583 - val_accuracy: 0.5347\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9783 - accuracy: 0.5282 - val_loss: 0.9564 - val_accuracy: 0.5374\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9777 - accuracy: 0.5292 - val_loss: 0.9566 - val_accuracy: 0.5378\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9778 - accuracy: 0.5293 - val_loss: 0.9575 - val_accuracy: 0.5378\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9780 - accuracy: 0.5294 - val_loss: 0.9575 - val_accuracy: 0.5374\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9781 - accuracy: 0.5294 - val_loss: 0.9572 - val_accuracy: 0.5365\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9778 - accuracy: 0.5281 - val_loss: 0.9566 - val_accuracy: 0.5378\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9777 - accuracy: 0.5286 - val_loss: 0.9570 - val_accuracy: 0.5374\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9779 - accuracy: 0.5292 - val_loss: 0.9567 - val_accuracy: 0.5374\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9782 - accuracy: 0.5302 - val_loss: 0.9567 - val_accuracy: 0.5378\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9777 - accuracy: 0.5279 - val_loss: 0.9560 - val_accuracy: 0.5378\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9777 - accuracy: 0.5295 - val_loss: 0.9566 - val_accuracy: 0.5352\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9782 - accuracy: 0.5289 - val_loss: 0.9562 - val_accuracy: 0.5374\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9778 - accuracy: 0.5279 - val_loss: 0.9563 - val_accuracy: 0.5347\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9778 - accuracy: 0.5280 - val_loss: 0.9562 - val_accuracy: 0.5374\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9778 - accuracy: 0.5272 - val_loss: 0.9560 - val_accuracy: 0.5383\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9777 - accuracy: 0.5288 - val_loss: 0.9558 - val_accuracy: 0.5374\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9781 - accuracy: 0.5300 - val_loss: 0.9562 - val_accuracy: 0.5378\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9780 - accuracy: 0.5298 - val_loss: 0.9551 - val_accuracy: 0.5378\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9777 - accuracy: 0.5293 - val_loss: 0.9552 - val_accuracy: 0.5365\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9787 - accuracy: 0.5288 - val_loss: 0.9562 - val_accuracy: 0.5374\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9778 - accuracy: 0.5297 - val_loss: 0.9558 - val_accuracy: 0.5383\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9776 - accuracy: 0.5282 - val_loss: 0.9565 - val_accuracy: 0.5378\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9780 - accuracy: 0.5306 - val_loss: 0.9559 - val_accuracy: 0.5374\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9775 - accuracy: 0.5289 - val_loss: 0.9557 - val_accuracy: 0.5374\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9776 - accuracy: 0.5286 - val_loss: 0.9562 - val_accuracy: 0.5365\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9775 - accuracy: 0.5282 - val_loss: 0.9555 - val_accuracy: 0.5365\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9776 - accuracy: 0.5288 - val_loss: 0.9554 - val_accuracy: 0.5374\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9780 - accuracy: 0.5291 - val_loss: 0.9555 - val_accuracy: 0.5374\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9778 - accuracy: 0.5289 - val_loss: 0.9554 - val_accuracy: 0.5378\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9776 - accuracy: 0.5281 - val_loss: 0.9563 - val_accuracy: 0.5356\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9777 - accuracy: 0.5278 - val_loss: 0.9554 - val_accuracy: 0.5378\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9778 - accuracy: 0.5293 - val_loss: 0.9554 - val_accuracy: 0.5383\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9776 - accuracy: 0.5287 - val_loss: 0.9554 - val_accuracy: 0.5356\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9777 - accuracy: 0.5282 - val_loss: 0.9560 - val_accuracy: 0.5365\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9776 - accuracy: 0.5275 - val_loss: 0.9549 - val_accuracy: 0.5378\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9777 - accuracy: 0.5285 - val_loss: 0.9552 - val_accuracy: 0.5383\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9778 - accuracy: 0.5295 - val_loss: 0.9552 - val_accuracy: 0.5378\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9779 - accuracy: 0.5286 - val_loss: 0.9552 - val_accuracy: 0.5356\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9780 - accuracy: 0.5277 - val_loss: 0.9549 - val_accuracy: 0.5356\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9777 - accuracy: 0.5288 - val_loss: 0.9559 - val_accuracy: 0.5365\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9776 - accuracy: 0.5279 - val_loss: 0.9555 - val_accuracy: 0.5365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5275 - val_loss: 0.9553 - val_accuracy: 0.5378\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9777 - accuracy: 0.5291 - val_loss: 0.9555 - val_accuracy: 0.5374\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9777 - accuracy: 0.5277 - val_loss: 0.9549 - val_accuracy: 0.5347\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9781 - accuracy: 0.5276 - val_loss: 0.9546 - val_accuracy: 0.5378\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9777 - accuracy: 0.5297 - val_loss: 0.9552 - val_accuracy: 0.5378\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9566 - val_accuracy: 0.5347\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9779 - accuracy: 0.5276 - val_loss: 0.9554 - val_accuracy: 0.5378\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9780 - accuracy: 0.5294 - val_loss: 0.9550 - val_accuracy: 0.5347\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9777 - accuracy: 0.5281 - val_loss: 0.9550 - val_accuracy: 0.5374\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9775 - accuracy: 0.5279 - val_loss: 0.9552 - val_accuracy: 0.5347\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9775 - accuracy: 0.5282 - val_loss: 0.9551 - val_accuracy: 0.5378\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9558 - val_accuracy: 0.5374\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9777 - accuracy: 0.5283 - val_loss: 0.9553 - val_accuracy: 0.5374\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9777 - accuracy: 0.5292 - val_loss: 0.9556 - val_accuracy: 0.5356\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9556 - val_accuracy: 0.5383\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9774 - accuracy: 0.5290 - val_loss: 0.9565 - val_accuracy: 0.5352\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9776 - accuracy: 0.5281 - val_loss: 0.9551 - val_accuracy: 0.5383\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9558 - val_accuracy: 0.5365\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9776 - accuracy: 0.5291 - val_loss: 0.9553 - val_accuracy: 0.5378\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9776 - accuracy: 0.5300 - val_loss: 0.9559 - val_accuracy: 0.5347\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9779 - accuracy: 0.5281 - val_loss: 0.9552 - val_accuracy: 0.5365\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9775 - accuracy: 0.5284 - val_loss: 0.9550 - val_accuracy: 0.5374\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9774 - accuracy: 0.5289 - val_loss: 0.9559 - val_accuracy: 0.5347\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9776 - accuracy: 0.5276 - val_loss: 0.9552 - val_accuracy: 0.5378\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9776 - accuracy: 0.5297 - val_loss: 0.9553 - val_accuracy: 0.5383\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 728us/step - loss: 0.9779 - accuracy: 0.5287 - val_loss: 0.9556 - val_accuracy: 0.5383\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9551 - val_accuracy: 0.5378\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9774 - accuracy: 0.5287 - val_loss: 0.9556 - val_accuracy: 0.5347\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 0.9553 - val_accuracy: 0.5383\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9775 - accuracy: 0.5294 - val_loss: 0.9562 - val_accuracy: 0.5365\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9776 - accuracy: 0.5271 - val_loss: 0.9553 - val_accuracy: 0.5383\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9774 - accuracy: 0.5293 - val_loss: 0.9555 - val_accuracy: 0.5374\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9776 - accuracy: 0.5280 - val_loss: 0.9550 - val_accuracy: 0.5374\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9775 - accuracy: 0.5280 - val_loss: 0.9551 - val_accuracy: 0.5383\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 813us/step - loss: 0.9774 - accuracy: 0.5295 - val_loss: 0.9554 - val_accuracy: 0.5352\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9556 - val_accuracy: 0.5356\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9775 - accuracy: 0.5305 - val_loss: 0.9555 - val_accuracy: 0.5365\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 566us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9550 - val_accuracy: 0.5383\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 0.9774 - accuracy: 0.5276 - val_loss: 0.9546 - val_accuracy: 0.5383\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9778 - accuracy: 0.5291 - val_loss: 0.9550 - val_accuracy: 0.5374\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9774 - accuracy: 0.5276 - val_loss: 0.9549 - val_accuracy: 0.5383\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9552 - val_accuracy: 0.5365\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9774 - accuracy: 0.5302 - val_loss: 0.9555 - val_accuracy: 0.5383\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9563 - val_accuracy: 0.5356\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9779 - accuracy: 0.5273 - val_loss: 0.9558 - val_accuracy: 0.5374\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9776 - accuracy: 0.5287 - val_loss: 0.9553 - val_accuracy: 0.5378\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9552 - val_accuracy: 0.5378\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9775 - accuracy: 0.5280 - val_loss: 0.9552 - val_accuracy: 0.5356\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 0.9550 - val_accuracy: 0.5378\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9772 - accuracy: 0.5280 - val_loss: 0.9547 - val_accuracy: 0.5383\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5290 - val_loss: 0.9550 - val_accuracy: 0.5378\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9544 - val_accuracy: 0.5383\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9778 - accuracy: 0.5286 - val_loss: 0.9539 - val_accuracy: 0.5356\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9778 - accuracy: 0.5289 - val_loss: 0.9542 - val_accuracy: 0.5361\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9775 - accuracy: 0.5290 - val_loss: 0.9540 - val_accuracy: 0.5383\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5287 - val_loss: 0.9542 - val_accuracy: 0.5374\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 586us/step - loss: 0.9773 - accuracy: 0.5286 - val_loss: 0.9543 - val_accuracy: 0.5374\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9775 - accuracy: 0.5279 - val_loss: 0.9546 - val_accuracy: 0.5374\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9774 - accuracy: 0.5287 - val_loss: 0.9547 - val_accuracy: 0.5378\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9773 - accuracy: 0.5291 - val_loss: 0.9546 - val_accuracy: 0.5378\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9773 - accuracy: 0.5294 - val_loss: 0.9552 - val_accuracy: 0.5378\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9547 - val_accuracy: 0.5383\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9773 - accuracy: 0.5294 - val_loss: 0.9545 - val_accuracy: 0.5378\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9775 - accuracy: 0.5295 - val_loss: 0.9554 - val_accuracy: 0.5374\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9546 - val_accuracy: 0.5374\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9774 - accuracy: 0.5295 - val_loss: 0.9553 - val_accuracy: 0.5347\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9775 - accuracy: 0.5264 - val_loss: 0.9544 - val_accuracy: 0.5378\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9774 - accuracy: 0.5291 - val_loss: 0.9555 - val_accuracy: 0.5378\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9554 - val_accuracy: 0.5356\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9774 - accuracy: 0.5278 - val_loss: 0.9546 - val_accuracy: 0.5383\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5287 - val_loss: 0.9551 - val_accuracy: 0.5383\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9775 - accuracy: 0.5289 - val_loss: 0.9551 - val_accuracy: 0.5378\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9550 - val_accuracy: 0.5383\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9774 - accuracy: 0.5269 - val_loss: 0.9541 - val_accuracy: 0.5383\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9774 - accuracy: 0.5291 - val_loss: 0.9545 - val_accuracy: 0.5365\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9774 - accuracy: 0.5293 - val_loss: 0.9549 - val_accuracy: 0.5374\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9776 - accuracy: 0.5284 - val_loss: 0.9543 - val_accuracy: 0.5383\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9774 - accuracy: 0.5297 - val_loss: 0.9543 - val_accuracy: 0.5378\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9776 - accuracy: 0.5304 - val_loss: 0.9544 - val_accuracy: 0.5383\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9791 - accuracy: 0.5298 - val_loss: 0.9557 - val_accuracy: 0.5378\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9547 - val_accuracy: 0.5378\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9773 - accuracy: 0.5294 - val_loss: 0.9549 - val_accuracy: 0.5356\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5282 - val_loss: 0.9546 - val_accuracy: 0.5361\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9773 - accuracy: 0.5293 - val_loss: 0.9545 - val_accuracy: 0.5361\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9773 - accuracy: 0.5283 - val_loss: 0.9540 - val_accuracy: 0.5374\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9776 - accuracy: 0.5289 - val_loss: 0.9542 - val_accuracy: 0.5383\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9545 - val_accuracy: 0.5378\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9541 - val_accuracy: 0.5374\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9545 - val_accuracy: 0.5374\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5286 - val_loss: 0.9544 - val_accuracy: 0.5378\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9777 - accuracy: 0.5288 - val_loss: 0.9544 - val_accuracy: 0.5383\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9773 - accuracy: 0.5287 - val_loss: 0.9547 - val_accuracy: 0.5365\n",
      "\n",
      "Train split:\n",
      "  1/636 [..............................] - ETA: 0s - loss: 1.1852 - accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "636/636 [==============================] - 0s 342us/step - loss: 0.9771 - accuracy: 0.5285\n",
      "Accuracy : 0.5285496711730957\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9547 - accuracy: 0.5365\n",
      "Accuracy : 0.5365206003189087\n",
      "\n",
      "The final train accuracy is:0.5297204494476319 \n",
      "\n",
      "The final test accuracy is:0.5280634820461273 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"LB.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data = np.array(df.iloc[:,0:3])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "    \n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "    \n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (3,1)),\n",
    "        keras.layers.Dense(3,activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels,batch_size = 221, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "normal-hanging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specialized-convention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "equal-pension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-softball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-pioneer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-contributor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
