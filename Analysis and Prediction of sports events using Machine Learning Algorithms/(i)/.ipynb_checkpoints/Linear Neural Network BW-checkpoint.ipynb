{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metric-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.2357 - accuracy: 0.4652 - val_loss: 1.1321 - val_accuracy: 0.4619\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 604us/step - loss: 1.1215 - accuracy: 0.4643 - val_loss: 1.0739 - val_accuracy: 0.4606\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 1.0748 - accuracy: 0.4626 - val_loss: 1.0507 - val_accuracy: 0.4597\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 532us/step - loss: 1.0512 - accuracy: 0.4617 - val_loss: 1.0357 - val_accuracy: 0.4615\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0344 - accuracy: 0.4644 - val_loss: 1.0235 - val_accuracy: 0.4619\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0208 - accuracy: 0.4646 - val_loss: 1.0122 - val_accuracy: 0.4637\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 1.0082 - accuracy: 0.4655 - val_loss: 1.0010 - val_accuracy: 0.4659\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9956 - accuracy: 0.5077 - val_loss: 0.9920 - val_accuracy: 0.5159\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9871 - accuracy: 0.5276 - val_loss: 0.9878 - val_accuracy: 0.5155\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9835 - accuracy: 0.5294 - val_loss: 0.9865 - val_accuracy: 0.5186\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9821 - accuracy: 0.5297 - val_loss: 0.9857 - val_accuracy: 0.5190\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9814 - accuracy: 0.5307 - val_loss: 0.9856 - val_accuracy: 0.5190\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 578us/step - loss: 0.9811 - accuracy: 0.5309 - val_loss: 0.9855 - val_accuracy: 0.5195\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9809 - accuracy: 0.5316 - val_loss: 0.9852 - val_accuracy: 0.5204\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 537us/step - loss: 0.9806 - accuracy: 0.5308 - val_loss: 0.9855 - val_accuracy: 0.5243\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9804 - accuracy: 0.5315 - val_loss: 0.9852 - val_accuracy: 0.5204\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9803 - accuracy: 0.5314 - val_loss: 0.9854 - val_accuracy: 0.5235\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9801 - accuracy: 0.5321 - val_loss: 0.9853 - val_accuracy: 0.5235\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9800 - accuracy: 0.5319 - val_loss: 0.9849 - val_accuracy: 0.5239\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9798 - accuracy: 0.5316 - val_loss: 0.9852 - val_accuracy: 0.5235\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9798 - accuracy: 0.5317 - val_loss: 0.9849 - val_accuracy: 0.5235\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9796 - accuracy: 0.5319 - val_loss: 0.9851 - val_accuracy: 0.5239\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9796 - accuracy: 0.5317 - val_loss: 0.9851 - val_accuracy: 0.5239\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9793 - accuracy: 0.5314 - val_loss: 0.9854 - val_accuracy: 0.5239\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9794 - accuracy: 0.5320 - val_loss: 0.9850 - val_accuracy: 0.5239\n",
      "Epoch 26/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9792 - accuracy: 0.5319 - val_loss: 0.9850 - val_accuracy: 0.5261\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9790 - accuracy: 0.5314 - val_loss: 0.9848 - val_accuracy: 0.5239\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9790 - accuracy: 0.5321 - val_loss: 0.9846 - val_accuracy: 0.5204\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9788 - accuracy: 0.5312 - val_loss: 0.9847 - val_accuracy: 0.5252\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9789 - accuracy: 0.5314 - val_loss: 0.9846 - val_accuracy: 0.5226\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9787 - accuracy: 0.5315 - val_loss: 0.9846 - val_accuracy: 0.5239\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9786 - accuracy: 0.5319 - val_loss: 0.9847 - val_accuracy: 0.5252\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9786 - accuracy: 0.5319 - val_loss: 0.9846 - val_accuracy: 0.5226\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9783 - accuracy: 0.5314 - val_loss: 0.9844 - val_accuracy: 0.5204\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9784 - accuracy: 0.5313 - val_loss: 0.9846 - val_accuracy: 0.5190\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9783 - accuracy: 0.5316 - val_loss: 0.9847 - val_accuracy: 0.5239\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9781 - accuracy: 0.5323 - val_loss: 0.9844 - val_accuracy: 0.5235\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9781 - accuracy: 0.5317 - val_loss: 0.9846 - val_accuracy: 0.5257\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9780 - accuracy: 0.5320 - val_loss: 0.9844 - val_accuracy: 0.5261\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9778 - accuracy: 0.5319 - val_loss: 0.9844 - val_accuracy: 0.5195\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9778 - accuracy: 0.5316 - val_loss: 0.9844 - val_accuracy: 0.5230\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9776 - accuracy: 0.5320 - val_loss: 0.9845 - val_accuracy: 0.5252\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9776 - accuracy: 0.5319 - val_loss: 0.9849 - val_accuracy: 0.5235\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9775 - accuracy: 0.5319 - val_loss: 0.9843 - val_accuracy: 0.5243\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9774 - accuracy: 0.5314 - val_loss: 0.9841 - val_accuracy: 0.5235\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9772 - accuracy: 0.5318 - val_loss: 0.9842 - val_accuracy: 0.5195\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 547us/step - loss: 0.9772 - accuracy: 0.5318 - val_loss: 0.9842 - val_accuracy: 0.5204\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 536us/step - loss: 0.9772 - accuracy: 0.5315 - val_loss: 0.9846 - val_accuracy: 0.5195\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9770 - accuracy: 0.5316 - val_loss: 0.9841 - val_accuracy: 0.5230\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9770 - accuracy: 0.5315 - val_loss: 0.9839 - val_accuracy: 0.5235\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9769 - accuracy: 0.5319 - val_loss: 0.9840 - val_accuracy: 0.5239\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9768 - accuracy: 0.5318 - val_loss: 0.9839 - val_accuracy: 0.5212\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9766 - accuracy: 0.5315 - val_loss: 0.9842 - val_accuracy: 0.5239\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9766 - accuracy: 0.5320 - val_loss: 0.9839 - val_accuracy: 0.5239\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9766 - accuracy: 0.5318 - val_loss: 0.9842 - val_accuracy: 0.5195\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 542us/step - loss: 0.9766 - accuracy: 0.5312 - val_loss: 0.9840 - val_accuracy: 0.5195\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9764 - accuracy: 0.5305 - val_loss: 0.9840 - val_accuracy: 0.5239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9764 - accuracy: 0.5317 - val_loss: 0.9839 - val_accuracy: 0.5195\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9763 - accuracy: 0.5315 - val_loss: 0.9838 - val_accuracy: 0.5239\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9763 - accuracy: 0.5311 - val_loss: 0.9838 - val_accuracy: 0.5186\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9763 - accuracy: 0.5307 - val_loss: 0.9837 - val_accuracy: 0.5195\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9761 - accuracy: 0.5316 - val_loss: 0.9836 - val_accuracy: 0.5230\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9760 - accuracy: 0.5315 - val_loss: 0.9837 - val_accuracy: 0.5212\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9759 - accuracy: 0.5321 - val_loss: 0.9837 - val_accuracy: 0.5230\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9758 - accuracy: 0.5313 - val_loss: 0.9836 - val_accuracy: 0.5230\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9758 - accuracy: 0.5318 - val_loss: 0.9836 - val_accuracy: 0.5186\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9757 - accuracy: 0.5317 - val_loss: 0.9835 - val_accuracy: 0.5204\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9757 - accuracy: 0.5309 - val_loss: 0.9835 - val_accuracy: 0.5239\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9756 - accuracy: 0.5316 - val_loss: 0.9837 - val_accuracy: 0.5181\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9756 - accuracy: 0.5319 - val_loss: 0.9835 - val_accuracy: 0.5226\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9755 - accuracy: 0.5332 - val_loss: 0.9837 - val_accuracy: 0.5173\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9754 - accuracy: 0.5317 - val_loss: 0.9834 - val_accuracy: 0.5195\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9755 - accuracy: 0.5315 - val_loss: 0.9836 - val_accuracy: 0.5204\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9754 - accuracy: 0.5322 - val_loss: 0.9834 - val_accuracy: 0.5235\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9754 - accuracy: 0.5323 - val_loss: 0.9833 - val_accuracy: 0.5190\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9753 - accuracy: 0.5314 - val_loss: 0.9833 - val_accuracy: 0.5230\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9752 - accuracy: 0.5321 - val_loss: 0.9833 - val_accuracy: 0.5186\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9751 - accuracy: 0.5317 - val_loss: 0.9835 - val_accuracy: 0.5235\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9752 - accuracy: 0.5306 - val_loss: 0.9834 - val_accuracy: 0.5186\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9751 - accuracy: 0.5318 - val_loss: 0.9832 - val_accuracy: 0.5190\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9751 - accuracy: 0.5316 - val_loss: 0.9833 - val_accuracy: 0.5208\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9750 - accuracy: 0.5324 - val_loss: 0.9835 - val_accuracy: 0.5204\n",
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9750 - accuracy: 0.5317 - val_loss: 0.9833 - val_accuracy: 0.5243\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9750 - accuracy: 0.5318 - val_loss: 0.9832 - val_accuracy: 0.5226\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9749 - accuracy: 0.5318 - val_loss: 0.9832 - val_accuracy: 0.5226\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9748 - accuracy: 0.5323 - val_loss: 0.9833 - val_accuracy: 0.5226\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9746 - accuracy: 0.5312 - val_loss: 0.9831 - val_accuracy: 0.5204\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9747 - accuracy: 0.5319 - val_loss: 0.9832 - val_accuracy: 0.5239\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 532us/step - loss: 0.9747 - accuracy: 0.5314 - val_loss: 0.9831 - val_accuracy: 0.5239\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9748 - accuracy: 0.5317 - val_loss: 0.9831 - val_accuracy: 0.5186\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9746 - accuracy: 0.5320 - val_loss: 0.9831 - val_accuracy: 0.5190\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.9745 - accuracy: 0.5327 - val_loss: 0.9831 - val_accuracy: 0.5186\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9745 - accuracy: 0.5311 - val_loss: 0.9832 - val_accuracy: 0.5243\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9745 - accuracy: 0.5317 - val_loss: 0.9830 - val_accuracy: 0.5204\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9744 - accuracy: 0.5318 - val_loss: 0.9832 - val_accuracy: 0.5226\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.9744 - accuracy: 0.5320 - val_loss: 0.9834 - val_accuracy: 0.5177\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9742 - accuracy: 0.5317 - val_loss: 0.9832 - val_accuracy: 0.5235\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9743 - accuracy: 0.5326 - val_loss: 0.9830 - val_accuracy: 0.5204\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9742 - accuracy: 0.5318 - val_loss: 0.9834 - val_accuracy: 0.5199\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9742 - accuracy: 0.5320 - val_loss: 0.9831 - val_accuracy: 0.5243\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9742 - accuracy: 0.5317 - val_loss: 0.9829 - val_accuracy: 0.5195\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9743 - accuracy: 0.5314 - val_loss: 0.9834 - val_accuracy: 0.5208\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9741 - accuracy: 0.5316 - val_loss: 0.9829 - val_accuracy: 0.5208\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 540us/step - loss: 0.9741 - accuracy: 0.5315 - val_loss: 0.9830 - val_accuracy: 0.5195\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9741 - accuracy: 0.5318 - val_loss: 0.9830 - val_accuracy: 0.5195\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 0.9834 - val_accuracy: 0.5243\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9740 - accuracy: 0.5311 - val_loss: 0.9833 - val_accuracy: 0.5239\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9740 - accuracy: 0.5325 - val_loss: 0.9832 - val_accuracy: 0.5173\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9741 - accuracy: 0.5319 - val_loss: 0.9829 - val_accuracy: 0.5195\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9739 - accuracy: 0.5320 - val_loss: 0.9828 - val_accuracy: 0.5195\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9740 - accuracy: 0.5321 - val_loss: 0.9829 - val_accuracy: 0.5199\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9739 - accuracy: 0.5316 - val_loss: 0.9829 - val_accuracy: 0.5195\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9739 - accuracy: 0.5319 - val_loss: 0.9829 - val_accuracy: 0.5199\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9739 - accuracy: 0.5312 - val_loss: 0.9829 - val_accuracy: 0.5190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9739 - accuracy: 0.5313 - val_loss: 0.9828 - val_accuracy: 0.5195\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 0.9831 - val_accuracy: 0.5190\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9737 - accuracy: 0.5316 - val_loss: 0.9828 - val_accuracy: 0.5181\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9736 - accuracy: 0.5317 - val_loss: 0.9832 - val_accuracy: 0.5252\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9737 - accuracy: 0.5311 - val_loss: 0.9828 - val_accuracy: 0.5195\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9737 - accuracy: 0.5318 - val_loss: 0.9830 - val_accuracy: 0.5173\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9737 - accuracy: 0.5309 - val_loss: 0.9828 - val_accuracy: 0.5239\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9737 - accuracy: 0.5319 - val_loss: 0.9830 - val_accuracy: 0.5168\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 0.9829 - val_accuracy: 0.5248\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9736 - accuracy: 0.5324 - val_loss: 0.9829 - val_accuracy: 0.5190\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9735 - accuracy: 0.5310 - val_loss: 0.9829 - val_accuracy: 0.5239\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9736 - accuracy: 0.5320 - val_loss: 0.9829 - val_accuracy: 0.5195\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9735 - accuracy: 0.5320 - val_loss: 0.9828 - val_accuracy: 0.5186\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9735 - accuracy: 0.5314 - val_loss: 0.9830 - val_accuracy: 0.5243\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9736 - accuracy: 0.5316 - val_loss: 0.9828 - val_accuracy: 0.5199\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9735 - accuracy: 0.5312 - val_loss: 0.9831 - val_accuracy: 0.5257\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9735 - accuracy: 0.5316 - val_loss: 0.9829 - val_accuracy: 0.5168\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9734 - accuracy: 0.5316 - val_loss: 0.9827 - val_accuracy: 0.5204\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9734 - accuracy: 0.5317 - val_loss: 0.9830 - val_accuracy: 0.5190\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 542us/step - loss: 0.9735 - accuracy: 0.5319 - val_loss: 0.9827 - val_accuracy: 0.5208\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 534us/step - loss: 0.9734 - accuracy: 0.5311 - val_loss: 0.9828 - val_accuracy: 0.5204\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9734 - accuracy: 0.5318 - val_loss: 0.9828 - val_accuracy: 0.5190\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9735 - accuracy: 0.5317 - val_loss: 0.9828 - val_accuracy: 0.5195\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9733 - accuracy: 0.5321 - val_loss: 0.9828 - val_accuracy: 0.5239\n",
      "Epoch 139/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9733 - accuracy: 0.5316 - val_loss: 0.9827 - val_accuracy: 0.5208\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9733 - accuracy: 0.5319 - val_loss: 0.9828 - val_accuracy: 0.5226\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9733 - accuracy: 0.5310 - val_loss: 0.9833 - val_accuracy: 0.5168\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9733 - accuracy: 0.5310 - val_loss: 0.9830 - val_accuracy: 0.5199\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9732 - accuracy: 0.5316 - val_loss: 0.9827 - val_accuracy: 0.5168\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 570us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 0.9828 - val_accuracy: 0.5243\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 535us/step - loss: 0.9732 - accuracy: 0.5319 - val_loss: 0.9828 - val_accuracy: 0.5248\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9732 - accuracy: 0.5314 - val_loss: 0.9827 - val_accuracy: 0.5208\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 0.9828 - val_accuracy: 0.5173\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 538us/step - loss: 0.9732 - accuracy: 0.5318 - val_loss: 0.9828 - val_accuracy: 0.5168\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9732 - accuracy: 0.5317 - val_loss: 0.9827 - val_accuracy: 0.5199\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 0.9828 - val_accuracy: 0.5168\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 570us/step - loss: 0.9732 - accuracy: 0.5316 - val_loss: 0.9830 - val_accuracy: 0.5261\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 546us/step - loss: 0.9729 - accuracy: 0.5323 - val_loss: 0.9831 - val_accuracy: 0.5181\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9732 - accuracy: 0.5314 - val_loss: 0.9829 - val_accuracy: 0.5168\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 0.9827 - val_accuracy: 0.5195\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 0.9830 - val_accuracy: 0.5168\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9732 - accuracy: 0.5313 - val_loss: 0.9827 - val_accuracy: 0.5168\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 0.9830 - val_accuracy: 0.5177\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9732 - accuracy: 0.5319 - val_loss: 0.9828 - val_accuracy: 0.5186\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9730 - accuracy: 0.5317 - val_loss: 0.9827 - val_accuracy: 0.5195\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9731 - accuracy: 0.5317 - val_loss: 0.9827 - val_accuracy: 0.5181\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9730 - accuracy: 0.5318 - val_loss: 0.9832 - val_accuracy: 0.5177\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9730 - accuracy: 0.5320 - val_loss: 0.9827 - val_accuracy: 0.5190\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9729 - accuracy: 0.5319 - val_loss: 0.9827 - val_accuracy: 0.5168\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 0.9827 - val_accuracy: 0.5186\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9729 - accuracy: 0.5318 - val_loss: 0.9831 - val_accuracy: 0.5173\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9730 - accuracy: 0.5317 - val_loss: 0.9827 - val_accuracy: 0.5190\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 546us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 0.9826 - val_accuracy: 0.5186\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 0.9730 - accuracy: 0.5325 - val_loss: 0.9827 - val_accuracy: 0.5186\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 571us/step - loss: 0.9729 - accuracy: 0.5314 - val_loss: 0.9827 - val_accuracy: 0.5190\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 571us/step - loss: 0.9728 - accuracy: 0.5321 - val_loss: 0.9832 - val_accuracy: 0.5186\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 555us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9827 - val_accuracy: 0.5199\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9729 - accuracy: 0.5316 - val_loss: 0.9827 - val_accuracy: 0.5221\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9728 - accuracy: 0.5314 - val_loss: 0.9829 - val_accuracy: 0.5252\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9731 - accuracy: 0.5317 - val_loss: 0.9828 - val_accuracy: 0.5173\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9729 - accuracy: 0.5321 - val_loss: 0.9827 - val_accuracy: 0.5168\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 0.9828 - val_accuracy: 0.5199\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9728 - accuracy: 0.5313 - val_loss: 0.9826 - val_accuracy: 0.5199\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9730 - accuracy: 0.5317 - val_loss: 0.9827 - val_accuracy: 0.5217\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 0.9828 - val_accuracy: 0.5199\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9728 - accuracy: 0.5312 - val_loss: 0.9827 - val_accuracy: 0.5199\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 0.9827 - val_accuracy: 0.5199\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9728 - accuracy: 0.5319 - val_loss: 0.9827 - val_accuracy: 0.5168\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9727 - accuracy: 0.5314 - val_loss: 0.9830 - val_accuracy: 0.5212\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9728 - accuracy: 0.5318 - val_loss: 0.9827 - val_accuracy: 0.5235\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9729 - accuracy: 0.5314 - val_loss: 0.9827 - val_accuracy: 0.5217\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9728 - accuracy: 0.5310 - val_loss: 0.9829 - val_accuracy: 0.5212\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9728 - accuracy: 0.5320 - val_loss: 0.9830 - val_accuracy: 0.5168\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9728 - accuracy: 0.5317 - val_loss: 0.9828 - val_accuracy: 0.5181\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 571us/step - loss: 0.9728 - accuracy: 0.5305 - val_loss: 0.9827 - val_accuracy: 0.5217\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9728 - accuracy: 0.5308 - val_loss: 0.9827 - val_accuracy: 0.5177\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9727 - accuracy: 0.5319 - val_loss: 0.9832 - val_accuracy: 0.5248\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 572us/step - loss: 0.9728 - accuracy: 0.5321 - val_loss: 0.9828 - val_accuracy: 0.5243\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9728 - accuracy: 0.5307 - val_loss: 0.9828 - val_accuracy: 0.5226\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 0.9827 - val_accuracy: 0.5181\n",
      "Epoch 195/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9729 - accuracy: 0.5315 - val_loss: 0.9827 - val_accuracy: 0.5195\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 604us/step - loss: 0.9727 - accuracy: 0.5317 - val_loss: 0.9828 - val_accuracy: 0.5226\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9728 - accuracy: 0.5318 - val_loss: 0.9829 - val_accuracy: 0.5168\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 582us/step - loss: 0.9728 - accuracy: 0.5316 - val_loss: 0.9827 - val_accuracy: 0.5226\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 574us/step - loss: 0.9727 - accuracy: 0.5315 - val_loss: 0.9827 - val_accuracy: 0.5195\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 541us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9827 - val_accuracy: 0.5181\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 330us/step - loss: 0.9725 - accuracy: 0.5316\n",
      "Accuracy : 0.5315758585929871\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9827 - accuracy: 0.5181\n",
      "Accuracy : 0.5181415677070618\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1.9917 - accuracy: 0.2194 - val_loss: 1.8500 - val_accuracy: 0.2111\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 593us/step - loss: 1.6627 - accuracy: 0.2188 - val_loss: 1.5297 - val_accuracy: 0.2124\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 1.4224 - accuracy: 0.2175 - val_loss: 1.3213 - val_accuracy: 0.2115\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 1.2740 - accuracy: 0.2162 - val_loss: 1.2089 - val_accuracy: 0.2088\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.1928 - accuracy: 0.2160 - val_loss: 1.1542 - val_accuracy: 0.2111\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 1.1501 - accuracy: 0.2171 - val_loss: 1.1270 - val_accuracy: 0.2133\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 1.1269 - accuracy: 0.2175 - val_loss: 1.1123 - val_accuracy: 0.2137\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.1135 - accuracy: 0.2175 - val_loss: 1.1035 - val_accuracy: 0.2128\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.1053 - accuracy: 0.2182 - val_loss: 1.0978 - val_accuracy: 0.2133\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0999 - accuracy: 0.2189 - val_loss: 1.0939 - val_accuracy: 0.2155\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 1.0962 - accuracy: 0.2194 - val_loss: 1.0910 - val_accuracy: 0.2155\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 573us/step - loss: 1.0936 - accuracy: 0.2200 - val_loss: 1.0888 - val_accuracy: 0.2155\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0915 - accuracy: 0.2200 - val_loss: 1.0870 - val_accuracy: 0.2164\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0899 - accuracy: 0.2199 - val_loss: 1.0857 - val_accuracy: 0.2159\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0887 - accuracy: 0.2199 - val_loss: 1.0844 - val_accuracy: 0.2168\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0876 - accuracy: 0.2200 - val_loss: 1.0835 - val_accuracy: 0.2168\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0868 - accuracy: 0.2199 - val_loss: 1.0826 - val_accuracy: 0.2168\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0861 - accuracy: 0.2198 - val_loss: 1.0819 - val_accuracy: 0.2164\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 1.0854 - accuracy: 0.2199 - val_loss: 1.0814 - val_accuracy: 0.2164\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 537us/step - loss: 1.0849 - accuracy: 0.2199 - val_loss: 1.0808 - val_accuracy: 0.2164\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0844 - accuracy: 0.2200 - val_loss: 1.0804 - val_accuracy: 0.2164\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0841 - accuracy: 0.2200 - val_loss: 1.0798 - val_accuracy: 0.2164\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0837 - accuracy: 0.2200 - val_loss: 1.0797 - val_accuracy: 0.2164\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0834 - accuracy: 0.2200 - val_loss: 1.0793 - val_accuracy: 0.2164\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0831 - accuracy: 0.2199 - val_loss: 1.0789 - val_accuracy: 0.2173\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 555us/step - loss: 1.0828 - accuracy: 0.2199 - val_loss: 1.0788 - val_accuracy: 0.2168\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 1.0826 - accuracy: 0.2199 - val_loss: 1.0783 - val_accuracy: 0.2168\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0824 - accuracy: 0.2199 - val_loss: 1.0782 - val_accuracy: 0.2168\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0822 - accuracy: 0.2199 - val_loss: 1.0781 - val_accuracy: 0.2168\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0821 - accuracy: 0.2199 - val_loss: 1.0779 - val_accuracy: 0.2168\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 532us/step - loss: 1.0819 - accuracy: 0.2199 - val_loss: 1.0777 - val_accuracy: 0.2168\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0817 - accuracy: 0.2199 - val_loss: 1.0775 - val_accuracy: 0.2168\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0816 - accuracy: 0.2199 - val_loss: 1.0775 - val_accuracy: 0.2168\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 1.0815 - accuracy: 0.2198 - val_loss: 1.0773 - val_accuracy: 0.2159\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 1.0814 - accuracy: 0.2198 - val_loss: 1.0771 - val_accuracy: 0.2159\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 1.0813 - accuracy: 0.2200 - val_loss: 1.0770 - val_accuracy: 0.2159\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0812 - accuracy: 0.2202 - val_loss: 1.0770 - val_accuracy: 0.2164\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 1.0811 - accuracy: 0.2201 - val_loss: 1.0768 - val_accuracy: 0.2164\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0810 - accuracy: 0.2200 - val_loss: 1.0768 - val_accuracy: 0.2155\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0809 - accuracy: 0.2200 - val_loss: 1.0767 - val_accuracy: 0.2155\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0809 - accuracy: 0.2202 - val_loss: 1.0767 - val_accuracy: 0.2155\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 1.0808 - accuracy: 0.2201 - val_loss: 1.0765 - val_accuracy: 0.2155\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 1.0807 - accuracy: 0.2202 - val_loss: 1.0764 - val_accuracy: 0.2155\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 1.0807 - accuracy: 0.2202 - val_loss: 1.0765 - val_accuracy: 0.2155\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0806 - accuracy: 0.2203 - val_loss: 1.0763 - val_accuracy: 0.2155\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0805 - accuracy: 0.2203 - val_loss: 1.0762 - val_accuracy: 0.2155\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 1.0805 - accuracy: 0.2201 - val_loss: 1.0762 - val_accuracy: 0.2155\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 1.0804 - accuracy: 0.2204 - val_loss: 1.0763 - val_accuracy: 0.2155\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0804 - accuracy: 0.2203 - val_loss: 1.0761 - val_accuracy: 0.2155\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0804 - accuracy: 0.2201 - val_loss: 1.0760 - val_accuracy: 0.2155\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 540us/step - loss: 1.0803 - accuracy: 0.2200 - val_loss: 1.0761 - val_accuracy: 0.2155\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0803 - accuracy: 0.2200 - val_loss: 1.0761 - val_accuracy: 0.2155\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0802 - accuracy: 0.2199 - val_loss: 1.0761 - val_accuracy: 0.2150\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 1.0802 - accuracy: 0.2198 - val_loss: 1.0760 - val_accuracy: 0.2146\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0802 - accuracy: 0.2200 - val_loss: 1.0759 - val_accuracy: 0.2150\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0802 - accuracy: 0.2199 - val_loss: 1.0759 - val_accuracy: 0.2150\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0801 - accuracy: 0.2198 - val_loss: 1.0759 - val_accuracy: 0.2150\n",
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 1.0801 - accuracy: 0.2198 - val_loss: 1.0759 - val_accuracy: 0.2155\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 546us/step - loss: 1.0801 - accuracy: 0.2198 - val_loss: 1.0759 - val_accuracy: 0.2155\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0801 - accuracy: 0.2199 - val_loss: 1.0757 - val_accuracy: 0.2150\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0800 - accuracy: 0.2197 - val_loss: 1.0759 - val_accuracy: 0.2146\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0800 - accuracy: 0.2194 - val_loss: 1.0758 - val_accuracy: 0.2137\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0800 - accuracy: 0.2193 - val_loss: 1.0758 - val_accuracy: 0.2137\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0799 - accuracy: 0.2192 - val_loss: 1.0757 - val_accuracy: 0.2137\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0799 - accuracy: 0.2194 - val_loss: 1.0759 - val_accuracy: 0.2137\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0799 - accuracy: 0.2191 - val_loss: 1.0758 - val_accuracy: 0.2133\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 1.0799 - accuracy: 0.2191 - val_loss: 1.0756 - val_accuracy: 0.2133\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0799 - accuracy: 0.2193 - val_loss: 1.0756 - val_accuracy: 0.2133\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0799 - accuracy: 0.2195 - val_loss: 1.0757 - val_accuracy: 0.2133\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0798 - accuracy: 0.2194 - val_loss: 1.0756 - val_accuracy: 0.2133\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0798 - accuracy: 0.2194 - val_loss: 1.0757 - val_accuracy: 0.2133\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0798 - accuracy: 0.2193 - val_loss: 1.0756 - val_accuracy: 0.2133\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0798 - accuracy: 0.2193 - val_loss: 1.0756 - val_accuracy: 0.2133\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 1.0798 - accuracy: 0.2199 - val_loss: 1.0756 - val_accuracy: 0.2128\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 1.0798 - accuracy: 0.2202 - val_loss: 1.0756 - val_accuracy: 0.2128\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0798 - accuracy: 0.2201 - val_loss: 1.0756 - val_accuracy: 0.2124\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0797 - accuracy: 0.2203 - val_loss: 1.0755 - val_accuracy: 0.2124\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0797 - accuracy: 0.2202 - val_loss: 1.0755 - val_accuracy: 0.2124\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0797 - accuracy: 0.2202 - val_loss: 1.0757 - val_accuracy: 0.2124\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 1.0797 - accuracy: 0.2200 - val_loss: 1.0755 - val_accuracy: 0.2128\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 1.0797 - accuracy: 0.2201 - val_loss: 1.0754 - val_accuracy: 0.2124\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 1.0797 - accuracy: 0.2202 - val_loss: 1.0754 - val_accuracy: 0.2124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0796 - accuracy: 0.2199 - val_loss: 1.0755 - val_accuracy: 0.2124\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 532us/step - loss: 1.0797 - accuracy: 0.2204 - val_loss: 1.0755 - val_accuracy: 0.2124\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0796 - accuracy: 0.2207 - val_loss: 1.0754 - val_accuracy: 0.2124\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0797 - accuracy: 0.2206 - val_loss: 1.0755 - val_accuracy: 0.2124\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0796 - accuracy: 0.2205 - val_loss: 1.0755 - val_accuracy: 0.2124\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 1.0797 - accuracy: 0.2205 - val_loss: 1.0755 - val_accuracy: 0.2124\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0796 - accuracy: 0.2205 - val_loss: 1.0756 - val_accuracy: 0.2124\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0796 - accuracy: 0.2205 - val_loss: 1.0754 - val_accuracy: 0.2124\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0796 - accuracy: 0.2206 - val_loss: 1.0755 - val_accuracy: 0.2124\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0796 - accuracy: 0.2202 - val_loss: 1.0754 - val_accuracy: 0.2128\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 1.0796 - accuracy: 0.2204 - val_loss: 1.0755 - val_accuracy: 0.2137\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 1.0795 - accuracy: 0.2207 - val_loss: 1.0754 - val_accuracy: 0.2142\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 540us/step - loss: 1.0796 - accuracy: 0.2209 - val_loss: 1.0754 - val_accuracy: 0.2137\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0796 - accuracy: 0.2218 - val_loss: 1.0756 - val_accuracy: 0.2137\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0796 - accuracy: 0.2222 - val_loss: 1.0755 - val_accuracy: 0.2137\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0795 - accuracy: 0.2223 - val_loss: 1.0754 - val_accuracy: 0.2137\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0795 - accuracy: 0.2221 - val_loss: 1.0755 - val_accuracy: 0.2119\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 1.0795 - accuracy: 0.2223 - val_loss: 1.0756 - val_accuracy: 0.2119\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0795 - accuracy: 0.2223 - val_loss: 1.0755 - val_accuracy: 0.2119\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 1.0795 - accuracy: 0.2223 - val_loss: 1.0755 - val_accuracy: 0.2119\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 538us/step - loss: 1.0795 - accuracy: 0.2220 - val_loss: 1.0753 - val_accuracy: 0.2119\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0795 - accuracy: 0.2221 - val_loss: 1.0755 - val_accuracy: 0.2119\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0795 - accuracy: 0.2225 - val_loss: 1.0755 - val_accuracy: 0.2119\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0795 - accuracy: 0.2226 - val_loss: 1.0754 - val_accuracy: 0.2119\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0795 - accuracy: 0.2228 - val_loss: 1.0754 - val_accuracy: 0.2115\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0795 - accuracy: 0.2227 - val_loss: 1.0754 - val_accuracy: 0.2115\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0795 - accuracy: 0.2229 - val_loss: 1.0755 - val_accuracy: 0.2128\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 1.0795 - accuracy: 0.2229 - val_loss: 1.0754 - val_accuracy: 0.2128\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 1.0795 - accuracy: 0.2229 - val_loss: 1.0755 - val_accuracy: 0.2128\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0795 - accuracy: 0.2229 - val_loss: 1.0754 - val_accuracy: 0.2137\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 1.0795 - accuracy: 0.2231 - val_loss: 1.0754 - val_accuracy: 0.2137\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0794 - accuracy: 0.2234 - val_loss: 1.0754 - val_accuracy: 0.2142\n",
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0795 - accuracy: 0.2237 - val_loss: 1.0755 - val_accuracy: 0.2142\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0795 - accuracy: 0.2239 - val_loss: 1.0755 - val_accuracy: 0.2142\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 1.0794 - accuracy: 0.2242 - val_loss: 1.0754 - val_accuracy: 0.2142\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0795 - accuracy: 0.2244 - val_loss: 1.0754 - val_accuracy: 0.2142\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0794 - accuracy: 0.2249 - val_loss: 1.0755 - val_accuracy: 0.2142\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0794 - accuracy: 0.2250 - val_loss: 1.0754 - val_accuracy: 0.2142\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 1.0794 - accuracy: 0.2254 - val_loss: 1.0755 - val_accuracy: 0.2142\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0794 - accuracy: 0.2256 - val_loss: 1.0755 - val_accuracy: 0.2155\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0794 - accuracy: 0.2259 - val_loss: 1.0754 - val_accuracy: 0.2155\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0794 - accuracy: 0.2261 - val_loss: 1.0754 - val_accuracy: 0.2155\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0794 - accuracy: 0.2262 - val_loss: 1.0755 - val_accuracy: 0.2155\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 1.0794 - accuracy: 0.2262 - val_loss: 1.0754 - val_accuracy: 0.2164\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0794 - accuracy: 0.2262 - val_loss: 1.0754 - val_accuracy: 0.2159\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0794 - accuracy: 0.2267 - val_loss: 1.0755 - val_accuracy: 0.2155\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0794 - accuracy: 0.2267 - val_loss: 1.0754 - val_accuracy: 0.2164\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0794 - accuracy: 0.2268 - val_loss: 1.0755 - val_accuracy: 0.2168\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0794 - accuracy: 0.2267 - val_loss: 1.0755 - val_accuracy: 0.2173\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0793 - accuracy: 0.2269 - val_loss: 1.0754 - val_accuracy: 0.2173\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 1.0794 - accuracy: 0.2270 - val_loss: 1.0755 - val_accuracy: 0.2173\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 540us/step - loss: 1.0793 - accuracy: 0.2272 - val_loss: 1.0755 - val_accuracy: 0.2177\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0794 - accuracy: 0.2275 - val_loss: 1.0755 - val_accuracy: 0.2186\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0793 - accuracy: 0.2275 - val_loss: 1.0756 - val_accuracy: 0.2190\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0793 - accuracy: 0.2280 - val_loss: 1.0756 - val_accuracy: 0.2190\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0794 - accuracy: 0.2284 - val_loss: 1.0755 - val_accuracy: 0.2195\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 543us/step - loss: 1.0793 - accuracy: 0.2285 - val_loss: 1.0755 - val_accuracy: 0.2199\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0793 - accuracy: 0.2288 - val_loss: 1.0755 - val_accuracy: 0.2204\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 1.0793 - accuracy: 0.2291 - val_loss: 1.0755 - val_accuracy: 0.2212\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0793 - accuracy: 0.2292 - val_loss: 1.0755 - val_accuracy: 0.2212\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0793 - accuracy: 0.2298 - val_loss: 1.0755 - val_accuracy: 0.2230\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0793 - accuracy: 0.2299 - val_loss: 1.0755 - val_accuracy: 0.2235\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 532us/step - loss: 1.0793 - accuracy: 0.2304 - val_loss: 1.0757 - val_accuracy: 0.2239\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0793 - accuracy: 0.2303 - val_loss: 1.0754 - val_accuracy: 0.2239\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0793 - accuracy: 0.2306 - val_loss: 1.0755 - val_accuracy: 0.2239\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 1.0793 - accuracy: 0.2309 - val_loss: 1.0754 - val_accuracy: 0.2239\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 532us/step - loss: 1.0793 - accuracy: 0.2316 - val_loss: 1.0755 - val_accuracy: 0.2261\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 1.0793 - accuracy: 0.2320 - val_loss: 1.0755 - val_accuracy: 0.2261\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0793 - accuracy: 0.2329 - val_loss: 1.0756 - val_accuracy: 0.2270\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0793 - accuracy: 0.2334 - val_loss: 1.0754 - val_accuracy: 0.2292\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 1.0793 - accuracy: 0.2338 - val_loss: 1.0754 - val_accuracy: 0.2288\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0793 - accuracy: 0.2341 - val_loss: 1.0755 - val_accuracy: 0.2296\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0792 - accuracy: 0.2347 - val_loss: 1.0755 - val_accuracy: 0.2305\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 1.0792 - accuracy: 0.2352 - val_loss: 1.0754 - val_accuracy: 0.2314\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 540us/step - loss: 1.0792 - accuracy: 0.2356 - val_loss: 1.0755 - val_accuracy: 0.2305\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0792 - accuracy: 0.2361 - val_loss: 1.0755 - val_accuracy: 0.2305\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0792 - accuracy: 0.2368 - val_loss: 1.0755 - val_accuracy: 0.2310\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0792 - accuracy: 0.2371 - val_loss: 1.0755 - val_accuracy: 0.2323\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0792 - accuracy: 0.2374 - val_loss: 1.0755 - val_accuracy: 0.2327\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0792 - accuracy: 0.2384 - val_loss: 1.0757 - val_accuracy: 0.2327\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 1.0792 - accuracy: 0.2387 - val_loss: 1.0756 - val_accuracy: 0.2332\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 540us/step - loss: 1.0792 - accuracy: 0.2393 - val_loss: 1.0755 - val_accuracy: 0.2341\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0792 - accuracy: 0.2394 - val_loss: 1.0755 - val_accuracy: 0.2345\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0792 - accuracy: 0.2400 - val_loss: 1.0756 - val_accuracy: 0.2350\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0792 - accuracy: 0.2408 - val_loss: 1.0755 - val_accuracy: 0.2358\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0792 - accuracy: 0.2415 - val_loss: 1.0755 - val_accuracy: 0.2385\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 1.0792 - accuracy: 0.2417 - val_loss: 1.0755 - val_accuracy: 0.2403\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0792 - accuracy: 0.2428 - val_loss: 1.0754 - val_accuracy: 0.2407\n",
      "Epoch 171/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0792 - accuracy: 0.2437 - val_loss: 1.0755 - val_accuracy: 0.2416\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 1.0791 - accuracy: 0.2442 - val_loss: 1.0755 - val_accuracy: 0.2425\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0792 - accuracy: 0.2453 - val_loss: 1.0754 - val_accuracy: 0.2434\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0792 - accuracy: 0.2457 - val_loss: 1.0754 - val_accuracy: 0.2447\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0791 - accuracy: 0.2463 - val_loss: 1.0755 - val_accuracy: 0.2473\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0791 - accuracy: 0.2472 - val_loss: 1.0756 - val_accuracy: 0.2478\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0792 - accuracy: 0.2476 - val_loss: 1.0757 - val_accuracy: 0.2513\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0791 - accuracy: 0.2478 - val_loss: 1.0755 - val_accuracy: 0.2513\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 570us/step - loss: 1.0791 - accuracy: 0.2484 - val_loss: 1.0755 - val_accuracy: 0.2531\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 546us/step - loss: 1.0791 - accuracy: 0.2489 - val_loss: 1.0755 - val_accuracy: 0.2540\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0791 - accuracy: 0.2500 - val_loss: 1.0755 - val_accuracy: 0.2562\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0791 - accuracy: 0.2509 - val_loss: 1.0756 - val_accuracy: 0.2575\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0791 - accuracy: 0.2514 - val_loss: 1.0755 - val_accuracy: 0.2571\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 1.0791 - accuracy: 0.2523 - val_loss: 1.0755 - val_accuracy: 0.2602\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 1.0790 - accuracy: 0.2528 - val_loss: 1.0757 - val_accuracy: 0.2615\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0790 - accuracy: 0.2536 - val_loss: 1.0756 - val_accuracy: 0.2615\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 540us/step - loss: 1.0791 - accuracy: 0.2539 - val_loss: 1.0755 - val_accuracy: 0.2624\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0790 - accuracy: 0.2547 - val_loss: 1.0755 - val_accuracy: 0.2628\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0790 - accuracy: 0.2553 - val_loss: 1.0755 - val_accuracy: 0.2650\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0790 - accuracy: 0.2560 - val_loss: 1.0756 - val_accuracy: 0.2659\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0790 - accuracy: 0.2568 - val_loss: 1.0755 - val_accuracy: 0.2681\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 1.0790 - accuracy: 0.2578 - val_loss: 1.0756 - val_accuracy: 0.2668\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 1.0790 - accuracy: 0.2584 - val_loss: 1.0756 - val_accuracy: 0.2699\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 1.0790 - accuracy: 0.2592 - val_loss: 1.0756 - val_accuracy: 0.2695\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 543us/step - loss: 1.0790 - accuracy: 0.2600 - val_loss: 1.0756 - val_accuracy: 0.2690\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0789 - accuracy: 0.2606 - val_loss: 1.0755 - val_accuracy: 0.2712\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0789 - accuracy: 0.2617 - val_loss: 1.0755 - val_accuracy: 0.2712\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0789 - accuracy: 0.2616 - val_loss: 1.0756 - val_accuracy: 0.2717\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0789 - accuracy: 0.2623 - val_loss: 1.0756 - val_accuracy: 0.2708\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0789 - accuracy: 0.2629 - val_loss: 1.0755 - val_accuracy: 0.2717\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 336us/step - loss: 1.0789 - accuracy: 0.2635\n",
      "Accuracy : 0.26352548599243164\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0755 - accuracy: 0.2717\n",
      "Accuracy : 0.27168142795562744\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.8159 - accuracy: 0.2304 - val_loss: 1.4482 - val_accuracy: 0.2351\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 1.5521 - accuracy: 0.2166 - val_loss: 1.2905 - val_accuracy: 0.2249\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 1.3654 - accuracy: 0.2287 - val_loss: 1.1972 - val_accuracy: 0.2492\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.2492 - accuracy: 0.2733 - val_loss: 1.1456 - val_accuracy: 0.3254\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.1799 - accuracy: 0.3240 - val_loss: 1.1159 - val_accuracy: 0.3484\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 1.1376 - accuracy: 0.3314 - val_loss: 1.0944 - val_accuracy: 0.3546\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 1.0975 - accuracy: 0.3363 - val_loss: 1.0738 - val_accuracy: 0.3612\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 1.0736 - accuracy: 0.3417 - val_loss: 1.0656 - val_accuracy: 0.3696\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0642 - accuracy: 0.3443 - val_loss: 1.0616 - val_accuracy: 0.3736\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 1.0587 - accuracy: 0.3478 - val_loss: 1.0585 - val_accuracy: 0.3798\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0548 - accuracy: 0.3533 - val_loss: 1.0566 - val_accuracy: 0.3816\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 1.0522 - accuracy: 0.3590 - val_loss: 1.0550 - val_accuracy: 0.3913\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 1.0502 - accuracy: 0.3661 - val_loss: 1.0537 - val_accuracy: 0.3966\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0486 - accuracy: 0.3693 - val_loss: 1.0532 - val_accuracy: 0.3980\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 1.0474 - accuracy: 0.3768 - val_loss: 1.0519 - val_accuracy: 0.4081\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 1.0460 - accuracy: 0.3858 - val_loss: 1.0505 - val_accuracy: 0.4166\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 1.0447 - accuracy: 0.3950 - val_loss: 1.0490 - val_accuracy: 0.4250\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 1.0435 - accuracy: 0.4033 - val_loss: 1.0481 - val_accuracy: 0.4329\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 1.0420 - accuracy: 0.4173 - val_loss: 1.0457 - val_accuracy: 0.4449\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.0399 - accuracy: 0.4336 - val_loss: 1.0424 - val_accuracy: 0.4493\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0365 - accuracy: 0.4475 - val_loss: 1.0375 - val_accuracy: 0.4582\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0312 - accuracy: 0.4554 - val_loss: 1.0311 - val_accuracy: 0.4591\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0175 - accuracy: 0.4590 - val_loss: 1.0240 - val_accuracy: 0.4591\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 548us/step - loss: 1.0063 - accuracy: 0.4591 - val_loss: 1.0220 - val_accuracy: 0.4591\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 1.0030 - accuracy: 0.4591 - val_loss: 1.0204 - val_accuracy: 0.4591\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0013 - accuracy: 0.4591 - val_loss: 1.0198 - val_accuracy: 0.4591\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0002 - accuracy: 0.4591 - val_loss: 1.0194 - val_accuracy: 0.4591\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9997 - accuracy: 0.4591 - val_loss: 1.0193 - val_accuracy: 0.4591\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9992 - accuracy: 0.4591 - val_loss: 1.0193 - val_accuracy: 0.4591\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9990 - accuracy: 0.4591 - val_loss: 1.0194 - val_accuracy: 0.4591\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9988 - accuracy: 0.4591 - val_loss: 1.0191 - val_accuracy: 0.4591\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9986 - accuracy: 0.4592 - val_loss: 1.0189 - val_accuracy: 0.4591\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9985 - accuracy: 0.4592 - val_loss: 1.0189 - val_accuracy: 0.4591\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9986 - accuracy: 0.4592 - val_loss: 1.0189 - val_accuracy: 0.4591\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9982 - accuracy: 0.4592 - val_loss: 1.0188 - val_accuracy: 0.4591\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9981 - accuracy: 0.4592 - val_loss: 1.0187 - val_accuracy: 0.4591\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9980 - accuracy: 0.4592 - val_loss: 1.0187 - val_accuracy: 0.4591\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9981 - accuracy: 0.4592 - val_loss: 1.0187 - val_accuracy: 0.4591\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9980 - accuracy: 0.4592 - val_loss: 1.0187 - val_accuracy: 0.4591\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9987 - accuracy: 0.4592 - val_loss: 1.0190 - val_accuracy: 0.4591\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9980 - accuracy: 0.4592 - val_loss: 1.0186 - val_accuracy: 0.4591\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9978 - accuracy: 0.4592 - val_loss: 1.0186 - val_accuracy: 0.4591\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9978 - accuracy: 0.4592 - val_loss: 1.0186 - val_accuracy: 0.4591\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9978 - accuracy: 0.4592 - val_loss: 1.0186 - val_accuracy: 0.4591\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9978 - accuracy: 0.4592 - val_loss: 1.0186 - val_accuracy: 0.4591\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9977 - accuracy: 0.4592 - val_loss: 1.0185 - val_accuracy: 0.4591\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9977 - accuracy: 0.4592 - val_loss: 1.0184 - val_accuracy: 0.4591\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9977 - accuracy: 0.4592 - val_loss: 1.0185 - val_accuracy: 0.4591\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9977 - accuracy: 0.4592 - val_loss: 1.0185 - val_accuracy: 0.4591\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 598us/step - loss: 0.9977 - accuracy: 0.4592 - val_loss: 1.0185 - val_accuracy: 0.4591\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9977 - accuracy: 0.4592 - val_loss: 1.0185 - val_accuracy: 0.4591\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9977 - accuracy: 0.4592 - val_loss: 1.0184 - val_accuracy: 0.4591\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9976 - accuracy: 0.4592 - val_loss: 1.0183 - val_accuracy: 0.4591\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9976 - accuracy: 0.4592 - val_loss: 1.0183 - val_accuracy: 0.4591\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9976 - accuracy: 0.4592 - val_loss: 1.0183 - val_accuracy: 0.4591\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9976 - accuracy: 0.4592 - val_loss: 1.0183 - val_accuracy: 0.4591\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9975 - accuracy: 0.4592 - val_loss: 1.0183 - val_accuracy: 0.4591\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9978 - accuracy: 0.4592 - val_loss: 1.0183 - val_accuracy: 0.4591\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9975 - accuracy: 0.4592 - val_loss: 1.0183 - val_accuracy: 0.4591\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9976 - accuracy: 0.4592 - val_loss: 1.0183 - val_accuracy: 0.4591\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9974 - accuracy: 0.4592 - val_loss: 1.0182 - val_accuracy: 0.4591\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9975 - accuracy: 0.4592 - val_loss: 1.0183 - val_accuracy: 0.4591\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9974 - accuracy: 0.4592 - val_loss: 1.0182 - val_accuracy: 0.4591\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9974 - accuracy: 0.4592 - val_loss: 1.0183 - val_accuracy: 0.4591\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9975 - accuracy: 0.4592 - val_loss: 1.0182 - val_accuracy: 0.4591\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9974 - accuracy: 0.4592 - val_loss: 1.0181 - val_accuracy: 0.4591\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9974 - accuracy: 0.4592 - val_loss: 1.0181 - val_accuracy: 0.4591\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9973 - accuracy: 0.4592 - val_loss: 1.0181 - val_accuracy: 0.4591\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9973 - accuracy: 0.4592 - val_loss: 1.0180 - val_accuracy: 0.4591\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9973 - accuracy: 0.4592 - val_loss: 1.0180 - val_accuracy: 0.4591\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 749us/step - loss: 0.9973 - accuracy: 0.4592 - val_loss: 1.0181 - val_accuracy: 0.4591\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9973 - accuracy: 0.4592 - val_loss: 1.0180 - val_accuracy: 0.4591\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9972 - accuracy: 0.4592 - val_loss: 1.0180 - val_accuracy: 0.4591\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9973 - accuracy: 0.4592 - val_loss: 1.0180 - val_accuracy: 0.4591\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9975 - accuracy: 0.4592 - val_loss: 1.0179 - val_accuracy: 0.4591\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9971 - accuracy: 0.4592 - val_loss: 1.0180 - val_accuracy: 0.4591\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9971 - accuracy: 0.4592 - val_loss: 1.0178 - val_accuracy: 0.4591\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9971 - accuracy: 0.4592 - val_loss: 1.0178 - val_accuracy: 0.4591\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9971 - accuracy: 0.4592 - val_loss: 1.0178 - val_accuracy: 0.4591\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9970 - accuracy: 0.4592 - val_loss: 1.0178 - val_accuracy: 0.4591\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9970 - accuracy: 0.4592 - val_loss: 1.0178 - val_accuracy: 0.4591\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9970 - accuracy: 0.4592 - val_loss: 1.0177 - val_accuracy: 0.4591\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9969 - accuracy: 0.4592 - val_loss: 1.0176 - val_accuracy: 0.4591\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9968 - accuracy: 0.4592 - val_loss: 1.0176 - val_accuracy: 0.4591\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9971 - accuracy: 0.4592 - val_loss: 1.0176 - val_accuracy: 0.4591\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9967 - accuracy: 0.4592 - val_loss: 1.0174 - val_accuracy: 0.4591\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9966 - accuracy: 0.4592 - val_loss: 1.0175 - val_accuracy: 0.4591\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9965 - accuracy: 0.4592 - val_loss: 1.0174 - val_accuracy: 0.4591\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9964 - accuracy: 0.4592 - val_loss: 1.0173 - val_accuracy: 0.4591\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9967 - accuracy: 0.4592 - val_loss: 1.0173 - val_accuracy: 0.4591\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9964 - accuracy: 0.4592 - val_loss: 1.0173 - val_accuracy: 0.4591\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9965 - accuracy: 0.4592 - val_loss: 1.0173 - val_accuracy: 0.4591\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9968 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9963 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9967 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9963 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9962 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9963 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9966 - accuracy: 0.4592 - val_loss: 1.0173 - val_accuracy: 0.4591\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9962 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9962 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9961 - accuracy: 0.4592 - val_loss: 1.0173 - val_accuracy: 0.4591\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9960 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9961 - accuracy: 0.4592 - val_loss: 1.0173 - val_accuracy: 0.4591\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9961 - accuracy: 0.4592 - val_loss: 1.0173 - val_accuracy: 0.4591\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9961 - accuracy: 0.4592 - val_loss: 1.0173 - val_accuracy: 0.4591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9960 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9959 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9960 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9959 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9959 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9959 - accuracy: 0.4592 - val_loss: 1.0171 - val_accuracy: 0.4591\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9958 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9958 - accuracy: 0.4592 - val_loss: 1.0172 - val_accuracy: 0.4591\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9959 - accuracy: 0.4592 - val_loss: 1.0171 - val_accuracy: 0.4591\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9958 - accuracy: 0.4592 - val_loss: 1.0171 - val_accuracy: 0.4591\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9958 - accuracy: 0.4592 - val_loss: 1.0171 - val_accuracy: 0.4591\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9958 - accuracy: 0.4592 - val_loss: 1.0171 - val_accuracy: 0.4591\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9958 - accuracy: 0.4592 - val_loss: 1.0171 - val_accuracy: 0.4591\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9957 - accuracy: 0.4592 - val_loss: 1.0170 - val_accuracy: 0.4591\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9957 - accuracy: 0.4592 - val_loss: 1.0171 - val_accuracy: 0.4591\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9957 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9958 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9957 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9957 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9956 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9956 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9956 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9958 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9955 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9955 - accuracy: 0.4592 - val_loss: 1.0170 - val_accuracy: 0.4591\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9955 - accuracy: 0.4592 - val_loss: 1.0168 - val_accuracy: 0.4591\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9955 - accuracy: 0.4592 - val_loss: 1.0168 - val_accuracy: 0.4591\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9954 - accuracy: 0.4592 - val_loss: 1.0168 - val_accuracy: 0.4591\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9954 - accuracy: 0.4592 - val_loss: 1.0167 - val_accuracy: 0.4591\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9953 - accuracy: 0.4592 - val_loss: 1.0168 - val_accuracy: 0.4591\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9954 - accuracy: 0.4592 - val_loss: 1.0168 - val_accuracy: 0.4591\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9953 - accuracy: 0.4592 - val_loss: 1.0167 - val_accuracy: 0.4591\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9953 - accuracy: 0.4592 - val_loss: 1.0167 - val_accuracy: 0.4591\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9953 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9961 - accuracy: 0.4592 - val_loss: 1.0169 - val_accuracy: 0.4591\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9952 - accuracy: 0.4592 - val_loss: 1.0167 - val_accuracy: 0.4591\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9953 - accuracy: 0.4592 - val_loss: 1.0167 - val_accuracy: 0.4591\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9952 - accuracy: 0.4592 - val_loss: 1.0167 - val_accuracy: 0.4591\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9952 - accuracy: 0.4592 - val_loss: 1.0166 - val_accuracy: 0.4591\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9953 - accuracy: 0.4592 - val_loss: 1.0166 - val_accuracy: 0.4591\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9968 - accuracy: 0.4591 - val_loss: 1.0166 - val_accuracy: 0.4591\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9953 - accuracy: 0.4592 - val_loss: 1.0167 - val_accuracy: 0.4591\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9951 - accuracy: 0.4592 - val_loss: 1.0165 - val_accuracy: 0.4591\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9951 - accuracy: 0.4592 - val_loss: 1.0165 - val_accuracy: 0.4591\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9950 - accuracy: 0.4592 - val_loss: 1.0165 - val_accuracy: 0.4591\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9951 - accuracy: 0.4592 - val_loss: 1.0165 - val_accuracy: 0.4591\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9951 - accuracy: 0.4592 - val_loss: 1.0164 - val_accuracy: 0.4591\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9950 - accuracy: 0.4592 - val_loss: 1.0164 - val_accuracy: 0.4591\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9950 - accuracy: 0.4592 - val_loss: 1.0164 - val_accuracy: 0.4591\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9953 - accuracy: 0.4592 - val_loss: 1.0163 - val_accuracy: 0.4591\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9950 - accuracy: 0.4592 - val_loss: 1.0164 - val_accuracy: 0.4591\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9950 - accuracy: 0.4592 - val_loss: 1.0164 - val_accuracy: 0.4591\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9949 - accuracy: 0.4592 - val_loss: 1.0163 - val_accuracy: 0.4591\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9950 - accuracy: 0.4592 - val_loss: 1.0163 - val_accuracy: 0.4591\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9955 - accuracy: 0.4592 - val_loss: 1.0167 - val_accuracy: 0.4591\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9949 - accuracy: 0.4592 - val_loss: 1.0163 - val_accuracy: 0.4591\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 641us/step - loss: 0.9949 - accuracy: 0.4592 - val_loss: 1.0163 - val_accuracy: 0.4591\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9948 - accuracy: 0.4592 - val_loss: 1.0163 - val_accuracy: 0.4591\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9949 - accuracy: 0.4592 - val_loss: 1.0163 - val_accuracy: 0.4591\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9950 - accuracy: 0.4592 - val_loss: 1.0163 - val_accuracy: 0.4591\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9948 - accuracy: 0.4592 - val_loss: 1.0162 - val_accuracy: 0.4591\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9951 - accuracy: 0.4592 - val_loss: 1.0162 - val_accuracy: 0.4591\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9948 - accuracy: 0.4592 - val_loss: 1.0162 - val_accuracy: 0.4591\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9947 - accuracy: 0.4592 - val_loss: 1.0162 - val_accuracy: 0.4591\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9948 - accuracy: 0.4592 - val_loss: 1.0162 - val_accuracy: 0.4591\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9947 - accuracy: 0.4592 - val_loss: 1.0161 - val_accuracy: 0.4591\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9947 - accuracy: 0.4592 - val_loss: 1.0161 - val_accuracy: 0.4591\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9946 - accuracy: 0.4592 - val_loss: 1.0161 - val_accuracy: 0.4591\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9947 - accuracy: 0.4592 - val_loss: 1.0161 - val_accuracy: 0.4591\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9947 - accuracy: 0.4592 - val_loss: 1.0161 - val_accuracy: 0.4591\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9946 - accuracy: 0.4592 - val_loss: 1.0161 - val_accuracy: 0.4591\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9952 - accuracy: 0.4592 - val_loss: 1.0161 - val_accuracy: 0.4591\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9946 - accuracy: 0.4592 - val_loss: 1.0161 - val_accuracy: 0.4591\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9946 - accuracy: 0.4592 - val_loss: 1.0161 - val_accuracy: 0.4591\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9947 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9945 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9948 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9945 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9945 - accuracy: 0.4592 - val_loss: 1.0159 - val_accuracy: 0.4591\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9946 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9944 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9945 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9944 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9947 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9944 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9944 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9944 - accuracy: 0.4592 - val_loss: 1.0159 - val_accuracy: 0.4591\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9944 - accuracy: 0.4592 - val_loss: 1.0159 - val_accuracy: 0.4591\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9944 - accuracy: 0.4592 - val_loss: 1.0159 - val_accuracy: 0.4591\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9943 - accuracy: 0.4592 - val_loss: 1.0159 - val_accuracy: 0.4591\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9943 - accuracy: 0.4592 - val_loss: 1.0159 - val_accuracy: 0.4591\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9944 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9943 - accuracy: 0.4592 - val_loss: 1.0160 - val_accuracy: 0.4591\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9944 - accuracy: 0.4592 - val_loss: 1.0159 - val_accuracy: 0.4591\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 342us/step - loss: 0.9942 - accuracy: 0.4592\n",
      "Accuracy : 0.4591550827026367\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0159 - accuracy: 0.4591\n",
      "Accuracy : 0.4590526819229126\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.2998 - accuracy: 0.5296 - val_loss: 1.1949 - val_accuracy: 0.5126\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 1.1293 - accuracy: 0.5327 - val_loss: 1.0788 - val_accuracy: 0.5091\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0488 - accuracy: 0.5341 - val_loss: 1.0362 - val_accuracy: 0.5046\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0187 - accuracy: 0.5336 - val_loss: 1.0188 - val_accuracy: 0.5069\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0015 - accuracy: 0.5345 - val_loss: 1.0083 - val_accuracy: 0.5100\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9896 - accuracy: 0.5346 - val_loss: 1.0021 - val_accuracy: 0.5091\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9843 - accuracy: 0.5339 - val_loss: 0.9994 - val_accuracy: 0.5086\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9812 - accuracy: 0.5338 - val_loss: 0.9979 - val_accuracy: 0.5100\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9792 - accuracy: 0.5318 - val_loss: 0.9968 - val_accuracy: 0.5095\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9777 - accuracy: 0.5333 - val_loss: 0.9963 - val_accuracy: 0.5122\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9768 - accuracy: 0.5315 - val_loss: 0.9959 - val_accuracy: 0.5108\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9761 - accuracy: 0.5323 - val_loss: 0.9957 - val_accuracy: 0.5113\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9756 - accuracy: 0.5312 - val_loss: 0.9956 - val_accuracy: 0.5100\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9753 - accuracy: 0.5323 - val_loss: 0.9955 - val_accuracy: 0.5104\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9750 - accuracy: 0.5317 - val_loss: 0.9955 - val_accuracy: 0.5091\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9748 - accuracy: 0.5328 - val_loss: 0.9954 - val_accuracy: 0.5095\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9746 - accuracy: 0.5327 - val_loss: 0.9954 - val_accuracy: 0.5139\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 606us/step - loss: 0.9748 - accuracy: 0.5311 - val_loss: 0.9955 - val_accuracy: 0.5144\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9743 - accuracy: 0.5319 - val_loss: 0.9954 - val_accuracy: 0.5131\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9745 - accuracy: 0.5302 - val_loss: 0.9954 - val_accuracy: 0.5144\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9741 - accuracy: 0.5315 - val_loss: 0.9955 - val_accuracy: 0.5148\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9740 - accuracy: 0.5319 - val_loss: 0.9953 - val_accuracy: 0.5135\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9738 - accuracy: 0.5318 - val_loss: 0.9954 - val_accuracy: 0.5148\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9740 - accuracy: 0.5314 - val_loss: 0.9955 - val_accuracy: 0.5126\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9738 - accuracy: 0.5317 - val_loss: 0.9954 - val_accuracy: 0.5135\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9735 - accuracy: 0.5315 - val_loss: 0.9953 - val_accuracy: 0.5104\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9734 - accuracy: 0.5325 - val_loss: 0.9954 - val_accuracy: 0.5122\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9954 - val_accuracy: 0.5095\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9733 - accuracy: 0.5317 - val_loss: 0.9953 - val_accuracy: 0.5139\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9732 - accuracy: 0.5315 - val_loss: 0.9953 - val_accuracy: 0.5104\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9732 - accuracy: 0.5313 - val_loss: 0.9954 - val_accuracy: 0.5122\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 0.9955 - val_accuracy: 0.5148\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 0.9955 - val_accuracy: 0.5113\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9730 - accuracy: 0.5330 - val_loss: 0.9956 - val_accuracy: 0.5148\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9729 - accuracy: 0.5319 - val_loss: 0.9956 - val_accuracy: 0.5122\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9732 - accuracy: 0.5319 - val_loss: 0.9957 - val_accuracy: 0.5122\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9728 - accuracy: 0.5318 - val_loss: 0.9955 - val_accuracy: 0.5122\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9956 - val_accuracy: 0.5091\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9728 - accuracy: 0.5331 - val_loss: 0.9956 - val_accuracy: 0.5117\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9727 - accuracy: 0.5320 - val_loss: 0.9958 - val_accuracy: 0.5086\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9730 - accuracy: 0.5323 - val_loss: 0.9956 - val_accuracy: 0.5117\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9725 - accuracy: 0.5320 - val_loss: 0.9958 - val_accuracy: 0.5135\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9725 - accuracy: 0.5317 - val_loss: 0.9957 - val_accuracy: 0.5122\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9728 - accuracy: 0.5331 - val_loss: 0.9959 - val_accuracy: 0.5104\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9723 - accuracy: 0.5317 - val_loss: 0.9958 - val_accuracy: 0.5148\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9723 - accuracy: 0.5317 - val_loss: 0.9958 - val_accuracy: 0.5135\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9725 - accuracy: 0.5321 - val_loss: 0.9960 - val_accuracy: 0.5095\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9723 - accuracy: 0.5319 - val_loss: 0.9959 - val_accuracy: 0.5117\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9721 - accuracy: 0.5316 - val_loss: 0.9962 - val_accuracy: 0.5095\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9723 - accuracy: 0.5315 - val_loss: 0.9960 - val_accuracy: 0.5122\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9721 - accuracy: 0.5316 - val_loss: 0.9961 - val_accuracy: 0.5122\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 0.9962 - val_accuracy: 0.5117\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9720 - accuracy: 0.5316 - val_loss: 0.9960 - val_accuracy: 0.5091\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9721 - accuracy: 0.5317 - val_loss: 0.9960 - val_accuracy: 0.5104\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9720 - accuracy: 0.5314 - val_loss: 0.9961 - val_accuracy: 0.5086\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9724 - accuracy: 0.5324 - val_loss: 0.9965 - val_accuracy: 0.5104\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9724 - accuracy: 0.5321 - val_loss: 0.9962 - val_accuracy: 0.5135\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9719 - accuracy: 0.5319 - val_loss: 0.9962 - val_accuracy: 0.5122\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9722 - accuracy: 0.5331 - val_loss: 0.9963 - val_accuracy: 0.5135\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9718 - accuracy: 0.5323 - val_loss: 0.9962 - val_accuracy: 0.5139\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9963 - val_accuracy: 0.5144\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9718 - accuracy: 0.5316 - val_loss: 0.9965 - val_accuracy: 0.5122\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9718 - accuracy: 0.5321 - val_loss: 0.9963 - val_accuracy: 0.5122\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9716 - accuracy: 0.5319 - val_loss: 0.9969 - val_accuracy: 0.5104\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9720 - accuracy: 0.5320 - val_loss: 0.9965 - val_accuracy: 0.5095\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9717 - accuracy: 0.5319 - val_loss: 0.9964 - val_accuracy: 0.5095\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9717 - accuracy: 0.5321 - val_loss: 0.9964 - val_accuracy: 0.5131\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9716 - accuracy: 0.5316 - val_loss: 0.9967 - val_accuracy: 0.5117\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9717 - accuracy: 0.5328 - val_loss: 0.9968 - val_accuracy: 0.5148\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9716 - accuracy: 0.5324 - val_loss: 0.9967 - val_accuracy: 0.5135\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9715 - accuracy: 0.5326 - val_loss: 0.9967 - val_accuracy: 0.5144\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9716 - accuracy: 0.5312 - val_loss: 0.9967 - val_accuracy: 0.5095\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9715 - accuracy: 0.5325 - val_loss: 0.9968 - val_accuracy: 0.5104\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9715 - accuracy: 0.5324 - val_loss: 0.9967 - val_accuracy: 0.5135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9716 - accuracy: 0.5319 - val_loss: 0.9968 - val_accuracy: 0.5113\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9715 - accuracy: 0.5329 - val_loss: 0.9968 - val_accuracy: 0.5126\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9714 - accuracy: 0.5328 - val_loss: 0.9969 - val_accuracy: 0.5135\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9714 - accuracy: 0.5320 - val_loss: 0.9970 - val_accuracy: 0.5131\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9712 - accuracy: 0.5318 - val_loss: 0.9970 - val_accuracy: 0.5100\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9716 - accuracy: 0.5325 - val_loss: 0.9971 - val_accuracy: 0.5104\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9715 - accuracy: 0.5318 - val_loss: 0.9972 - val_accuracy: 0.5126\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9714 - accuracy: 0.5319 - val_loss: 0.9974 - val_accuracy: 0.5135\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9717 - accuracy: 0.5316 - val_loss: 0.9971 - val_accuracy: 0.5144\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9712 - accuracy: 0.5314 - val_loss: 0.9971 - val_accuracy: 0.5144\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9715 - accuracy: 0.5304 - val_loss: 0.9971 - val_accuracy: 0.5135\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9712 - accuracy: 0.5317 - val_loss: 0.9971 - val_accuracy: 0.5153\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9712 - accuracy: 0.5315 - val_loss: 0.9972 - val_accuracy: 0.5131\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9712 - accuracy: 0.5322 - val_loss: 0.9971 - val_accuracy: 0.5135\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9711 - accuracy: 0.5316 - val_loss: 0.9971 - val_accuracy: 0.5122\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9711 - accuracy: 0.5321 - val_loss: 0.9972 - val_accuracy: 0.5104\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9714 - accuracy: 0.5317 - val_loss: 0.9972 - val_accuracy: 0.5117\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9710 - accuracy: 0.5315 - val_loss: 0.9971 - val_accuracy: 0.5131\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9711 - accuracy: 0.5319 - val_loss: 0.9972 - val_accuracy: 0.5117\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9710 - accuracy: 0.5316 - val_loss: 0.9976 - val_accuracy: 0.5148\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9711 - accuracy: 0.5318 - val_loss: 0.9973 - val_accuracy: 0.5126\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9712 - accuracy: 0.5314 - val_loss: 0.9973 - val_accuracy: 0.5095\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9711 - accuracy: 0.5325 - val_loss: 0.9974 - val_accuracy: 0.5122\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9709 - accuracy: 0.5320 - val_loss: 0.9976 - val_accuracy: 0.5122\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9710 - accuracy: 0.5324 - val_loss: 0.9974 - val_accuracy: 0.5104\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9711 - accuracy: 0.5323 - val_loss: 0.9973 - val_accuracy: 0.5095\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9714 - accuracy: 0.5317 - val_loss: 0.9974 - val_accuracy: 0.5131\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9709 - accuracy: 0.5317 - val_loss: 0.9977 - val_accuracy: 0.5126\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9710 - accuracy: 0.5321 - val_loss: 0.9976 - val_accuracy: 0.5122\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9709 - accuracy: 0.5320 - val_loss: 0.9976 - val_accuracy: 0.5104\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9710 - accuracy: 0.5323 - val_loss: 0.9975 - val_accuracy: 0.5126\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9709 - accuracy: 0.5318 - val_loss: 0.9976 - val_accuracy: 0.5135\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9709 - accuracy: 0.5327 - val_loss: 0.9976 - val_accuracy: 0.5117\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9708 - accuracy: 0.5318 - val_loss: 0.9976 - val_accuracy: 0.5104\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9708 - accuracy: 0.5317 - val_loss: 0.9976 - val_accuracy: 0.5095\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9708 - accuracy: 0.5325 - val_loss: 0.9978 - val_accuracy: 0.5104\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9708 - accuracy: 0.5321 - val_loss: 0.9975 - val_accuracy: 0.5104\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9711 - accuracy: 0.5324 - val_loss: 0.9978 - val_accuracy: 0.5117\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9707 - accuracy: 0.5319 - val_loss: 0.9977 - val_accuracy: 0.5131\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9710 - accuracy: 0.5321 - val_loss: 0.9977 - val_accuracy: 0.5117\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9709 - accuracy: 0.5318 - val_loss: 0.9981 - val_accuracy: 0.5131\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9713 - accuracy: 0.5318 - val_loss: 0.9979 - val_accuracy: 0.5135\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9708 - accuracy: 0.5322 - val_loss: 0.9978 - val_accuracy: 0.5117\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9707 - accuracy: 0.5321 - val_loss: 0.9977 - val_accuracy: 0.5148\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9707 - accuracy: 0.5321 - val_loss: 0.9979 - val_accuracy: 0.5126\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9707 - accuracy: 0.5317 - val_loss: 0.9981 - val_accuracy: 0.5113\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9711 - accuracy: 0.5321 - val_loss: 0.9981 - val_accuracy: 0.5117\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9708 - accuracy: 0.5318 - val_loss: 0.9978 - val_accuracy: 0.5100\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9709 - accuracy: 0.5328 - val_loss: 0.9979 - val_accuracy: 0.5122\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9707 - accuracy: 0.5317 - val_loss: 0.9980 - val_accuracy: 0.5131\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9707 - accuracy: 0.5318 - val_loss: 0.9979 - val_accuracy: 0.5086\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9710 - accuracy: 0.5329 - val_loss: 0.9979 - val_accuracy: 0.5095\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9711 - accuracy: 0.5322 - val_loss: 0.9981 - val_accuracy: 0.5117\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9707 - accuracy: 0.5318 - val_loss: 0.9979 - val_accuracy: 0.5131\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9707 - accuracy: 0.5317 - val_loss: 0.9980 - val_accuracy: 0.5131\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9706 - accuracy: 0.5324 - val_loss: 0.9981 - val_accuracy: 0.5113\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9711 - accuracy: 0.5319 - val_loss: 0.9980 - val_accuracy: 0.5117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9706 - accuracy: 0.5318 - val_loss: 0.9980 - val_accuracy: 0.5126\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9705 - accuracy: 0.5315 - val_loss: 0.9980 - val_accuracy: 0.5126\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9706 - accuracy: 0.5317 - val_loss: 0.9980 - val_accuracy: 0.5117\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9706 - accuracy: 0.5321 - val_loss: 0.9980 - val_accuracy: 0.5086\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9705 - accuracy: 0.5325 - val_loss: 0.9982 - val_accuracy: 0.5117\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 566us/step - loss: 0.9704 - accuracy: 0.5316 - val_loss: 0.9982 - val_accuracy: 0.5095\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 737us/step - loss: 0.9705 - accuracy: 0.5315 - val_loss: 0.9981 - val_accuracy: 0.5122\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9705 - accuracy: 0.5313 - val_loss: 0.9985 - val_accuracy: 0.5104\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9709 - accuracy: 0.5321 - val_loss: 0.9983 - val_accuracy: 0.5122\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9705 - accuracy: 0.5319 - val_loss: 0.9983 - val_accuracy: 0.5091\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9705 - accuracy: 0.5316 - val_loss: 0.9981 - val_accuracy: 0.5117\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9704 - accuracy: 0.5315 - val_loss: 0.9982 - val_accuracy: 0.5104\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9703 - accuracy: 0.5317 - val_loss: 0.9982 - val_accuracy: 0.5104\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9704 - accuracy: 0.5319 - val_loss: 0.9982 - val_accuracy: 0.5108\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9705 - accuracy: 0.5318 - val_loss: 0.9982 - val_accuracy: 0.5108\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9703 - accuracy: 0.5320 - val_loss: 0.9984 - val_accuracy: 0.5122\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9704 - accuracy: 0.5319 - val_loss: 0.9982 - val_accuracy: 0.5095\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9705 - accuracy: 0.5316 - val_loss: 0.9982 - val_accuracy: 0.5095\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9704 - accuracy: 0.5313 - val_loss: 0.9985 - val_accuracy: 0.5122\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9704 - accuracy: 0.5317 - val_loss: 0.9982 - val_accuracy: 0.5117\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9706 - accuracy: 0.5321 - val_loss: 0.9981 - val_accuracy: 0.5117\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9704 - accuracy: 0.5311 - val_loss: 0.9982 - val_accuracy: 0.5122\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9702 - accuracy: 0.5320 - val_loss: 0.9984 - val_accuracy: 0.5122\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9706 - accuracy: 0.5317 - val_loss: 0.9984 - val_accuracy: 0.5139\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9702 - accuracy: 0.5319 - val_loss: 0.9985 - val_accuracy: 0.5100\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9705 - accuracy: 0.5322 - val_loss: 0.9982 - val_accuracy: 0.5122\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9702 - accuracy: 0.5315 - val_loss: 0.9985 - val_accuracy: 0.5095\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9703 - accuracy: 0.5316 - val_loss: 0.9984 - val_accuracy: 0.5131\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9704 - accuracy: 0.5314 - val_loss: 0.9984 - val_accuracy: 0.5122\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9701 - accuracy: 0.5322 - val_loss: 0.9983 - val_accuracy: 0.5095\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9703 - accuracy: 0.5329 - val_loss: 0.9988 - val_accuracy: 0.5104\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9706 - accuracy: 0.5316 - val_loss: 0.9986 - val_accuracy: 0.5095\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9706 - accuracy: 0.5325 - val_loss: 0.9985 - val_accuracy: 0.5108\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9701 - accuracy: 0.5316 - val_loss: 0.9985 - val_accuracy: 0.5126\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9703 - accuracy: 0.5320 - val_loss: 0.9985 - val_accuracy: 0.5122\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9702 - accuracy: 0.5316 - val_loss: 0.9987 - val_accuracy: 0.5117\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9703 - accuracy: 0.5316 - val_loss: 0.9986 - val_accuracy: 0.5131\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9702 - accuracy: 0.5313 - val_loss: 0.9987 - val_accuracy: 0.5117\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9703 - accuracy: 0.5315 - val_loss: 0.9988 - val_accuracy: 0.5108\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9702 - accuracy: 0.5318 - val_loss: 0.9985 - val_accuracy: 0.5117\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9701 - accuracy: 0.5319 - val_loss: 0.9986 - val_accuracy: 0.5095\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9712 - accuracy: 0.5340 - val_loss: 0.9986 - val_accuracy: 0.5122\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9705 - accuracy: 0.5315 - val_loss: 0.9987 - val_accuracy: 0.5144\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9702 - accuracy: 0.5321 - val_loss: 0.9991 - val_accuracy: 0.5122\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9703 - accuracy: 0.5315 - val_loss: 0.9986 - val_accuracy: 0.5091\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9702 - accuracy: 0.5316 - val_loss: 0.9987 - val_accuracy: 0.5104\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9701 - accuracy: 0.5323 - val_loss: 0.9987 - val_accuracy: 0.5122\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9700 - accuracy: 0.5318 - val_loss: 0.9986 - val_accuracy: 0.5122\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9701 - accuracy: 0.5317 - val_loss: 0.9988 - val_accuracy: 0.5095\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9700 - accuracy: 0.5314 - val_loss: 0.9989 - val_accuracy: 0.5104\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9701 - accuracy: 0.5315 - val_loss: 0.9988 - val_accuracy: 0.5117\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9701 - accuracy: 0.5317 - val_loss: 0.9987 - val_accuracy: 0.5104\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9701 - accuracy: 0.5334 - val_loss: 0.9989 - val_accuracy: 0.5117\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9704 - accuracy: 0.5313 - val_loss: 0.9988 - val_accuracy: 0.5104\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9700 - accuracy: 0.5314 - val_loss: 0.9988 - val_accuracy: 0.5095\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9703 - accuracy: 0.5321 - val_loss: 0.9989 - val_accuracy: 0.5122\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 581us/step - loss: 0.9701 - accuracy: 0.5317 - val_loss: 0.9990 - val_accuracy: 0.5122\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9701 - accuracy: 0.5318 - val_loss: 0.9989 - val_accuracy: 0.5095\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9700 - accuracy: 0.5324 - val_loss: 0.9990 - val_accuracy: 0.5095\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9700 - accuracy: 0.5324 - val_loss: 0.9988 - val_accuracy: 0.5095\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9700 - accuracy: 0.5325 - val_loss: 0.9990 - val_accuracy: 0.5091\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9701 - accuracy: 0.5322 - val_loss: 0.9990 - val_accuracy: 0.5104\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9700 - accuracy: 0.5317 - val_loss: 0.9989 - val_accuracy: 0.5113\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9700 - accuracy: 0.5320 - val_loss: 0.9988 - val_accuracy: 0.5117\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9701 - accuracy: 0.5328 - val_loss: 0.9989 - val_accuracy: 0.5095\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9700 - accuracy: 0.5323 - val_loss: 0.9989 - val_accuracy: 0.5100\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9700 - accuracy: 0.5318 - val_loss: 0.9990 - val_accuracy: 0.5108\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9700 - accuracy: 0.5311 - val_loss: 0.9988 - val_accuracy: 0.5104\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9700 - accuracy: 0.5316 - val_loss: 0.9988 - val_accuracy: 0.5095\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 337us/step - loss: 0.9698 - accuracy: 0.5317\n",
      "Accuracy : 0.5316972136497498\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9988 - accuracy: 0.5095\n",
      "Accuracy : 0.5095174908638\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.0810 - accuracy: 0.5019 - val_loss: 1.0774 - val_accuracy: 0.5126\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 766us/step - loss: 1.0465 - accuracy: 0.5223 - val_loss: 1.0408 - val_accuracy: 0.5197\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0093 - accuracy: 0.5302 - val_loss: 1.0208 - val_accuracy: 0.5170\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9979 - accuracy: 0.5304 - val_loss: 1.0169 - val_accuracy: 0.5073\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9953 - accuracy: 0.5281 - val_loss: 1.0156 - val_accuracy: 0.5095\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9940 - accuracy: 0.5307 - val_loss: 1.0142 - val_accuracy: 0.5113\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9929 - accuracy: 0.5315 - val_loss: 1.0131 - val_accuracy: 0.5135\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9918 - accuracy: 0.5315 - val_loss: 1.0122 - val_accuracy: 0.5166\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9909 - accuracy: 0.5316 - val_loss: 1.0113 - val_accuracy: 0.5184\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9904 - accuracy: 0.5315 - val_loss: 1.0105 - val_accuracy: 0.5184\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9896 - accuracy: 0.5325 - val_loss: 1.0097 - val_accuracy: 0.5166\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9889 - accuracy: 0.5316 - val_loss: 1.0090 - val_accuracy: 0.5166\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9885 - accuracy: 0.5323 - val_loss: 1.0085 - val_accuracy: 0.5170\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9881 - accuracy: 0.5320 - val_loss: 1.0079 - val_accuracy: 0.5193\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9876 - accuracy: 0.5315 - val_loss: 1.0075 - val_accuracy: 0.5179\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9872 - accuracy: 0.5317 - val_loss: 1.0071 - val_accuracy: 0.5215\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9872 - accuracy: 0.5318 - val_loss: 1.0067 - val_accuracy: 0.5268\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9868 - accuracy: 0.5310 - val_loss: 1.0062 - val_accuracy: 0.5232\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9865 - accuracy: 0.5323 - val_loss: 1.0060 - val_accuracy: 0.5232\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9863 - accuracy: 0.5317 - val_loss: 1.0059 - val_accuracy: 0.5232\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9861 - accuracy: 0.5320 - val_loss: 1.0054 - val_accuracy: 0.5246\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9860 - accuracy: 0.5315 - val_loss: 1.0052 - val_accuracy: 0.5246\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9857 - accuracy: 0.5313 - val_loss: 1.0051 - val_accuracy: 0.5232\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9857 - accuracy: 0.5317 - val_loss: 1.0049 - val_accuracy: 0.5255\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9856 - accuracy: 0.5315 - val_loss: 1.0047 - val_accuracy: 0.5246\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9854 - accuracy: 0.5312 - val_loss: 1.0045 - val_accuracy: 0.5272\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9853 - accuracy: 0.5316 - val_loss: 1.0043 - val_accuracy: 0.5232\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9852 - accuracy: 0.5317 - val_loss: 1.0041 - val_accuracy: 0.5246\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9853 - accuracy: 0.5315 - val_loss: 1.0040 - val_accuracy: 0.5246\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9849 - accuracy: 0.5320 - val_loss: 1.0040 - val_accuracy: 0.5259\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9848 - accuracy: 0.5315 - val_loss: 1.0038 - val_accuracy: 0.5237\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9853 - accuracy: 0.5316 - val_loss: 1.0036 - val_accuracy: 0.5232\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9848 - accuracy: 0.5316 - val_loss: 1.0035 - val_accuracy: 0.5259\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9848 - accuracy: 0.5316 - val_loss: 1.0034 - val_accuracy: 0.5259\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9844 - accuracy: 0.5306 - val_loss: 1.0034 - val_accuracy: 0.5259\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9844 - accuracy: 0.5320 - val_loss: 1.0034 - val_accuracy: 0.5241\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9841 - accuracy: 0.5318 - val_loss: 1.0033 - val_accuracy: 0.5263\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9841 - accuracy: 0.5316 - val_loss: 1.0030 - val_accuracy: 0.5268\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9838 - accuracy: 0.5321 - val_loss: 1.0030 - val_accuracy: 0.5259\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9837 - accuracy: 0.5319 - val_loss: 1.0028 - val_accuracy: 0.5232\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9836 - accuracy: 0.5321 - val_loss: 1.0026 - val_accuracy: 0.5237\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9835 - accuracy: 0.5326 - val_loss: 1.0025 - val_accuracy: 0.5232\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 592us/step - loss: 0.9833 - accuracy: 0.5320 - val_loss: 1.0023 - val_accuracy: 0.5237\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9830 - accuracy: 0.5319 - val_loss: 1.0021 - val_accuracy: 0.5228\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9835 - accuracy: 0.5321 - val_loss: 1.0018 - val_accuracy: 0.5228\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9827 - accuracy: 0.5317 - val_loss: 1.0015 - val_accuracy: 0.5232\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9826 - accuracy: 0.5321 - val_loss: 1.0014 - val_accuracy: 0.5232\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9823 - accuracy: 0.5320 - val_loss: 1.0012 - val_accuracy: 0.5237\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9820 - accuracy: 0.5321 - val_loss: 1.0011 - val_accuracy: 0.5232\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9816 - accuracy: 0.5316 - val_loss: 1.0008 - val_accuracy: 0.5241\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9813 - accuracy: 0.5318 - val_loss: 1.0003 - val_accuracy: 0.5237\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9811 - accuracy: 0.5316 - val_loss: 1.0000 - val_accuracy: 0.5232\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9811 - accuracy: 0.5322 - val_loss: 0.9996 - val_accuracy: 0.5232\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9805 - accuracy: 0.5319 - val_loss: 0.9993 - val_accuracy: 0.5215\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9805 - accuracy: 0.5321 - val_loss: 0.9988 - val_accuracy: 0.5215\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9795 - accuracy: 0.5321 - val_loss: 0.9985 - val_accuracy: 0.5210\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9794 - accuracy: 0.5314 - val_loss: 0.9982 - val_accuracy: 0.5210\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9790 - accuracy: 0.5329 - val_loss: 0.9977 - val_accuracy: 0.5206\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 508us/step - loss: 0.9782 - accuracy: 0.5315 - val_loss: 0.9971 - val_accuracy: 0.5206\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9780 - accuracy: 0.5322 - val_loss: 0.9965 - val_accuracy: 0.5215\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5323 - val_loss: 0.9961 - val_accuracy: 0.5206\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9770 - accuracy: 0.5318 - val_loss: 0.9956 - val_accuracy: 0.5201\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9765 - accuracy: 0.5326 - val_loss: 0.9951 - val_accuracy: 0.5210\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 690us/step - loss: 0.9758 - accuracy: 0.5317 - val_loss: 0.9946 - val_accuracy: 0.5210\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9757 - accuracy: 0.5327 - val_loss: 0.9941 - val_accuracy: 0.5237\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9752 - accuracy: 0.5312 - val_loss: 0.9937 - val_accuracy: 0.5241\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9747 - accuracy: 0.5317 - val_loss: 0.9933 - val_accuracy: 0.5215\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9743 - accuracy: 0.5325 - val_loss: 0.9929 - val_accuracy: 0.5210\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9739 - accuracy: 0.5319 - val_loss: 0.9926 - val_accuracy: 0.5210\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9735 - accuracy: 0.5326 - val_loss: 0.9924 - val_accuracy: 0.5179\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9738 - accuracy: 0.5313 - val_loss: 0.9921 - val_accuracy: 0.5197\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9733 - accuracy: 0.5322 - val_loss: 0.9918 - val_accuracy: 0.5201\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9729 - accuracy: 0.5323 - val_loss: 0.9916 - val_accuracy: 0.5215\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9727 - accuracy: 0.5327 - val_loss: 0.9915 - val_accuracy: 0.5215\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9730 - accuracy: 0.5324 - val_loss: 0.9912 - val_accuracy: 0.5237\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9727 - accuracy: 0.5319 - val_loss: 0.9910 - val_accuracy: 0.5228\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9725 - accuracy: 0.5323 - val_loss: 0.9910 - val_accuracy: 0.5206\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9722 - accuracy: 0.5322 - val_loss: 0.9908 - val_accuracy: 0.5237\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9722 - accuracy: 0.5316 - val_loss: 0.9907 - val_accuracy: 0.5237\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9720 - accuracy: 0.5322 - val_loss: 0.9907 - val_accuracy: 0.5215\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9720 - accuracy: 0.5324 - val_loss: 0.9906 - val_accuracy: 0.5232\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9719 - accuracy: 0.5320 - val_loss: 0.9905 - val_accuracy: 0.5228\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9720 - accuracy: 0.5327 - val_loss: 0.9904 - val_accuracy: 0.5228\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9719 - accuracy: 0.5315 - val_loss: 0.9903 - val_accuracy: 0.5237\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9719 - accuracy: 0.5325 - val_loss: 0.9902 - val_accuracy: 0.5237\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9719 - accuracy: 0.5318 - val_loss: 0.9901 - val_accuracy: 0.5228\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9901 - val_accuracy: 0.5237\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9718 - accuracy: 0.5319 - val_loss: 0.9899 - val_accuracy: 0.5228\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9717 - accuracy: 0.5319 - val_loss: 0.9898 - val_accuracy: 0.5237\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9716 - accuracy: 0.5319 - val_loss: 0.9898 - val_accuracy: 0.5237\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9716 - accuracy: 0.5322 - val_loss: 0.9898 - val_accuracy: 0.5237\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9716 - accuracy: 0.5317 - val_loss: 0.9897 - val_accuracy: 0.5237\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9717 - accuracy: 0.5319 - val_loss: 0.9897 - val_accuracy: 0.5232\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9717 - accuracy: 0.5318 - val_loss: 0.9897 - val_accuracy: 0.5232\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9717 - accuracy: 0.5318 - val_loss: 0.9896 - val_accuracy: 0.5237\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9714 - accuracy: 0.5319 - val_loss: 0.9898 - val_accuracy: 0.5250\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9896 - val_accuracy: 0.5246\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9714 - accuracy: 0.5313 - val_loss: 0.9896 - val_accuracy: 0.5237\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9714 - accuracy: 0.5318 - val_loss: 0.9896 - val_accuracy: 0.5237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9715 - accuracy: 0.5320 - val_loss: 0.9895 - val_accuracy: 0.5250\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9715 - accuracy: 0.5321 - val_loss: 0.9894 - val_accuracy: 0.5263\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9715 - accuracy: 0.5310 - val_loss: 0.9894 - val_accuracy: 0.5268\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9717 - accuracy: 0.5311 - val_loss: 0.9893 - val_accuracy: 0.5268\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9715 - accuracy: 0.5323 - val_loss: 0.9893 - val_accuracy: 0.5237\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9714 - accuracy: 0.5316 - val_loss: 0.9893 - val_accuracy: 0.5246\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9714 - accuracy: 0.5312 - val_loss: 0.9892 - val_accuracy: 0.5250\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9715 - accuracy: 0.5304 - val_loss: 0.9892 - val_accuracy: 0.5232\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9713 - accuracy: 0.5319 - val_loss: 0.9892 - val_accuracy: 0.5237\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9715 - accuracy: 0.5316 - val_loss: 0.9892 - val_accuracy: 0.5250\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9716 - accuracy: 0.5314 - val_loss: 0.9891 - val_accuracy: 0.5241\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9713 - accuracy: 0.5317 - val_loss: 0.9891 - val_accuracy: 0.5268\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9713 - accuracy: 0.5315 - val_loss: 0.9891 - val_accuracy: 0.5268\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9714 - accuracy: 0.5306 - val_loss: 0.9889 - val_accuracy: 0.5237\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9713 - accuracy: 0.5311 - val_loss: 0.9889 - val_accuracy: 0.5263\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9716 - accuracy: 0.5323 - val_loss: 0.9889 - val_accuracy: 0.5250\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9713 - accuracy: 0.5315 - val_loss: 0.9889 - val_accuracy: 0.5268\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9712 - accuracy: 0.5311 - val_loss: 0.9889 - val_accuracy: 0.5250\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9712 - accuracy: 0.5317 - val_loss: 0.9891 - val_accuracy: 0.5268\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9714 - accuracy: 0.5315 - val_loss: 0.9890 - val_accuracy: 0.5237\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9713 - accuracy: 0.5321 - val_loss: 0.9889 - val_accuracy: 0.5272\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9712 - accuracy: 0.5313 - val_loss: 0.9888 - val_accuracy: 0.5250\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9713 - accuracy: 0.5321 - val_loss: 0.9889 - val_accuracy: 0.5250\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9712 - accuracy: 0.5310 - val_loss: 0.9888 - val_accuracy: 0.5250\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9712 - accuracy: 0.5314 - val_loss: 0.9888 - val_accuracy: 0.5268\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9713 - accuracy: 0.5314 - val_loss: 0.9888 - val_accuracy: 0.5241\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9713 - accuracy: 0.5314 - val_loss: 0.9888 - val_accuracy: 0.5268\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9712 - accuracy: 0.5313 - val_loss: 0.9890 - val_accuracy: 0.5268\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9714 - accuracy: 0.5315 - val_loss: 0.9887 - val_accuracy: 0.5250\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9714 - accuracy: 0.5318 - val_loss: 0.9888 - val_accuracy: 0.5232\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9715 - accuracy: 0.5319 - val_loss: 0.9888 - val_accuracy: 0.5232\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9715 - accuracy: 0.5318 - val_loss: 0.9887 - val_accuracy: 0.5268\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9713 - accuracy: 0.5307 - val_loss: 0.9888 - val_accuracy: 0.5268\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9714 - accuracy: 0.5320 - val_loss: 0.9887 - val_accuracy: 0.5241\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 0.9887 - val_accuracy: 0.5250\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9713 - accuracy: 0.5325 - val_loss: 0.9887 - val_accuracy: 0.5250\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9710 - accuracy: 0.5309 - val_loss: 0.9887 - val_accuracy: 0.5241\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9714 - accuracy: 0.5322 - val_loss: 0.9888 - val_accuracy: 0.5268\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9712 - accuracy: 0.5313 - val_loss: 0.9887 - val_accuracy: 0.5268\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9712 - accuracy: 0.5321 - val_loss: 0.9886 - val_accuracy: 0.5241\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9712 - accuracy: 0.5326 - val_loss: 0.9887 - val_accuracy: 0.5268\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9711 - accuracy: 0.5321 - val_loss: 0.9887 - val_accuracy: 0.5241\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 0.9886 - val_accuracy: 0.5250\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9711 - accuracy: 0.5319 - val_loss: 0.9886 - val_accuracy: 0.5263\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9714 - accuracy: 0.5315 - val_loss: 0.9884 - val_accuracy: 0.5250\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9716 - accuracy: 0.5306 - val_loss: 0.9884 - val_accuracy: 0.5263\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9711 - accuracy: 0.5305 - val_loss: 0.9884 - val_accuracy: 0.5259\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9711 - accuracy: 0.5324 - val_loss: 0.9886 - val_accuracy: 0.5272\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9711 - accuracy: 0.5310 - val_loss: 0.9885 - val_accuracy: 0.5250\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9711 - accuracy: 0.5314 - val_loss: 0.9884 - val_accuracy: 0.5250\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9712 - accuracy: 0.5315 - val_loss: 0.9884 - val_accuracy: 0.5263\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9711 - accuracy: 0.5320 - val_loss: 0.9883 - val_accuracy: 0.5268\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9712 - accuracy: 0.5315 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9712 - accuracy: 0.5306 - val_loss: 0.9882 - val_accuracy: 0.5259\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9710 - accuracy: 0.5316 - val_loss: 0.9884 - val_accuracy: 0.5241\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 0.9883 - val_accuracy: 0.5250\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 570us/step - loss: 0.9710 - accuracy: 0.5306 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9710 - accuracy: 0.5315 - val_loss: 0.9883 - val_accuracy: 0.5250\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9712 - accuracy: 0.5310 - val_loss: 0.9882 - val_accuracy: 0.5250\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9709 - accuracy: 0.5315 - val_loss: 0.9883 - val_accuracy: 0.5263\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9713 - accuracy: 0.5305 - val_loss: 0.9881 - val_accuracy: 0.5263\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9710 - accuracy: 0.5306 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9710 - accuracy: 0.5314 - val_loss: 0.9882 - val_accuracy: 0.5250\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9709 - accuracy: 0.5313 - val_loss: 0.9882 - val_accuracy: 0.5250\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9710 - accuracy: 0.5305 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9709 - accuracy: 0.5308 - val_loss: 0.9881 - val_accuracy: 0.5259\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9709 - accuracy: 0.5311 - val_loss: 0.9882 - val_accuracy: 0.5250\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9711 - accuracy: 0.5314 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9710 - accuracy: 0.5308 - val_loss: 0.9881 - val_accuracy: 0.5250\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9710 - accuracy: 0.5324 - val_loss: 0.9883 - val_accuracy: 0.5241\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9713 - accuracy: 0.5318 - val_loss: 0.9882 - val_accuracy: 0.5281\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9713 - accuracy: 0.5309 - val_loss: 0.9881 - val_accuracy: 0.5268\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9713 - accuracy: 0.5313 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9709 - accuracy: 0.5314 - val_loss: 0.9883 - val_accuracy: 0.5250\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9710 - accuracy: 0.5315 - val_loss: 0.9882 - val_accuracy: 0.5263\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9710 - accuracy: 0.5302 - val_loss: 0.9882 - val_accuracy: 0.5263\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9709 - accuracy: 0.5302 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9712 - accuracy: 0.5318 - val_loss: 0.9882 - val_accuracy: 0.5259\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9710 - accuracy: 0.5308 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9712 - accuracy: 0.5324 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9709 - accuracy: 0.5315 - val_loss: 0.9882 - val_accuracy: 0.5259\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9710 - accuracy: 0.5309 - val_loss: 0.9881 - val_accuracy: 0.5268\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9711 - accuracy: 0.5310 - val_loss: 0.9881 - val_accuracy: 0.5272\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9710 - accuracy: 0.5311 - val_loss: 0.9881 - val_accuracy: 0.5272\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9716 - accuracy: 0.5301 - val_loss: 0.9881 - val_accuracy: 0.5281\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9710 - accuracy: 0.5309 - val_loss: 0.9880 - val_accuracy: 0.5255\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9709 - accuracy: 0.5312 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9708 - accuracy: 0.5311 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9709 - accuracy: 0.5308 - val_loss: 0.9882 - val_accuracy: 0.5263\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9709 - accuracy: 0.5305 - val_loss: 0.9881 - val_accuracy: 0.5259\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9711 - accuracy: 0.5318 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9711 - accuracy: 0.5314 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9709 - accuracy: 0.5321 - val_loss: 0.9881 - val_accuracy: 0.5259\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9708 - accuracy: 0.5313 - val_loss: 0.9882 - val_accuracy: 0.5250\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9709 - accuracy: 0.5308 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9708 - accuracy: 0.5310 - val_loss: 0.9882 - val_accuracy: 0.5263\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9708 - accuracy: 0.5318 - val_loss: 0.9882 - val_accuracy: 0.5263\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 0.9709 - accuracy: 0.5309 - val_loss: 0.9881 - val_accuracy: 0.5250\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9709 - accuracy: 0.5330 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9709 - accuracy: 0.5319 - val_loss: 0.9882 - val_accuracy: 0.5263\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 711us/step - loss: 0.9708 - accuracy: 0.5310 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 358us/step - loss: 0.9707 - accuracy: 0.5320\n",
      "Accuracy : 0.5320414900779724\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9882 - accuracy: 0.5255\n",
      "Accuracy : 0.5254537463188171\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.1335 - accuracy: 0.5105 - val_loss: 1.0587 - val_accuracy: 0.5144\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 1.0869 - accuracy: 0.4454 - val_loss: 1.0338 - val_accuracy: 0.4148\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0674 - accuracy: 0.3832 - val_loss: 1.0247 - val_accuracy: 0.3820\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 1.0566 - accuracy: 0.3649 - val_loss: 1.0202 - val_accuracy: 0.3630\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0493 - accuracy: 0.3449 - val_loss: 1.0181 - val_accuracy: 0.3524\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0447 - accuracy: 0.3365 - val_loss: 1.0170 - val_accuracy: 0.3533\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0410 - accuracy: 0.3351 - val_loss: 1.0163 - val_accuracy: 0.3537\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 1.0384 - accuracy: 0.3386 - val_loss: 1.0162 - val_accuracy: 0.3559\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0365 - accuracy: 0.3589 - val_loss: 1.0161 - val_accuracy: 0.3639\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 1.0348 - accuracy: 0.3684 - val_loss: 1.0156 - val_accuracy: 0.3656\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 629us/step - loss: 1.0336 - accuracy: 0.3792 - val_loss: 1.0153 - val_accuracy: 0.3927\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0325 - accuracy: 0.4232 - val_loss: 1.0149 - val_accuracy: 0.4586\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 1.0315 - accuracy: 0.4620 - val_loss: 1.0142 - val_accuracy: 0.5237\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0308 - accuracy: 0.5096 - val_loss: 1.0136 - val_accuracy: 0.5392\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 1.0299 - accuracy: 0.5204 - val_loss: 1.0129 - val_accuracy: 0.5387\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 1.0291 - accuracy: 0.5219 - val_loss: 1.0122 - val_accuracy: 0.5423\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0282 - accuracy: 0.5239 - val_loss: 1.0110 - val_accuracy: 0.5409\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 1.0273 - accuracy: 0.5241 - val_loss: 1.0101 - val_accuracy: 0.5414\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 1.0266 - accuracy: 0.5253 - val_loss: 1.0096 - val_accuracy: 0.5409\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 1.0255 - accuracy: 0.5257 - val_loss: 1.0083 - val_accuracy: 0.5427\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0244 - accuracy: 0.5270 - val_loss: 1.0068 - val_accuracy: 0.5432\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 1.0230 - accuracy: 0.5276 - val_loss: 1.0051 - val_accuracy: 0.5432\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0215 - accuracy: 0.5282 - val_loss: 1.0031 - val_accuracy: 0.5427\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 1.0200 - accuracy: 0.5284 - val_loss: 1.0017 - val_accuracy: 0.5427\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0179 - accuracy: 0.5282 - val_loss: 0.9989 - val_accuracy: 0.5423\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0158 - accuracy: 0.5282 - val_loss: 0.9966 - val_accuracy: 0.5427\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 1.0122 - accuracy: 0.5285 - val_loss: 0.9921 - val_accuracy: 0.5423\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0060 - accuracy: 0.5282 - val_loss: 0.9831 - val_accuracy: 0.5423\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9954 - accuracy: 0.5285 - val_loss: 0.9741 - val_accuracy: 0.5427\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9869 - accuracy: 0.5285 - val_loss: 0.9712 - val_accuracy: 0.5409\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9834 - accuracy: 0.5289 - val_loss: 0.9702 - val_accuracy: 0.5409\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9816 - accuracy: 0.5287 - val_loss: 0.9698 - val_accuracy: 0.5409\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9803 - accuracy: 0.5291 - val_loss: 0.9699 - val_accuracy: 0.5409\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9793 - accuracy: 0.5285 - val_loss: 0.9692 - val_accuracy: 0.5418\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9787 - accuracy: 0.5284 - val_loss: 0.9689 - val_accuracy: 0.5405\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9783 - accuracy: 0.5293 - val_loss: 0.9695 - val_accuracy: 0.5409\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9774 - accuracy: 0.5295 - val_loss: 0.9684 - val_accuracy: 0.5401\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9675 - val_accuracy: 0.5405\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9764 - accuracy: 0.5285 - val_loss: 0.9672 - val_accuracy: 0.5405\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9761 - accuracy: 0.5285 - val_loss: 0.9671 - val_accuracy: 0.5401\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9671 - val_accuracy: 0.5405\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9755 - accuracy: 0.5288 - val_loss: 0.9669 - val_accuracy: 0.5409\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9752 - accuracy: 0.5287 - val_loss: 0.9667 - val_accuracy: 0.5409\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9751 - accuracy: 0.5296 - val_loss: 0.9667 - val_accuracy: 0.5405\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9749 - accuracy: 0.5286 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9748 - accuracy: 0.5291 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9746 - accuracy: 0.5289 - val_loss: 0.9665 - val_accuracy: 0.5414\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9746 - accuracy: 0.5291 - val_loss: 0.9667 - val_accuracy: 0.5414\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9748 - accuracy: 0.5290 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9743 - accuracy: 0.5289 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9745 - accuracy: 0.5291 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9743 - accuracy: 0.5295 - val_loss: 0.9661 - val_accuracy: 0.5409\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9743 - accuracy: 0.5278 - val_loss: 0.9663 - val_accuracy: 0.5401\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9742 - accuracy: 0.5290 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9741 - accuracy: 0.5292 - val_loss: 0.9661 - val_accuracy: 0.5414\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9742 - accuracy: 0.5288 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9740 - accuracy: 0.5284 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9741 - accuracy: 0.5287 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9741 - accuracy: 0.5291 - val_loss: 0.9663 - val_accuracy: 0.5414\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9743 - accuracy: 0.5290 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9739 - accuracy: 0.5290 - val_loss: 0.9661 - val_accuracy: 0.5401\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9743 - accuracy: 0.5287 - val_loss: 0.9664 - val_accuracy: 0.5409\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9739 - accuracy: 0.5282 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9664 - val_accuracy: 0.5401\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9739 - accuracy: 0.5281 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9742 - accuracy: 0.5287 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9739 - accuracy: 0.5287 - val_loss: 0.9661 - val_accuracy: 0.5405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9741 - accuracy: 0.5292 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9742 - accuracy: 0.5285 - val_loss: 0.9666 - val_accuracy: 0.5396\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9740 - accuracy: 0.5289 - val_loss: 0.9664 - val_accuracy: 0.5396\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9741 - accuracy: 0.5289 - val_loss: 0.9664 - val_accuracy: 0.5409\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9738 - accuracy: 0.5283 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9737 - accuracy: 0.5293 - val_loss: 0.9661 - val_accuracy: 0.5401\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9738 - accuracy: 0.5284 - val_loss: 0.9665 - val_accuracy: 0.5414\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9739 - accuracy: 0.5296 - val_loss: 0.9661 - val_accuracy: 0.5401\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9738 - accuracy: 0.5292 - val_loss: 0.9661 - val_accuracy: 0.5409\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9738 - accuracy: 0.5280 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9740 - accuracy: 0.5285 - val_loss: 0.9664 - val_accuracy: 0.5414\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9740 - accuracy: 0.5295 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9738 - accuracy: 0.5288 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9738 - accuracy: 0.5285 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9738 - accuracy: 0.5283 - val_loss: 0.9663 - val_accuracy: 0.5401\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9737 - accuracy: 0.5283 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9737 - accuracy: 0.5283 - val_loss: 0.9663 - val_accuracy: 0.5401\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9739 - accuracy: 0.5283 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9737 - accuracy: 0.5281 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9738 - accuracy: 0.5283 - val_loss: 0.9660 - val_accuracy: 0.5401\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9737 - accuracy: 0.5284 - val_loss: 0.9661 - val_accuracy: 0.5409\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9741 - accuracy: 0.5286 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9739 - accuracy: 0.5293 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9738 - accuracy: 0.5289 - val_loss: 0.9663 - val_accuracy: 0.5396\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9740 - accuracy: 0.5284 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9737 - accuracy: 0.5288 - val_loss: 0.9661 - val_accuracy: 0.5405\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9739 - accuracy: 0.5278 - val_loss: 0.9665 - val_accuracy: 0.5414\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9739 - accuracy: 0.5290 - val_loss: 0.9659 - val_accuracy: 0.5401\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9738 - accuracy: 0.5291 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9738 - accuracy: 0.5286 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9737 - accuracy: 0.5287 - val_loss: 0.9669 - val_accuracy: 0.5409\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9746 - accuracy: 0.5283 - val_loss: 0.9671 - val_accuracy: 0.5409\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9737 - accuracy: 0.5283 - val_loss: 0.9668 - val_accuracy: 0.5409\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9741 - accuracy: 0.5295 - val_loss: 0.9669 - val_accuracy: 0.5396\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9738 - accuracy: 0.5290 - val_loss: 0.9666 - val_accuracy: 0.5405\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9738 - accuracy: 0.5283 - val_loss: 0.9672 - val_accuracy: 0.5405\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9739 - accuracy: 0.5285 - val_loss: 0.9668 - val_accuracy: 0.5401\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9737 - accuracy: 0.5285 - val_loss: 0.9668 - val_accuracy: 0.5405\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9667 - val_accuracy: 0.5409\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9738 - accuracy: 0.5292 - val_loss: 0.9664 - val_accuracy: 0.5401\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9736 - accuracy: 0.5281 - val_loss: 0.9665 - val_accuracy: 0.5405\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9737 - accuracy: 0.5283 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9736 - accuracy: 0.5287 - val_loss: 0.9666 - val_accuracy: 0.5414\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9739 - accuracy: 0.5279 - val_loss: 0.9666 - val_accuracy: 0.5401\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9736 - accuracy: 0.5285 - val_loss: 0.9664 - val_accuracy: 0.5401\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9736 - accuracy: 0.5285 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9736 - accuracy: 0.5295 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9736 - accuracy: 0.5285 - val_loss: 0.9659 - val_accuracy: 0.5405\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9736 - accuracy: 0.5284 - val_loss: 0.9660 - val_accuracy: 0.5409\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9738 - accuracy: 0.5288 - val_loss: 0.9661 - val_accuracy: 0.5409\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9739 - accuracy: 0.5288 - val_loss: 0.9661 - val_accuracy: 0.5401\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9738 - accuracy: 0.5283 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9736 - accuracy: 0.5280 - val_loss: 0.9664 - val_accuracy: 0.5414\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9737 - accuracy: 0.5295 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9736 - accuracy: 0.5292 - val_loss: 0.9659 - val_accuracy: 0.5401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9736 - accuracy: 0.5282 - val_loss: 0.9663 - val_accuracy: 0.5401\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9737 - accuracy: 0.5289 - val_loss: 0.9662 - val_accuracy: 0.5414\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9738 - accuracy: 0.5311 - val_loss: 0.9659 - val_accuracy: 0.5401\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9736 - accuracy: 0.5291 - val_loss: 0.9658 - val_accuracy: 0.5401\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9736 - accuracy: 0.5289 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9740 - accuracy: 0.5295 - val_loss: 0.9668 - val_accuracy: 0.5409\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9735 - accuracy: 0.5284 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9736 - accuracy: 0.5297 - val_loss: 0.9665 - val_accuracy: 0.5418\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9737 - accuracy: 0.5280 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9735 - accuracy: 0.5294 - val_loss: 0.9664 - val_accuracy: 0.5396\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9737 - accuracy: 0.5283 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9736 - accuracy: 0.5292 - val_loss: 0.9665 - val_accuracy: 0.5396\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9735 - accuracy: 0.5281 - val_loss: 0.9664 - val_accuracy: 0.5401\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9738 - accuracy: 0.5289 - val_loss: 0.9668 - val_accuracy: 0.5409\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9738 - accuracy: 0.5283 - val_loss: 0.9668 - val_accuracy: 0.5409\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9738 - accuracy: 0.5297 - val_loss: 0.9665 - val_accuracy: 0.5405\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9738 - accuracy: 0.5284 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9737 - accuracy: 0.5294 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 0.9661 - val_accuracy: 0.5405\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9735 - accuracy: 0.5289 - val_loss: 0.9661 - val_accuracy: 0.5401\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9735 - accuracy: 0.5285 - val_loss: 0.9661 - val_accuracy: 0.5401\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9738 - accuracy: 0.5290 - val_loss: 0.9666 - val_accuracy: 0.5401\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9736 - accuracy: 0.5296 - val_loss: 0.9661 - val_accuracy: 0.5409\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9735 - accuracy: 0.5288 - val_loss: 0.9664 - val_accuracy: 0.5401\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9736 - accuracy: 0.5300 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9736 - accuracy: 0.5286 - val_loss: 0.9663 - val_accuracy: 0.5401\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9738 - accuracy: 0.5291 - val_loss: 0.9667 - val_accuracy: 0.5401\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9735 - accuracy: 0.5290 - val_loss: 0.9663 - val_accuracy: 0.5414\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9734 - accuracy: 0.5292 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9735 - accuracy: 0.5296 - val_loss: 0.9665 - val_accuracy: 0.5405\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9736 - accuracy: 0.5283 - val_loss: 0.9663 - val_accuracy: 0.5401\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9734 - accuracy: 0.5287 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9735 - accuracy: 0.5286 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9734 - accuracy: 0.5288 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9737 - accuracy: 0.5293 - val_loss: 0.9664 - val_accuracy: 0.5409\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9736 - accuracy: 0.5286 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9735 - accuracy: 0.5280 - val_loss: 0.9666 - val_accuracy: 0.5409\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9739 - accuracy: 0.5287 - val_loss: 0.9664 - val_accuracy: 0.5409\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9736 - accuracy: 0.5285 - val_loss: 0.9664 - val_accuracy: 0.5401\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9734 - accuracy: 0.5285 - val_loss: 0.9665 - val_accuracy: 0.5401\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9740 - accuracy: 0.5290 - val_loss: 0.9660 - val_accuracy: 0.5418\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9736 - accuracy: 0.5293 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9734 - accuracy: 0.5283 - val_loss: 0.9661 - val_accuracy: 0.5405\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9735 - accuracy: 0.5297 - val_loss: 0.9659 - val_accuracy: 0.5401\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9736 - accuracy: 0.5287 - val_loss: 0.9661 - val_accuracy: 0.5409\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9736 - accuracy: 0.5300 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9740 - accuracy: 0.5290 - val_loss: 0.9667 - val_accuracy: 0.5409\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9734 - accuracy: 0.5285 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9734 - accuracy: 0.5289 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9735 - accuracy: 0.5284 - val_loss: 0.9667 - val_accuracy: 0.5409\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9736 - accuracy: 0.5279 - val_loss: 0.9666 - val_accuracy: 0.5405\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9733 - accuracy: 0.5291 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9735 - accuracy: 0.5287 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9735 - accuracy: 0.5292 - val_loss: 0.9661 - val_accuracy: 0.5409\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9736 - accuracy: 0.5287 - val_loss: 0.9661 - val_accuracy: 0.5401\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9734 - accuracy: 0.5284 - val_loss: 0.9664 - val_accuracy: 0.5401\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 629us/step - loss: 0.9735 - accuracy: 0.5291 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9734 - accuracy: 0.5286 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9735 - accuracy: 0.5287 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9734 - accuracy: 0.5283 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9733 - accuracy: 0.5293 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9738 - accuracy: 0.5289 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 685us/step - loss: 0.9735 - accuracy: 0.5284 - val_loss: 0.9665 - val_accuracy: 0.5414\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9735 - accuracy: 0.5291 - val_loss: 0.9667 - val_accuracy: 0.5405\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9736 - accuracy: 0.5296 - val_loss: 0.9664 - val_accuracy: 0.5409\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9734 - accuracy: 0.5293 - val_loss: 0.9660 - val_accuracy: 0.5401\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9734 - accuracy: 0.5285 - val_loss: 0.9661 - val_accuracy: 0.5409\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9733 - accuracy: 0.5285 - val_loss: 0.9661 - val_accuracy: 0.5401\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9734 - accuracy: 0.5287 - val_loss: 0.9662 - val_accuracy: 0.5418\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9735 - accuracy: 0.5285 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9735 - accuracy: 0.5286 - val_loss: 0.9661 - val_accuracy: 0.5405\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9736 - accuracy: 0.5285 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9734 - accuracy: 0.5295 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9737 - accuracy: 0.5282 - val_loss: 0.9666 - val_accuracy: 0.5409\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9735 - accuracy: 0.5288 - val_loss: 0.9666 - val_accuracy: 0.5409\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9734 - accuracy: 0.5290 - val_loss: 0.9665 - val_accuracy: 0.5405\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 336us/step - loss: 0.9733 - accuracy: 0.5283\n",
      "Accuracy : 0.5282545685768127\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9665 - accuracy: 0.5405\n",
      "Accuracy : 0.5405046343803406\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.5962 - accuracy: 0.3838 - val_loss: 1.5534 - val_accuracy: 0.3023\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 1.4644 - accuracy: 0.3059 - val_loss: 1.4224 - val_accuracy: 0.2364\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 1.3613 - accuracy: 0.2454 - val_loss: 1.3211 - val_accuracy: 0.2063\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.2795 - accuracy: 0.2172 - val_loss: 1.2283 - val_accuracy: 0.2072\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.2035 - accuracy: 0.2275 - val_loss: 1.1592 - val_accuracy: 0.2222\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 1.1513 - accuracy: 0.2456 - val_loss: 1.1196 - val_accuracy: 0.2457\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.1201 - accuracy: 0.2619 - val_loss: 1.0979 - val_accuracy: 0.2683\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 1.1022 - accuracy: 0.2771 - val_loss: 1.0864 - val_accuracy: 0.2824\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.0917 - accuracy: 0.2859 - val_loss: 1.0795 - val_accuracy: 0.2895\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0852 - accuracy: 0.2916 - val_loss: 1.0756 - val_accuracy: 0.2904\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 1.0810 - accuracy: 0.2934 - val_loss: 1.0730 - val_accuracy: 0.2917\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 1.0782 - accuracy: 0.2942 - val_loss: 1.0710 - val_accuracy: 0.2935\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 1.0759 - accuracy: 0.2967 - val_loss: 1.0697 - val_accuracy: 0.2939\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 1.0744 - accuracy: 0.2973 - val_loss: 1.0684 - val_accuracy: 0.2939\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0730 - accuracy: 0.2985 - val_loss: 1.0672 - val_accuracy: 0.2953\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 1.0722 - accuracy: 0.2995 - val_loss: 1.0668 - val_accuracy: 0.2953\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0712 - accuracy: 0.3008 - val_loss: 1.0667 - val_accuracy: 0.2975\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0706 - accuracy: 0.3031 - val_loss: 1.0663 - val_accuracy: 0.2988\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 1.0701 - accuracy: 0.3037 - val_loss: 1.0658 - val_accuracy: 0.3001\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0693 - accuracy: 0.3051 - val_loss: 1.0650 - val_accuracy: 0.3010\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 1.0689 - accuracy: 0.3058 - val_loss: 1.0647 - val_accuracy: 0.3041\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0684 - accuracy: 0.3154 - val_loss: 1.0643 - val_accuracy: 0.3161\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0679 - accuracy: 0.3287 - val_loss: 1.0638 - val_accuracy: 0.3347\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0675 - accuracy: 0.3403 - val_loss: 1.0635 - val_accuracy: 0.3581\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0672 - accuracy: 0.3621 - val_loss: 1.0635 - val_accuracy: 0.3811\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 1.0668 - accuracy: 0.3695 - val_loss: 1.0634 - val_accuracy: 0.3900\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0666 - accuracy: 0.3698 - val_loss: 1.0630 - val_accuracy: 0.3958\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0663 - accuracy: 0.3856 - val_loss: 1.0631 - val_accuracy: 0.4104\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.0661 - accuracy: 0.3924 - val_loss: 1.0628 - val_accuracy: 0.4214\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0658 - accuracy: 0.4050 - val_loss: 1.0630 - val_accuracy: 0.4365\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0656 - accuracy: 0.4164 - val_loss: 1.0625 - val_accuracy: 0.4396\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.0655 - accuracy: 0.4079 - val_loss: 1.0627 - val_accuracy: 0.4360\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 1.0661 - accuracy: 0.4180 - val_loss: 1.0636 - val_accuracy: 0.4431\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0655 - accuracy: 0.4256 - val_loss: 1.0629 - val_accuracy: 0.4546\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0654 - accuracy: 0.4293 - val_loss: 1.0629 - val_accuracy: 0.4604\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 587us/step - loss: 1.0652 - accuracy: 0.4341 - val_loss: 1.0626 - val_accuracy: 0.4670\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 1.0650 - accuracy: 0.4465 - val_loss: 1.0625 - val_accuracy: 0.4723\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 1.0649 - accuracy: 0.4484 - val_loss: 1.0627 - val_accuracy: 0.4785\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.0652 - accuracy: 0.4508 - val_loss: 1.0630 - val_accuracy: 0.4821\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 1.0646 - accuracy: 0.4544 - val_loss: 1.0623 - val_accuracy: 0.4896\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 1.0645 - accuracy: 0.4644 - val_loss: 1.0621 - val_accuracy: 0.4918\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 1.0645 - accuracy: 0.4537 - val_loss: 1.0620 - val_accuracy: 0.4918\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 1.0643 - accuracy: 0.4706 - val_loss: 1.0621 - val_accuracy: 0.4927\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0642 - accuracy: 0.4660 - val_loss: 1.0620 - val_accuracy: 0.5002\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0641 - accuracy: 0.4669 - val_loss: 1.0619 - val_accuracy: 0.5015\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 1.0640 - accuracy: 0.4842 - val_loss: 1.0618 - val_accuracy: 0.5091\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0638 - accuracy: 0.4849 - val_loss: 1.0618 - val_accuracy: 0.5122\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 1.0637 - accuracy: 0.4916 - val_loss: 1.0617 - val_accuracy: 0.5166\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0636 - accuracy: 0.5009 - val_loss: 1.0618 - val_accuracy: 0.5197\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 1.0634 - accuracy: 0.5018 - val_loss: 1.0616 - val_accuracy: 0.5241\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 1.0632 - accuracy: 0.5071 - val_loss: 1.0615 - val_accuracy: 0.5312\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0630 - accuracy: 0.5135 - val_loss: 1.0617 - val_accuracy: 0.5352\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 1.0628 - accuracy: 0.5216 - val_loss: 1.0614 - val_accuracy: 0.5409\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0625 - accuracy: 0.5255 - val_loss: 1.0612 - val_accuracy: 0.5383\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 1.0622 - accuracy: 0.5257 - val_loss: 1.0607 - val_accuracy: 0.5401\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 1.0614 - accuracy: 0.5291 - val_loss: 1.0602 - val_accuracy: 0.5392\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 1.0603 - accuracy: 0.5294 - val_loss: 1.0594 - val_accuracy: 0.5356\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 1.0581 - accuracy: 0.5245 - val_loss: 1.0568 - val_accuracy: 0.5343\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0526 - accuracy: 0.5210 - val_loss: 1.0483 - val_accuracy: 0.5179\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 1.0307 - accuracy: 0.5084 - val_loss: 1.0001 - val_accuracy: 0.5069\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9975 - accuracy: 0.5131 - val_loss: 0.9820 - val_accuracy: 0.5250\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9918 - accuracy: 0.5202 - val_loss: 0.9787 - val_accuracy: 0.5281\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9898 - accuracy: 0.5224 - val_loss: 0.9768 - val_accuracy: 0.5312\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9887 - accuracy: 0.5237 - val_loss: 0.9761 - val_accuracy: 0.5246\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9881 - accuracy: 0.5203 - val_loss: 0.9757 - val_accuracy: 0.5259\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9869 - accuracy: 0.5229 - val_loss: 0.9745 - val_accuracy: 0.5246\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9864 - accuracy: 0.5226 - val_loss: 0.9736 - val_accuracy: 0.5290\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9856 - accuracy: 0.5251 - val_loss: 0.9724 - val_accuracy: 0.5312\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9854 - accuracy: 0.5233 - val_loss: 0.9721 - val_accuracy: 0.5312\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9846 - accuracy: 0.5246 - val_loss: 0.9718 - val_accuracy: 0.5294\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9845 - accuracy: 0.5258 - val_loss: 0.9715 - val_accuracy: 0.5286\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9841 - accuracy: 0.5251 - val_loss: 0.9711 - val_accuracy: 0.5299\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9837 - accuracy: 0.5261 - val_loss: 0.9707 - val_accuracy: 0.5290\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9837 - accuracy: 0.5248 - val_loss: 0.9705 - val_accuracy: 0.5294\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9840 - accuracy: 0.5238 - val_loss: 0.9704 - val_accuracy: 0.5299\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9833 - accuracy: 0.5268 - val_loss: 0.9702 - val_accuracy: 0.5272\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9832 - accuracy: 0.5242 - val_loss: 0.9710 - val_accuracy: 0.5272\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9840 - accuracy: 0.5204 - val_loss: 0.9715 - val_accuracy: 0.5268\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9830 - accuracy: 0.5246 - val_loss: 0.9707 - val_accuracy: 0.5277\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9828 - accuracy: 0.5268 - val_loss: 0.9704 - val_accuracy: 0.5250\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9826 - accuracy: 0.5282 - val_loss: 0.9698 - val_accuracy: 0.5290\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9824 - accuracy: 0.5282 - val_loss: 0.9695 - val_accuracy: 0.5308\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9824 - accuracy: 0.5270 - val_loss: 0.9694 - val_accuracy: 0.5303\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9822 - accuracy: 0.5273 - val_loss: 0.9693 - val_accuracy: 0.5303\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9822 - accuracy: 0.5270 - val_loss: 0.9694 - val_accuracy: 0.5303\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9821 - accuracy: 0.5271 - val_loss: 0.9689 - val_accuracy: 0.5312\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9820 - accuracy: 0.5292 - val_loss: 0.9690 - val_accuracy: 0.5303\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9820 - accuracy: 0.5275 - val_loss: 0.9689 - val_accuracy: 0.5308\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9818 - accuracy: 0.5287 - val_loss: 0.9686 - val_accuracy: 0.5343\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9819 - accuracy: 0.5283 - val_loss: 0.9687 - val_accuracy: 0.5343\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9817 - accuracy: 0.5289 - val_loss: 0.9684 - val_accuracy: 0.5347\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9818 - accuracy: 0.5290 - val_loss: 0.9684 - val_accuracy: 0.5347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9816 - accuracy: 0.5296 - val_loss: 0.9682 - val_accuracy: 0.5321\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9815 - accuracy: 0.5285 - val_loss: 0.9681 - val_accuracy: 0.5325\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9816 - accuracy: 0.5278 - val_loss: 0.9683 - val_accuracy: 0.5343\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9813 - accuracy: 0.5279 - val_loss: 0.9681 - val_accuracy: 0.5352\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9813 - accuracy: 0.5286 - val_loss: 0.9680 - val_accuracy: 0.5330\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9813 - accuracy: 0.5276 - val_loss: 0.9681 - val_accuracy: 0.5365\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9813 - accuracy: 0.5290 - val_loss: 0.9682 - val_accuracy: 0.5347\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9815 - accuracy: 0.5283 - val_loss: 0.9682 - val_accuracy: 0.5312\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9811 - accuracy: 0.5278 - val_loss: 0.9680 - val_accuracy: 0.5347\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9810 - accuracy: 0.5289 - val_loss: 0.9679 - val_accuracy: 0.5347\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9809 - accuracy: 0.5292 - val_loss: 0.9677 - val_accuracy: 0.5356\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9809 - accuracy: 0.5286 - val_loss: 0.9677 - val_accuracy: 0.5365\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9808 - accuracy: 0.5289 - val_loss: 0.9677 - val_accuracy: 0.5356\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9807 - accuracy: 0.5289 - val_loss: 0.9675 - val_accuracy: 0.5356\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9807 - accuracy: 0.5278 - val_loss: 0.9675 - val_accuracy: 0.5370\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9808 - accuracy: 0.5285 - val_loss: 0.9675 - val_accuracy: 0.5356\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9806 - accuracy: 0.5291 - val_loss: 0.9674 - val_accuracy: 0.5361\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9808 - accuracy: 0.5290 - val_loss: 0.9672 - val_accuracy: 0.5387\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9806 - accuracy: 0.5288 - val_loss: 0.9672 - val_accuracy: 0.5370\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9805 - accuracy: 0.5298 - val_loss: 0.9669 - val_accuracy: 0.5392\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9804 - accuracy: 0.5288 - val_loss: 0.9669 - val_accuracy: 0.5374\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9805 - accuracy: 0.5296 - val_loss: 0.9670 - val_accuracy: 0.5374\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9803 - accuracy: 0.5290 - val_loss: 0.9669 - val_accuracy: 0.5378\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9803 - accuracy: 0.5291 - val_loss: 0.9670 - val_accuracy: 0.5374\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9803 - accuracy: 0.5288 - val_loss: 0.9669 - val_accuracy: 0.5392\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9803 - accuracy: 0.5289 - val_loss: 0.9669 - val_accuracy: 0.5387\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9801 - accuracy: 0.5293 - val_loss: 0.9669 - val_accuracy: 0.5370\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9803 - accuracy: 0.5289 - val_loss: 0.9668 - val_accuracy: 0.5392\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9803 - accuracy: 0.5286 - val_loss: 0.9667 - val_accuracy: 0.5392\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9799 - accuracy: 0.5291 - val_loss: 0.9666 - val_accuracy: 0.5374\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9799 - accuracy: 0.5297 - val_loss: 0.9664 - val_accuracy: 0.5383\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9798 - accuracy: 0.5294 - val_loss: 0.9663 - val_accuracy: 0.5392\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9798 - accuracy: 0.5290 - val_loss: 0.9664 - val_accuracy: 0.5396\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9798 - accuracy: 0.5288 - val_loss: 0.9664 - val_accuracy: 0.5392\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9799 - accuracy: 0.5299 - val_loss: 0.9663 - val_accuracy: 0.5387\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9797 - accuracy: 0.5291 - val_loss: 0.9663 - val_accuracy: 0.5392\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9796 - accuracy: 0.5299 - val_loss: 0.9662 - val_accuracy: 0.5383\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9798 - accuracy: 0.5294 - val_loss: 0.9661 - val_accuracy: 0.5401\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9795 - accuracy: 0.5288 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9796 - accuracy: 0.5294 - val_loss: 0.9659 - val_accuracy: 0.5401\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9794 - accuracy: 0.5293 - val_loss: 0.9660 - val_accuracy: 0.5401\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9795 - accuracy: 0.5295 - val_loss: 0.9660 - val_accuracy: 0.5392\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9794 - accuracy: 0.5294 - val_loss: 0.9662 - val_accuracy: 0.5374\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9795 - accuracy: 0.5298 - val_loss: 0.9657 - val_accuracy: 0.5401\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9795 - accuracy: 0.5286 - val_loss: 0.9660 - val_accuracy: 0.5401\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9795 - accuracy: 0.5295 - val_loss: 0.9657 - val_accuracy: 0.5396\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 665us/step - loss: 0.9792 - accuracy: 0.5292 - val_loss: 0.9657 - val_accuracy: 0.5401\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 568us/step - loss: 0.9791 - accuracy: 0.5295 - val_loss: 0.9656 - val_accuracy: 0.5401\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9792 - accuracy: 0.5303 - val_loss: 0.9660 - val_accuracy: 0.5392\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9791 - accuracy: 0.5294 - val_loss: 0.9658 - val_accuracy: 0.5401\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9792 - accuracy: 0.5296 - val_loss: 0.9660 - val_accuracy: 0.5392\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9792 - accuracy: 0.5299 - val_loss: 0.9657 - val_accuracy: 0.5401\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9791 - accuracy: 0.5295 - val_loss: 0.9655 - val_accuracy: 0.5396\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9790 - accuracy: 0.5285 - val_loss: 0.9656 - val_accuracy: 0.5392\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9790 - accuracy: 0.5299 - val_loss: 0.9654 - val_accuracy: 0.5401\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9790 - accuracy: 0.5289 - val_loss: 0.9653 - val_accuracy: 0.5396\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 588us/step - loss: 0.9792 - accuracy: 0.5287 - val_loss: 0.9653 - val_accuracy: 0.5374\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9788 - accuracy: 0.5299 - val_loss: 0.9652 - val_accuracy: 0.5401\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9788 - accuracy: 0.5290 - val_loss: 0.9652 - val_accuracy: 0.5401\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9791 - accuracy: 0.5300 - val_loss: 0.9655 - val_accuracy: 0.5392\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9791 - accuracy: 0.5301 - val_loss: 0.9659 - val_accuracy: 0.5401\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9788 - accuracy: 0.5300 - val_loss: 0.9657 - val_accuracy: 0.5383\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9787 - accuracy: 0.5304 - val_loss: 0.9653 - val_accuracy: 0.5392\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9787 - accuracy: 0.5300 - val_loss: 0.9652 - val_accuracy: 0.5405\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9786 - accuracy: 0.5300 - val_loss: 0.9651 - val_accuracy: 0.5401\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9786 - accuracy: 0.5302 - val_loss: 0.9650 - val_accuracy: 0.5401\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9786 - accuracy: 0.5299 - val_loss: 0.9650 - val_accuracy: 0.5392\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9786 - accuracy: 0.5304 - val_loss: 0.9649 - val_accuracy: 0.5392\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9785 - accuracy: 0.5295 - val_loss: 0.9649 - val_accuracy: 0.5401\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9785 - accuracy: 0.5300 - val_loss: 0.9649 - val_accuracy: 0.5405\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9785 - accuracy: 0.5301 - val_loss: 0.9646 - val_accuracy: 0.5392\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9784 - accuracy: 0.5301 - val_loss: 0.9647 - val_accuracy: 0.5392\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9785 - accuracy: 0.5299 - val_loss: 0.9647 - val_accuracy: 0.5383\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9783 - accuracy: 0.5300 - val_loss: 0.9648 - val_accuracy: 0.5396\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9786 - accuracy: 0.5298 - val_loss: 0.9652 - val_accuracy: 0.5383\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9783 - accuracy: 0.5302 - val_loss: 0.9649 - val_accuracy: 0.5383\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9783 - accuracy: 0.5300 - val_loss: 0.9648 - val_accuracy: 0.5401\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9782 - accuracy: 0.5299 - val_loss: 0.9649 - val_accuracy: 0.5409\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9783 - accuracy: 0.5304 - val_loss: 0.9646 - val_accuracy: 0.5387\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9782 - accuracy: 0.5299 - val_loss: 0.9646 - val_accuracy: 0.5387\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9782 - accuracy: 0.5307 - val_loss: 0.9647 - val_accuracy: 0.5409\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9782 - accuracy: 0.5296 - val_loss: 0.9645 - val_accuracy: 0.5409\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9783 - accuracy: 0.5296 - val_loss: 0.9645 - val_accuracy: 0.5423\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9781 - accuracy: 0.5296 - val_loss: 0.9644 - val_accuracy: 0.5401\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9780 - accuracy: 0.5298 - val_loss: 0.9644 - val_accuracy: 0.5401\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9781 - accuracy: 0.5306 - val_loss: 0.9644 - val_accuracy: 0.5392\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9779 - accuracy: 0.5298 - val_loss: 0.9642 - val_accuracy: 0.5392\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9779 - accuracy: 0.5299 - val_loss: 0.9642 - val_accuracy: 0.5401\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9780 - accuracy: 0.5299 - val_loss: 0.9641 - val_accuracy: 0.5401\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9781 - accuracy: 0.5294 - val_loss: 0.9642 - val_accuracy: 0.5401\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9779 - accuracy: 0.5301 - val_loss: 0.9643 - val_accuracy: 0.5401\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9779 - accuracy: 0.5298 - val_loss: 0.9642 - val_accuracy: 0.5392\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9779 - accuracy: 0.5298 - val_loss: 0.9641 - val_accuracy: 0.5414\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9778 - accuracy: 0.5298 - val_loss: 0.9640 - val_accuracy: 0.5383\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9778 - accuracy: 0.5304 - val_loss: 0.9641 - val_accuracy: 0.5405\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9777 - accuracy: 0.5305 - val_loss: 0.9640 - val_accuracy: 0.5401\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9778 - accuracy: 0.5296 - val_loss: 0.9640 - val_accuracy: 0.5401\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9778 - accuracy: 0.5298 - val_loss: 0.9640 - val_accuracy: 0.5396\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9779 - accuracy: 0.5299 - val_loss: 0.9641 - val_accuracy: 0.5401\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9777 - accuracy: 0.5301 - val_loss: 0.9640 - val_accuracy: 0.5401\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9777 - accuracy: 0.5299 - val_loss: 0.9640 - val_accuracy: 0.5401\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9778 - accuracy: 0.5304 - val_loss: 0.9640 - val_accuracy: 0.5423\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9787 - accuracy: 0.5301 - val_loss: 0.9648 - val_accuracy: 0.5401\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9777 - accuracy: 0.5302 - val_loss: 0.9642 - val_accuracy: 0.5401\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9777 - accuracy: 0.5301 - val_loss: 0.9640 - val_accuracy: 0.5401\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9775 - accuracy: 0.5296 - val_loss: 0.9639 - val_accuracy: 0.5401\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9639 - val_accuracy: 0.5401\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9775 - accuracy: 0.5299 - val_loss: 0.9638 - val_accuracy: 0.5401\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 340us/step - loss: 0.9773 - accuracy: 0.5301\n",
      "Accuracy : 0.5301234722137451\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9638 - accuracy: 0.5401\n",
      "Accuracy : 0.5400619506835938\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.9584 - accuracy: 0.2162 - val_loss: 1.8249 - val_accuracy: 0.2160\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 748us/step - loss: 1.4810 - accuracy: 0.2850 - val_loss: 1.4344 - val_accuracy: 0.3417\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.2798 - accuracy: 0.4118 - val_loss: 1.2513 - val_accuracy: 0.4254\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 579us/step - loss: 1.1825 - accuracy: 0.4478 - val_loss: 1.1518 - val_accuracy: 0.4533\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.1231 - accuracy: 0.4570 - val_loss: 1.0877 - val_accuracy: 0.4706\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0815 - accuracy: 0.4595 - val_loss: 1.0444 - val_accuracy: 0.4737\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 1.0525 - accuracy: 0.4600 - val_loss: 1.0156 - val_accuracy: 0.4728\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 1.0312 - accuracy: 0.4613 - val_loss: 0.9941 - val_accuracy: 0.4737\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 1.0157 - accuracy: 0.4627 - val_loss: 0.9789 - val_accuracy: 0.4745\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 1.0047 - accuracy: 0.4641 - val_loss: 0.9689 - val_accuracy: 0.4737\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9976 - accuracy: 0.4896 - val_loss: 0.9619 - val_accuracy: 0.5387\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9926 - accuracy: 0.5235 - val_loss: 0.9568 - val_accuracy: 0.5387\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9891 - accuracy: 0.5259 - val_loss: 0.9542 - val_accuracy: 0.5387\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9862 - accuracy: 0.5257 - val_loss: 0.9510 - val_accuracy: 0.5392\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9847 - accuracy: 0.5269 - val_loss: 0.9483 - val_accuracy: 0.5392\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9832 - accuracy: 0.5270 - val_loss: 0.9467 - val_accuracy: 0.5409\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9822 - accuracy: 0.5273 - val_loss: 0.9477 - val_accuracy: 0.5409\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9829 - accuracy: 0.5274 - val_loss: 0.9466 - val_accuracy: 0.5392\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9812 - accuracy: 0.5276 - val_loss: 0.9443 - val_accuracy: 0.5405\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9809 - accuracy: 0.5278 - val_loss: 0.9448 - val_accuracy: 0.5392\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9804 - accuracy: 0.5282 - val_loss: 0.9427 - val_accuracy: 0.5409\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9806 - accuracy: 0.5284 - val_loss: 0.9422 - val_accuracy: 0.5418\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9802 - accuracy: 0.5276 - val_loss: 0.9429 - val_accuracy: 0.5392\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9802 - accuracy: 0.5286 - val_loss: 0.9425 - val_accuracy: 0.5387\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9803 - accuracy: 0.5275 - val_loss: 0.9426 - val_accuracy: 0.5392\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9801 - accuracy: 0.5280 - val_loss: 0.9419 - val_accuracy: 0.5383\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9799 - accuracy: 0.5281 - val_loss: 0.9433 - val_accuracy: 0.5370\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9798 - accuracy: 0.5282 - val_loss: 0.9424 - val_accuracy: 0.5378\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9799 - accuracy: 0.5283 - val_loss: 0.9407 - val_accuracy: 0.5405\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9796 - accuracy: 0.5286 - val_loss: 0.9428 - val_accuracy: 0.5361\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9797 - accuracy: 0.5282 - val_loss: 0.9424 - val_accuracy: 0.5361\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9793 - accuracy: 0.5273 - val_loss: 0.9408 - val_accuracy: 0.5383\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9793 - accuracy: 0.5276 - val_loss: 0.9410 - val_accuracy: 0.5378\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9792 - accuracy: 0.5282 - val_loss: 0.9411 - val_accuracy: 0.5378\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9791 - accuracy: 0.5281 - val_loss: 0.9407 - val_accuracy: 0.5383\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9792 - accuracy: 0.5284 - val_loss: 0.9410 - val_accuracy: 0.5383\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9791 - accuracy: 0.5280 - val_loss: 0.9420 - val_accuracy: 0.5361\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9793 - accuracy: 0.5278 - val_loss: 0.9420 - val_accuracy: 0.5361\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9793 - accuracy: 0.5273 - val_loss: 0.9405 - val_accuracy: 0.5387\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9789 - accuracy: 0.5285 - val_loss: 0.9412 - val_accuracy: 0.5383\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9789 - accuracy: 0.5285 - val_loss: 0.9411 - val_accuracy: 0.5383\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9792 - accuracy: 0.5285 - val_loss: 0.9412 - val_accuracy: 0.5361\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9789 - accuracy: 0.5276 - val_loss: 0.9408 - val_accuracy: 0.5383\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9788 - accuracy: 0.5283 - val_loss: 0.9393 - val_accuracy: 0.5423\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9789 - accuracy: 0.5279 - val_loss: 0.9405 - val_accuracy: 0.5383\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9788 - accuracy: 0.5284 - val_loss: 0.9403 - val_accuracy: 0.5387\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9786 - accuracy: 0.5282 - val_loss: 0.9398 - val_accuracy: 0.5409\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9785 - accuracy: 0.5289 - val_loss: 0.9397 - val_accuracy: 0.5409\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9785 - accuracy: 0.5289 - val_loss: 0.9400 - val_accuracy: 0.5409\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9784 - accuracy: 0.5286 - val_loss: 0.9404 - val_accuracy: 0.5392\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9785 - accuracy: 0.5290 - val_loss: 0.9397 - val_accuracy: 0.5409\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9784 - accuracy: 0.5284 - val_loss: 0.9403 - val_accuracy: 0.5387\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9787 - accuracy: 0.5284 - val_loss: 0.9391 - val_accuracy: 0.5418\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9784 - accuracy: 0.5282 - val_loss: 0.9402 - val_accuracy: 0.5392\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9785 - accuracy: 0.5292 - val_loss: 0.9398 - val_accuracy: 0.5409\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9785 - accuracy: 0.5290 - val_loss: 0.9393 - val_accuracy: 0.5418\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9784 - accuracy: 0.5285 - val_loss: 0.9402 - val_accuracy: 0.5409\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9783 - accuracy: 0.5280 - val_loss: 0.9398 - val_accuracy: 0.5414\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9782 - accuracy: 0.5287 - val_loss: 0.9403 - val_accuracy: 0.5409\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9781 - accuracy: 0.5288 - val_loss: 0.9403 - val_accuracy: 0.5409\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 586us/step - loss: 0.9784 - accuracy: 0.5287 - val_loss: 0.9404 - val_accuracy: 0.5387\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9785 - accuracy: 0.5281 - val_loss: 0.9401 - val_accuracy: 0.5392\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9782 - accuracy: 0.5286 - val_loss: 0.9392 - val_accuracy: 0.5405\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9781 - accuracy: 0.5287 - val_loss: 0.9400 - val_accuracy: 0.5401\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9781 - accuracy: 0.5286 - val_loss: 0.9394 - val_accuracy: 0.5423\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9780 - accuracy: 0.5301 - val_loss: 0.9403 - val_accuracy: 0.5392\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9782 - accuracy: 0.5290 - val_loss: 0.9390 - val_accuracy: 0.5418\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9783 - accuracy: 0.5282 - val_loss: 0.9391 - val_accuracy: 0.5418\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9782 - accuracy: 0.5275 - val_loss: 0.9390 - val_accuracy: 0.5414\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9782 - accuracy: 0.5286 - val_loss: 0.9393 - val_accuracy: 0.5414\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9783 - accuracy: 0.5283 - val_loss: 0.9401 - val_accuracy: 0.5414\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9780 - accuracy: 0.5289 - val_loss: 0.9406 - val_accuracy: 0.5392\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9782 - accuracy: 0.5283 - val_loss: 0.9392 - val_accuracy: 0.5418\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9780 - accuracy: 0.5285 - val_loss: 0.9396 - val_accuracy: 0.5409\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9782 - accuracy: 0.5286 - val_loss: 0.9389 - val_accuracy: 0.5418\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9779 - accuracy: 0.5282 - val_loss: 0.9396 - val_accuracy: 0.5418\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9779 - accuracy: 0.5282 - val_loss: 0.9391 - val_accuracy: 0.5414\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9779 - accuracy: 0.5285 - val_loss: 0.9391 - val_accuracy: 0.5418\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9781 - accuracy: 0.5288 - val_loss: 0.9387 - val_accuracy: 0.5409\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9779 - accuracy: 0.5283 - val_loss: 0.9397 - val_accuracy: 0.5414\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9779 - accuracy: 0.5292 - val_loss: 0.9394 - val_accuracy: 0.5409\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9777 - accuracy: 0.5287 - val_loss: 0.9395 - val_accuracy: 0.5409\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9777 - accuracy: 0.5285 - val_loss: 0.9392 - val_accuracy: 0.5418\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9779 - accuracy: 0.5290 - val_loss: 0.9395 - val_accuracy: 0.5423\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9781 - accuracy: 0.5278 - val_loss: 0.9389 - val_accuracy: 0.5414\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9778 - accuracy: 0.5287 - val_loss: 0.9391 - val_accuracy: 0.5423\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9782 - accuracy: 0.5280 - val_loss: 0.9411 - val_accuracy: 0.5370\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9791 - accuracy: 0.5277 - val_loss: 0.9393 - val_accuracy: 0.5405\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9780 - accuracy: 0.5287 - val_loss: 0.9395 - val_accuracy: 0.5409\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9779 - accuracy: 0.5283 - val_loss: 0.9392 - val_accuracy: 0.5414\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9777 - accuracy: 0.5289 - val_loss: 0.9399 - val_accuracy: 0.5409\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9778 - accuracy: 0.5274 - val_loss: 0.9399 - val_accuracy: 0.5409\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9777 - accuracy: 0.5289 - val_loss: 0.9391 - val_accuracy: 0.5414\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9776 - accuracy: 0.5274 - val_loss: 0.9401 - val_accuracy: 0.5401\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9776 - accuracy: 0.5281 - val_loss: 0.9394 - val_accuracy: 0.5423\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9777 - accuracy: 0.5278 - val_loss: 0.9393 - val_accuracy: 0.5409\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9775 - accuracy: 0.5282 - val_loss: 0.9393 - val_accuracy: 0.5409\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9777 - accuracy: 0.5284 - val_loss: 0.9393 - val_accuracy: 0.5401\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9397 - val_accuracy: 0.5401\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9776 - accuracy: 0.5285 - val_loss: 0.9389 - val_accuracy: 0.5418\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9776 - accuracy: 0.5283 - val_loss: 0.9390 - val_accuracy: 0.5418\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9777 - accuracy: 0.5281 - val_loss: 0.9388 - val_accuracy: 0.5418\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9777 - accuracy: 0.5288 - val_loss: 0.9393 - val_accuracy: 0.5414\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9778 - accuracy: 0.5286 - val_loss: 0.9395 - val_accuracy: 0.5401\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9777 - accuracy: 0.5288 - val_loss: 0.9392 - val_accuracy: 0.5409\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9774 - accuracy: 0.5289 - val_loss: 0.9389 - val_accuracy: 0.5418\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9780 - accuracy: 0.5282 - val_loss: 0.9394 - val_accuracy: 0.5401\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9775 - accuracy: 0.5289 - val_loss: 0.9397 - val_accuracy: 0.5401\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9779 - accuracy: 0.5295 - val_loss: 0.9393 - val_accuracy: 0.5409\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9781 - accuracy: 0.5288 - val_loss: 0.9393 - val_accuracy: 0.5427\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9776 - accuracy: 0.5282 - val_loss: 0.9386 - val_accuracy: 0.5409\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9774 - accuracy: 0.5295 - val_loss: 0.9391 - val_accuracy: 0.5423\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9773 - accuracy: 0.5284 - val_loss: 0.9401 - val_accuracy: 0.5392\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9399 - val_accuracy: 0.5401\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9784 - accuracy: 0.5283 - val_loss: 0.9389 - val_accuracy: 0.5409\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9399 - val_accuracy: 0.5405\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9398 - val_accuracy: 0.5401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9774 - accuracy: 0.5284 - val_loss: 0.9392 - val_accuracy: 0.5414\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9775 - accuracy: 0.5278 - val_loss: 0.9384 - val_accuracy: 0.5409\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9775 - accuracy: 0.5292 - val_loss: 0.9399 - val_accuracy: 0.5405\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9391 - val_accuracy: 0.5418\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9397 - val_accuracy: 0.5414\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9777 - accuracy: 0.5283 - val_loss: 0.9394 - val_accuracy: 0.5418\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9775 - accuracy: 0.5286 - val_loss: 0.9395 - val_accuracy: 0.5418\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9773 - accuracy: 0.5286 - val_loss: 0.9398 - val_accuracy: 0.5418\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9775 - accuracy: 0.5289 - val_loss: 0.9390 - val_accuracy: 0.5423\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 562us/step - loss: 0.9774 - accuracy: 0.5287 - val_loss: 0.9398 - val_accuracy: 0.5405\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 0.9776 - accuracy: 0.5286 - val_loss: 0.9402 - val_accuracy: 0.5405\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9777 - accuracy: 0.5292 - val_loss: 0.9399 - val_accuracy: 0.5405\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9393 - val_accuracy: 0.5405\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9773 - accuracy: 0.5278 - val_loss: 0.9401 - val_accuracy: 0.5405\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9391 - val_accuracy: 0.5409\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9395 - val_accuracy: 0.5405\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9406 - val_accuracy: 0.5392\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9776 - accuracy: 0.5285 - val_loss: 0.9395 - val_accuracy: 0.5409\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9771 - accuracy: 0.5283 - val_loss: 0.9402 - val_accuracy: 0.5405\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9388 - val_accuracy: 0.5418\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9386 - val_accuracy: 0.5409\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 0.9388 - val_accuracy: 0.5418\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9775 - accuracy: 0.5286 - val_loss: 0.9396 - val_accuracy: 0.5409\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9396 - val_accuracy: 0.5409\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9774 - accuracy: 0.5284 - val_loss: 0.9385 - val_accuracy: 0.5409\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9397 - val_accuracy: 0.5409\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9386 - val_accuracy: 0.5414\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9774 - accuracy: 0.5288 - val_loss: 0.9390 - val_accuracy: 0.5423\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9389 - val_accuracy: 0.5414\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9387 - val_accuracy: 0.5414\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9774 - accuracy: 0.5288 - val_loss: 0.9387 - val_accuracy: 0.5418\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5282 - val_loss: 0.9394 - val_accuracy: 0.5409\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9776 - accuracy: 0.5283 - val_loss: 0.9397 - val_accuracy: 0.5409\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9772 - accuracy: 0.5282 - val_loss: 0.9388 - val_accuracy: 0.5418\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9383 - val_accuracy: 0.5405\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9775 - accuracy: 0.5279 - val_loss: 0.9392 - val_accuracy: 0.5409\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5286 - val_loss: 0.9397 - val_accuracy: 0.5409\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9773 - accuracy: 0.5289 - val_loss: 0.9386 - val_accuracy: 0.5418\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9774 - accuracy: 0.5284 - val_loss: 0.9392 - val_accuracy: 0.5409\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5284 - val_loss: 0.9386 - val_accuracy: 0.5409\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9774 - accuracy: 0.5278 - val_loss: 0.9383 - val_accuracy: 0.5405\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9390 - val_accuracy: 0.5414\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9772 - accuracy: 0.5288 - val_loss: 0.9389 - val_accuracy: 0.5423\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9774 - accuracy: 0.5279 - val_loss: 0.9395 - val_accuracy: 0.5414\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9776 - accuracy: 0.5291 - val_loss: 0.9386 - val_accuracy: 0.5414\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9772 - accuracy: 0.5278 - val_loss: 0.9392 - val_accuracy: 0.5418\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9393 - val_accuracy: 0.5409\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9770 - accuracy: 0.5287 - val_loss: 0.9388 - val_accuracy: 0.5418\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9772 - accuracy: 0.5273 - val_loss: 0.9392 - val_accuracy: 0.5414\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9773 - accuracy: 0.5289 - val_loss: 0.9387 - val_accuracy: 0.5409\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9403 - val_accuracy: 0.5423\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9777 - accuracy: 0.5280 - val_loss: 0.9388 - val_accuracy: 0.5405\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5284 - val_loss: 0.9391 - val_accuracy: 0.5414\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9772 - accuracy: 0.5286 - val_loss: 0.9390 - val_accuracy: 0.5414\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9396 - val_accuracy: 0.5414\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9770 - accuracy: 0.5283 - val_loss: 0.9386 - val_accuracy: 0.5414\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 581us/step - loss: 0.9772 - accuracy: 0.5282 - val_loss: 0.9390 - val_accuracy: 0.5414\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9778 - accuracy: 0.5282 - val_loss: 0.9391 - val_accuracy: 0.5414\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9771 - accuracy: 0.5282 - val_loss: 0.9388 - val_accuracy: 0.5414\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9772 - accuracy: 0.5284 - val_loss: 0.9385 - val_accuracy: 0.5409\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5286 - val_loss: 0.9389 - val_accuracy: 0.5418\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5282 - val_loss: 0.9395 - val_accuracy: 0.5418\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9771 - accuracy: 0.5289 - val_loss: 0.9388 - val_accuracy: 0.5414\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9386 - val_accuracy: 0.5414\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9771 - accuracy: 0.5282 - val_loss: 0.9387 - val_accuracy: 0.5414\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9771 - accuracy: 0.5283 - val_loss: 0.9387 - val_accuracy: 0.5418\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9775 - accuracy: 0.5283 - val_loss: 0.9388 - val_accuracy: 0.5418\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9387 - val_accuracy: 0.5405\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5281 - val_loss: 0.9387 - val_accuracy: 0.5414\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9772 - accuracy: 0.5281 - val_loss: 0.9392 - val_accuracy: 0.5418\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9772 - accuracy: 0.5279 - val_loss: 0.9387 - val_accuracy: 0.5414\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9385 - val_accuracy: 0.5405\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9391 - val_accuracy: 0.5414\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9769 - accuracy: 0.5293 - val_loss: 0.9390 - val_accuracy: 0.5414\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9387 - val_accuracy: 0.5414\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9387 - val_accuracy: 0.5414\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9396 - val_accuracy: 0.5418\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9774 - accuracy: 0.5297 - val_loss: 0.9386 - val_accuracy: 0.5418\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9771 - accuracy: 0.5284 - val_loss: 0.9389 - val_accuracy: 0.5414\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9389 - val_accuracy: 0.5418\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9769 - accuracy: 0.5284 - val_loss: 0.9387 - val_accuracy: 0.5414\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9385 - val_accuracy: 0.5414\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9772 - accuracy: 0.5283 - val_loss: 0.9390 - val_accuracy: 0.5414\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 331us/step - loss: 0.9767 - accuracy: 0.5283\n",
      "Accuracy : 0.5282545685768127\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9390 - accuracy: 0.5414\n",
      "Accuracy : 0.5413900017738342\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 1.8747 - accuracy: 0.4590 - val_loss: 1.6614 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 1.5363 - accuracy: 0.4589 - val_loss: 1.3296 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 563us/step - loss: 1.1923 - accuracy: 0.4609 - val_loss: 1.0511 - val_accuracy: 0.4613\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 1.0099 - accuracy: 0.4820 - val_loss: 0.9906 - val_accuracy: 0.5193\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9848 - accuracy: 0.5248 - val_loss: 0.9844 - val_accuracy: 0.5241\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9810 - accuracy: 0.5285 - val_loss: 0.9815 - val_accuracy: 0.5290\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9789 - accuracy: 0.5307 - val_loss: 0.9789 - val_accuracy: 0.5312\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9779 - accuracy: 0.5299 - val_loss: 0.9774 - val_accuracy: 0.5308\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9775 - accuracy: 0.5299 - val_loss: 0.9767 - val_accuracy: 0.5317\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9773 - accuracy: 0.5312 - val_loss: 0.9765 - val_accuracy: 0.5321\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9770 - accuracy: 0.5309 - val_loss: 0.9756 - val_accuracy: 0.5325\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9771 - accuracy: 0.5309 - val_loss: 0.9754 - val_accuracy: 0.5317\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9771 - accuracy: 0.5307 - val_loss: 0.9756 - val_accuracy: 0.5330\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9771 - accuracy: 0.5306 - val_loss: 0.9747 - val_accuracy: 0.5330\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9770 - accuracy: 0.5296 - val_loss: 0.9751 - val_accuracy: 0.5330\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9767 - accuracy: 0.5304 - val_loss: 0.9746 - val_accuracy: 0.5308\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9767 - accuracy: 0.5296 - val_loss: 0.9746 - val_accuracy: 0.5312\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9768 - accuracy: 0.5299 - val_loss: 0.9746 - val_accuracy: 0.5321\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9765 - accuracy: 0.5315 - val_loss: 0.9745 - val_accuracy: 0.5317\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9766 - accuracy: 0.5303 - val_loss: 0.9742 - val_accuracy: 0.5330\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9766 - accuracy: 0.5304 - val_loss: 0.9744 - val_accuracy: 0.5321\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9767 - accuracy: 0.5302 - val_loss: 0.9742 - val_accuracy: 0.5325\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9770 - accuracy: 0.5302 - val_loss: 0.9742 - val_accuracy: 0.5312\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9764 - accuracy: 0.5301 - val_loss: 0.9743 - val_accuracy: 0.5330\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9764 - accuracy: 0.5305 - val_loss: 0.9746 - val_accuracy: 0.5330\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9763 - accuracy: 0.5316 - val_loss: 0.9736 - val_accuracy: 0.5281\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9766 - accuracy: 0.5299 - val_loss: 0.9737 - val_accuracy: 0.5303\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5304 - val_loss: 0.9745 - val_accuracy: 0.5325\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 587us/step - loss: 0.9765 - accuracy: 0.5300 - val_loss: 0.9740 - val_accuracy: 0.5312\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9764 - accuracy: 0.5312 - val_loss: 0.9738 - val_accuracy: 0.5317\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9763 - accuracy: 0.5301 - val_loss: 0.9738 - val_accuracy: 0.5325\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9763 - accuracy: 0.5308 - val_loss: 0.9738 - val_accuracy: 0.5321\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9762 - accuracy: 0.5304 - val_loss: 0.9733 - val_accuracy: 0.5312\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9761 - accuracy: 0.5306 - val_loss: 0.9731 - val_accuracy: 0.5286\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9763 - accuracy: 0.5301 - val_loss: 0.9737 - val_accuracy: 0.5312\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9761 - accuracy: 0.5297 - val_loss: 0.9730 - val_accuracy: 0.5286\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9761 - accuracy: 0.5292 - val_loss: 0.9731 - val_accuracy: 0.5286\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9760 - accuracy: 0.5300 - val_loss: 0.9732 - val_accuracy: 0.5290\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9759 - accuracy: 0.5295 - val_loss: 0.9730 - val_accuracy: 0.5290\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9762 - accuracy: 0.5307 - val_loss: 0.9727 - val_accuracy: 0.5281\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9760 - accuracy: 0.5298 - val_loss: 0.9727 - val_accuracy: 0.5290\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9759 - accuracy: 0.5295 - val_loss: 0.9728 - val_accuracy: 0.5299\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9759 - accuracy: 0.5304 - val_loss: 0.9726 - val_accuracy: 0.5286\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9728 - val_accuracy: 0.5290\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9757 - accuracy: 0.5297 - val_loss: 0.9727 - val_accuracy: 0.5290\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9757 - accuracy: 0.5308 - val_loss: 0.9723 - val_accuracy: 0.5268\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9759 - accuracy: 0.5289 - val_loss: 0.9723 - val_accuracy: 0.5281\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9758 - accuracy: 0.5303 - val_loss: 0.9728 - val_accuracy: 0.5321\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9759 - accuracy: 0.5302 - val_loss: 0.9721 - val_accuracy: 0.5281\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9756 - accuracy: 0.5307 - val_loss: 0.9721 - val_accuracy: 0.5290\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9754 - accuracy: 0.5303 - val_loss: 0.9728 - val_accuracy: 0.5286\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9763 - accuracy: 0.5296 - val_loss: 0.9720 - val_accuracy: 0.5286\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9756 - accuracy: 0.5297 - val_loss: 0.9724 - val_accuracy: 0.5290\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9755 - accuracy: 0.5301 - val_loss: 0.9723 - val_accuracy: 0.5290\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9758 - accuracy: 0.5294 - val_loss: 0.9718 - val_accuracy: 0.5268\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 0.9719 - val_accuracy: 0.5290\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9719 - val_accuracy: 0.5286\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9754 - accuracy: 0.5293 - val_loss: 0.9720 - val_accuracy: 0.5290\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9754 - accuracy: 0.5297 - val_loss: 0.9721 - val_accuracy: 0.5290\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9756 - accuracy: 0.5304 - val_loss: 0.9723 - val_accuracy: 0.5272\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9724 - val_accuracy: 0.5286\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9759 - accuracy: 0.5302 - val_loss: 0.9718 - val_accuracy: 0.5277\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9755 - accuracy: 0.5291 - val_loss: 0.9721 - val_accuracy: 0.5286\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9754 - accuracy: 0.5292 - val_loss: 0.9719 - val_accuracy: 0.5272\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9754 - accuracy: 0.5297 - val_loss: 0.9719 - val_accuracy: 0.5286\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9755 - accuracy: 0.5286 - val_loss: 0.9719 - val_accuracy: 0.5286\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9757 - accuracy: 0.5297 - val_loss: 0.9722 - val_accuracy: 0.5286\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9755 - accuracy: 0.5295 - val_loss: 0.9720 - val_accuracy: 0.5281\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9716 - val_accuracy: 0.5259\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9717 - val_accuracy: 0.5277\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9753 - accuracy: 0.5294 - val_loss: 0.9714 - val_accuracy: 0.5263\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9753 - accuracy: 0.5295 - val_loss: 0.9721 - val_accuracy: 0.5286\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9758 - accuracy: 0.5298 - val_loss: 0.9723 - val_accuracy: 0.5290\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9716 - val_accuracy: 0.5268\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9753 - accuracy: 0.5304 - val_loss: 0.9711 - val_accuracy: 0.5259\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9716 - val_accuracy: 0.5281\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9711 - val_accuracy: 0.5263\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9752 - accuracy: 0.5299 - val_loss: 0.9718 - val_accuracy: 0.5290\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9752 - accuracy: 0.5298 - val_loss: 0.9719 - val_accuracy: 0.5290\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9717 - val_accuracy: 0.5290\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9754 - accuracy: 0.5305 - val_loss: 0.9712 - val_accuracy: 0.5281\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9753 - accuracy: 0.5309 - val_loss: 0.9720 - val_accuracy: 0.5290\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9755 - accuracy: 0.5300 - val_loss: 0.9713 - val_accuracy: 0.5263\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9753 - accuracy: 0.5297 - val_loss: 0.9717 - val_accuracy: 0.5290\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9755 - accuracy: 0.5306 - val_loss: 0.9709 - val_accuracy: 0.5263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9755 - accuracy: 0.5300 - val_loss: 0.9711 - val_accuracy: 0.5272\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9752 - accuracy: 0.5312 - val_loss: 0.9715 - val_accuracy: 0.5286\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9753 - accuracy: 0.5292 - val_loss: 0.9711 - val_accuracy: 0.5281\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9709 - val_accuracy: 0.5263\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9753 - accuracy: 0.5307 - val_loss: 0.9721 - val_accuracy: 0.5294\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9766 - accuracy: 0.5306 - val_loss: 0.9721 - val_accuracy: 0.5263\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9755 - accuracy: 0.5290 - val_loss: 0.9722 - val_accuracy: 0.5259\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9752 - accuracy: 0.5305 - val_loss: 0.9718 - val_accuracy: 0.5272\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9755 - accuracy: 0.5299 - val_loss: 0.9716 - val_accuracy: 0.5268\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9751 - accuracy: 0.5296 - val_loss: 0.9716 - val_accuracy: 0.5281\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9750 - accuracy: 0.5299 - val_loss: 0.9714 - val_accuracy: 0.5281\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9715 - val_accuracy: 0.5281\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9719 - val_accuracy: 0.5290\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9708 - val_accuracy: 0.5259\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9753 - accuracy: 0.5294 - val_loss: 0.9708 - val_accuracy: 0.5268\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9713 - val_accuracy: 0.5281\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9753 - accuracy: 0.5295 - val_loss: 0.9713 - val_accuracy: 0.5286\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9751 - accuracy: 0.5292 - val_loss: 0.9710 - val_accuracy: 0.5281\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9712 - val_accuracy: 0.5281\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9752 - accuracy: 0.5303 - val_loss: 0.9709 - val_accuracy: 0.5268\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9753 - accuracy: 0.5302 - val_loss: 0.9715 - val_accuracy: 0.5281\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9752 - accuracy: 0.5304 - val_loss: 0.9708 - val_accuracy: 0.5263\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9714 - val_accuracy: 0.5286\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9706 - val_accuracy: 0.5263\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9752 - accuracy: 0.5308 - val_loss: 0.9710 - val_accuracy: 0.5259\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9750 - accuracy: 0.5308 - val_loss: 0.9711 - val_accuracy: 0.5272\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9749 - accuracy: 0.5303 - val_loss: 0.9709 - val_accuracy: 0.5263\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9752 - accuracy: 0.5294 - val_loss: 0.9708 - val_accuracy: 0.5263\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9751 - accuracy: 0.5296 - val_loss: 0.9705 - val_accuracy: 0.5263\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9751 - accuracy: 0.5301 - val_loss: 0.9709 - val_accuracy: 0.5281\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9756 - accuracy: 0.5305 - val_loss: 0.9716 - val_accuracy: 0.5268\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9754 - accuracy: 0.5297 - val_loss: 0.9710 - val_accuracy: 0.5259\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9750 - accuracy: 0.5302 - val_loss: 0.9710 - val_accuracy: 0.5263\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9706 - val_accuracy: 0.5263\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9753 - accuracy: 0.5307 - val_loss: 0.9713 - val_accuracy: 0.5263\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9754 - accuracy: 0.5307 - val_loss: 0.9710 - val_accuracy: 0.5286\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9750 - accuracy: 0.5296 - val_loss: 0.9708 - val_accuracy: 0.5281\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9751 - accuracy: 0.5298 - val_loss: 0.9707 - val_accuracy: 0.5281\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9750 - accuracy: 0.5295 - val_loss: 0.9715 - val_accuracy: 0.5290\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9756 - accuracy: 0.5308 - val_loss: 0.9713 - val_accuracy: 0.5259\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9752 - accuracy: 0.5298 - val_loss: 0.9709 - val_accuracy: 0.5263\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9752 - accuracy: 0.5302 - val_loss: 0.9708 - val_accuracy: 0.5268\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9751 - accuracy: 0.5293 - val_loss: 0.9707 - val_accuracy: 0.5286\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9750 - accuracy: 0.5302 - val_loss: 0.9708 - val_accuracy: 0.5286\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9707 - val_accuracy: 0.5259\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9752 - accuracy: 0.5293 - val_loss: 0.9723 - val_accuracy: 0.5286\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9762 - accuracy: 0.5301 - val_loss: 0.9711 - val_accuracy: 0.5272\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 0.9707 - val_accuracy: 0.5259\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9755 - accuracy: 0.5305 - val_loss: 0.9715 - val_accuracy: 0.5259\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9752 - accuracy: 0.5305 - val_loss: 0.9712 - val_accuracy: 0.5259\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9757 - accuracy: 0.5293 - val_loss: 0.9713 - val_accuracy: 0.5263\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9752 - accuracy: 0.5289 - val_loss: 0.9711 - val_accuracy: 0.5259\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9750 - accuracy: 0.5297 - val_loss: 0.9710 - val_accuracy: 0.5259\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9749 - accuracy: 0.5298 - val_loss: 0.9709 - val_accuracy: 0.5263\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9754 - accuracy: 0.5291 - val_loss: 0.9722 - val_accuracy: 0.5290\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9725 - val_accuracy: 0.5263\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 632us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9715 - val_accuracy: 0.5259\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9749 - accuracy: 0.5300 - val_loss: 0.9716 - val_accuracy: 0.5268\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9707 - val_accuracy: 0.5263\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9707 - val_accuracy: 0.5263\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9709 - val_accuracy: 0.5272\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9748 - accuracy: 0.5300 - val_loss: 0.9704 - val_accuracy: 0.5263\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9707 - val_accuracy: 0.5259\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9747 - accuracy: 0.5303 - val_loss: 0.9705 - val_accuracy: 0.5263\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9749 - accuracy: 0.5291 - val_loss: 0.9707 - val_accuracy: 0.5255\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9708 - val_accuracy: 0.5263\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9748 - accuracy: 0.5304 - val_loss: 0.9707 - val_accuracy: 0.5263\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9750 - accuracy: 0.5299 - val_loss: 0.9708 - val_accuracy: 0.5263\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9750 - accuracy: 0.5304 - val_loss: 0.9708 - val_accuracy: 0.5263\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9749 - accuracy: 0.5302 - val_loss: 0.9703 - val_accuracy: 0.5263\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9748 - accuracy: 0.5303 - val_loss: 0.9707 - val_accuracy: 0.5259\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9752 - accuracy: 0.5305 - val_loss: 0.9707 - val_accuracy: 0.5268\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9748 - accuracy: 0.5304 - val_loss: 0.9707 - val_accuracy: 0.5268\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9704 - val_accuracy: 0.5263\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9749 - accuracy: 0.5303 - val_loss: 0.9705 - val_accuracy: 0.5255\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9753 - accuracy: 0.5290 - val_loss: 0.9712 - val_accuracy: 0.5259\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9708 - val_accuracy: 0.5263\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9751 - accuracy: 0.5297 - val_loss: 0.9705 - val_accuracy: 0.5263\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9751 - accuracy: 0.5295 - val_loss: 0.9707 - val_accuracy: 0.5259\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9748 - accuracy: 0.5299 - val_loss: 0.9706 - val_accuracy: 0.5259\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9748 - accuracy: 0.5302 - val_loss: 0.9710 - val_accuracy: 0.5281\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9750 - accuracy: 0.5311 - val_loss: 0.9713 - val_accuracy: 0.5281\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9752 - accuracy: 0.5307 - val_loss: 0.9709 - val_accuracy: 0.5263\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9749 - accuracy: 0.5306 - val_loss: 0.9709 - val_accuracy: 0.5272\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9750 - accuracy: 0.5297 - val_loss: 0.9708 - val_accuracy: 0.5268\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9748 - accuracy: 0.5298 - val_loss: 0.9709 - val_accuracy: 0.5263\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9709 - val_accuracy: 0.5268\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9751 - accuracy: 0.5311 - val_loss: 0.9706 - val_accuracy: 0.5263\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9747 - accuracy: 0.5307 - val_loss: 0.9707 - val_accuracy: 0.5255\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9749 - accuracy: 0.5294 - val_loss: 0.9709 - val_accuracy: 0.5277\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9749 - accuracy: 0.5308 - val_loss: 0.9703 - val_accuracy: 0.5259\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9750 - accuracy: 0.5302 - val_loss: 0.9705 - val_accuracy: 0.5263\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9714 - val_accuracy: 0.5281\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9705 - val_accuracy: 0.5263\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9748 - accuracy: 0.5302 - val_loss: 0.9707 - val_accuracy: 0.5259\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9749 - accuracy: 0.5303 - val_loss: 0.9706 - val_accuracy: 0.5259\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9749 - accuracy: 0.5305 - val_loss: 0.9709 - val_accuracy: 0.5281\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9756 - accuracy: 0.5326 - val_loss: 0.9716 - val_accuracy: 0.5263\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9755 - accuracy: 0.5301 - val_loss: 0.9706 - val_accuracy: 0.5259\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9746 - accuracy: 0.5300 - val_loss: 0.9713 - val_accuracy: 0.5281\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9715 - val_accuracy: 0.5286\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9753 - accuracy: 0.5308 - val_loss: 0.9709 - val_accuracy: 0.5255\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 0.9708 - val_accuracy: 0.5277\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9750 - accuracy: 0.5306 - val_loss: 0.9706 - val_accuracy: 0.5268\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9750 - accuracy: 0.5305 - val_loss: 0.9703 - val_accuracy: 0.5263\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9747 - accuracy: 0.5301 - val_loss: 0.9703 - val_accuracy: 0.5263\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 0.9706 - val_accuracy: 0.5263\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9705 - val_accuracy: 0.5263\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9748 - accuracy: 0.5302 - val_loss: 0.9704 - val_accuracy: 0.5259\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9751 - accuracy: 0.5304 - val_loss: 0.9704 - val_accuracy: 0.5259\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9748 - accuracy: 0.5307 - val_loss: 0.9702 - val_accuracy: 0.5263\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9749 - accuracy: 0.5302 - val_loss: 0.9706 - val_accuracy: 0.5259\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 712us/step - loss: 0.9749 - accuracy: 0.5315 - val_loss: 0.9705 - val_accuracy: 0.5263\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9749 - accuracy: 0.5297 - val_loss: 0.9707 - val_accuracy: 0.5259\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9746 - accuracy: 0.5302 - val_loss: 0.9707 - val_accuracy: 0.5263\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 336us/step - loss: 0.9747 - accuracy: 0.5304\n",
      "Accuracy : 0.5303693413734436\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9707 - accuracy: 0.5263\n",
      "Accuracy : 0.5263391137123108\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 2.7728 - accuracy: 0.2626 - val_loss: 2.9768 - val_accuracy: 0.2320\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 2.2222 - accuracy: 0.2234 - val_loss: 2.5010 - val_accuracy: 0.2103\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.7905 - accuracy: 0.2131 - val_loss: 2.0254 - val_accuracy: 0.2174\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.4558 - accuracy: 0.2596 - val_loss: 1.5608 - val_accuracy: 0.2864\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 1.2366 - accuracy: 0.3374 - val_loss: 1.2387 - val_accuracy: 0.3559\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 1.1107 - accuracy: 0.4257 - val_loss: 1.0696 - val_accuracy: 0.4489\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 1.0485 - accuracy: 0.4741 - val_loss: 1.0068 - val_accuracy: 0.5082\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 1.0208 - accuracy: 0.4978 - val_loss: 0.9865 - val_accuracy: 0.5170\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 1.0074 - accuracy: 0.5106 - val_loss: 0.9795 - val_accuracy: 0.5281\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0002 - accuracy: 0.5175 - val_loss: 0.9766 - val_accuracy: 0.5308\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9963 - accuracy: 0.5175 - val_loss: 0.9755 - val_accuracy: 0.5308\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9938 - accuracy: 0.5193 - val_loss: 0.9752 - val_accuracy: 0.5330\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9930 - accuracy: 0.5182 - val_loss: 0.9747 - val_accuracy: 0.5330\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9916 - accuracy: 0.5209 - val_loss: 0.9756 - val_accuracy: 0.5361\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9910 - accuracy: 0.5218 - val_loss: 0.9755 - val_accuracy: 0.5365\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9908 - accuracy: 0.5194 - val_loss: 0.9772 - val_accuracy: 0.5356\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9901 - accuracy: 0.5223 - val_loss: 0.9766 - val_accuracy: 0.5352\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9895 - accuracy: 0.5226 - val_loss: 0.9761 - val_accuracy: 0.5347\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9890 - accuracy: 0.5236 - val_loss: 0.9755 - val_accuracy: 0.5343\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9886 - accuracy: 0.5226 - val_loss: 0.9748 - val_accuracy: 0.5347\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9885 - accuracy: 0.5240 - val_loss: 0.9740 - val_accuracy: 0.5356\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9878 - accuracy: 0.5230 - val_loss: 0.9737 - val_accuracy: 0.5361\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9877 - accuracy: 0.5225 - val_loss: 0.9729 - val_accuracy: 0.5356\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9874 - accuracy: 0.5228 - val_loss: 0.9728 - val_accuracy: 0.5339\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9870 - accuracy: 0.5246 - val_loss: 0.9718 - val_accuracy: 0.5343\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9866 - accuracy: 0.5240 - val_loss: 0.9723 - val_accuracy: 0.5347\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9863 - accuracy: 0.5238 - val_loss: 0.9720 - val_accuracy: 0.5356\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9860 - accuracy: 0.5232 - val_loss: 0.9711 - val_accuracy: 0.5352\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9855 - accuracy: 0.5239 - val_loss: 0.9710 - val_accuracy: 0.5352\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9852 - accuracy: 0.5251 - val_loss: 0.9702 - val_accuracy: 0.5347\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9855 - accuracy: 0.5237 - val_loss: 0.9702 - val_accuracy: 0.5343\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9847 - accuracy: 0.5247 - val_loss: 0.9705 - val_accuracy: 0.5343\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9845 - accuracy: 0.5251 - val_loss: 0.9700 - val_accuracy: 0.5347\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9844 - accuracy: 0.5261 - val_loss: 0.9695 - val_accuracy: 0.5347\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9840 - accuracy: 0.5261 - val_loss: 0.9701 - val_accuracy: 0.5343\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9840 - accuracy: 0.5255 - val_loss: 0.9692 - val_accuracy: 0.5356\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9835 - accuracy: 0.5263 - val_loss: 0.9688 - val_accuracy: 0.5374\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9832 - accuracy: 0.5258 - val_loss: 0.9683 - val_accuracy: 0.5370\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9831 - accuracy: 0.5262 - val_loss: 0.9678 - val_accuracy: 0.5339\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9830 - accuracy: 0.5275 - val_loss: 0.9669 - val_accuracy: 0.5352\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9829 - accuracy: 0.5252 - val_loss: 0.9667 - val_accuracy: 0.5370\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9825 - accuracy: 0.5259 - val_loss: 0.9669 - val_accuracy: 0.5352\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9827 - accuracy: 0.5270 - val_loss: 0.9654 - val_accuracy: 0.5343\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9822 - accuracy: 0.5256 - val_loss: 0.9655 - val_accuracy: 0.5356\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9820 - accuracy: 0.5261 - val_loss: 0.9656 - val_accuracy: 0.5347\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9820 - accuracy: 0.5260 - val_loss: 0.9652 - val_accuracy: 0.5343\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9817 - accuracy: 0.5267 - val_loss: 0.9658 - val_accuracy: 0.5347\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9818 - accuracy: 0.5264 - val_loss: 0.9655 - val_accuracy: 0.5356\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9815 - accuracy: 0.5265 - val_loss: 0.9657 - val_accuracy: 0.5352\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9815 - accuracy: 0.5272 - val_loss: 0.9649 - val_accuracy: 0.5352\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9813 - accuracy: 0.5263 - val_loss: 0.9647 - val_accuracy: 0.5365\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9809 - accuracy: 0.5266 - val_loss: 0.9649 - val_accuracy: 0.5378\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 590us/step - loss: 0.9814 - accuracy: 0.5269 - val_loss: 0.9646 - val_accuracy: 0.5365\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9815 - accuracy: 0.5286 - val_loss: 0.9632 - val_accuracy: 0.5352\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9811 - accuracy: 0.5271 - val_loss: 0.9631 - val_accuracy: 0.5356\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9806 - accuracy: 0.5274 - val_loss: 0.9634 - val_accuracy: 0.5356\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9805 - accuracy: 0.5282 - val_loss: 0.9634 - val_accuracy: 0.5356\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9810 - accuracy: 0.5248 - val_loss: 0.9622 - val_accuracy: 0.5347\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9806 - accuracy: 0.5273 - val_loss: 0.9618 - val_accuracy: 0.5347\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9803 - accuracy: 0.5270 - val_loss: 0.9631 - val_accuracy: 0.5361\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9802 - accuracy: 0.5271 - val_loss: 0.9628 - val_accuracy: 0.5365\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9799 - accuracy: 0.5279 - val_loss: 0.9631 - val_accuracy: 0.5361\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9800 - accuracy: 0.5278 - val_loss: 0.9634 - val_accuracy: 0.5365\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9798 - accuracy: 0.5275 - val_loss: 0.9631 - val_accuracy: 0.5374\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9797 - accuracy: 0.5291 - val_loss: 0.9627 - val_accuracy: 0.5370\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5295 - val_loss: 0.9630 - val_accuracy: 0.5365\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9795 - accuracy: 0.5284 - val_loss: 0.9635 - val_accuracy: 0.5374\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5285 - val_loss: 0.9629 - val_accuracy: 0.5383\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9794 - accuracy: 0.5285 - val_loss: 0.9625 - val_accuracy: 0.5361\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9792 - accuracy: 0.5279 - val_loss: 0.9623 - val_accuracy: 0.5383\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9792 - accuracy: 0.5289 - val_loss: 0.9622 - val_accuracy: 0.5365\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9791 - accuracy: 0.5279 - val_loss: 0.9621 - val_accuracy: 0.5356\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9792 - accuracy: 0.5286 - val_loss: 0.9625 - val_accuracy: 0.5378\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9792 - accuracy: 0.5277 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9790 - accuracy: 0.5276 - val_loss: 0.9624 - val_accuracy: 0.5374\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9790 - accuracy: 0.5286 - val_loss: 0.9624 - val_accuracy: 0.5352\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9790 - accuracy: 0.5272 - val_loss: 0.9622 - val_accuracy: 0.5365\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9789 - accuracy: 0.5278 - val_loss: 0.9619 - val_accuracy: 0.5378\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9787 - accuracy: 0.5287 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9788 - accuracy: 0.5271 - val_loss: 0.9621 - val_accuracy: 0.5361\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9786 - accuracy: 0.5286 - val_loss: 0.9613 - val_accuracy: 0.5378\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9788 - accuracy: 0.5268 - val_loss: 0.9608 - val_accuracy: 0.5365\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9786 - accuracy: 0.5288 - val_loss: 0.9613 - val_accuracy: 0.5378\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9787 - accuracy: 0.5274 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9786 - accuracy: 0.5292 - val_loss: 0.9620 - val_accuracy: 0.5378\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9783 - accuracy: 0.5295 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9788 - accuracy: 0.5276 - val_loss: 0.9611 - val_accuracy: 0.5374\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9785 - accuracy: 0.5290 - val_loss: 0.9617 - val_accuracy: 0.5374\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9782 - accuracy: 0.5283 - val_loss: 0.9613 - val_accuracy: 0.5370\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9780 - accuracy: 0.5296 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9782 - accuracy: 0.5295 - val_loss: 0.9615 - val_accuracy: 0.5365\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9784 - accuracy: 0.5287 - val_loss: 0.9610 - val_accuracy: 0.5365\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9781 - accuracy: 0.5276 - val_loss: 0.9606 - val_accuracy: 0.5374\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9785 - accuracy: 0.5294 - val_loss: 0.9614 - val_accuracy: 0.5365\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9783 - accuracy: 0.5291 - val_loss: 0.9612 - val_accuracy: 0.5374\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9778 - accuracy: 0.5288 - val_loss: 0.9605 - val_accuracy: 0.5365\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9778 - accuracy: 0.5295 - val_loss: 0.9607 - val_accuracy: 0.5365\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9781 - accuracy: 0.5292 - val_loss: 0.9604 - val_accuracy: 0.5365\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9781 - accuracy: 0.5285 - val_loss: 0.9603 - val_accuracy: 0.5374\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9781 - accuracy: 0.5290 - val_loss: 0.9603 - val_accuracy: 0.5374\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9779 - accuracy: 0.5289 - val_loss: 0.9612 - val_accuracy: 0.5378\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9779 - accuracy: 0.5278 - val_loss: 0.9610 - val_accuracy: 0.5383\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9778 - accuracy: 0.5279 - val_loss: 0.9602 - val_accuracy: 0.5374\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9777 - accuracy: 0.5284 - val_loss: 0.9601 - val_accuracy: 0.5378\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9776 - accuracy: 0.5287 - val_loss: 0.9614 - val_accuracy: 0.5370\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9777 - accuracy: 0.5282 - val_loss: 0.9614 - val_accuracy: 0.5374\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9778 - accuracy: 0.5282 - val_loss: 0.9616 - val_accuracy: 0.5370\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9775 - accuracy: 0.5288 - val_loss: 0.9605 - val_accuracy: 0.5383\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9785 - accuracy: 0.5292 - val_loss: 0.9603 - val_accuracy: 0.5370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9777 - accuracy: 0.5287 - val_loss: 0.9601 - val_accuracy: 0.5356\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9778 - accuracy: 0.5285 - val_loss: 0.9606 - val_accuracy: 0.5370\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9780 - accuracy: 0.5292 - val_loss: 0.9605 - val_accuracy: 0.5365\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9779 - accuracy: 0.5290 - val_loss: 0.9601 - val_accuracy: 0.5365\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9782 - accuracy: 0.5289 - val_loss: 0.9592 - val_accuracy: 0.5370\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9775 - accuracy: 0.5282 - val_loss: 0.9590 - val_accuracy: 0.5378\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9777 - accuracy: 0.5285 - val_loss: 0.9596 - val_accuracy: 0.5383\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9777 - accuracy: 0.5292 - val_loss: 0.9598 - val_accuracy: 0.5365\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9774 - accuracy: 0.5276 - val_loss: 0.9599 - val_accuracy: 0.5370\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9773 - accuracy: 0.5284 - val_loss: 0.9602 - val_accuracy: 0.5365\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9772 - accuracy: 0.5288 - val_loss: 0.9607 - val_accuracy: 0.5370\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9772 - accuracy: 0.5291 - val_loss: 0.9604 - val_accuracy: 0.5370\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9772 - accuracy: 0.5294 - val_loss: 0.9599 - val_accuracy: 0.5356\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9779 - accuracy: 0.5293 - val_loss: 0.9601 - val_accuracy: 0.5365\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 0.9603 - val_accuracy: 0.5370\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5292 - val_loss: 0.9603 - val_accuracy: 0.5370\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5277 - val_loss: 0.9596 - val_accuracy: 0.5370\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9773 - accuracy: 0.5287 - val_loss: 0.9610 - val_accuracy: 0.5370\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9775 - accuracy: 0.5277 - val_loss: 0.9601 - val_accuracy: 0.5374\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9776 - accuracy: 0.5307 - val_loss: 0.9601 - val_accuracy: 0.5365\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9773 - accuracy: 0.5294 - val_loss: 0.9599 - val_accuracy: 0.5370\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9772 - accuracy: 0.5290 - val_loss: 0.9599 - val_accuracy: 0.5370\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9776 - accuracy: 0.5285 - val_loss: 0.9606 - val_accuracy: 0.5370\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9773 - accuracy: 0.5289 - val_loss: 0.9603 - val_accuracy: 0.5374\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9771 - accuracy: 0.5294 - val_loss: 0.9606 - val_accuracy: 0.5370\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9604 - val_accuracy: 0.5378\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5284 - val_loss: 0.9606 - val_accuracy: 0.5374\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9609 - val_accuracy: 0.5374\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9609 - val_accuracy: 0.5374\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9610 - val_accuracy: 0.5356\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9771 - accuracy: 0.5303 - val_loss: 0.9602 - val_accuracy: 0.5370\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9771 - accuracy: 0.5296 - val_loss: 0.9607 - val_accuracy: 0.5370\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9771 - accuracy: 0.5282 - val_loss: 0.9598 - val_accuracy: 0.5374\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9770 - accuracy: 0.5290 - val_loss: 0.9600 - val_accuracy: 0.5370\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9771 - accuracy: 0.5293 - val_loss: 0.9603 - val_accuracy: 0.5370\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9773 - accuracy: 0.5291 - val_loss: 0.9597 - val_accuracy: 0.5378\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5290 - val_loss: 0.9596 - val_accuracy: 0.5370\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9771 - accuracy: 0.5283 - val_loss: 0.9603 - val_accuracy: 0.5374\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9771 - accuracy: 0.5291 - val_loss: 0.9597 - val_accuracy: 0.5374\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9770 - accuracy: 0.5289 - val_loss: 0.9602 - val_accuracy: 0.5374\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9771 - accuracy: 0.5298 - val_loss: 0.9598 - val_accuracy: 0.5370\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9768 - accuracy: 0.5286 - val_loss: 0.9608 - val_accuracy: 0.5365\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9771 - accuracy: 0.5291 - val_loss: 0.9595 - val_accuracy: 0.5361\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9772 - accuracy: 0.5296 - val_loss: 0.9602 - val_accuracy: 0.5370\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9771 - accuracy: 0.5283 - val_loss: 0.9602 - val_accuracy: 0.5365\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9590 - val_accuracy: 0.5370\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9769 - accuracy: 0.5285 - val_loss: 0.9595 - val_accuracy: 0.5370\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9770 - accuracy: 0.5290 - val_loss: 0.9604 - val_accuracy: 0.5374\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9768 - accuracy: 0.5296 - val_loss: 0.9597 - val_accuracy: 0.5374\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9768 - accuracy: 0.5285 - val_loss: 0.9600 - val_accuracy: 0.5370\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9592 - val_accuracy: 0.5365\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9771 - accuracy: 0.5291 - val_loss: 0.9601 - val_accuracy: 0.5374\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9768 - accuracy: 0.5284 - val_loss: 0.9593 - val_accuracy: 0.5374\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9595 - val_accuracy: 0.5370\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9601 - val_accuracy: 0.5370\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9767 - accuracy: 0.5287 - val_loss: 0.9599 - val_accuracy: 0.5356\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 636us/step - loss: 0.9768 - accuracy: 0.5293 - val_loss: 0.9605 - val_accuracy: 0.5370\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9602 - val_accuracy: 0.5361\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9595 - val_accuracy: 0.5361\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9767 - accuracy: 0.5291 - val_loss: 0.9600 - val_accuracy: 0.5365\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9769 - accuracy: 0.5286 - val_loss: 0.9591 - val_accuracy: 0.5374\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9595 - val_accuracy: 0.5374\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9768 - accuracy: 0.5285 - val_loss: 0.9594 - val_accuracy: 0.5370\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 704us/step - loss: 0.9767 - accuracy: 0.5287 - val_loss: 0.9596 - val_accuracy: 0.5361\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9767 - accuracy: 0.5287 - val_loss: 0.9604 - val_accuracy: 0.5365\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9767 - accuracy: 0.5286 - val_loss: 0.9601 - val_accuracy: 0.5374\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 665us/step - loss: 0.9767 - accuracy: 0.5292 - val_loss: 0.9608 - val_accuracy: 0.5370\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 563us/step - loss: 0.9768 - accuracy: 0.5290 - val_loss: 0.9601 - val_accuracy: 0.5370\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9766 - accuracy: 0.5288 - val_loss: 0.9600 - val_accuracy: 0.5374\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9608 - val_accuracy: 0.5370\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 735us/step - loss: 0.9767 - accuracy: 0.5295 - val_loss: 0.9607 - val_accuracy: 0.5374\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9773 - accuracy: 0.5308 - val_loss: 0.9590 - val_accuracy: 0.5356\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9768 - accuracy: 0.5291 - val_loss: 0.9602 - val_accuracy: 0.5374\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9770 - accuracy: 0.5290 - val_loss: 0.9593 - val_accuracy: 0.5361\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9767 - accuracy: 0.5291 - val_loss: 0.9602 - val_accuracy: 0.5365\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9766 - accuracy: 0.5280 - val_loss: 0.9598 - val_accuracy: 0.5374\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9766 - accuracy: 0.5283 - val_loss: 0.9604 - val_accuracy: 0.5370\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5295 - val_loss: 0.9592 - val_accuracy: 0.5374\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9767 - accuracy: 0.5296 - val_loss: 0.9598 - val_accuracy: 0.5374\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9766 - accuracy: 0.5289 - val_loss: 0.9604 - val_accuracy: 0.5370\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9597 - val_accuracy: 0.5374\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9765 - accuracy: 0.5286 - val_loss: 0.9611 - val_accuracy: 0.5374\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9768 - accuracy: 0.5284 - val_loss: 0.9595 - val_accuracy: 0.5370\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9783 - accuracy: 0.5291 - val_loss: 0.9601 - val_accuracy: 0.5361\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9765 - accuracy: 0.5279 - val_loss: 0.9597 - val_accuracy: 0.5361\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9766 - accuracy: 0.5284 - val_loss: 0.9596 - val_accuracy: 0.5370\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9590 - val_accuracy: 0.5370\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9765 - accuracy: 0.5285 - val_loss: 0.9601 - val_accuracy: 0.5378\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9764 - accuracy: 0.5291 - val_loss: 0.9597 - val_accuracy: 0.5370\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9598 - val_accuracy: 0.5374\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9591 - val_accuracy: 0.5370\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 339us/step - loss: 0.9763 - accuracy: 0.5290\n",
      "Accuracy : 0.5290414690971375\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9591 - accuracy: 0.5370\n",
      "Accuracy : 0.5369632840156555\n",
      "\n",
      "The final train accuracy is:0.49640385508537294 \n",
      "\n",
      "The final test accuracy is:0.4969105899333954 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"BW.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data = np.array(df.iloc[:,0:3])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "    \n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "    \n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (3,1)),\n",
    "        keras.layers.Dense(3,activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels,batch_size = 221, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "registered-midwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prospective-translator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arbitrary-mining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-board",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
