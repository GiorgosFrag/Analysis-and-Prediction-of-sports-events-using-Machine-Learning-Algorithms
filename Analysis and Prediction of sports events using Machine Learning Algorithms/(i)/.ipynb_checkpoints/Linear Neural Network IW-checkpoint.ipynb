{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "technological-hours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1.3702 - accuracy: 0.2324 - val_loss: 1.1725 - val_accuracy: 0.2841\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 1.1258 - accuracy: 0.3951 - val_loss: 1.0780 - val_accuracy: 0.4588\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0608 - accuracy: 0.4591 - val_loss: 1.0486 - val_accuracy: 0.4588\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 575us/step - loss: 1.0369 - accuracy: 0.4591 - val_loss: 1.0334 - val_accuracy: 0.4588\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 575us/step - loss: 1.0239 - accuracy: 0.4591 - val_loss: 1.0240 - val_accuracy: 0.4588\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 1.0160 - accuracy: 0.4591 - val_loss: 1.0174 - val_accuracy: 0.4588\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 1.0105 - accuracy: 0.4591 - val_loss: 1.0130 - val_accuracy: 0.4588\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 1.0066 - accuracy: 0.4591 - val_loss: 1.0094 - val_accuracy: 0.4588\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 1.0037 - accuracy: 0.4622 - val_loss: 1.0066 - val_accuracy: 0.4628\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 1.0011 - accuracy: 0.4851 - val_loss: 1.0038 - val_accuracy: 0.4841\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9989 - accuracy: 0.5054 - val_loss: 1.0016 - val_accuracy: 0.5044\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9967 - accuracy: 0.5140 - val_loss: 0.9995 - val_accuracy: 0.5146\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 614us/step - loss: 0.9945 - accuracy: 0.5218 - val_loss: 0.9972 - val_accuracy: 0.5173\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 0.9921 - accuracy: 0.5258 - val_loss: 0.9946 - val_accuracy: 0.5226\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9896 - accuracy: 0.5292 - val_loss: 0.9923 - val_accuracy: 0.5239\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9867 - accuracy: 0.5305 - val_loss: 0.9900 - val_accuracy: 0.5292\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9845 - accuracy: 0.5301 - val_loss: 0.9883 - val_accuracy: 0.5279\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9827 - accuracy: 0.5304 - val_loss: 0.9872 - val_accuracy: 0.5283\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9816 - accuracy: 0.5297 - val_loss: 0.9870 - val_accuracy: 0.5288\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9808 - accuracy: 0.5307 - val_loss: 0.9860 - val_accuracy: 0.5288\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9803 - accuracy: 0.5301 - val_loss: 0.9860 - val_accuracy: 0.5292\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9797 - accuracy: 0.5305 - val_loss: 0.9854 - val_accuracy: 0.5283\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9792 - accuracy: 0.5301 - val_loss: 0.9852 - val_accuracy: 0.5292\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9789 - accuracy: 0.5304 - val_loss: 0.9849 - val_accuracy: 0.5283\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9786 - accuracy: 0.5312 - val_loss: 0.9849 - val_accuracy: 0.5235\n",
      "Epoch 26/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 0.9783 - accuracy: 0.5308 - val_loss: 0.9844 - val_accuracy: 0.5283\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9782 - accuracy: 0.5310 - val_loss: 0.9845 - val_accuracy: 0.5239\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9779 - accuracy: 0.5308 - val_loss: 0.9841 - val_accuracy: 0.5239\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9776 - accuracy: 0.5300 - val_loss: 0.9844 - val_accuracy: 0.5235\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9775 - accuracy: 0.5302 - val_loss: 0.9840 - val_accuracy: 0.5235\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9772 - accuracy: 0.5315 - val_loss: 0.9840 - val_accuracy: 0.5226\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9771 - accuracy: 0.5306 - val_loss: 0.9839 - val_accuracy: 0.5235\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9769 - accuracy: 0.5313 - val_loss: 0.9838 - val_accuracy: 0.5226\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9769 - accuracy: 0.5307 - val_loss: 0.9836 - val_accuracy: 0.5235\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9766 - accuracy: 0.5316 - val_loss: 0.9834 - val_accuracy: 0.5235\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 0.9765 - accuracy: 0.5305 - val_loss: 0.9834 - val_accuracy: 0.5235\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9764 - accuracy: 0.5307 - val_loss: 0.9834 - val_accuracy: 0.5230\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9763 - accuracy: 0.5305 - val_loss: 0.9831 - val_accuracy: 0.5221\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9762 - accuracy: 0.5304 - val_loss: 0.9834 - val_accuracy: 0.5226\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9762 - accuracy: 0.5299 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9761 - accuracy: 0.5302 - val_loss: 0.9833 - val_accuracy: 0.5221\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9759 - accuracy: 0.5300 - val_loss: 0.9831 - val_accuracy: 0.5230\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9759 - accuracy: 0.5303 - val_loss: 0.9831 - val_accuracy: 0.5226\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9758 - accuracy: 0.5305 - val_loss: 0.9828 - val_accuracy: 0.5230\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9758 - accuracy: 0.5304 - val_loss: 0.9830 - val_accuracy: 0.5221\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5294 - val_loss: 0.9827 - val_accuracy: 0.5221\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9757 - accuracy: 0.5300 - val_loss: 0.9828 - val_accuracy: 0.5230\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 0.9829 - val_accuracy: 0.5226\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5297 - val_loss: 0.9827 - val_accuracy: 0.5221\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9826 - val_accuracy: 0.5221\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9754 - accuracy: 0.5300 - val_loss: 0.9827 - val_accuracy: 0.5226\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 575us/step - loss: 0.9755 - accuracy: 0.5294 - val_loss: 0.9826 - val_accuracy: 0.5226\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9826 - val_accuracy: 0.5230\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9826 - val_accuracy: 0.5230\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9752 - accuracy: 0.5303 - val_loss: 0.9827 - val_accuracy: 0.5221\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9753 - accuracy: 0.5294 - val_loss: 0.9829 - val_accuracy: 0.5230\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9827 - val_accuracy: 0.5226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9752 - accuracy: 0.5298 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9751 - accuracy: 0.5301 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5301 - val_loss: 0.9827 - val_accuracy: 0.5199\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9751 - accuracy: 0.5297 - val_loss: 0.9824 - val_accuracy: 0.5221\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9750 - accuracy: 0.5295 - val_loss: 0.9826 - val_accuracy: 0.5221\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9750 - accuracy: 0.5296 - val_loss: 0.9827 - val_accuracy: 0.5226\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9748 - accuracy: 0.5295 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9749 - accuracy: 0.5300 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9748 - accuracy: 0.5294 - val_loss: 0.9824 - val_accuracy: 0.5221\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9750 - accuracy: 0.5297 - val_loss: 0.9828 - val_accuracy: 0.5199\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9826 - val_accuracy: 0.5230\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9747 - accuracy: 0.5292 - val_loss: 0.9826 - val_accuracy: 0.5230\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5299 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 589us/step - loss: 0.9749 - accuracy: 0.5296 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9748 - accuracy: 0.5303 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9749 - accuracy: 0.5292 - val_loss: 0.9823 - val_accuracy: 0.5221\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9748 - accuracy: 0.5299 - val_loss: 0.9825 - val_accuracy: 0.5221\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9748 - accuracy: 0.5297 - val_loss: 0.9823 - val_accuracy: 0.5221\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9746 - accuracy: 0.5300 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9746 - accuracy: 0.5300 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9825 - val_accuracy: 0.5226\n",
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9747 - accuracy: 0.5296 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 547us/step - loss: 0.9746 - accuracy: 0.5296 - val_loss: 0.9823 - val_accuracy: 0.5221\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9746 - accuracy: 0.5297 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9746 - accuracy: 0.5299 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9745 - accuracy: 0.5298 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 0.9746 - accuracy: 0.5297 - val_loss: 0.9825 - val_accuracy: 0.5221\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 538us/step - loss: 0.9745 - accuracy: 0.5299 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 538us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9745 - accuracy: 0.5296 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9744 - accuracy: 0.5304 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9746 - accuracy: 0.5297 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9744 - accuracy: 0.5297 - val_loss: 0.9830 - val_accuracy: 0.5221\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9746 - accuracy: 0.5297 - val_loss: 0.9822 - val_accuracy: 0.5212\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9744 - accuracy: 0.5295 - val_loss: 0.9822 - val_accuracy: 0.5230\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9745 - accuracy: 0.5293 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9745 - accuracy: 0.5298 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9745 - accuracy: 0.5299 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9744 - accuracy: 0.5299 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9745 - accuracy: 0.5291 - val_loss: 0.9822 - val_accuracy: 0.5217\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9744 - accuracy: 0.5301 - val_loss: 0.9822 - val_accuracy: 0.5230\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 538us/step - loss: 0.9744 - accuracy: 0.5296 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9743 - accuracy: 0.5296 - val_loss: 0.9825 - val_accuracy: 0.5217\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9745 - accuracy: 0.5292 - val_loss: 0.9823 - val_accuracy: 0.5221\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9746 - accuracy: 0.5305 - val_loss: 0.9825 - val_accuracy: 0.5212\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9744 - accuracy: 0.5297 - val_loss: 0.9822 - val_accuracy: 0.5230\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9823 - val_accuracy: 0.5221\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9744 - accuracy: 0.5288 - val_loss: 0.9822 - val_accuracy: 0.5221\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9742 - accuracy: 0.5294 - val_loss: 0.9824 - val_accuracy: 0.5199\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 542us/step - loss: 0.9743 - accuracy: 0.5296 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9743 - accuracy: 0.5294 - val_loss: 0.9822 - val_accuracy: 0.5230\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9743 - accuracy: 0.5297 - val_loss: 0.9825 - val_accuracy: 0.5212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9743 - accuracy: 0.5298 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9743 - accuracy: 0.5301 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9742 - accuracy: 0.5297 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9744 - accuracy: 0.5293 - val_loss: 0.9825 - val_accuracy: 0.5226\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9743 - accuracy: 0.5293 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.9741 - accuracy: 0.5289 - val_loss: 0.9821 - val_accuracy: 0.5212\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9742 - accuracy: 0.5297 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9741 - accuracy: 0.5299 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9743 - accuracy: 0.5298 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9742 - accuracy: 0.5297 - val_loss: 0.9826 - val_accuracy: 0.5221\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9741 - accuracy: 0.5297 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9745 - accuracy: 0.5295 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9742 - accuracy: 0.5293 - val_loss: 0.9822 - val_accuracy: 0.5230\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9743 - accuracy: 0.5297 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9742 - accuracy: 0.5295 - val_loss: 0.9826 - val_accuracy: 0.5226\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9741 - accuracy: 0.5294 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 604us/step - loss: 0.9741 - accuracy: 0.5294 - val_loss: 0.9830 - val_accuracy: 0.5226\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9742 - accuracy: 0.5296 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9741 - accuracy: 0.5297 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9739 - accuracy: 0.5294 - val_loss: 0.9826 - val_accuracy: 0.5199\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9743 - accuracy: 0.5293 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9740 - accuracy: 0.5298 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9741 - accuracy: 0.5293 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 139/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9742 - accuracy: 0.5285 - val_loss: 0.9823 - val_accuracy: 0.5217\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9740 - accuracy: 0.5298 - val_loss: 0.9829 - val_accuracy: 0.5217\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9741 - accuracy: 0.5293 - val_loss: 0.9821 - val_accuracy: 0.5230\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9739 - accuracy: 0.5300 - val_loss: 0.9827 - val_accuracy: 0.5212\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9740 - accuracy: 0.5291 - val_loss: 0.9827 - val_accuracy: 0.5230\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5302 - val_loss: 0.9822 - val_accuracy: 0.5221\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9741 - accuracy: 0.5304 - val_loss: 0.9820 - val_accuracy: 0.5221\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9740 - accuracy: 0.5298 - val_loss: 0.9823 - val_accuracy: 0.5221\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5296 - val_loss: 0.9826 - val_accuracy: 0.5230\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5300 - val_loss: 0.9822 - val_accuracy: 0.5217\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9739 - accuracy: 0.5300 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9739 - accuracy: 0.5291 - val_loss: 0.9825 - val_accuracy: 0.5212\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9741 - accuracy: 0.5295 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9741 - accuracy: 0.5295 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5292 - val_loss: 0.9824 - val_accuracy: 0.5199\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5297 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9740 - accuracy: 0.5298 - val_loss: 0.9822 - val_accuracy: 0.5221\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9740 - accuracy: 0.5303 - val_loss: 0.9822 - val_accuracy: 0.5230\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9741 - accuracy: 0.5294 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9738 - accuracy: 0.5294 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9740 - accuracy: 0.5301 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9740 - accuracy: 0.5298 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9739 - accuracy: 0.5301 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9740 - accuracy: 0.5293 - val_loss: 0.9822 - val_accuracy: 0.5230\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9740 - accuracy: 0.5303 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9738 - accuracy: 0.5298 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9739 - accuracy: 0.5291 - val_loss: 0.9824 - val_accuracy: 0.5199\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9739 - accuracy: 0.5296 - val_loss: 0.9827 - val_accuracy: 0.5217\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 547us/step - loss: 0.9739 - accuracy: 0.5302 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 547us/step - loss: 0.9739 - accuracy: 0.5299 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9739 - accuracy: 0.5301 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9739 - accuracy: 0.5298 - val_loss: 0.9821 - val_accuracy: 0.5212\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5302 - val_loss: 0.9821 - val_accuracy: 0.5212\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9740 - accuracy: 0.5296 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9739 - accuracy: 0.5294 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9739 - accuracy: 0.5295 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9739 - accuracy: 0.5302 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9739 - accuracy: 0.5290 - val_loss: 0.9823 - val_accuracy: 0.5221\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 547us/step - loss: 0.9741 - accuracy: 0.5303 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9738 - accuracy: 0.5300 - val_loss: 0.9823 - val_accuracy: 0.5208\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9739 - accuracy: 0.5295 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9738 - accuracy: 0.5296 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9739 - accuracy: 0.5301 - val_loss: 0.9824 - val_accuracy: 0.5199\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9738 - accuracy: 0.5290 - val_loss: 0.9820 - val_accuracy: 0.5221\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9738 - accuracy: 0.5298 - val_loss: 0.9823 - val_accuracy: 0.5221\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 574us/step - loss: 0.9738 - accuracy: 0.5297 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9738 - accuracy: 0.5294 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9738 - accuracy: 0.5290 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9738 - accuracy: 0.5296 - val_loss: 0.9822 - val_accuracy: 0.5221\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9739 - accuracy: 0.5296 - val_loss: 0.9821 - val_accuracy: 0.5212\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9738 - accuracy: 0.5299 - val_loss: 0.9826 - val_accuracy: 0.5212\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9738 - accuracy: 0.5300 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9737 - accuracy: 0.5290 - val_loss: 0.9822 - val_accuracy: 0.5221\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9738 - accuracy: 0.5293 - val_loss: 0.9826 - val_accuracy: 0.5221\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9737 - accuracy: 0.5295 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9737 - accuracy: 0.5294 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 195/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9737 - accuracy: 0.5293 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9738 - accuracy: 0.5298 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 0.9821 - val_accuracy: 0.5208\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9739 - accuracy: 0.5295 - val_loss: 0.9822 - val_accuracy: 0.5221\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9738 - accuracy: 0.5288 - val_loss: 0.9821 - val_accuracy: 0.5212\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9736 - accuracy: 0.5295 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 339us/step - loss: 0.9741 - accuracy: 0.5308\n",
      "Accuracy : 0.5308380722999573\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9824 - accuracy: 0.5226\n",
      "Accuracy : 0.5225663781166077\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1.7659 - accuracy: 0.2721 - val_loss: 1.6222 - val_accuracy: 0.3292\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 1.5282 - accuracy: 0.3728 - val_loss: 1.4527 - val_accuracy: 0.3978\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 1.3867 - accuracy: 0.4133 - val_loss: 1.3148 - val_accuracy: 0.4363\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 1.2621 - accuracy: 0.4525 - val_loss: 1.1927 - val_accuracy: 0.4704\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 1.1563 - accuracy: 0.4605 - val_loss: 1.0985 - val_accuracy: 0.4717\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 1.0793 - accuracy: 0.4614 - val_loss: 1.0369 - val_accuracy: 0.4735\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 1.0320 - accuracy: 0.4671 - val_loss: 1.0039 - val_accuracy: 0.4858\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 1.0072 - accuracy: 0.4982 - val_loss: 0.9879 - val_accuracy: 0.5212\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9947 - accuracy: 0.5130 - val_loss: 0.9807 - val_accuracy: 0.5296\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9886 - accuracy: 0.5201 - val_loss: 0.9775 - val_accuracy: 0.5310\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9853 - accuracy: 0.5234 - val_loss: 0.9756 - val_accuracy: 0.5332\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9837 - accuracy: 0.5252 - val_loss: 0.9752 - val_accuracy: 0.5310\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 470us/step - loss: 0.9827 - accuracy: 0.5259 - val_loss: 0.9750 - val_accuracy: 0.5354\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9821 - accuracy: 0.5263 - val_loss: 0.9750 - val_accuracy: 0.5345\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 686us/step - loss: 0.9818 - accuracy: 0.5271 - val_loss: 0.9754 - val_accuracy: 0.5305\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 610us/step - loss: 0.9815 - accuracy: 0.5264 - val_loss: 0.9753 - val_accuracy: 0.5350\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9813 - accuracy: 0.5271 - val_loss: 0.9755 - val_accuracy: 0.5301\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9812 - accuracy: 0.5278 - val_loss: 0.9755 - val_accuracy: 0.5301\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9810 - accuracy: 0.5271 - val_loss: 0.9752 - val_accuracy: 0.5354\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9809 - accuracy: 0.5278 - val_loss: 0.9751 - val_accuracy: 0.5305\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9806 - accuracy: 0.5272 - val_loss: 0.9750 - val_accuracy: 0.5354\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9804 - accuracy: 0.5281 - val_loss: 0.9752 - val_accuracy: 0.5358\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9803 - accuracy: 0.5266 - val_loss: 0.9748 - val_accuracy: 0.5354\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9801 - accuracy: 0.5278 - val_loss: 0.9749 - val_accuracy: 0.5301\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9801 - accuracy: 0.5263 - val_loss: 0.9748 - val_accuracy: 0.5301\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 598us/step - loss: 0.9798 - accuracy: 0.5280 - val_loss: 0.9746 - val_accuracy: 0.5301\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9798 - accuracy: 0.5271 - val_loss: 0.9745 - val_accuracy: 0.5345\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9796 - accuracy: 0.5273 - val_loss: 0.9745 - val_accuracy: 0.5354\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9795 - accuracy: 0.5285 - val_loss: 0.9745 - val_accuracy: 0.5301\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9793 - accuracy: 0.5277 - val_loss: 0.9744 - val_accuracy: 0.5301\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9792 - accuracy: 0.5272 - val_loss: 0.9744 - val_accuracy: 0.5354\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9792 - accuracy: 0.5271 - val_loss: 0.9743 - val_accuracy: 0.5345\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9791 - accuracy: 0.5279 - val_loss: 0.9747 - val_accuracy: 0.5292\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9790 - accuracy: 0.5273 - val_loss: 0.9743 - val_accuracy: 0.5301\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9788 - accuracy: 0.5275 - val_loss: 0.9742 - val_accuracy: 0.5350\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9788 - accuracy: 0.5286 - val_loss: 0.9743 - val_accuracy: 0.5345\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9786 - accuracy: 0.5271 - val_loss: 0.9744 - val_accuracy: 0.5363\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9787 - accuracy: 0.5272 - val_loss: 0.9743 - val_accuracy: 0.5301\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9785 - accuracy: 0.5282 - val_loss: 0.9745 - val_accuracy: 0.5292\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9785 - accuracy: 0.5275 - val_loss: 0.9744 - val_accuracy: 0.5301\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9785 - accuracy: 0.5282 - val_loss: 0.9742 - val_accuracy: 0.5354\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9785 - accuracy: 0.5272 - val_loss: 0.9742 - val_accuracy: 0.5341\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9784 - accuracy: 0.5284 - val_loss: 0.9741 - val_accuracy: 0.5332\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9785 - accuracy: 0.5275 - val_loss: 0.9742 - val_accuracy: 0.5350\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9784 - accuracy: 0.5277 - val_loss: 0.9744 - val_accuracy: 0.5301\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9782 - accuracy: 0.5280 - val_loss: 0.9746 - val_accuracy: 0.5292\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 524us/step - loss: 0.9783 - accuracy: 0.5278 - val_loss: 0.9744 - val_accuracy: 0.5301\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9782 - accuracy: 0.5281 - val_loss: 0.9743 - val_accuracy: 0.5301\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 634us/step - loss: 0.9782 - accuracy: 0.5272 - val_loss: 0.9743 - val_accuracy: 0.5354\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 584us/step - loss: 0.9781 - accuracy: 0.5275 - val_loss: 0.9745 - val_accuracy: 0.5301\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9780 - accuracy: 0.5277 - val_loss: 0.9742 - val_accuracy: 0.5358\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9781 - accuracy: 0.5278 - val_loss: 0.9744 - val_accuracy: 0.5358\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9780 - accuracy: 0.5281 - val_loss: 0.9742 - val_accuracy: 0.5350\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9781 - accuracy: 0.5281 - val_loss: 0.9745 - val_accuracy: 0.5305\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9780 - accuracy: 0.5284 - val_loss: 0.9742 - val_accuracy: 0.5350\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9779 - accuracy: 0.5276 - val_loss: 0.9742 - val_accuracy: 0.5354\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9780 - accuracy: 0.5283 - val_loss: 0.9743 - val_accuracy: 0.5341\n",
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9780 - accuracy: 0.5282 - val_loss: 0.9743 - val_accuracy: 0.5296\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9779 - accuracy: 0.5273 - val_loss: 0.9743 - val_accuracy: 0.5358\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9779 - accuracy: 0.5278 - val_loss: 0.9744 - val_accuracy: 0.5296\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9778 - accuracy: 0.5280 - val_loss: 0.9743 - val_accuracy: 0.5358\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9779 - accuracy: 0.5277 - val_loss: 0.9743 - val_accuracy: 0.5358\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9777 - accuracy: 0.5289 - val_loss: 0.9750 - val_accuracy: 0.5363\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9779 - accuracy: 0.5285 - val_loss: 0.9744 - val_accuracy: 0.5296\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9778 - accuracy: 0.5278 - val_loss: 0.9742 - val_accuracy: 0.5350\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9777 - accuracy: 0.5279 - val_loss: 0.9743 - val_accuracy: 0.5350\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 0.9777 - accuracy: 0.5287 - val_loss: 0.9743 - val_accuracy: 0.5341\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 416us/step - loss: 0.9778 - accuracy: 0.5277 - val_loss: 0.9746 - val_accuracy: 0.5296\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 501us/step - loss: 0.9776 - accuracy: 0.5285 - val_loss: 0.9743 - val_accuracy: 0.5296\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9776 - accuracy: 0.5282 - val_loss: 0.9743 - val_accuracy: 0.5358\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9776 - accuracy: 0.5292 - val_loss: 0.9744 - val_accuracy: 0.5296\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9776 - accuracy: 0.5282 - val_loss: 0.9742 - val_accuracy: 0.5350\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 469us/step - loss: 0.9778 - accuracy: 0.5283 - val_loss: 0.9742 - val_accuracy: 0.5341\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 650us/step - loss: 0.9776 - accuracy: 0.5282 - val_loss: 0.9741 - val_accuracy: 0.5354\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9776 - accuracy: 0.5283 - val_loss: 0.9742 - val_accuracy: 0.5341\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9775 - accuracy: 0.5286 - val_loss: 0.9743 - val_accuracy: 0.5341\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9776 - accuracy: 0.5283 - val_loss: 0.9745 - val_accuracy: 0.5296\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9776 - accuracy: 0.5283 - val_loss: 0.9743 - val_accuracy: 0.5350\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9775 - accuracy: 0.5277 - val_loss: 0.9743 - val_accuracy: 0.5350\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9775 - accuracy: 0.5279 - val_loss: 0.9743 - val_accuracy: 0.5341\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9774 - accuracy: 0.5279 - val_loss: 0.9742 - val_accuracy: 0.5350\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9773 - accuracy: 0.5281 - val_loss: 0.9745 - val_accuracy: 0.5372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9775 - accuracy: 0.5280 - val_loss: 0.9742 - val_accuracy: 0.5350\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9775 - accuracy: 0.5288 - val_loss: 0.9741 - val_accuracy: 0.5350\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9773 - accuracy: 0.5283 - val_loss: 0.9741 - val_accuracy: 0.5358\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 0.9773 - accuracy: 0.5277 - val_loss: 0.9742 - val_accuracy: 0.5358\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9745 - val_accuracy: 0.5296\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9744 - val_accuracy: 0.5350\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9772 - accuracy: 0.5276 - val_loss: 0.9747 - val_accuracy: 0.5341\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9772 - accuracy: 0.5282 - val_loss: 0.9740 - val_accuracy: 0.5350\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 523us/step - loss: 0.9774 - accuracy: 0.5278 - val_loss: 0.9741 - val_accuracy: 0.5354\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 612us/step - loss: 0.9774 - accuracy: 0.5284 - val_loss: 0.9741 - val_accuracy: 0.5350\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 466us/step - loss: 0.9771 - accuracy: 0.5279 - val_loss: 0.9743 - val_accuracy: 0.5376\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 580us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9740 - val_accuracy: 0.5350\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 0.9771 - accuracy: 0.5278 - val_loss: 0.9745 - val_accuracy: 0.5296\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 504us/step - loss: 0.9771 - accuracy: 0.5279 - val_loss: 0.9740 - val_accuracy: 0.5358\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 640us/step - loss: 0.9771 - accuracy: 0.5279 - val_loss: 0.9740 - val_accuracy: 0.5358\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 434us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9743 - val_accuracy: 0.5341\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 689us/step - loss: 0.9773 - accuracy: 0.5280 - val_loss: 0.9741 - val_accuracy: 0.5350\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 582us/step - loss: 0.9772 - accuracy: 0.5276 - val_loss: 0.9740 - val_accuracy: 0.5358\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9742 - val_accuracy: 0.5341\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9772 - accuracy: 0.5280 - val_loss: 0.9740 - val_accuracy: 0.5354\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9770 - accuracy: 0.5289 - val_loss: 0.9741 - val_accuracy: 0.5350\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9770 - accuracy: 0.5286 - val_loss: 0.9741 - val_accuracy: 0.5354\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9770 - accuracy: 0.5294 - val_loss: 0.9741 - val_accuracy: 0.5350\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9771 - accuracy: 0.5279 - val_loss: 0.9741 - val_accuracy: 0.5341\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9770 - accuracy: 0.5282 - val_loss: 0.9740 - val_accuracy: 0.5350\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9769 - accuracy: 0.5283 - val_loss: 0.9740 - val_accuracy: 0.5358\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 578us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9740 - val_accuracy: 0.5341\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9742 - val_accuracy: 0.5296\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9740 - val_accuracy: 0.5341\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9768 - accuracy: 0.5281 - val_loss: 0.9739 - val_accuracy: 0.5358\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9770 - accuracy: 0.5273 - val_loss: 0.9740 - val_accuracy: 0.5354\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9768 - accuracy: 0.5284 - val_loss: 0.9738 - val_accuracy: 0.5358\n",
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9768 - accuracy: 0.5282 - val_loss: 0.9741 - val_accuracy: 0.5296\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9769 - accuracy: 0.5285 - val_loss: 0.9741 - val_accuracy: 0.5341\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9768 - accuracy: 0.5283 - val_loss: 0.9741 - val_accuracy: 0.5376\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9767 - accuracy: 0.5290 - val_loss: 0.9742 - val_accuracy: 0.5296\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9768 - accuracy: 0.5287 - val_loss: 0.9739 - val_accuracy: 0.5341\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9741 - val_accuracy: 0.5341\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9768 - accuracy: 0.5286 - val_loss: 0.9740 - val_accuracy: 0.5350\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9768 - accuracy: 0.5288 - val_loss: 0.9739 - val_accuracy: 0.5341\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9767 - accuracy: 0.5276 - val_loss: 0.9738 - val_accuracy: 0.5358\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 542us/step - loss: 0.9766 - accuracy: 0.5279 - val_loss: 0.9743 - val_accuracy: 0.5296\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9767 - accuracy: 0.5287 - val_loss: 0.9740 - val_accuracy: 0.5358\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9739 - val_accuracy: 0.5350\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9767 - accuracy: 0.5292 - val_loss: 0.9740 - val_accuracy: 0.5358\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9768 - accuracy: 0.5293 - val_loss: 0.9737 - val_accuracy: 0.5350\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9767 - accuracy: 0.5277 - val_loss: 0.9738 - val_accuracy: 0.5354\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9738 - val_accuracy: 0.5358\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 573us/step - loss: 0.9767 - accuracy: 0.5280 - val_loss: 0.9738 - val_accuracy: 0.5358\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 481us/step - loss: 0.9766 - accuracy: 0.5288 - val_loss: 0.9738 - val_accuracy: 0.5354\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 643us/step - loss: 0.9766 - accuracy: 0.5289 - val_loss: 0.9738 - val_accuracy: 0.5358\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9768 - accuracy: 0.5288 - val_loss: 0.9739 - val_accuracy: 0.5350\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9766 - accuracy: 0.5291 - val_loss: 0.9738 - val_accuracy: 0.5358\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9739 - val_accuracy: 0.5350\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9765 - accuracy: 0.5287 - val_loss: 0.9740 - val_accuracy: 0.5381\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9767 - accuracy: 0.5286 - val_loss: 0.9739 - val_accuracy: 0.5358\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 412us/step - loss: 0.9766 - accuracy: 0.5276 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9739 - val_accuracy: 0.5341\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 573us/step - loss: 0.9765 - accuracy: 0.5291 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9765 - accuracy: 0.5288 - val_loss: 0.9740 - val_accuracy: 0.5350\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9737 - val_accuracy: 0.5350\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 578us/step - loss: 0.9765 - accuracy: 0.5289 - val_loss: 0.9738 - val_accuracy: 0.5350\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9739 - val_accuracy: 0.5296\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 584us/step - loss: 0.9766 - accuracy: 0.5286 - val_loss: 0.9736 - val_accuracy: 0.5354\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9764 - accuracy: 0.5293 - val_loss: 0.9742 - val_accuracy: 0.5350\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 594us/step - loss: 0.9764 - accuracy: 0.5285 - val_loss: 0.9740 - val_accuracy: 0.5341\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 414us/step - loss: 0.9765 - accuracy: 0.5286 - val_loss: 0.9737 - val_accuracy: 0.5350\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 720us/step - loss: 0.9765 - accuracy: 0.5288 - val_loss: 0.9740 - val_accuracy: 0.5296\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 514us/step - loss: 0.9764 - accuracy: 0.5295 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9764 - accuracy: 0.5286 - val_loss: 0.9738 - val_accuracy: 0.5341\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9763 - accuracy: 0.5283 - val_loss: 0.9740 - val_accuracy: 0.5332\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9738 - val_accuracy: 0.5350\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9764 - accuracy: 0.5282 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9765 - accuracy: 0.5287 - val_loss: 0.9737 - val_accuracy: 0.5354\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9764 - accuracy: 0.5284 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9764 - accuracy: 0.5282 - val_loss: 0.9738 - val_accuracy: 0.5358\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9764 - accuracy: 0.5282 - val_loss: 0.9736 - val_accuracy: 0.5354\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9736 - val_accuracy: 0.5341\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9764 - accuracy: 0.5289 - val_loss: 0.9738 - val_accuracy: 0.5301\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9763 - accuracy: 0.5284 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9763 - accuracy: 0.5285 - val_loss: 0.9737 - val_accuracy: 0.5354\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 584us/step - loss: 0.9762 - accuracy: 0.5284 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9763 - accuracy: 0.5289 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9763 - accuracy: 0.5291 - val_loss: 0.9738 - val_accuracy: 0.5341\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 580us/step - loss: 0.9762 - accuracy: 0.5285 - val_loss: 0.9740 - val_accuracy: 0.5341\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9763 - accuracy: 0.5281 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9762 - accuracy: 0.5280 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 0.9762 - accuracy: 0.5286 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 171/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9764 - accuracy: 0.5284 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 0.9762 - accuracy: 0.5283 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9763 - accuracy: 0.5287 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9762 - accuracy: 0.5285 - val_loss: 0.9737 - val_accuracy: 0.5372\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9762 - accuracy: 0.5286 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 452us/step - loss: 0.9762 - accuracy: 0.5288 - val_loss: 0.9736 - val_accuracy: 0.5350\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 733us/step - loss: 0.9761 - accuracy: 0.5287 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9761 - accuracy: 0.5279 - val_loss: 0.9738 - val_accuracy: 0.5350\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9761 - accuracy: 0.5283 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9762 - accuracy: 0.5288 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9763 - accuracy: 0.5293 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9762 - accuracy: 0.5286 - val_loss: 0.9735 - val_accuracy: 0.5372\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9763 - accuracy: 0.5290 - val_loss: 0.9737 - val_accuracy: 0.5345\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9762 - accuracy: 0.5283 - val_loss: 0.9735 - val_accuracy: 0.5372\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9761 - accuracy: 0.5283 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9761 - accuracy: 0.5291 - val_loss: 0.9735 - val_accuracy: 0.5372\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9760 - accuracy: 0.5281 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9761 - accuracy: 0.5291 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9761 - accuracy: 0.5281 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9762 - accuracy: 0.5295 - val_loss: 0.9740 - val_accuracy: 0.5296\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9761 - accuracy: 0.5287 - val_loss: 0.9740 - val_accuracy: 0.5341\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9762 - accuracy: 0.5276 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9760 - accuracy: 0.5288 - val_loss: 0.9734 - val_accuracy: 0.5358\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9760 - accuracy: 0.5287 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 565us/step - loss: 0.9761 - accuracy: 0.5282 - val_loss: 0.9734 - val_accuracy: 0.5358\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9759 - accuracy: 0.5291 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9761 - accuracy: 0.5291 - val_loss: 0.9733 - val_accuracy: 0.5354\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9760 - accuracy: 0.5287 - val_loss: 0.9736 - val_accuracy: 0.5341\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9760 - accuracy: 0.5286 - val_loss: 0.9734 - val_accuracy: 0.5358\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9760 - accuracy: 0.5294 - val_loss: 0.9736 - val_accuracy: 0.5332\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 346us/step - loss: 0.9759 - accuracy: 0.5273\n",
      "Accuracy : 0.5273460745811462\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9736 - accuracy: 0.5332\n",
      "Accuracy : 0.5331858396530151\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.4433 - accuracy: 0.4590 - val_loss: 1.2900 - val_accuracy: 0.4595\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 767us/step - loss: 1.2358 - accuracy: 0.4590 - val_loss: 1.1394 - val_accuracy: 0.4595\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0842 - accuracy: 0.4665 - val_loss: 1.0370 - val_accuracy: 0.4732\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0005 - accuracy: 0.5167 - val_loss: 1.0121 - val_accuracy: 0.5113\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9833 - accuracy: 0.5238 - val_loss: 1.0077 - val_accuracy: 0.5135\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9783 - accuracy: 0.5275 - val_loss: 1.0055 - val_accuracy: 0.5135\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9761 - accuracy: 0.5265 - val_loss: 1.0044 - val_accuracy: 0.5210\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9746 - accuracy: 0.5279 - val_loss: 1.0041 - val_accuracy: 0.5193\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9738 - accuracy: 0.5273 - val_loss: 1.0037 - val_accuracy: 0.5210\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9735 - accuracy: 0.5283 - val_loss: 1.0037 - val_accuracy: 0.5215\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9733 - accuracy: 0.5276 - val_loss: 1.0036 - val_accuracy: 0.5219\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9734 - accuracy: 0.5288 - val_loss: 1.0040 - val_accuracy: 0.5224\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9734 - accuracy: 0.5278 - val_loss: 1.0041 - val_accuracy: 0.5215\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9732 - accuracy: 0.5278 - val_loss: 1.0043 - val_accuracy: 0.5219\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 564us/step - loss: 0.9732 - accuracy: 0.5280 - val_loss: 1.0041 - val_accuracy: 0.5219\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9730 - accuracy: 0.5280 - val_loss: 1.0042 - val_accuracy: 0.5215\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9732 - accuracy: 0.5295 - val_loss: 1.0043 - val_accuracy: 0.5219\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9732 - accuracy: 0.5267 - val_loss: 1.0044 - val_accuracy: 0.5210\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9730 - accuracy: 0.5273 - val_loss: 1.0043 - val_accuracy: 0.5224\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9729 - accuracy: 0.5284 - val_loss: 1.0046 - val_accuracy: 0.5215\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9732 - accuracy: 0.5273 - val_loss: 1.0043 - val_accuracy: 0.5215\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9731 - accuracy: 0.5266 - val_loss: 1.0042 - val_accuracy: 0.5224\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9732 - accuracy: 0.5290 - val_loss: 1.0046 - val_accuracy: 0.5224\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9731 - accuracy: 0.5277 - val_loss: 1.0042 - val_accuracy: 0.5215\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9730 - accuracy: 0.5280 - val_loss: 1.0045 - val_accuracy: 0.5224\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9731 - accuracy: 0.5286 - val_loss: 1.0043 - val_accuracy: 0.5215\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9730 - accuracy: 0.5294 - val_loss: 1.0044 - val_accuracy: 0.5219\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9731 - accuracy: 0.5281 - val_loss: 1.0046 - val_accuracy: 0.5219\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9732 - accuracy: 0.5266 - val_loss: 1.0047 - val_accuracy: 0.5210\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9731 - accuracy: 0.5285 - val_loss: 1.0045 - val_accuracy: 0.5219\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9729 - accuracy: 0.5296 - val_loss: 1.0045 - val_accuracy: 0.5215\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9732 - accuracy: 0.5274 - val_loss: 1.0046 - val_accuracy: 0.5219\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9731 - accuracy: 0.5285 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9729 - accuracy: 0.5282 - val_loss: 1.0041 - val_accuracy: 0.5224\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9731 - accuracy: 0.5290 - val_loss: 1.0041 - val_accuracy: 0.5215\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9736 - accuracy: 0.5294 - val_loss: 1.0045 - val_accuracy: 0.5219\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9732 - accuracy: 0.5285 - val_loss: 1.0043 - val_accuracy: 0.5215\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9731 - accuracy: 0.5294 - val_loss: 1.0044 - val_accuracy: 0.5219\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9729 - accuracy: 0.5275 - val_loss: 1.0045 - val_accuracy: 0.5219\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9729 - accuracy: 0.5276 - val_loss: 1.0043 - val_accuracy: 0.5215\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9728 - accuracy: 0.5284 - val_loss: 1.0044 - val_accuracy: 0.5210\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9730 - accuracy: 0.5285 - val_loss: 1.0049 - val_accuracy: 0.5224\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9730 - accuracy: 0.5286 - val_loss: 1.0044 - val_accuracy: 0.5224\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9729 - accuracy: 0.5285 - val_loss: 1.0042 - val_accuracy: 0.5210\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9732 - accuracy: 0.5284 - val_loss: 1.0041 - val_accuracy: 0.5224\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9730 - accuracy: 0.5297 - val_loss: 1.0044 - val_accuracy: 0.5219\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9729 - accuracy: 0.5279 - val_loss: 1.0041 - val_accuracy: 0.5224\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9729 - accuracy: 0.5303 - val_loss: 1.0042 - val_accuracy: 0.5210\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9728 - accuracy: 0.5271 - val_loss: 1.0042 - val_accuracy: 0.5224\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 596us/step - loss: 0.9729 - accuracy: 0.5294 - val_loss: 1.0039 - val_accuracy: 0.5246\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9731 - accuracy: 0.5305 - val_loss: 1.0044 - val_accuracy: 0.5219\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9728 - accuracy: 0.5287 - val_loss: 1.0039 - val_accuracy: 0.5219\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9728 - accuracy: 0.5282 - val_loss: 1.0043 - val_accuracy: 0.5219\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9729 - accuracy: 0.5294 - val_loss: 1.0041 - val_accuracy: 0.5224\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9728 - accuracy: 0.5291 - val_loss: 1.0041 - val_accuracy: 0.5219\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9729 - accuracy: 0.5280 - val_loss: 1.0039 - val_accuracy: 0.5228\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9728 - accuracy: 0.5286 - val_loss: 1.0041 - val_accuracy: 0.5219\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9730 - accuracy: 0.5281 - val_loss: 1.0043 - val_accuracy: 0.5224\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9727 - accuracy: 0.5287 - val_loss: 1.0039 - val_accuracy: 0.5215\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9727 - accuracy: 0.5289 - val_loss: 1.0040 - val_accuracy: 0.5224\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 664us/step - loss: 0.9729 - accuracy: 0.5274 - val_loss: 1.0040 - val_accuracy: 0.5224\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9730 - accuracy: 0.5278 - val_loss: 1.0041 - val_accuracy: 0.5219\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9727 - accuracy: 0.5292 - val_loss: 1.0041 - val_accuracy: 0.5219\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9728 - accuracy: 0.5305 - val_loss: 1.0043 - val_accuracy: 0.5224\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9732 - accuracy: 0.5288 - val_loss: 1.0037 - val_accuracy: 0.5215\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9729 - accuracy: 0.5298 - val_loss: 1.0038 - val_accuracy: 0.5224\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9728 - accuracy: 0.5282 - val_loss: 1.0038 - val_accuracy: 0.5224\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9728 - accuracy: 0.5301 - val_loss: 1.0043 - val_accuracy: 0.5219\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9729 - accuracy: 0.5287 - val_loss: 1.0042 - val_accuracy: 0.5215\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9728 - accuracy: 0.5292 - val_loss: 1.0045 - val_accuracy: 0.5228\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9727 - accuracy: 0.5274 - val_loss: 1.0042 - val_accuracy: 0.5224\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9727 - accuracy: 0.5284 - val_loss: 1.0042 - val_accuracy: 0.5224\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9727 - accuracy: 0.5285 - val_loss: 1.0042 - val_accuracy: 0.5228\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9730 - accuracy: 0.5295 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9726 - accuracy: 0.5285 - val_loss: 1.0048 - val_accuracy: 0.5215\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9730 - accuracy: 0.5298 - val_loss: 1.0042 - val_accuracy: 0.5215\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9730 - accuracy: 0.5301 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9727 - accuracy: 0.5295 - val_loss: 1.0043 - val_accuracy: 0.5219\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9729 - accuracy: 0.5294 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9729 - accuracy: 0.5288 - val_loss: 1.0046 - val_accuracy: 0.5224\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9727 - accuracy: 0.5286 - val_loss: 1.0040 - val_accuracy: 0.5215\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9728 - accuracy: 0.5303 - val_loss: 1.0041 - val_accuracy: 0.5224\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9727 - accuracy: 0.5291 - val_loss: 1.0042 - val_accuracy: 0.5224\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5287 - val_loss: 1.0043 - val_accuracy: 0.5219\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9726 - accuracy: 0.5286 - val_loss: 1.0044 - val_accuracy: 0.5219\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9727 - accuracy: 0.5282 - val_loss: 1.0042 - val_accuracy: 0.5215\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9728 - accuracy: 0.5296 - val_loss: 1.0041 - val_accuracy: 0.5219\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9728 - accuracy: 0.5278 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9728 - accuracy: 0.5292 - val_loss: 1.0042 - val_accuracy: 0.5228\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9728 - accuracy: 0.5275 - val_loss: 1.0041 - val_accuracy: 0.5224\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9727 - accuracy: 0.5287 - val_loss: 1.0041 - val_accuracy: 0.5219\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9727 - accuracy: 0.5286 - val_loss: 1.0040 - val_accuracy: 0.5232\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9727 - accuracy: 0.5278 - val_loss: 1.0040 - val_accuracy: 0.5224\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5287 - val_loss: 1.0039 - val_accuracy: 0.5224\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9728 - accuracy: 0.5289 - val_loss: 1.0041 - val_accuracy: 0.5215\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9726 - accuracy: 0.5283 - val_loss: 1.0039 - val_accuracy: 0.5241\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9734 - accuracy: 0.5304 - val_loss: 1.0047 - val_accuracy: 0.5219\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9733 - accuracy: 0.5279 - val_loss: 1.0050 - val_accuracy: 0.5219\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9728 - accuracy: 0.5278 - val_loss: 1.0044 - val_accuracy: 0.5232\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5300 - val_loss: 1.0043 - val_accuracy: 0.5232\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9729 - accuracy: 0.5277 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9729 - accuracy: 0.5271 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9728 - accuracy: 0.5281 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9726 - accuracy: 0.5282 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9730 - accuracy: 0.5298 - val_loss: 1.0041 - val_accuracy: 0.5224\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9726 - accuracy: 0.5277 - val_loss: 1.0041 - val_accuracy: 0.5219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9726 - accuracy: 0.5284 - val_loss: 1.0042 - val_accuracy: 0.5232\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9728 - accuracy: 0.5282 - val_loss: 1.0044 - val_accuracy: 0.5219\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9726 - accuracy: 0.5286 - val_loss: 1.0039 - val_accuracy: 0.5232\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5298 - val_loss: 1.0041 - val_accuracy: 0.5241\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9730 - accuracy: 0.5311 - val_loss: 1.0041 - val_accuracy: 0.5232\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9727 - accuracy: 0.5280 - val_loss: 1.0041 - val_accuracy: 0.5215\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9727 - accuracy: 0.5303 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9727 - accuracy: 0.5300 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9726 - accuracy: 0.5291 - val_loss: 1.0039 - val_accuracy: 0.5228\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9727 - accuracy: 0.5298 - val_loss: 1.0039 - val_accuracy: 0.5228\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9727 - accuracy: 0.5286 - val_loss: 1.0043 - val_accuracy: 0.5232\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9727 - accuracy: 0.5299 - val_loss: 1.0040 - val_accuracy: 0.5224\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9726 - accuracy: 0.5287 - val_loss: 1.0043 - val_accuracy: 0.5219\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 566us/step - loss: 0.9727 - accuracy: 0.5286 - val_loss: 1.0041 - val_accuracy: 0.5224\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9729 - accuracy: 0.5293 - val_loss: 1.0039 - val_accuracy: 0.5219\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9729 - accuracy: 0.5297 - val_loss: 1.0039 - val_accuracy: 0.5215\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9727 - accuracy: 0.5297 - val_loss: 1.0038 - val_accuracy: 0.5224\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9737 - accuracy: 0.5260 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9730 - accuracy: 0.5287 - val_loss: 1.0044 - val_accuracy: 0.5219\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9726 - accuracy: 0.5273 - val_loss: 1.0044 - val_accuracy: 0.5215\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9726 - accuracy: 0.5291 - val_loss: 1.0040 - val_accuracy: 0.5219\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9726 - accuracy: 0.5302 - val_loss: 1.0038 - val_accuracy: 0.5228\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9727 - accuracy: 0.5290 - val_loss: 1.0039 - val_accuracy: 0.5228\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9728 - accuracy: 0.5286 - val_loss: 1.0039 - val_accuracy: 0.5232\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9727 - accuracy: 0.5280 - val_loss: 1.0038 - val_accuracy: 0.5224\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9726 - accuracy: 0.5307 - val_loss: 1.0043 - val_accuracy: 0.5224\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9727 - accuracy: 0.5297 - val_loss: 1.0041 - val_accuracy: 0.5232\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9727 - accuracy: 0.5283 - val_loss: 1.0038 - val_accuracy: 0.5219\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9726 - accuracy: 0.5305 - val_loss: 1.0041 - val_accuracy: 0.5232\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9726 - accuracy: 0.5293 - val_loss: 1.0041 - val_accuracy: 0.5228\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9725 - accuracy: 0.5282 - val_loss: 1.0042 - val_accuracy: 0.5228\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9725 - accuracy: 0.5298 - val_loss: 1.0043 - val_accuracy: 0.5224\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9726 - accuracy: 0.5279 - val_loss: 1.0038 - val_accuracy: 0.5219\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5311 - val_loss: 1.0050 - val_accuracy: 0.5215\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9728 - accuracy: 0.5292 - val_loss: 1.0041 - val_accuracy: 0.5228\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 1.0043 - val_accuracy: 0.5219\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9726 - accuracy: 0.5310 - val_loss: 1.0041 - val_accuracy: 0.5224\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9725 - accuracy: 0.5301 - val_loss: 1.0037 - val_accuracy: 0.5228\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9726 - accuracy: 0.5286 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9727 - accuracy: 0.5293 - val_loss: 1.0038 - val_accuracy: 0.5228\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9725 - accuracy: 0.5296 - val_loss: 1.0039 - val_accuracy: 0.5241\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 1.0045 - val_accuracy: 0.5219\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9729 - accuracy: 0.5296 - val_loss: 1.0041 - val_accuracy: 0.5228\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9726 - accuracy: 0.5296 - val_loss: 1.0039 - val_accuracy: 0.5219\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9727 - accuracy: 0.5298 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9726 - accuracy: 0.5299 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9726 - accuracy: 0.5286 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9725 - accuracy: 0.5284 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9726 - accuracy: 0.5296 - val_loss: 1.0041 - val_accuracy: 0.5232\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9727 - accuracy: 0.5291 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9725 - accuracy: 0.5286 - val_loss: 1.0041 - val_accuracy: 0.5232\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9726 - accuracy: 0.5297 - val_loss: 1.0042 - val_accuracy: 0.5228\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9726 - accuracy: 0.5300 - val_loss: 1.0044 - val_accuracy: 0.5219\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9729 - accuracy: 0.5278 - val_loss: 1.0044 - val_accuracy: 0.5237\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9727 - accuracy: 0.5302 - val_loss: 1.0045 - val_accuracy: 0.5228\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 673us/step - loss: 0.9725 - accuracy: 0.5287 - val_loss: 1.0044 - val_accuracy: 0.5246\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 580us/step - loss: 0.9729 - accuracy: 0.5305 - val_loss: 1.0041 - val_accuracy: 0.5228\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9725 - accuracy: 0.5298 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9726 - accuracy: 0.5293 - val_loss: 1.0039 - val_accuracy: 0.5237\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9725 - accuracy: 0.5297 - val_loss: 1.0043 - val_accuracy: 0.5228\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9724 - accuracy: 0.5293 - val_loss: 1.0043 - val_accuracy: 0.5228\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9726 - accuracy: 0.5300 - val_loss: 1.0045 - val_accuracy: 0.5215\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9727 - accuracy: 0.5292 - val_loss: 1.0044 - val_accuracy: 0.5237\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 1.0045 - val_accuracy: 0.5228\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9727 - accuracy: 0.5307 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 1.0040 - val_accuracy: 0.5219\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9724 - accuracy: 0.5298 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9727 - accuracy: 0.5273 - val_loss: 1.0041 - val_accuracy: 0.5219\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9726 - accuracy: 0.5298 - val_loss: 1.0041 - val_accuracy: 0.5232\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9729 - accuracy: 0.5303 - val_loss: 1.0045 - val_accuracy: 0.5215\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9727 - accuracy: 0.5294 - val_loss: 1.0038 - val_accuracy: 0.5228\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9725 - accuracy: 0.5290 - val_loss: 1.0039 - val_accuracy: 0.5232\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9726 - accuracy: 0.5305 - val_loss: 1.0041 - val_accuracy: 0.5237\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9732 - accuracy: 0.5293 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9725 - accuracy: 0.5282 - val_loss: 1.0036 - val_accuracy: 0.5246\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9729 - accuracy: 0.5296 - val_loss: 1.0038 - val_accuracy: 0.5228\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9724 - accuracy: 0.5295 - val_loss: 1.0037 - val_accuracy: 0.5228\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9727 - accuracy: 0.5299 - val_loss: 1.0041 - val_accuracy: 0.5228\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9724 - accuracy: 0.5283 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9727 - accuracy: 0.5297 - val_loss: 1.0041 - val_accuracy: 0.5228\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9726 - accuracy: 0.5311 - val_loss: 1.0038 - val_accuracy: 0.5237\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9725 - accuracy: 0.5309 - val_loss: 1.0036 - val_accuracy: 0.5224\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9724 - accuracy: 0.5297 - val_loss: 1.0038 - val_accuracy: 0.5232\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9725 - accuracy: 0.5300 - val_loss: 1.0037 - val_accuracy: 0.5232\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9726 - accuracy: 0.5289 - val_loss: 1.0038 - val_accuracy: 0.5224\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9725 - accuracy: 0.5300 - val_loss: 1.0036 - val_accuracy: 0.5224\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9724 - accuracy: 0.5299 - val_loss: 1.0042 - val_accuracy: 0.5241\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9726 - accuracy: 0.5298 - val_loss: 1.0036 - val_accuracy: 0.5241\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9729 - accuracy: 0.5298 - val_loss: 1.0041 - val_accuracy: 0.5228\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9726 - accuracy: 0.5299 - val_loss: 1.0037 - val_accuracy: 0.5228\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9726 - accuracy: 0.5302 - val_loss: 1.0036 - val_accuracy: 0.5224\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9724 - accuracy: 0.5299 - val_loss: 1.0040 - val_accuracy: 0.5241\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9724 - accuracy: 0.5289 - val_loss: 1.0037 - val_accuracy: 0.5215\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 337us/step - loss: 0.9723 - accuracy: 0.5289\n",
      "Accuracy : 0.5288938879966736\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0037 - accuracy: 0.5215\n",
      "Accuracy : 0.5214696526527405\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0945 - accuracy: 0.2880 - val_loss: 1.0832 - val_accuracy: 0.2886\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 1.0770 - accuracy: 0.3654 - val_loss: 1.0730 - val_accuracy: 0.5060\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 1.0692 - accuracy: 0.5235 - val_loss: 1.0658 - val_accuracy: 0.5046\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 1.0589 - accuracy: 0.5238 - val_loss: 1.0544 - val_accuracy: 0.4993\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0426 - accuracy: 0.5203 - val_loss: 1.0382 - val_accuracy: 0.4940\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0188 - accuracy: 0.5215 - val_loss: 1.0212 - val_accuracy: 0.4989\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9992 - accuracy: 0.5249 - val_loss: 1.0114 - val_accuracy: 0.5069\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9896 - accuracy: 0.5284 - val_loss: 1.0076 - val_accuracy: 0.5100\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9845 - accuracy: 0.5291 - val_loss: 1.0054 - val_accuracy: 0.5126\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9825 - accuracy: 0.5306 - val_loss: 1.0043 - val_accuracy: 0.5148\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9815 - accuracy: 0.5303 - val_loss: 1.0038 - val_accuracy: 0.5113\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9805 - accuracy: 0.5279 - val_loss: 1.0032 - val_accuracy: 0.5122\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9794 - accuracy: 0.5283 - val_loss: 1.0027 - val_accuracy: 0.5108\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9790 - accuracy: 0.5294 - val_loss: 1.0023 - val_accuracy: 0.5131\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9782 - accuracy: 0.5288 - val_loss: 1.0022 - val_accuracy: 0.5131\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9778 - accuracy: 0.5297 - val_loss: 1.0019 - val_accuracy: 0.5144\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9781 - accuracy: 0.5304 - val_loss: 1.0018 - val_accuracy: 0.5108\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 596us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 1.0016 - val_accuracy: 0.5104\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9770 - accuracy: 0.5285 - val_loss: 1.0013 - val_accuracy: 0.5100\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9767 - accuracy: 0.5284 - val_loss: 1.0015 - val_accuracy: 0.5122\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 1.0013 - val_accuracy: 0.5122\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9762 - accuracy: 0.5288 - val_loss: 1.0010 - val_accuracy: 0.5104\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5284 - val_loss: 1.0009 - val_accuracy: 0.5104\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9759 - accuracy: 0.5283 - val_loss: 1.0010 - val_accuracy: 0.5122\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9759 - accuracy: 0.5285 - val_loss: 1.0008 - val_accuracy: 0.5104\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9757 - accuracy: 0.5289 - val_loss: 1.0010 - val_accuracy: 0.5117\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9757 - accuracy: 0.5286 - val_loss: 1.0006 - val_accuracy: 0.5104\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9755 - accuracy: 0.5288 - val_loss: 1.0006 - val_accuracy: 0.5104\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9751 - accuracy: 0.5287 - val_loss: 1.0008 - val_accuracy: 0.5113\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9755 - accuracy: 0.5289 - val_loss: 1.0005 - val_accuracy: 0.5104\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9749 - accuracy: 0.5293 - val_loss: 1.0006 - val_accuracy: 0.5113\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9750 - accuracy: 0.5289 - val_loss: 1.0010 - val_accuracy: 0.5104\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9751 - accuracy: 0.5289 - val_loss: 1.0005 - val_accuracy: 0.5113\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9749 - accuracy: 0.5299 - val_loss: 1.0004 - val_accuracy: 0.5139\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9747 - accuracy: 0.5299 - val_loss: 1.0009 - val_accuracy: 0.5108\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9748 - accuracy: 0.5289 - val_loss: 1.0004 - val_accuracy: 0.5104\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 1.0008 - val_accuracy: 0.5104\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9748 - accuracy: 0.5288 - val_loss: 1.0005 - val_accuracy: 0.5131\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9744 - accuracy: 0.5296 - val_loss: 1.0003 - val_accuracy: 0.5117\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9743 - accuracy: 0.5287 - val_loss: 1.0003 - val_accuracy: 0.5108\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9743 - accuracy: 0.5295 - val_loss: 1.0006 - val_accuracy: 0.5122\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9741 - accuracy: 0.5293 - val_loss: 1.0004 - val_accuracy: 0.5131\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9743 - accuracy: 0.5287 - val_loss: 1.0003 - val_accuracy: 0.5108\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9741 - accuracy: 0.5285 - val_loss: 1.0001 - val_accuracy: 0.5113\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9743 - accuracy: 0.5278 - val_loss: 1.0004 - val_accuracy: 0.5122\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9740 - accuracy: 0.5285 - val_loss: 1.0000 - val_accuracy: 0.5108\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9738 - accuracy: 0.5289 - val_loss: 0.9999 - val_accuracy: 0.5108\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9739 - accuracy: 0.5307 - val_loss: 1.0001 - val_accuracy: 0.5108\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9737 - accuracy: 0.5288 - val_loss: 1.0001 - val_accuracy: 0.5104\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9737 - accuracy: 0.5287 - val_loss: 0.9999 - val_accuracy: 0.5104\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9741 - accuracy: 0.5295 - val_loss: 0.9998 - val_accuracy: 0.5135\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9737 - accuracy: 0.5311 - val_loss: 1.0000 - val_accuracy: 0.5108\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 1.0000 - val_accuracy: 0.5104\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9736 - accuracy: 0.5295 - val_loss: 1.0001 - val_accuracy: 0.5104\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9736 - accuracy: 0.5290 - val_loss: 0.9999 - val_accuracy: 0.5135\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 1.0000 - val_accuracy: 0.5139\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9734 - accuracy: 0.5299 - val_loss: 1.0004 - val_accuracy: 0.5108\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9734 - accuracy: 0.5290 - val_loss: 1.0000 - val_accuracy: 0.5135\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9734 - accuracy: 0.5308 - val_loss: 1.0000 - val_accuracy: 0.5104\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9734 - accuracy: 0.5283 - val_loss: 1.0001 - val_accuracy: 0.5139\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9734 - accuracy: 0.5298 - val_loss: 0.9999 - val_accuracy: 0.5104\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9732 - accuracy: 0.5292 - val_loss: 1.0000 - val_accuracy: 0.5135\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9731 - accuracy: 0.5305 - val_loss: 1.0001 - val_accuracy: 0.5131\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9733 - accuracy: 0.5299 - val_loss: 1.0000 - val_accuracy: 0.5135\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9734 - accuracy: 0.5307 - val_loss: 1.0000 - val_accuracy: 0.5131\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9730 - accuracy: 0.5305 - val_loss: 1.0001 - val_accuracy: 0.5139\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9729 - accuracy: 0.5309 - val_loss: 1.0004 - val_accuracy: 0.5108\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9730 - accuracy: 0.5298 - val_loss: 1.0004 - val_accuracy: 0.5144\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9737 - accuracy: 0.5300 - val_loss: 1.0004 - val_accuracy: 0.5148\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9732 - accuracy: 0.5300 - val_loss: 1.0002 - val_accuracy: 0.5126\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9729 - accuracy: 0.5297 - val_loss: 0.9999 - val_accuracy: 0.5135\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9739 - accuracy: 0.5316 - val_loss: 1.0000 - val_accuracy: 0.5108\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9731 - accuracy: 0.5283 - val_loss: 1.0002 - val_accuracy: 0.5126\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9731 - accuracy: 0.5288 - val_loss: 0.9999 - val_accuracy: 0.5100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9731 - accuracy: 0.5286 - val_loss: 1.0001 - val_accuracy: 0.5108\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9728 - accuracy: 0.5287 - val_loss: 1.0001 - val_accuracy: 0.5104\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9729 - accuracy: 0.5290 - val_loss: 1.0000 - val_accuracy: 0.5135\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9730 - accuracy: 0.5295 - val_loss: 0.9999 - val_accuracy: 0.5135\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9734 - accuracy: 0.5318 - val_loss: 0.9999 - val_accuracy: 0.5131\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9729 - accuracy: 0.5294 - val_loss: 1.0000 - val_accuracy: 0.5122\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9728 - accuracy: 0.5286 - val_loss: 1.0002 - val_accuracy: 0.5126\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9728 - accuracy: 0.5289 - val_loss: 1.0001 - val_accuracy: 0.5104\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9727 - accuracy: 0.5296 - val_loss: 1.0001 - val_accuracy: 0.5144\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9727 - accuracy: 0.5308 - val_loss: 1.0002 - val_accuracy: 0.5100\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5294 - val_loss: 1.0002 - val_accuracy: 0.5144\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9727 - accuracy: 0.5288 - val_loss: 1.0001 - val_accuracy: 0.5131\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9727 - accuracy: 0.5312 - val_loss: 1.0001 - val_accuracy: 0.5144\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9726 - accuracy: 0.5312 - val_loss: 1.0000 - val_accuracy: 0.5144\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9729 - accuracy: 0.5304 - val_loss: 1.0001 - val_accuracy: 0.5144\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 1.0002 - val_accuracy: 0.5131\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9726 - accuracy: 0.5298 - val_loss: 1.0000 - val_accuracy: 0.5139\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9728 - accuracy: 0.5305 - val_loss: 1.0003 - val_accuracy: 0.5139\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9730 - accuracy: 0.5314 - val_loss: 1.0001 - val_accuracy: 0.5131\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9727 - accuracy: 0.5297 - val_loss: 1.0003 - val_accuracy: 0.5122\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9726 - accuracy: 0.5293 - val_loss: 1.0000 - val_accuracy: 0.5131\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9727 - accuracy: 0.5317 - val_loss: 1.0004 - val_accuracy: 0.5131\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9733 - accuracy: 0.5294 - val_loss: 1.0005 - val_accuracy: 0.5131\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 1.0003 - val_accuracy: 0.5144\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9725 - accuracy: 0.5305 - val_loss: 1.0002 - val_accuracy: 0.5144\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9725 - accuracy: 0.5301 - val_loss: 1.0003 - val_accuracy: 0.5139\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9726 - accuracy: 0.5304 - val_loss: 1.0003 - val_accuracy: 0.5144\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9724 - accuracy: 0.5294 - val_loss: 1.0003 - val_accuracy: 0.5144\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 1.0004 - val_accuracy: 0.5139\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9724 - accuracy: 0.5306 - val_loss: 1.0004 - val_accuracy: 0.5144\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9723 - accuracy: 0.5304 - val_loss: 1.0004 - val_accuracy: 0.5139\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 1.0003 - val_accuracy: 0.5144\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9726 - accuracy: 0.5292 - val_loss: 1.0002 - val_accuracy: 0.5148\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9724 - accuracy: 0.5296 - val_loss: 1.0002 - val_accuracy: 0.5144\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9723 - accuracy: 0.5310 - val_loss: 1.0006 - val_accuracy: 0.5144\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9722 - accuracy: 0.5304 - val_loss: 1.0003 - val_accuracy: 0.5135\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9723 - accuracy: 0.5314 - val_loss: 1.0004 - val_accuracy: 0.5139\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9723 - accuracy: 0.5313 - val_loss: 1.0007 - val_accuracy: 0.5139\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9726 - accuracy: 0.5315 - val_loss: 1.0004 - val_accuracy: 0.5144\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9722 - accuracy: 0.5298 - val_loss: 1.0004 - val_accuracy: 0.5139\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9722 - accuracy: 0.5307 - val_loss: 1.0003 - val_accuracy: 0.5131\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9724 - accuracy: 0.5293 - val_loss: 1.0004 - val_accuracy: 0.5139\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9723 - accuracy: 0.5295 - val_loss: 1.0003 - val_accuracy: 0.5139\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9727 - accuracy: 0.5313 - val_loss: 1.0002 - val_accuracy: 0.5139\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9722 - accuracy: 0.5292 - val_loss: 1.0004 - val_accuracy: 0.5131\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9728 - accuracy: 0.5287 - val_loss: 1.0008 - val_accuracy: 0.5108\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9722 - accuracy: 0.5303 - val_loss: 1.0007 - val_accuracy: 0.5139\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9731 - accuracy: 0.5310 - val_loss: 1.0005 - val_accuracy: 0.5139\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9723 - accuracy: 0.5301 - val_loss: 1.0004 - val_accuracy: 0.5139\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9722 - accuracy: 0.5307 - val_loss: 1.0006 - val_accuracy: 0.5148\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9722 - accuracy: 0.5302 - val_loss: 1.0003 - val_accuracy: 0.5139\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9722 - accuracy: 0.5316 - val_loss: 1.0004 - val_accuracy: 0.5144\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9722 - accuracy: 0.5295 - val_loss: 1.0007 - val_accuracy: 0.5144\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9721 - accuracy: 0.5298 - val_loss: 1.0006 - val_accuracy: 0.5139\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9722 - accuracy: 0.5311 - val_loss: 1.0005 - val_accuracy: 0.5139\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9721 - accuracy: 0.5299 - val_loss: 1.0006 - val_accuracy: 0.5139\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9721 - accuracy: 0.5324 - val_loss: 1.0006 - val_accuracy: 0.5139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9722 - accuracy: 0.5315 - val_loss: 1.0007 - val_accuracy: 0.5144\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9720 - accuracy: 0.5307 - val_loss: 1.0004 - val_accuracy: 0.5131\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9721 - accuracy: 0.5295 - val_loss: 1.0005 - val_accuracy: 0.5144\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9721 - accuracy: 0.5300 - val_loss: 1.0005 - val_accuracy: 0.5139\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9722 - accuracy: 0.5301 - val_loss: 1.0009 - val_accuracy: 0.5139\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9721 - accuracy: 0.5306 - val_loss: 1.0004 - val_accuracy: 0.5139\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9721 - accuracy: 0.5319 - val_loss: 1.0004 - val_accuracy: 0.5144\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9721 - accuracy: 0.5321 - val_loss: 1.0003 - val_accuracy: 0.5144\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9720 - accuracy: 0.5325 - val_loss: 1.0007 - val_accuracy: 0.5139\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9722 - accuracy: 0.5311 - val_loss: 1.0008 - val_accuracy: 0.5131\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9722 - accuracy: 0.5313 - val_loss: 1.0005 - val_accuracy: 0.5148\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9719 - accuracy: 0.5310 - val_loss: 1.0008 - val_accuracy: 0.5139\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9721 - accuracy: 0.5307 - val_loss: 1.0006 - val_accuracy: 0.5139\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9722 - accuracy: 0.5315 - val_loss: 1.0005 - val_accuracy: 0.5139\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9722 - accuracy: 0.5294 - val_loss: 1.0005 - val_accuracy: 0.5139\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9719 - accuracy: 0.5304 - val_loss: 1.0007 - val_accuracy: 0.5139\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9721 - accuracy: 0.5294 - val_loss: 1.0008 - val_accuracy: 0.5144\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9720 - accuracy: 0.5298 - val_loss: 1.0006 - val_accuracy: 0.5139\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9719 - accuracy: 0.5303 - val_loss: 1.0006 - val_accuracy: 0.5131\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9720 - accuracy: 0.5303 - val_loss: 1.0007 - val_accuracy: 0.5139\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9721 - accuracy: 0.5303 - val_loss: 1.0006 - val_accuracy: 0.5139\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9719 - accuracy: 0.5316 - val_loss: 1.0008 - val_accuracy: 0.5139\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9721 - accuracy: 0.5308 - val_loss: 1.0008 - val_accuracy: 0.5135\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9721 - accuracy: 0.5303 - val_loss: 1.0007 - val_accuracy: 0.5139\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9721 - accuracy: 0.5301 - val_loss: 1.0008 - val_accuracy: 0.5135\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9724 - accuracy: 0.5319 - val_loss: 1.0007 - val_accuracy: 0.5139\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9719 - accuracy: 0.5301 - val_loss: 1.0006 - val_accuracy: 0.5139\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9722 - accuracy: 0.5317 - val_loss: 1.0007 - val_accuracy: 0.5139\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9722 - accuracy: 0.5318 - val_loss: 1.0006 - val_accuracy: 0.5126\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9724 - accuracy: 0.5316 - val_loss: 1.0006 - val_accuracy: 0.5135\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9719 - accuracy: 0.5301 - val_loss: 1.0008 - val_accuracy: 0.5139\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9718 - accuracy: 0.5302 - val_loss: 1.0009 - val_accuracy: 0.5139\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9719 - accuracy: 0.5299 - val_loss: 1.0008 - val_accuracy: 0.5148\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 1.0009 - val_accuracy: 0.5139\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9718 - accuracy: 0.5309 - val_loss: 1.0008 - val_accuracy: 0.5139\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9720 - accuracy: 0.5315 - val_loss: 1.0008 - val_accuracy: 0.5144\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9718 - accuracy: 0.5303 - val_loss: 1.0007 - val_accuracy: 0.5135\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9718 - accuracy: 0.5299 - val_loss: 1.0010 - val_accuracy: 0.5139\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9717 - accuracy: 0.5306 - val_loss: 1.0010 - val_accuracy: 0.5139\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9719 - accuracy: 0.5308 - val_loss: 1.0008 - val_accuracy: 0.5135\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9718 - accuracy: 0.5293 - val_loss: 1.0009 - val_accuracy: 0.5135\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9718 - accuracy: 0.5300 - val_loss: 1.0008 - val_accuracy: 0.5139\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9718 - accuracy: 0.5307 - val_loss: 1.0011 - val_accuracy: 0.5144\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9719 - accuracy: 0.5306 - val_loss: 1.0009 - val_accuracy: 0.5139\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9718 - accuracy: 0.5303 - val_loss: 1.0007 - val_accuracy: 0.5135\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9720 - accuracy: 0.5297 - val_loss: 1.0008 - val_accuracy: 0.5139\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9718 - accuracy: 0.5290 - val_loss: 1.0007 - val_accuracy: 0.5135\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9718 - accuracy: 0.5310 - val_loss: 1.0010 - val_accuracy: 0.5139\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9718 - accuracy: 0.5316 - val_loss: 1.0010 - val_accuracy: 0.5135\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9720 - accuracy: 0.5315 - val_loss: 1.0008 - val_accuracy: 0.5139\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9717 - accuracy: 0.5306 - val_loss: 1.0009 - val_accuracy: 0.5139\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9719 - accuracy: 0.5308 - val_loss: 1.0010 - val_accuracy: 0.5144\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9719 - accuracy: 0.5310 - val_loss: 1.0008 - val_accuracy: 0.5135\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9718 - accuracy: 0.5307 - val_loss: 1.0012 - val_accuracy: 0.5135\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9718 - accuracy: 0.5301 - val_loss: 1.0016 - val_accuracy: 0.5148\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9719 - accuracy: 0.5282 - val_loss: 1.0010 - val_accuracy: 0.5135\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 579us/step - loss: 0.9716 - accuracy: 0.5301 - val_loss: 1.0007 - val_accuracy: 0.5139\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9717 - accuracy: 0.5315 - val_loss: 1.0011 - val_accuracy: 0.5144\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9718 - accuracy: 0.5298 - val_loss: 1.0010 - val_accuracy: 0.5139\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9717 - accuracy: 0.5305 - val_loss: 1.0010 - val_accuracy: 0.5135\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9718 - accuracy: 0.5302 - val_loss: 1.0010 - val_accuracy: 0.5144\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9723 - accuracy: 0.5311 - val_loss: 1.0014 - val_accuracy: 0.5139\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9720 - accuracy: 0.5307 - val_loss: 1.0013 - val_accuracy: 0.5139\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9719 - accuracy: 0.5299 - val_loss: 1.0011 - val_accuracy: 0.5135\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9718 - accuracy: 0.5307 - val_loss: 1.0015 - val_accuracy: 0.5135\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9718 - accuracy: 0.5301 - val_loss: 1.0011 - val_accuracy: 0.5139\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9719 - accuracy: 0.5306 - val_loss: 1.0011 - val_accuracy: 0.5135\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 1.0010 - val_accuracy: 0.5139\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9717 - accuracy: 0.5293 - val_loss: 1.0010 - val_accuracy: 0.5144\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 335us/step - loss: 0.9715 - accuracy: 0.5312\n",
      "Accuracy : 0.5311562418937683\n",
      "\n",
      "Test split:\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "71/71 - 0s - loss: 1.0010 - accuracy: 0.5144\n",
      "Accuracy : 0.5143868923187256\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.9203 - accuracy: 0.2530 - val_loss: 1.6826 - val_accuracy: 0.2519\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 748us/step - loss: 1.5609 - accuracy: 0.2508 - val_loss: 1.4197 - val_accuracy: 0.2435\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.3659 - accuracy: 0.2206 - val_loss: 1.2970 - val_accuracy: 0.2244\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.2771 - accuracy: 0.2157 - val_loss: 1.2408 - val_accuracy: 0.2231\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.2275 - accuracy: 0.2216 - val_loss: 1.2038 - val_accuracy: 0.2293\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 1.1909 - accuracy: 0.2294 - val_loss: 1.1751 - val_accuracy: 0.2359\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.1633 - accuracy: 0.2373 - val_loss: 1.1526 - val_accuracy: 0.2510\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 1.1425 - accuracy: 0.2494 - val_loss: 1.1354 - val_accuracy: 0.2585\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.1268 - accuracy: 0.2608 - val_loss: 1.1220 - val_accuracy: 0.2687\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 1.1147 - accuracy: 0.2756 - val_loss: 1.1114 - val_accuracy: 0.2807\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.1054 - accuracy: 0.2862 - val_loss: 1.1028 - val_accuracy: 0.2877\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0981 - accuracy: 0.2880 - val_loss: 1.0961 - val_accuracy: 0.2877\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 1.0917 - accuracy: 0.2879 - val_loss: 1.0899 - val_accuracy: 0.2895\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0861 - accuracy: 0.2878 - val_loss: 1.0840 - val_accuracy: 0.2895\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 1.0805 - accuracy: 0.2983 - val_loss: 1.0780 - val_accuracy: 0.3723\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 1.0746 - accuracy: 0.4884 - val_loss: 1.0714 - val_accuracy: 0.5038\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 685us/step - loss: 1.0685 - accuracy: 0.5226 - val_loss: 1.0644 - val_accuracy: 0.5272\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 1.0609 - accuracy: 0.5254 - val_loss: 1.0554 - val_accuracy: 0.5179\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 1.0506 - accuracy: 0.5227 - val_loss: 1.0440 - val_accuracy: 0.5175\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 1.0381 - accuracy: 0.5232 - val_loss: 1.0307 - val_accuracy: 0.5162\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0218 - accuracy: 0.5193 - val_loss: 1.0161 - val_accuracy: 0.5170\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 742us/step - loss: 1.0066 - accuracy: 0.5231 - val_loss: 1.0055 - val_accuracy: 0.5166\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9958 - accuracy: 0.5242 - val_loss: 0.9984 - val_accuracy: 0.5197\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9888 - accuracy: 0.5280 - val_loss: 0.9945 - val_accuracy: 0.5206\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9857 - accuracy: 0.5291 - val_loss: 0.9930 - val_accuracy: 0.5219\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9833 - accuracy: 0.5287 - val_loss: 0.9916 - val_accuracy: 0.5224\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9816 - accuracy: 0.5309 - val_loss: 0.9911 - val_accuracy: 0.5219\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9803 - accuracy: 0.5300 - val_loss: 0.9903 - val_accuracy: 0.5250\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9795 - accuracy: 0.5309 - val_loss: 0.9900 - val_accuracy: 0.5224\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9788 - accuracy: 0.5300 - val_loss: 0.9896 - val_accuracy: 0.5241\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9782 - accuracy: 0.5303 - val_loss: 0.9890 - val_accuracy: 0.5259\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9777 - accuracy: 0.5303 - val_loss: 0.9886 - val_accuracy: 0.5246\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9774 - accuracy: 0.5303 - val_loss: 0.9884 - val_accuracy: 0.5219\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9768 - accuracy: 0.5296 - val_loss: 0.9880 - val_accuracy: 0.5246\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9764 - accuracy: 0.5309 - val_loss: 0.9881 - val_accuracy: 0.5219\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9760 - accuracy: 0.5303 - val_loss: 0.9877 - val_accuracy: 0.5259\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9876 - val_accuracy: 0.5237\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 0.9878 - val_accuracy: 0.5219\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9755 - accuracy: 0.5305 - val_loss: 0.9876 - val_accuracy: 0.5224\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9756 - accuracy: 0.5306 - val_loss: 0.9875 - val_accuracy: 0.5224\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9752 - accuracy: 0.5306 - val_loss: 0.9874 - val_accuracy: 0.5237\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 583us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9875 - val_accuracy: 0.5259\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9752 - accuracy: 0.5302 - val_loss: 0.9874 - val_accuracy: 0.5259\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9747 - accuracy: 0.5312 - val_loss: 0.9876 - val_accuracy: 0.5241\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9873 - val_accuracy: 0.5241\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9752 - accuracy: 0.5314 - val_loss: 0.9873 - val_accuracy: 0.5259\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9747 - accuracy: 0.5296 - val_loss: 0.9873 - val_accuracy: 0.5246\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9745 - accuracy: 0.5304 - val_loss: 0.9875 - val_accuracy: 0.5219\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9747 - accuracy: 0.5311 - val_loss: 0.9872 - val_accuracy: 0.5246\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9746 - accuracy: 0.5307 - val_loss: 0.9872 - val_accuracy: 0.5246\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9748 - accuracy: 0.5308 - val_loss: 0.9873 - val_accuracy: 0.5259\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9745 - accuracy: 0.5306 - val_loss: 0.9873 - val_accuracy: 0.5210\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9745 - accuracy: 0.5307 - val_loss: 0.9874 - val_accuracy: 0.5237\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9746 - accuracy: 0.5307 - val_loss: 0.9873 - val_accuracy: 0.5241\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9747 - accuracy: 0.5318 - val_loss: 0.9874 - val_accuracy: 0.5219\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9746 - accuracy: 0.5303 - val_loss: 0.9872 - val_accuracy: 0.5255\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9743 - accuracy: 0.5303 - val_loss: 0.9873 - val_accuracy: 0.5250\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9747 - accuracy: 0.5316 - val_loss: 0.9873 - val_accuracy: 0.5259\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9746 - accuracy: 0.5307 - val_loss: 0.9873 - val_accuracy: 0.5259\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9744 - accuracy: 0.5305 - val_loss: 0.9876 - val_accuracy: 0.5219\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9761 - accuracy: 0.5283 - val_loss: 0.9879 - val_accuracy: 0.5259\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9747 - accuracy: 0.5306 - val_loss: 0.9877 - val_accuracy: 0.5246\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9746 - accuracy: 0.5298 - val_loss: 0.9876 - val_accuracy: 0.5219\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9747 - accuracy: 0.5292 - val_loss: 0.9873 - val_accuracy: 0.5241\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9746 - accuracy: 0.5318 - val_loss: 0.9876 - val_accuracy: 0.5219\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9746 - accuracy: 0.5311 - val_loss: 0.9875 - val_accuracy: 0.5215\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9746 - accuracy: 0.5313 - val_loss: 0.9875 - val_accuracy: 0.5250\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9744 - accuracy: 0.5302 - val_loss: 0.9875 - val_accuracy: 0.5246\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9745 - accuracy: 0.5322 - val_loss: 0.9874 - val_accuracy: 0.5255\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9744 - accuracy: 0.5300 - val_loss: 0.9876 - val_accuracy: 0.5219\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9745 - accuracy: 0.5288 - val_loss: 0.9873 - val_accuracy: 0.5259\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9746 - accuracy: 0.5321 - val_loss: 0.9874 - val_accuracy: 0.5197\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9746 - accuracy: 0.5322 - val_loss: 0.9874 - val_accuracy: 0.5255\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9745 - accuracy: 0.5309 - val_loss: 0.9875 - val_accuracy: 0.5219\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9744 - accuracy: 0.5304 - val_loss: 0.9875 - val_accuracy: 0.5197\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9748 - accuracy: 0.5304 - val_loss: 0.9874 - val_accuracy: 0.5241\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9742 - accuracy: 0.5303 - val_loss: 0.9875 - val_accuracy: 0.5237\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9744 - accuracy: 0.5303 - val_loss: 0.9877 - val_accuracy: 0.5255\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9745 - accuracy: 0.5321 - val_loss: 0.9876 - val_accuracy: 0.5237\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9743 - accuracy: 0.5304 - val_loss: 0.9876 - val_accuracy: 0.5246\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9745 - accuracy: 0.5312 - val_loss: 0.9876 - val_accuracy: 0.5241\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9745 - accuracy: 0.5309 - val_loss: 0.9875 - val_accuracy: 0.5241\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9742 - accuracy: 0.5311 - val_loss: 0.9876 - val_accuracy: 0.5237\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9744 - accuracy: 0.5306 - val_loss: 0.9876 - val_accuracy: 0.5241\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9745 - accuracy: 0.5303 - val_loss: 0.9875 - val_accuracy: 0.5259\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9743 - accuracy: 0.5311 - val_loss: 0.9875 - val_accuracy: 0.5259\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9743 - accuracy: 0.5301 - val_loss: 0.9878 - val_accuracy: 0.5201\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9747 - accuracy: 0.5322 - val_loss: 0.9878 - val_accuracy: 0.5224\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9877 - val_accuracy: 0.5255\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9749 - accuracy: 0.5306 - val_loss: 0.9876 - val_accuracy: 0.5259\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9743 - accuracy: 0.5304 - val_loss: 0.9876 - val_accuracy: 0.5259\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9745 - accuracy: 0.5302 - val_loss: 0.9876 - val_accuracy: 0.5219\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9744 - accuracy: 0.5300 - val_loss: 0.9876 - val_accuracy: 0.5259\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9744 - accuracy: 0.5308 - val_loss: 0.9875 - val_accuracy: 0.5246\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 0.9875 - val_accuracy: 0.5259\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9745 - accuracy: 0.5302 - val_loss: 0.9875 - val_accuracy: 0.5246\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9743 - accuracy: 0.5307 - val_loss: 0.9878 - val_accuracy: 0.5241\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9748 - accuracy: 0.5305 - val_loss: 0.9876 - val_accuracy: 0.5259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9752 - accuracy: 0.5311 - val_loss: 0.9873 - val_accuracy: 0.5219\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9745 - accuracy: 0.5301 - val_loss: 0.9873 - val_accuracy: 0.5246\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9745 - accuracy: 0.5305 - val_loss: 0.9873 - val_accuracy: 0.5215\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9743 - accuracy: 0.5303 - val_loss: 0.9874 - val_accuracy: 0.5219\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9873 - val_accuracy: 0.5255\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9744 - accuracy: 0.5308 - val_loss: 0.9875 - val_accuracy: 0.5241\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9743 - accuracy: 0.5303 - val_loss: 0.9874 - val_accuracy: 0.5259\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9747 - accuracy: 0.5309 - val_loss: 0.9874 - val_accuracy: 0.5237\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9747 - accuracy: 0.5308 - val_loss: 0.9875 - val_accuracy: 0.5255\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9744 - accuracy: 0.5300 - val_loss: 0.9873 - val_accuracy: 0.5259\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9742 - accuracy: 0.5300 - val_loss: 0.9874 - val_accuracy: 0.5224\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9744 - accuracy: 0.5303 - val_loss: 0.9874 - val_accuracy: 0.5246\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9742 - accuracy: 0.5287 - val_loss: 0.9873 - val_accuracy: 0.5255\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9746 - accuracy: 0.5312 - val_loss: 0.9874 - val_accuracy: 0.5201\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9745 - accuracy: 0.5313 - val_loss: 0.9874 - val_accuracy: 0.5241\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9741 - accuracy: 0.5312 - val_loss: 0.9877 - val_accuracy: 0.5224\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9744 - accuracy: 0.5303 - val_loss: 0.9874 - val_accuracy: 0.5255\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9742 - accuracy: 0.5311 - val_loss: 0.9875 - val_accuracy: 0.5219\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9743 - accuracy: 0.5304 - val_loss: 0.9874 - val_accuracy: 0.5250\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9741 - accuracy: 0.5298 - val_loss: 0.9875 - val_accuracy: 0.5255\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9743 - accuracy: 0.5314 - val_loss: 0.9879 - val_accuracy: 0.5219\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9743 - accuracy: 0.5282 - val_loss: 0.9874 - val_accuracy: 0.5241\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9743 - accuracy: 0.5306 - val_loss: 0.9874 - val_accuracy: 0.5259\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9748 - accuracy: 0.5293 - val_loss: 0.9874 - val_accuracy: 0.5241\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9746 - accuracy: 0.5297 - val_loss: 0.9877 - val_accuracy: 0.5224\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9743 - accuracy: 0.5303 - val_loss: 0.9878 - val_accuracy: 0.5219\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9743 - accuracy: 0.5302 - val_loss: 0.9878 - val_accuracy: 0.5219\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9742 - accuracy: 0.5292 - val_loss: 0.9875 - val_accuracy: 0.5250\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9741 - accuracy: 0.5293 - val_loss: 0.9875 - val_accuracy: 0.5246\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9745 - accuracy: 0.5311 - val_loss: 0.9875 - val_accuracy: 0.5255\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9741 - accuracy: 0.5304 - val_loss: 0.9875 - val_accuracy: 0.5259\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9743 - accuracy: 0.5301 - val_loss: 0.9876 - val_accuracy: 0.5241\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9744 - accuracy: 0.5305 - val_loss: 0.9874 - val_accuracy: 0.5241\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9742 - accuracy: 0.5310 - val_loss: 0.9875 - val_accuracy: 0.5224\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9741 - accuracy: 0.5310 - val_loss: 0.9878 - val_accuracy: 0.5219\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9746 - accuracy: 0.5297 - val_loss: 0.9875 - val_accuracy: 0.5237\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9745 - accuracy: 0.5301 - val_loss: 0.9874 - val_accuracy: 0.5255\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9742 - accuracy: 0.5304 - val_loss: 0.9874 - val_accuracy: 0.5250\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9742 - accuracy: 0.5308 - val_loss: 0.9875 - val_accuracy: 0.5237\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9743 - accuracy: 0.5306 - val_loss: 0.9875 - val_accuracy: 0.5224\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9742 - accuracy: 0.5309 - val_loss: 0.9880 - val_accuracy: 0.5219\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9743 - accuracy: 0.5306 - val_loss: 0.9878 - val_accuracy: 0.5219\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9743 - accuracy: 0.5298 - val_loss: 0.9875 - val_accuracy: 0.5259\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 0.9877 - val_accuracy: 0.5219\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9743 - accuracy: 0.5303 - val_loss: 0.9878 - val_accuracy: 0.5219\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9745 - accuracy: 0.5307 - val_loss: 0.9876 - val_accuracy: 0.5219\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9743 - accuracy: 0.5299 - val_loss: 0.9876 - val_accuracy: 0.5237\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9742 - accuracy: 0.5297 - val_loss: 0.9875 - val_accuracy: 0.5197\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9745 - accuracy: 0.5314 - val_loss: 0.9875 - val_accuracy: 0.5224\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9743 - accuracy: 0.5295 - val_loss: 0.9874 - val_accuracy: 0.5259\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9873 - val_accuracy: 0.5241\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9744 - accuracy: 0.5310 - val_loss: 0.9874 - val_accuracy: 0.5250\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9742 - accuracy: 0.5306 - val_loss: 0.9876 - val_accuracy: 0.5224\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9744 - accuracy: 0.5304 - val_loss: 0.9875 - val_accuracy: 0.5255\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 0.9875 - val_accuracy: 0.5224\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9741 - accuracy: 0.5299 - val_loss: 0.9875 - val_accuracy: 0.5237\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 605us/step - loss: 0.9740 - accuracy: 0.5296 - val_loss: 0.9875 - val_accuracy: 0.5197\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9744 - accuracy: 0.5314 - val_loss: 0.9875 - val_accuracy: 0.5197\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9743 - accuracy: 0.5307 - val_loss: 0.9876 - val_accuracy: 0.5224\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9743 - accuracy: 0.5308 - val_loss: 0.9875 - val_accuracy: 0.5255\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9741 - accuracy: 0.5297 - val_loss: 0.9876 - val_accuracy: 0.5241\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9741 - accuracy: 0.5310 - val_loss: 0.9874 - val_accuracy: 0.5250\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9741 - accuracy: 0.5313 - val_loss: 0.9875 - val_accuracy: 0.5224\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9875 - val_accuracy: 0.5232\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9742 - accuracy: 0.5308 - val_loss: 0.9876 - val_accuracy: 0.5241\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9741 - accuracy: 0.5298 - val_loss: 0.9875 - val_accuracy: 0.5197\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9743 - accuracy: 0.5313 - val_loss: 0.9875 - val_accuracy: 0.5241\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9740 - accuracy: 0.5307 - val_loss: 0.9877 - val_accuracy: 0.5219\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9742 - accuracy: 0.5303 - val_loss: 0.9877 - val_accuracy: 0.5210\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9742 - accuracy: 0.5309 - val_loss: 0.9876 - val_accuracy: 0.5250\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9745 - accuracy: 0.5317 - val_loss: 0.9875 - val_accuracy: 0.5255\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9744 - accuracy: 0.5316 - val_loss: 0.9877 - val_accuracy: 0.5241\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9744 - accuracy: 0.5301 - val_loss: 0.9874 - val_accuracy: 0.5241\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9744 - accuracy: 0.5305 - val_loss: 0.9877 - val_accuracy: 0.5255\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9741 - accuracy: 0.5306 - val_loss: 0.9876 - val_accuracy: 0.5241\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9741 - accuracy: 0.5308 - val_loss: 0.9875 - val_accuracy: 0.5272\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9741 - accuracy: 0.5293 - val_loss: 0.9875 - val_accuracy: 0.5272\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9740 - accuracy: 0.5305 - val_loss: 0.9876 - val_accuracy: 0.5237\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9742 - accuracy: 0.5297 - val_loss: 0.9875 - val_accuracy: 0.5272\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9743 - accuracy: 0.5299 - val_loss: 0.9875 - val_accuracy: 0.5250\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9740 - accuracy: 0.5299 - val_loss: 0.9876 - val_accuracy: 0.5250\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9875 - val_accuracy: 0.5255\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9745 - accuracy: 0.5298 - val_loss: 0.9877 - val_accuracy: 0.5237\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9741 - accuracy: 0.5304 - val_loss: 0.9876 - val_accuracy: 0.5272\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9742 - accuracy: 0.5306 - val_loss: 0.9878 - val_accuracy: 0.5232\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9741 - accuracy: 0.5315 - val_loss: 0.9881 - val_accuracy: 0.5232\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9740 - accuracy: 0.5304 - val_loss: 0.9876 - val_accuracy: 0.5255\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9741 - accuracy: 0.5303 - val_loss: 0.9876 - val_accuracy: 0.5272\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9743 - accuracy: 0.5309 - val_loss: 0.9877 - val_accuracy: 0.5237\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9743 - accuracy: 0.5285 - val_loss: 0.9877 - val_accuracy: 0.5246\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9742 - accuracy: 0.5308 - val_loss: 0.9877 - val_accuracy: 0.5255\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9743 - accuracy: 0.5299 - val_loss: 0.9876 - val_accuracy: 0.5232\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9875 - val_accuracy: 0.5255\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 0.9878 - val_accuracy: 0.5237\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9746 - accuracy: 0.5291 - val_loss: 0.9878 - val_accuracy: 0.5232\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9741 - accuracy: 0.5288 - val_loss: 0.9874 - val_accuracy: 0.5259\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9741 - accuracy: 0.5297 - val_loss: 0.9874 - val_accuracy: 0.5263\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9741 - accuracy: 0.5302 - val_loss: 0.9874 - val_accuracy: 0.5272\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9741 - accuracy: 0.5289 - val_loss: 0.9875 - val_accuracy: 0.5241\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9745 - accuracy: 0.5317 - val_loss: 0.9875 - val_accuracy: 0.5255\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9742 - accuracy: 0.5288 - val_loss: 0.9876 - val_accuracy: 0.5237\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9741 - accuracy: 0.5298 - val_loss: 0.9875 - val_accuracy: 0.5259\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 333us/step - loss: 0.9738 - accuracy: 0.5304\n",
      "Accuracy : 0.5304185152053833\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9875 - accuracy: 0.5259\n",
      "Accuracy : 0.525896430015564\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.9235 - accuracy: 0.3243 - val_loss: 1.7161 - val_accuracy: 0.4263\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.5720 - accuracy: 0.4518 - val_loss: 1.4386 - val_accuracy: 0.4564\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.3316 - accuracy: 0.4633 - val_loss: 1.2564 - val_accuracy: 0.4622\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.2009 - accuracy: 0.4561 - val_loss: 1.1714 - val_accuracy: 0.4626\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.1356 - accuracy: 0.4567 - val_loss: 1.1233 - val_accuracy: 0.4608\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 1.0937 - accuracy: 0.4622 - val_loss: 1.0900 - val_accuracy: 0.4608\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0637 - accuracy: 0.4641 - val_loss: 1.0661 - val_accuracy: 0.4617\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 1.0428 - accuracy: 0.4621 - val_loss: 1.0487 - val_accuracy: 0.4613\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0277 - accuracy: 0.4635 - val_loss: 1.0352 - val_accuracy: 0.4595\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 613us/step - loss: 1.0159 - accuracy: 0.4641 - val_loss: 1.0237 - val_accuracy: 0.4577\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 1.0062 - accuracy: 0.4747 - val_loss: 1.0140 - val_accuracy: 0.4732\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9978 - accuracy: 0.5021 - val_loss: 1.0054 - val_accuracy: 0.5188\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9916 - accuracy: 0.5176 - val_loss: 0.9985 - val_accuracy: 0.5330\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9868 - accuracy: 0.5224 - val_loss: 0.9930 - val_accuracy: 0.5343\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9833 - accuracy: 0.5246 - val_loss: 0.9889 - val_accuracy: 0.5370\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9807 - accuracy: 0.5250 - val_loss: 0.9861 - val_accuracy: 0.5339\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5246 - val_loss: 0.9841 - val_accuracy: 0.5330\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9787 - accuracy: 0.5248 - val_loss: 0.9827 - val_accuracy: 0.5343\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9781 - accuracy: 0.5252 - val_loss: 0.9819 - val_accuracy: 0.5347\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9780 - accuracy: 0.5256 - val_loss: 0.9812 - val_accuracy: 0.5343\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9779 - accuracy: 0.5250 - val_loss: 0.9808 - val_accuracy: 0.5356\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9776 - accuracy: 0.5258 - val_loss: 0.9804 - val_accuracy: 0.5356\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9776 - accuracy: 0.5271 - val_loss: 0.9800 - val_accuracy: 0.5352\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5256 - val_loss: 0.9798 - val_accuracy: 0.5365\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5257 - val_loss: 0.9796 - val_accuracy: 0.5343\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9776 - accuracy: 0.5266 - val_loss: 0.9795 - val_accuracy: 0.5356\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5258 - val_loss: 0.9797 - val_accuracy: 0.5361\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9774 - accuracy: 0.5261 - val_loss: 0.9795 - val_accuracy: 0.5361\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9773 - accuracy: 0.5259 - val_loss: 0.9797 - val_accuracy: 0.5356\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9780 - accuracy: 0.5262 - val_loss: 0.9794 - val_accuracy: 0.5356\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9779 - accuracy: 0.5270 - val_loss: 0.9796 - val_accuracy: 0.5365\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5260 - val_loss: 0.9797 - val_accuracy: 0.5356\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9776 - accuracy: 0.5266 - val_loss: 0.9795 - val_accuracy: 0.5361\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5255 - val_loss: 0.9793 - val_accuracy: 0.5365\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9772 - accuracy: 0.5262 - val_loss: 0.9790 - val_accuracy: 0.5361\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5250 - val_loss: 0.9793 - val_accuracy: 0.5356\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9775 - accuracy: 0.5256 - val_loss: 0.9790 - val_accuracy: 0.5365\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9774 - accuracy: 0.5271 - val_loss: 0.9791 - val_accuracy: 0.5356\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9775 - accuracy: 0.5259 - val_loss: 0.9790 - val_accuracy: 0.5365\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9773 - accuracy: 0.5262 - val_loss: 0.9791 - val_accuracy: 0.5356\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9773 - accuracy: 0.5262 - val_loss: 0.9789 - val_accuracy: 0.5365\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9775 - accuracy: 0.5265 - val_loss: 0.9791 - val_accuracy: 0.5365\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9791 - val_accuracy: 0.5361\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5263 - val_loss: 0.9791 - val_accuracy: 0.5361\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5261 - val_loss: 0.9790 - val_accuracy: 0.5365\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5259 - val_loss: 0.9788 - val_accuracy: 0.5365\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9773 - accuracy: 0.5264 - val_loss: 0.9788 - val_accuracy: 0.5365\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9779 - accuracy: 0.5271 - val_loss: 0.9786 - val_accuracy: 0.5361\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5253 - val_loss: 0.9790 - val_accuracy: 0.5365\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5268 - val_loss: 0.9786 - val_accuracy: 0.5361\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9772 - accuracy: 0.5253 - val_loss: 0.9791 - val_accuracy: 0.5361\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9772 - accuracy: 0.5267 - val_loss: 0.9788 - val_accuracy: 0.5361\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9772 - accuracy: 0.5258 - val_loss: 0.9793 - val_accuracy: 0.5365\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9772 - accuracy: 0.5267 - val_loss: 0.9786 - val_accuracy: 0.5370\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9771 - accuracy: 0.5264 - val_loss: 0.9783 - val_accuracy: 0.5356\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5262 - val_loss: 0.9785 - val_accuracy: 0.5365\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9781 - accuracy: 0.5268 - val_loss: 0.9783 - val_accuracy: 0.5370\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9771 - accuracy: 0.5256 - val_loss: 0.9782 - val_accuracy: 0.5365\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9769 - accuracy: 0.5276 - val_loss: 0.9781 - val_accuracy: 0.5365\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5262 - val_loss: 0.9782 - val_accuracy: 0.5361\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9775 - accuracy: 0.5264 - val_loss: 0.9783 - val_accuracy: 0.5365\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9771 - accuracy: 0.5267 - val_loss: 0.9782 - val_accuracy: 0.5347\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5266 - val_loss: 0.9783 - val_accuracy: 0.5356\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9771 - accuracy: 0.5261 - val_loss: 0.9786 - val_accuracy: 0.5347\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5257 - val_loss: 0.9784 - val_accuracy: 0.5365\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9771 - accuracy: 0.5268 - val_loss: 0.9784 - val_accuracy: 0.5361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5261 - val_loss: 0.9785 - val_accuracy: 0.5356\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9771 - accuracy: 0.5256 - val_loss: 0.9783 - val_accuracy: 0.5347\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9771 - accuracy: 0.5259 - val_loss: 0.9788 - val_accuracy: 0.5370\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9770 - accuracy: 0.5268 - val_loss: 0.9788 - val_accuracy: 0.5365\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9770 - accuracy: 0.5272 - val_loss: 0.9783 - val_accuracy: 0.5356\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9772 - accuracy: 0.5255 - val_loss: 0.9784 - val_accuracy: 0.5365\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5265 - val_loss: 0.9782 - val_accuracy: 0.5361\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5257 - val_loss: 0.9788 - val_accuracy: 0.5365\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5264 - val_loss: 0.9782 - val_accuracy: 0.5356\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5266 - val_loss: 0.9785 - val_accuracy: 0.5365\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9770 - accuracy: 0.5269 - val_loss: 0.9785 - val_accuracy: 0.5365\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5266 - val_loss: 0.9781 - val_accuracy: 0.5361\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9774 - accuracy: 0.5267 - val_loss: 0.9782 - val_accuracy: 0.5365\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9770 - accuracy: 0.5273 - val_loss: 0.9783 - val_accuracy: 0.5378\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9769 - accuracy: 0.5269 - val_loss: 0.9782 - val_accuracy: 0.5365\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9767 - accuracy: 0.5263 - val_loss: 0.9780 - val_accuracy: 0.5365\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9768 - accuracy: 0.5257 - val_loss: 0.9782 - val_accuracy: 0.5370\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9769 - accuracy: 0.5266 - val_loss: 0.9778 - val_accuracy: 0.5352\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9768 - accuracy: 0.5261 - val_loss: 0.9779 - val_accuracy: 0.5365\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9772 - accuracy: 0.5268 - val_loss: 0.9780 - val_accuracy: 0.5356\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5256 - val_loss: 0.9780 - val_accuracy: 0.5378\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9769 - accuracy: 0.5254 - val_loss: 0.9778 - val_accuracy: 0.5378\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9773 - accuracy: 0.5265 - val_loss: 0.9777 - val_accuracy: 0.5352\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9767 - accuracy: 0.5262 - val_loss: 0.9778 - val_accuracy: 0.5370\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9767 - accuracy: 0.5280 - val_loss: 0.9777 - val_accuracy: 0.5352\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9767 - accuracy: 0.5267 - val_loss: 0.9775 - val_accuracy: 0.5365\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9767 - accuracy: 0.5263 - val_loss: 0.9783 - val_accuracy: 0.5352\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9768 - accuracy: 0.5268 - val_loss: 0.9778 - val_accuracy: 0.5370\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9767 - accuracy: 0.5267 - val_loss: 0.9773 - val_accuracy: 0.5365\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9771 - accuracy: 0.5263 - val_loss: 0.9776 - val_accuracy: 0.5378\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9767 - accuracy: 0.5265 - val_loss: 0.9774 - val_accuracy: 0.5365\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9768 - accuracy: 0.5263 - val_loss: 0.9779 - val_accuracy: 0.5365\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9767 - accuracy: 0.5269 - val_loss: 0.9777 - val_accuracy: 0.5378\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9766 - accuracy: 0.5261 - val_loss: 0.9778 - val_accuracy: 0.5378\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5267 - val_loss: 0.9774 - val_accuracy: 0.5352\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9768 - accuracy: 0.5271 - val_loss: 0.9780 - val_accuracy: 0.5347\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9779 - accuracy: 0.5265 - val_loss: 0.9772 - val_accuracy: 0.5370\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9767 - accuracy: 0.5267 - val_loss: 0.9770 - val_accuracy: 0.5365\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9767 - accuracy: 0.5258 - val_loss: 0.9773 - val_accuracy: 0.5365\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9766 - accuracy: 0.5261 - val_loss: 0.9771 - val_accuracy: 0.5365\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9766 - accuracy: 0.5265 - val_loss: 0.9771 - val_accuracy: 0.5365\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9768 - accuracy: 0.5269 - val_loss: 0.9777 - val_accuracy: 0.5365\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9766 - accuracy: 0.5265 - val_loss: 0.9772 - val_accuracy: 0.5365\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9766 - accuracy: 0.5263 - val_loss: 0.9775 - val_accuracy: 0.5365\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9765 - accuracy: 0.5270 - val_loss: 0.9774 - val_accuracy: 0.5374\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9770 - accuracy: 0.5259 - val_loss: 0.9775 - val_accuracy: 0.5365\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9768 - accuracy: 0.5273 - val_loss: 0.9776 - val_accuracy: 0.5365\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9766 - accuracy: 0.5265 - val_loss: 0.9774 - val_accuracy: 0.5365\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9764 - accuracy: 0.5266 - val_loss: 0.9772 - val_accuracy: 0.5365\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9767 - accuracy: 0.5274 - val_loss: 0.9775 - val_accuracy: 0.5370\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9767 - accuracy: 0.5268 - val_loss: 0.9777 - val_accuracy: 0.5378\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9783 - accuracy: 0.5260 - val_loss: 0.9782 - val_accuracy: 0.5347\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9769 - accuracy: 0.5259 - val_loss: 0.9783 - val_accuracy: 0.5352\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9765 - accuracy: 0.5263 - val_loss: 0.9780 - val_accuracy: 0.5356\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9766 - accuracy: 0.5263 - val_loss: 0.9778 - val_accuracy: 0.5365\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9765 - accuracy: 0.5255 - val_loss: 0.9777 - val_accuracy: 0.5352\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9766 - accuracy: 0.5267 - val_loss: 0.9775 - val_accuracy: 0.5365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5263 - val_loss: 0.9774 - val_accuracy: 0.5352\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5272 - val_loss: 0.9773 - val_accuracy: 0.5365\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5269 - val_loss: 0.9772 - val_accuracy: 0.5378\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9767 - accuracy: 0.5278 - val_loss: 0.9772 - val_accuracy: 0.5365\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5269 - val_loss: 0.9772 - val_accuracy: 0.5365\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5274 - val_loss: 0.9770 - val_accuracy: 0.5365\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5273 - val_loss: 0.9769 - val_accuracy: 0.5365\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9769 - accuracy: 0.5268 - val_loss: 0.9768 - val_accuracy: 0.5365\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9766 - accuracy: 0.5274 - val_loss: 0.9769 - val_accuracy: 0.5356\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9767 - accuracy: 0.5259 - val_loss: 0.9775 - val_accuracy: 0.5378\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9773 - accuracy: 0.5263 - val_loss: 0.9776 - val_accuracy: 0.5378\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5269 - val_loss: 0.9770 - val_accuracy: 0.5352\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9762 - accuracy: 0.5265 - val_loss: 0.9771 - val_accuracy: 0.5374\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5262 - val_loss: 0.9772 - val_accuracy: 0.5378\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5275 - val_loss: 0.9771 - val_accuracy: 0.5370\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9764 - accuracy: 0.5256 - val_loss: 0.9770 - val_accuracy: 0.5365\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9768 - accuracy: 0.5255 - val_loss: 0.9771 - val_accuracy: 0.5365\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9767 - accuracy: 0.5265 - val_loss: 0.9771 - val_accuracy: 0.5374\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9766 - accuracy: 0.5255 - val_loss: 0.9771 - val_accuracy: 0.5365\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5269 - val_loss: 0.9769 - val_accuracy: 0.5370\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9765 - accuracy: 0.5265 - val_loss: 0.9768 - val_accuracy: 0.5365\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9764 - accuracy: 0.5262 - val_loss: 0.9767 - val_accuracy: 0.5374\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9762 - accuracy: 0.5265 - val_loss: 0.9765 - val_accuracy: 0.5365\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9763 - accuracy: 0.5267 - val_loss: 0.9769 - val_accuracy: 0.5365\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9764 - accuracy: 0.5267 - val_loss: 0.9767 - val_accuracy: 0.5374\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9766 - accuracy: 0.5271 - val_loss: 0.9766 - val_accuracy: 0.5374\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9762 - accuracy: 0.5280 - val_loss: 0.9766 - val_accuracy: 0.5378\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9763 - accuracy: 0.5266 - val_loss: 0.9764 - val_accuracy: 0.5383\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9763 - accuracy: 0.5260 - val_loss: 0.9766 - val_accuracy: 0.5378\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5270 - val_loss: 0.9768 - val_accuracy: 0.5383\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9765 - accuracy: 0.5268 - val_loss: 0.9765 - val_accuracy: 0.5383\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9764 - accuracy: 0.5271 - val_loss: 0.9771 - val_accuracy: 0.5374\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5268 - val_loss: 0.9768 - val_accuracy: 0.5374\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9762 - accuracy: 0.5266 - val_loss: 0.9770 - val_accuracy: 0.5378\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5276 - val_loss: 0.9770 - val_accuracy: 0.5378\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9763 - accuracy: 0.5269 - val_loss: 0.9768 - val_accuracy: 0.5378\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9763 - accuracy: 0.5271 - val_loss: 0.9767 - val_accuracy: 0.5383\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5267 - val_loss: 0.9770 - val_accuracy: 0.5383\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9761 - accuracy: 0.5264 - val_loss: 0.9767 - val_accuracy: 0.5361\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9761 - accuracy: 0.5271 - val_loss: 0.9769 - val_accuracy: 0.5361\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9764 - accuracy: 0.5275 - val_loss: 0.9769 - val_accuracy: 0.5356\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9762 - accuracy: 0.5274 - val_loss: 0.9767 - val_accuracy: 0.5361\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9764 - accuracy: 0.5272 - val_loss: 0.9768 - val_accuracy: 0.5370\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9763 - accuracy: 0.5273 - val_loss: 0.9765 - val_accuracy: 0.5365\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5272 - val_loss: 0.9767 - val_accuracy: 0.5374\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9761 - accuracy: 0.5270 - val_loss: 0.9763 - val_accuracy: 0.5365\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9761 - accuracy: 0.5275 - val_loss: 0.9763 - val_accuracy: 0.5347\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9763 - accuracy: 0.5266 - val_loss: 0.9762 - val_accuracy: 0.5356\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9765 - accuracy: 0.5273 - val_loss: 0.9763 - val_accuracy: 0.5365\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9761 - accuracy: 0.5271 - val_loss: 0.9762 - val_accuracy: 0.5374\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9762 - accuracy: 0.5277 - val_loss: 0.9764 - val_accuracy: 0.5356\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9762 - accuracy: 0.5267 - val_loss: 0.9763 - val_accuracy: 0.5374\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9764 - accuracy: 0.5264 - val_loss: 0.9767 - val_accuracy: 0.5361\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9779 - accuracy: 0.5259 - val_loss: 0.9774 - val_accuracy: 0.5356\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9763 - accuracy: 0.5258 - val_loss: 0.9771 - val_accuracy: 0.5356\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9761 - accuracy: 0.5263 - val_loss: 0.9769 - val_accuracy: 0.5356\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 613us/step - loss: 0.9760 - accuracy: 0.5268 - val_loss: 0.9769 - val_accuracy: 0.5361\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9762 - accuracy: 0.5280 - val_loss: 0.9766 - val_accuracy: 0.5365\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9760 - accuracy: 0.5276 - val_loss: 0.9766 - val_accuracy: 0.5361\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9760 - accuracy: 0.5267 - val_loss: 0.9766 - val_accuracy: 0.5374\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9762 - accuracy: 0.5262 - val_loss: 0.9766 - val_accuracy: 0.5378\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9761 - accuracy: 0.5285 - val_loss: 0.9761 - val_accuracy: 0.5361\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9761 - accuracy: 0.5271 - val_loss: 0.9764 - val_accuracy: 0.5374\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9760 - accuracy: 0.5274 - val_loss: 0.9765 - val_accuracy: 0.5361\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9761 - accuracy: 0.5276 - val_loss: 0.9764 - val_accuracy: 0.5374\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9763 - accuracy: 0.5280 - val_loss: 0.9764 - val_accuracy: 0.5365\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9759 - accuracy: 0.5276 - val_loss: 0.9763 - val_accuracy: 0.5365\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9763 - accuracy: 0.5270 - val_loss: 0.9765 - val_accuracy: 0.5370\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 658us/step - loss: 0.9760 - accuracy: 0.5281 - val_loss: 0.9761 - val_accuracy: 0.5365\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9758 - accuracy: 0.5282 - val_loss: 0.9761 - val_accuracy: 0.5356\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9763 - accuracy: 0.5276 - val_loss: 0.9760 - val_accuracy: 0.5347\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9759 - accuracy: 0.5265 - val_loss: 0.9761 - val_accuracy: 0.5356\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5267 - val_loss: 0.9762 - val_accuracy: 0.5365\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9759 - accuracy: 0.5277 - val_loss: 0.9761 - val_accuracy: 0.5374\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5279 - val_loss: 0.9762 - val_accuracy: 0.5374\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9759 - accuracy: 0.5278 - val_loss: 0.9764 - val_accuracy: 0.5383\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9762 - accuracy: 0.5276 - val_loss: 0.9760 - val_accuracy: 0.5365\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 337us/step - loss: 0.9757 - accuracy: 0.5275\n",
      "Accuracy : 0.5275168418884277\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9760 - accuracy: 0.5365\n",
      "Accuracy : 0.5365206003189087\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.4588 - accuracy: 0.2871 - val_loss: 1.3784 - val_accuracy: 0.2820\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.2613 - accuracy: 0.2651 - val_loss: 1.2204 - val_accuracy: 0.2377\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.1645 - accuracy: 0.2282 - val_loss: 1.1465 - val_accuracy: 0.2045\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.1122 - accuracy: 0.2934 - val_loss: 1.0946 - val_accuracy: 0.3488\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 1.0579 - accuracy: 0.4429 - val_loss: 1.0263 - val_accuracy: 0.4591\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0232 - accuracy: 0.4591 - val_loss: 1.0080 - val_accuracy: 0.4591\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0143 - accuracy: 0.4591 - val_loss: 1.0015 - val_accuracy: 0.4591\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0106 - accuracy: 0.4591 - val_loss: 0.9980 - val_accuracy: 0.4591\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.0084 - accuracy: 0.4591 - val_loss: 0.9957 - val_accuracy: 0.4591\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0070 - accuracy: 0.4591 - val_loss: 0.9942 - val_accuracy: 0.4591\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0060 - accuracy: 0.4591 - val_loss: 0.9929 - val_accuracy: 0.4591\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0051 - accuracy: 0.4591 - val_loss: 0.9922 - val_accuracy: 0.4591\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 1.0046 - accuracy: 0.4591 - val_loss: 0.9916 - val_accuracy: 0.4591\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0042 - accuracy: 0.4591 - val_loss: 0.9911 - val_accuracy: 0.4591\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 1.0039 - accuracy: 0.4591 - val_loss: 0.9907 - val_accuracy: 0.4591\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0035 - accuracy: 0.4591 - val_loss: 0.9904 - val_accuracy: 0.4591\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0033 - accuracy: 0.4591 - val_loss: 0.9903 - val_accuracy: 0.4586\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0031 - accuracy: 0.4591 - val_loss: 0.9900 - val_accuracy: 0.4586\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0030 - accuracy: 0.4591 - val_loss: 0.9898 - val_accuracy: 0.4586\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 1.0029 - accuracy: 0.4591 - val_loss: 0.9897 - val_accuracy: 0.4586\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0028 - accuracy: 0.4591 - val_loss: 0.9895 - val_accuracy: 0.4586\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0034 - accuracy: 0.4591 - val_loss: 0.9893 - val_accuracy: 0.4586\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0027 - accuracy: 0.4591 - val_loss: 0.9892 - val_accuracy: 0.4586\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0026 - accuracy: 0.4591 - val_loss: 0.9891 - val_accuracy: 0.4586\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 1.0025 - accuracy: 0.4591 - val_loss: 0.9891 - val_accuracy: 0.4586\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 1.0025 - accuracy: 0.4591 - val_loss: 0.9892 - val_accuracy: 0.4586\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0025 - accuracy: 0.4591 - val_loss: 0.9891 - val_accuracy: 0.4586\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0024 - accuracy: 0.4591 - val_loss: 0.9889 - val_accuracy: 0.4586\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.0024 - accuracy: 0.4591 - val_loss: 0.9890 - val_accuracy: 0.4586\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 1.0023 - accuracy: 0.4591 - val_loss: 0.9890 - val_accuracy: 0.4586\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 1.0023 - accuracy: 0.4591 - val_loss: 0.9889 - val_accuracy: 0.4586\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0026 - accuracy: 0.4591 - val_loss: 0.9889 - val_accuracy: 0.4586\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 1.0022 - accuracy: 0.4591 - val_loss: 0.9889 - val_accuracy: 0.4586\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0022 - accuracy: 0.4591 - val_loss: 0.9888 - val_accuracy: 0.4586\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 587us/step - loss: 1.0023 - accuracy: 0.4591 - val_loss: 0.9887 - val_accuracy: 0.4586\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0021 - accuracy: 0.4591 - val_loss: 0.9889 - val_accuracy: 0.4586\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0021 - accuracy: 0.4591 - val_loss: 0.9889 - val_accuracy: 0.4586\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.0022 - accuracy: 0.4591 - val_loss: 0.9887 - val_accuracy: 0.4586\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0021 - accuracy: 0.4591 - val_loss: 0.9887 - val_accuracy: 0.4586\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0021 - accuracy: 0.4591 - val_loss: 0.9888 - val_accuracy: 0.4586\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0020 - accuracy: 0.4591 - val_loss: 0.9886 - val_accuracy: 0.4586\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0020 - accuracy: 0.4591 - val_loss: 0.9887 - val_accuracy: 0.4586\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.0020 - accuracy: 0.4591 - val_loss: 0.9888 - val_accuracy: 0.4586\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0020 - accuracy: 0.4593 - val_loss: 0.9886 - val_accuracy: 0.4586\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0019 - accuracy: 0.4615 - val_loss: 0.9884 - val_accuracy: 0.4586\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0019 - accuracy: 0.4624 - val_loss: 0.9885 - val_accuracy: 0.4599\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0018 - accuracy: 0.4623 - val_loss: 0.9884 - val_accuracy: 0.4599\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0026 - accuracy: 0.4663 - val_loss: 0.9881 - val_accuracy: 0.4608\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.0019 - accuracy: 0.4641 - val_loss: 0.9883 - val_accuracy: 0.4608\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0017 - accuracy: 0.4654 - val_loss: 0.9884 - val_accuracy: 0.4635\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 1.0017 - accuracy: 0.4665 - val_loss: 0.9882 - val_accuracy: 0.4666\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 1.0018 - accuracy: 0.4708 - val_loss: 0.9880 - val_accuracy: 0.4772\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0016 - accuracy: 0.4759 - val_loss: 0.9881 - val_accuracy: 0.4772\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0015 - accuracy: 0.4773 - val_loss: 0.9880 - val_accuracy: 0.4790\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0015 - accuracy: 0.4832 - val_loss: 0.9879 - val_accuracy: 0.4830\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0014 - accuracy: 0.4818 - val_loss: 0.9879 - val_accuracy: 0.4830\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0013 - accuracy: 0.4832 - val_loss: 0.9878 - val_accuracy: 0.4838\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0011 - accuracy: 0.4911 - val_loss: 0.9875 - val_accuracy: 0.4892\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 1.0011 - accuracy: 0.4919 - val_loss: 0.9873 - val_accuracy: 0.4923\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0008 - accuracy: 0.4996 - val_loss: 0.9870 - val_accuracy: 0.5046\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0006 - accuracy: 0.5045 - val_loss: 0.9866 - val_accuracy: 0.5135\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0002 - accuracy: 0.5096 - val_loss: 0.9858 - val_accuracy: 0.5197\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9999 - accuracy: 0.5146 - val_loss: 0.9850 - val_accuracy: 0.5250\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9994 - accuracy: 0.5152 - val_loss: 0.9841 - val_accuracy: 0.5303\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9990 - accuracy: 0.5226 - val_loss: 0.9836 - val_accuracy: 0.5308\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9978 - accuracy: 0.5220 - val_loss: 0.9825 - val_accuracy: 0.5321\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9969 - accuracy: 0.5252 - val_loss: 0.9808 - val_accuracy: 0.5343\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9954 - accuracy: 0.5243 - val_loss: 0.9787 - val_accuracy: 0.5365\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9943 - accuracy: 0.5287 - val_loss: 0.9768 - val_accuracy: 0.5356\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9921 - accuracy: 0.5285 - val_loss: 0.9755 - val_accuracy: 0.5361\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9904 - accuracy: 0.5296 - val_loss: 0.9729 - val_accuracy: 0.5361\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9877 - accuracy: 0.5293 - val_loss: 0.9717 - val_accuracy: 0.5365\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9855 - accuracy: 0.5295 - val_loss: 0.9684 - val_accuracy: 0.5409\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9838 - accuracy: 0.5282 - val_loss: 0.9675 - val_accuracy: 0.5423\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9823 - accuracy: 0.5299 - val_loss: 0.9656 - val_accuracy: 0.5409\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9830 - accuracy: 0.5289 - val_loss: 0.9656 - val_accuracy: 0.5361\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9806 - accuracy: 0.5292 - val_loss: 0.9648 - val_accuracy: 0.5387\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9801 - accuracy: 0.5302 - val_loss: 0.9646 - val_accuracy: 0.5387\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9797 - accuracy: 0.5285 - val_loss: 0.9655 - val_accuracy: 0.5361\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9792 - accuracy: 0.5301 - val_loss: 0.9643 - val_accuracy: 0.5356\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9789 - accuracy: 0.5295 - val_loss: 0.9642 - val_accuracy: 0.5361\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9785 - accuracy: 0.5295 - val_loss: 0.9632 - val_accuracy: 0.5352\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9784 - accuracy: 0.5289 - val_loss: 0.9630 - val_accuracy: 0.5352\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9779 - accuracy: 0.5290 - val_loss: 0.9639 - val_accuracy: 0.5352\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9781 - accuracy: 0.5282 - val_loss: 0.9633 - val_accuracy: 0.5352\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9781 - accuracy: 0.5296 - val_loss: 0.9633 - val_accuracy: 0.5347\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9779 - accuracy: 0.5292 - val_loss: 0.9638 - val_accuracy: 0.5352\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9777 - accuracy: 0.5283 - val_loss: 0.9625 - val_accuracy: 0.5361\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9774 - accuracy: 0.5294 - val_loss: 0.9631 - val_accuracy: 0.5361\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9776 - accuracy: 0.5285 - val_loss: 0.9631 - val_accuracy: 0.5365\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9773 - accuracy: 0.5284 - val_loss: 0.9625 - val_accuracy: 0.5365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5289 - val_loss: 0.9636 - val_accuracy: 0.5374\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5273 - val_loss: 0.9624 - val_accuracy: 0.5365\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9772 - accuracy: 0.5296 - val_loss: 0.9626 - val_accuracy: 0.5352\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9632 - val_accuracy: 0.5356\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5279 - val_loss: 0.9624 - val_accuracy: 0.5356\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5286 - val_loss: 0.9625 - val_accuracy: 0.5365\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9768 - accuracy: 0.5281 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5280 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9628 - val_accuracy: 0.5356\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9773 - accuracy: 0.5272 - val_loss: 0.9631 - val_accuracy: 0.5356\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9771 - accuracy: 0.5278 - val_loss: 0.9631 - val_accuracy: 0.5374\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5265 - val_loss: 0.9627 - val_accuracy: 0.5361\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9767 - accuracy: 0.5279 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 690us/step - loss: 0.9766 - accuracy: 0.5287 - val_loss: 0.9627 - val_accuracy: 0.5378\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9772 - accuracy: 0.5263 - val_loss: 0.9619 - val_accuracy: 0.5356\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9767 - accuracy: 0.5275 - val_loss: 0.9626 - val_accuracy: 0.5356\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9768 - accuracy: 0.5280 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9767 - accuracy: 0.5280 - val_loss: 0.9618 - val_accuracy: 0.5361\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9768 - accuracy: 0.5302 - val_loss: 0.9620 - val_accuracy: 0.5356\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9767 - accuracy: 0.5268 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9768 - accuracy: 0.5280 - val_loss: 0.9622 - val_accuracy: 0.5356\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9767 - accuracy: 0.5270 - val_loss: 0.9623 - val_accuracy: 0.5356\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9766 - accuracy: 0.5291 - val_loss: 0.9620 - val_accuracy: 0.5356\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9767 - accuracy: 0.5279 - val_loss: 0.9624 - val_accuracy: 0.5356\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9766 - accuracy: 0.5277 - val_loss: 0.9620 - val_accuracy: 0.5361\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9767 - accuracy: 0.5279 - val_loss: 0.9621 - val_accuracy: 0.5356\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9765 - accuracy: 0.5280 - val_loss: 0.9620 - val_accuracy: 0.5356\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9766 - accuracy: 0.5295 - val_loss: 0.9620 - val_accuracy: 0.5356\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9766 - accuracy: 0.5286 - val_loss: 0.9622 - val_accuracy: 0.5361\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9765 - accuracy: 0.5289 - val_loss: 0.9631 - val_accuracy: 0.5356\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9766 - accuracy: 0.5288 - val_loss: 0.9619 - val_accuracy: 0.5356\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5272 - val_loss: 0.9617 - val_accuracy: 0.5356\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5277 - val_loss: 0.9620 - val_accuracy: 0.5356\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9766 - accuracy: 0.5275 - val_loss: 0.9627 - val_accuracy: 0.5374\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5274 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9764 - accuracy: 0.5262 - val_loss: 0.9620 - val_accuracy: 0.5356\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5267 - val_loss: 0.9615 - val_accuracy: 0.5356\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9765 - accuracy: 0.5283 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9766 - accuracy: 0.5262 - val_loss: 0.9616 - val_accuracy: 0.5356\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9766 - accuracy: 0.5277 - val_loss: 0.9616 - val_accuracy: 0.5356\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9766 - accuracy: 0.5270 - val_loss: 0.9621 - val_accuracy: 0.5356\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5269 - val_loss: 0.9616 - val_accuracy: 0.5356\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5270 - val_loss: 0.9617 - val_accuracy: 0.5356\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9763 - accuracy: 0.5270 - val_loss: 0.9613 - val_accuracy: 0.5365\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9782 - accuracy: 0.5278 - val_loss: 0.9619 - val_accuracy: 0.5378\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5278 - val_loss: 0.9614 - val_accuracy: 0.5356\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5279 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9766 - accuracy: 0.5276 - val_loss: 0.9616 - val_accuracy: 0.5356\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9764 - accuracy: 0.5278 - val_loss: 0.9616 - val_accuracy: 0.5365\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9767 - accuracy: 0.5282 - val_loss: 0.9619 - val_accuracy: 0.5356\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9763 - accuracy: 0.5271 - val_loss: 0.9617 - val_accuracy: 0.5356\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9762 - accuracy: 0.5281 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9619 - val_accuracy: 0.5361\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9762 - accuracy: 0.5280 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9773 - accuracy: 0.5286 - val_loss: 0.9625 - val_accuracy: 0.5374\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9764 - accuracy: 0.5271 - val_loss: 0.9626 - val_accuracy: 0.5378\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 624us/step - loss: 0.9762 - accuracy: 0.5270 - val_loss: 0.9624 - val_accuracy: 0.5374\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9762 - accuracy: 0.5276 - val_loss: 0.9619 - val_accuracy: 0.5356\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9764 - accuracy: 0.5283 - val_loss: 0.9626 - val_accuracy: 0.5374\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9763 - accuracy: 0.5271 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9762 - accuracy: 0.5278 - val_loss: 0.9625 - val_accuracy: 0.5374\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9762 - accuracy: 0.5269 - val_loss: 0.9615 - val_accuracy: 0.5356\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9763 - accuracy: 0.5286 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9766 - accuracy: 0.5277 - val_loss: 0.9617 - val_accuracy: 0.5361\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9617 - val_accuracy: 0.5356\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9762 - accuracy: 0.5278 - val_loss: 0.9617 - val_accuracy: 0.5356\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5276 - val_loss: 0.9614 - val_accuracy: 0.5365\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9763 - accuracy: 0.5278 - val_loss: 0.9616 - val_accuracy: 0.5361\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9765 - accuracy: 0.5289 - val_loss: 0.9619 - val_accuracy: 0.5356\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9762 - accuracy: 0.5294 - val_loss: 0.9625 - val_accuracy: 0.5374\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9762 - accuracy: 0.5278 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9761 - accuracy: 0.5277 - val_loss: 0.9616 - val_accuracy: 0.5356\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9763 - accuracy: 0.5277 - val_loss: 0.9619 - val_accuracy: 0.5356\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9762 - accuracy: 0.5276 - val_loss: 0.9623 - val_accuracy: 0.5361\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9763 - accuracy: 0.5278 - val_loss: 0.9615 - val_accuracy: 0.5365\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9762 - accuracy: 0.5287 - val_loss: 0.9618 - val_accuracy: 0.5361\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9761 - accuracy: 0.5285 - val_loss: 0.9614 - val_accuracy: 0.5365\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9761 - accuracy: 0.5280 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9765 - accuracy: 0.5281 - val_loss: 0.9621 - val_accuracy: 0.5356\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5269 - val_loss: 0.9616 - val_accuracy: 0.5365\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9762 - accuracy: 0.5285 - val_loss: 0.9627 - val_accuracy: 0.5374\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9763 - accuracy: 0.5272 - val_loss: 0.9619 - val_accuracy: 0.5361\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5278 - val_loss: 0.9622 - val_accuracy: 0.5356\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9763 - accuracy: 0.5281 - val_loss: 0.9627 - val_accuracy: 0.5356\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9763 - accuracy: 0.5275 - val_loss: 0.9615 - val_accuracy: 0.5361\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9761 - accuracy: 0.5278 - val_loss: 0.9629 - val_accuracy: 0.5374\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9761 - accuracy: 0.5283 - val_loss: 0.9629 - val_accuracy: 0.5374\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5271 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5271 - val_loss: 0.9621 - val_accuracy: 0.5356\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9762 - accuracy: 0.5276 - val_loss: 0.9615 - val_accuracy: 0.5356\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9624 - val_accuracy: 0.5374\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9762 - accuracy: 0.5272 - val_loss: 0.9623 - val_accuracy: 0.5374\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5276 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9761 - accuracy: 0.5286 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5274 - val_loss: 0.9628 - val_accuracy: 0.5374\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5272 - val_loss: 0.9620 - val_accuracy: 0.5356\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9762 - accuracy: 0.5281 - val_loss: 0.9630 - val_accuracy: 0.5374\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9761 - accuracy: 0.5271 - val_loss: 0.9616 - val_accuracy: 0.5356\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9761 - accuracy: 0.5281 - val_loss: 0.9627 - val_accuracy: 0.5374\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9761 - accuracy: 0.5276 - val_loss: 0.9614 - val_accuracy: 0.5356\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9761 - accuracy: 0.5288 - val_loss: 0.9615 - val_accuracy: 0.5356\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9763 - accuracy: 0.5279 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9760 - accuracy: 0.5279 - val_loss: 0.9620 - val_accuracy: 0.5356\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9762 - accuracy: 0.5276 - val_loss: 0.9619 - val_accuracy: 0.5356\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9765 - accuracy: 0.5287 - val_loss: 0.9622 - val_accuracy: 0.5356\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9764 - accuracy: 0.5284 - val_loss: 0.9635 - val_accuracy: 0.5370\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9765 - accuracy: 0.5271 - val_loss: 0.9622 - val_accuracy: 0.5356\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9764 - accuracy: 0.5263 - val_loss: 0.9620 - val_accuracy: 0.5383\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9762 - accuracy: 0.5271 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 340us/step - loss: 0.9759 - accuracy: 0.5276\n",
      "Accuracy : 0.5276151895523071\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9621 - accuracy: 0.5374\n",
      "Accuracy : 0.5374059081077576\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 2.1341 - accuracy: 0.4589 - val_loss: 1.6692 - val_accuracy: 0.4599\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.4032 - accuracy: 0.4589 - val_loss: 1.1605 - val_accuracy: 0.4599\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 603us/step - loss: 1.0979 - accuracy: 0.4591 - val_loss: 1.0180 - val_accuracy: 0.4599\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 1.0201 - accuracy: 0.4703 - val_loss: 0.9850 - val_accuracy: 0.5179\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 1.0020 - accuracy: 0.5003 - val_loss: 0.9725 - val_accuracy: 0.5361\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9952 - accuracy: 0.5086 - val_loss: 0.9637 - val_accuracy: 0.5374\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9901 - accuracy: 0.5173 - val_loss: 0.9575 - val_accuracy: 0.5383\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9870 - accuracy: 0.5202 - val_loss: 0.9528 - val_accuracy: 0.5414\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9841 - accuracy: 0.5220 - val_loss: 0.9496 - val_accuracy: 0.5414\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9823 - accuracy: 0.5238 - val_loss: 0.9473 - val_accuracy: 0.5418\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9814 - accuracy: 0.5246 - val_loss: 0.9461 - val_accuracy: 0.5405\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9807 - accuracy: 0.5252 - val_loss: 0.9449 - val_accuracy: 0.5414\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9801 - accuracy: 0.5279 - val_loss: 0.9444 - val_accuracy: 0.5409\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9801 - accuracy: 0.5278 - val_loss: 0.9444 - val_accuracy: 0.5405\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9799 - accuracy: 0.5279 - val_loss: 0.9439 - val_accuracy: 0.5401\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9797 - accuracy: 0.5285 - val_loss: 0.9436 - val_accuracy: 0.5405\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9798 - accuracy: 0.5280 - val_loss: 0.9433 - val_accuracy: 0.5405\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9799 - accuracy: 0.5283 - val_loss: 0.9427 - val_accuracy: 0.5409\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5266 - val_loss: 0.9431 - val_accuracy: 0.5405\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9796 - accuracy: 0.5280 - val_loss: 0.9428 - val_accuracy: 0.5405\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9800 - accuracy: 0.5283 - val_loss: 0.9427 - val_accuracy: 0.5405\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9796 - accuracy: 0.5281 - val_loss: 0.9431 - val_accuracy: 0.5427\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5276 - val_loss: 0.9426 - val_accuracy: 0.5401\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5281 - val_loss: 0.9421 - val_accuracy: 0.5409\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9795 - accuracy: 0.5283 - val_loss: 0.9423 - val_accuracy: 0.5405\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9796 - accuracy: 0.5278 - val_loss: 0.9426 - val_accuracy: 0.5427\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5271 - val_loss: 0.9430 - val_accuracy: 0.5440\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9796 - accuracy: 0.5287 - val_loss: 0.9422 - val_accuracy: 0.5409\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9798 - accuracy: 0.5282 - val_loss: 0.9421 - val_accuracy: 0.5401\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9797 - accuracy: 0.5278 - val_loss: 0.9437 - val_accuracy: 0.5436\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9801 - accuracy: 0.5278 - val_loss: 0.9422 - val_accuracy: 0.5409\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9799 - accuracy: 0.5272 - val_loss: 0.9426 - val_accuracy: 0.5405\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9795 - accuracy: 0.5280 - val_loss: 0.9431 - val_accuracy: 0.5423\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9797 - accuracy: 0.5290 - val_loss: 0.9440 - val_accuracy: 0.5436\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5282 - val_loss: 0.9432 - val_accuracy: 0.5440\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5288 - val_loss: 0.9424 - val_accuracy: 0.5401\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9795 - accuracy: 0.5276 - val_loss: 0.9426 - val_accuracy: 0.5405\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9797 - accuracy: 0.5277 - val_loss: 0.9434 - val_accuracy: 0.5440\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9797 - accuracy: 0.5287 - val_loss: 0.9421 - val_accuracy: 0.5409\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9794 - accuracy: 0.5285 - val_loss: 0.9435 - val_accuracy: 0.5440\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9798 - accuracy: 0.5287 - val_loss: 0.9432 - val_accuracy: 0.5440\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9797 - accuracy: 0.5269 - val_loss: 0.9426 - val_accuracy: 0.5405\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9798 - accuracy: 0.5280 - val_loss: 0.9420 - val_accuracy: 0.5409\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9795 - accuracy: 0.5277 - val_loss: 0.9422 - val_accuracy: 0.5409\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9795 - accuracy: 0.5282 - val_loss: 0.9428 - val_accuracy: 0.5405\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9797 - accuracy: 0.5281 - val_loss: 0.9425 - val_accuracy: 0.5405\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5282 - val_loss: 0.9422 - val_accuracy: 0.5401\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5273 - val_loss: 0.9443 - val_accuracy: 0.5440\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9798 - accuracy: 0.5274 - val_loss: 0.9433 - val_accuracy: 0.5405\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9798 - accuracy: 0.5280 - val_loss: 0.9425 - val_accuracy: 0.5401\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9794 - accuracy: 0.5277 - val_loss: 0.9431 - val_accuracy: 0.5432\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9795 - accuracy: 0.5282 - val_loss: 0.9424 - val_accuracy: 0.5409\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9798 - accuracy: 0.5273 - val_loss: 0.9438 - val_accuracy: 0.5436\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9797 - accuracy: 0.5275 - val_loss: 0.9421 - val_accuracy: 0.5423\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9796 - accuracy: 0.5277 - val_loss: 0.9419 - val_accuracy: 0.5423\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5280 - val_loss: 0.9431 - val_accuracy: 0.5423\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9807 - accuracy: 0.5274 - val_loss: 0.9437 - val_accuracy: 0.5405\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9799 - accuracy: 0.5267 - val_loss: 0.9431 - val_accuracy: 0.5409\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5264 - val_loss: 0.9425 - val_accuracy: 0.5418\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 615us/step - loss: 0.9794 - accuracy: 0.5280 - val_loss: 0.9431 - val_accuracy: 0.5401\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9797 - accuracy: 0.5281 - val_loss: 0.9430 - val_accuracy: 0.5405\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5279 - val_loss: 0.9429 - val_accuracy: 0.5401\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5277 - val_loss: 0.9426 - val_accuracy: 0.5409\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9794 - accuracy: 0.5259 - val_loss: 0.9433 - val_accuracy: 0.5405\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9795 - accuracy: 0.5264 - val_loss: 0.9430 - val_accuracy: 0.5401\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9794 - accuracy: 0.5264 - val_loss: 0.9428 - val_accuracy: 0.5401\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5278 - val_loss: 0.9426 - val_accuracy: 0.5401\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5266 - val_loss: 0.9442 - val_accuracy: 0.5436\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9796 - accuracy: 0.5281 - val_loss: 0.9419 - val_accuracy: 0.5418\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9795 - accuracy: 0.5276 - val_loss: 0.9422 - val_accuracy: 0.5409\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5274 - val_loss: 0.9422 - val_accuracy: 0.5409\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5270 - val_loss: 0.9426 - val_accuracy: 0.5405\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9796 - accuracy: 0.5274 - val_loss: 0.9437 - val_accuracy: 0.5440\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5274 - val_loss: 0.9431 - val_accuracy: 0.5405\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5276 - val_loss: 0.9415 - val_accuracy: 0.5405\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9797 - accuracy: 0.5275 - val_loss: 0.9418 - val_accuracy: 0.5405\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9795 - accuracy: 0.5272 - val_loss: 0.9426 - val_accuracy: 0.5409\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9795 - accuracy: 0.5270 - val_loss: 0.9425 - val_accuracy: 0.5409\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9793 - accuracy: 0.5270 - val_loss: 0.9435 - val_accuracy: 0.5432\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9796 - accuracy: 0.5274 - val_loss: 0.9420 - val_accuracy: 0.5414\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9793 - accuracy: 0.5287 - val_loss: 0.9419 - val_accuracy: 0.5405\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9794 - accuracy: 0.5280 - val_loss: 0.9420 - val_accuracy: 0.5414\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9799 - accuracy: 0.5255 - val_loss: 0.9428 - val_accuracy: 0.5414\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9794 - accuracy: 0.5257 - val_loss: 0.9432 - val_accuracy: 0.5409\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9794 - accuracy: 0.5280 - val_loss: 0.9424 - val_accuracy: 0.5409\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9795 - accuracy: 0.5289 - val_loss: 0.9423 - val_accuracy: 0.5418\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9793 - accuracy: 0.5269 - val_loss: 0.9439 - val_accuracy: 0.5440\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9802 - accuracy: 0.5271 - val_loss: 0.9424 - val_accuracy: 0.5414\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9793 - accuracy: 0.5264 - val_loss: 0.9430 - val_accuracy: 0.5414\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9794 - accuracy: 0.5276 - val_loss: 0.9425 - val_accuracy: 0.5409\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9794 - accuracy: 0.5270 - val_loss: 0.9426 - val_accuracy: 0.5409\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9794 - accuracy: 0.5269 - val_loss: 0.9427 - val_accuracy: 0.5409\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9795 - accuracy: 0.5271 - val_loss: 0.9433 - val_accuracy: 0.5427\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5279 - val_loss: 0.9421 - val_accuracy: 0.5409\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9795 - accuracy: 0.5274 - val_loss: 0.9417 - val_accuracy: 0.5405\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9796 - accuracy: 0.5260 - val_loss: 0.9431 - val_accuracy: 0.5409\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9796 - accuracy: 0.5272 - val_loss: 0.9430 - val_accuracy: 0.5401\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9793 - accuracy: 0.5270 - val_loss: 0.9428 - val_accuracy: 0.5409\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9793 - accuracy: 0.5269 - val_loss: 0.9425 - val_accuracy: 0.5418\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9795 - accuracy: 0.5268 - val_loss: 0.9419 - val_accuracy: 0.5405\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9794 - accuracy: 0.5270 - val_loss: 0.9427 - val_accuracy: 0.5409\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5265 - val_loss: 0.9433 - val_accuracy: 0.5409\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9815 - accuracy: 0.5265 - val_loss: 0.9442 - val_accuracy: 0.5409\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9797 - accuracy: 0.5275 - val_loss: 0.9432 - val_accuracy: 0.5409\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9793 - accuracy: 0.5269 - val_loss: 0.9434 - val_accuracy: 0.5409\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9800 - accuracy: 0.5281 - val_loss: 0.9424 - val_accuracy: 0.5409\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5260 - val_loss: 0.9435 - val_accuracy: 0.5401\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9794 - accuracy: 0.5279 - val_loss: 0.9422 - val_accuracy: 0.5405\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5273 - val_loss: 0.9429 - val_accuracy: 0.5409\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9804 - accuracy: 0.5274 - val_loss: 0.9438 - val_accuracy: 0.5401\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5277 - val_loss: 0.9426 - val_accuracy: 0.5418\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5273 - val_loss: 0.9430 - val_accuracy: 0.5409\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9792 - accuracy: 0.5273 - val_loss: 0.9427 - val_accuracy: 0.5409\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5282 - val_loss: 0.9429 - val_accuracy: 0.5409\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9794 - accuracy: 0.5261 - val_loss: 0.9425 - val_accuracy: 0.5405\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9804 - accuracy: 0.5253 - val_loss: 0.9430 - val_accuracy: 0.5409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9796 - accuracy: 0.5271 - val_loss: 0.9432 - val_accuracy: 0.5401\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9793 - accuracy: 0.5286 - val_loss: 0.9425 - val_accuracy: 0.5409\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9794 - accuracy: 0.5275 - val_loss: 0.9433 - val_accuracy: 0.5401\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9799 - accuracy: 0.5273 - val_loss: 0.9422 - val_accuracy: 0.5405\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5258 - val_loss: 0.9437 - val_accuracy: 0.5409\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9792 - accuracy: 0.5274 - val_loss: 0.9424 - val_accuracy: 0.5414\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9794 - accuracy: 0.5263 - val_loss: 0.9421 - val_accuracy: 0.5414\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5264 - val_loss: 0.9422 - val_accuracy: 0.5414\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9792 - accuracy: 0.5268 - val_loss: 0.9422 - val_accuracy: 0.5405\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9795 - accuracy: 0.5282 - val_loss: 0.9422 - val_accuracy: 0.5414\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9793 - accuracy: 0.5277 - val_loss: 0.9428 - val_accuracy: 0.5409\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9798 - accuracy: 0.5273 - val_loss: 0.9436 - val_accuracy: 0.5405\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9801 - accuracy: 0.5273 - val_loss: 0.9429 - val_accuracy: 0.5409\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9793 - accuracy: 0.5278 - val_loss: 0.9424 - val_accuracy: 0.5418\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5273 - val_loss: 0.9420 - val_accuracy: 0.5418\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9792 - accuracy: 0.5271 - val_loss: 0.9431 - val_accuracy: 0.5401\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9796 - accuracy: 0.5279 - val_loss: 0.9428 - val_accuracy: 0.5409\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9796 - accuracy: 0.5278 - val_loss: 0.9430 - val_accuracy: 0.5401\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9792 - accuracy: 0.5278 - val_loss: 0.9427 - val_accuracy: 0.5409\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9796 - accuracy: 0.5278 - val_loss: 0.9421 - val_accuracy: 0.5405\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9793 - accuracy: 0.5259 - val_loss: 0.9421 - val_accuracy: 0.5401\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9794 - accuracy: 0.5258 - val_loss: 0.9425 - val_accuracy: 0.5418\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9792 - accuracy: 0.5262 - val_loss: 0.9426 - val_accuracy: 0.5405\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9793 - accuracy: 0.5274 - val_loss: 0.9426 - val_accuracy: 0.5409\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9794 - accuracy: 0.5282 - val_loss: 0.9427 - val_accuracy: 0.5409\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9797 - accuracy: 0.5281 - val_loss: 0.9424 - val_accuracy: 0.5409\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9792 - accuracy: 0.5267 - val_loss: 0.9426 - val_accuracy: 0.5409\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5270 - val_loss: 0.9422 - val_accuracy: 0.5405\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9799 - accuracy: 0.5266 - val_loss: 0.9417 - val_accuracy: 0.5409\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5264 - val_loss: 0.9443 - val_accuracy: 0.5440\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5282 - val_loss: 0.9417 - val_accuracy: 0.5405\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5274 - val_loss: 0.9440 - val_accuracy: 0.5440\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5279 - val_loss: 0.9422 - val_accuracy: 0.5409\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9792 - accuracy: 0.5275 - val_loss: 0.9416 - val_accuracy: 0.5401\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5270 - val_loss: 0.9421 - val_accuracy: 0.5409\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5275 - val_loss: 0.9428 - val_accuracy: 0.5401\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5284 - val_loss: 0.9420 - val_accuracy: 0.5405\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9797 - accuracy: 0.5264 - val_loss: 0.9423 - val_accuracy: 0.5418\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9794 - accuracy: 0.5277 - val_loss: 0.9438 - val_accuracy: 0.5427\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5284 - val_loss: 0.9422 - val_accuracy: 0.5409\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5275 - val_loss: 0.9437 - val_accuracy: 0.5436\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9797 - accuracy: 0.5264 - val_loss: 0.9418 - val_accuracy: 0.5409\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5272 - val_loss: 0.9422 - val_accuracy: 0.5414\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5271 - val_loss: 0.9425 - val_accuracy: 0.5409\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5276 - val_loss: 0.9425 - val_accuracy: 0.5409\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5283 - val_loss: 0.9433 - val_accuracy: 0.5401\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9795 - accuracy: 0.5271 - val_loss: 0.9424 - val_accuracy: 0.5409\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5275 - val_loss: 0.9419 - val_accuracy: 0.5418\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5260 - val_loss: 0.9420 - val_accuracy: 0.5405\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9792 - accuracy: 0.5271 - val_loss: 0.9424 - val_accuracy: 0.5409\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9793 - accuracy: 0.5260 - val_loss: 0.9434 - val_accuracy: 0.5401\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9798 - accuracy: 0.5272 - val_loss: 0.9424 - val_accuracy: 0.5405\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5275 - val_loss: 0.9417 - val_accuracy: 0.5396\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9797 - accuracy: 0.5247 - val_loss: 0.9429 - val_accuracy: 0.5409\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9792 - accuracy: 0.5269 - val_loss: 0.9421 - val_accuracy: 0.5405\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9792 - accuracy: 0.5263 - val_loss: 0.9429 - val_accuracy: 0.5409\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 592us/step - loss: 0.9795 - accuracy: 0.5279 - val_loss: 0.9424 - val_accuracy: 0.5409\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9797 - accuracy: 0.5274 - val_loss: 0.9420 - val_accuracy: 0.5414\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9794 - accuracy: 0.5265 - val_loss: 0.9425 - val_accuracy: 0.5409\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9792 - accuracy: 0.5270 - val_loss: 0.9419 - val_accuracy: 0.5418\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9796 - accuracy: 0.5268 - val_loss: 0.9421 - val_accuracy: 0.5414\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9795 - accuracy: 0.5274 - val_loss: 0.9421 - val_accuracy: 0.5418\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9793 - accuracy: 0.5271 - val_loss: 0.9423 - val_accuracy: 0.5409\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9798 - accuracy: 0.5257 - val_loss: 0.9422 - val_accuracy: 0.5418\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9796 - accuracy: 0.5269 - val_loss: 0.9426 - val_accuracy: 0.5409\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9793 - accuracy: 0.5279 - val_loss: 0.9421 - val_accuracy: 0.5414\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9793 - accuracy: 0.5266 - val_loss: 0.9424 - val_accuracy: 0.5409\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9793 - accuracy: 0.5272 - val_loss: 0.9418 - val_accuracy: 0.5414\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9794 - accuracy: 0.5266 - val_loss: 0.9433 - val_accuracy: 0.5401\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9792 - accuracy: 0.5278 - val_loss: 0.9419 - val_accuracy: 0.5405\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9792 - accuracy: 0.5283 - val_loss: 0.9420 - val_accuracy: 0.5405\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9793 - accuracy: 0.5271 - val_loss: 0.9422 - val_accuracy: 0.5418\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9793 - accuracy: 0.5272 - val_loss: 0.9429 - val_accuracy: 0.5409\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9800 - accuracy: 0.5285 - val_loss: 0.9417 - val_accuracy: 0.5401\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5267 - val_loss: 0.9420 - val_accuracy: 0.5414\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9793 - accuracy: 0.5261 - val_loss: 0.9425 - val_accuracy: 0.5418\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9796 - accuracy: 0.5271 - val_loss: 0.9423 - val_accuracy: 0.5405\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9794 - accuracy: 0.5265 - val_loss: 0.9424 - val_accuracy: 0.5405\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9793 - accuracy: 0.5277 - val_loss: 0.9421 - val_accuracy: 0.5401\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9794 - accuracy: 0.5256 - val_loss: 0.9433 - val_accuracy: 0.5409\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9795 - accuracy: 0.5255 - val_loss: 0.9428 - val_accuracy: 0.5414\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9793 - accuracy: 0.5262 - val_loss: 0.9422 - val_accuracy: 0.5401\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9793 - accuracy: 0.5269 - val_loss: 0.9425 - val_accuracy: 0.5418\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9794 - accuracy: 0.5288 - val_loss: 0.9424 - val_accuracy: 0.5414\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 335us/step - loss: 0.9790 - accuracy: 0.5265\n",
      "Accuracy : 0.5265332460403442\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9424 - accuracy: 0.5414\n",
      "Accuracy : 0.5413900017738342\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.8029 - accuracy: 0.4318 - val_loss: 1.6179 - val_accuracy: 0.4369\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 1.4587 - accuracy: 0.4425 - val_loss: 1.3419 - val_accuracy: 0.4533\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 1.2766 - accuracy: 0.4570 - val_loss: 1.2288 - val_accuracy: 0.4657\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 1.1936 - accuracy: 0.4637 - val_loss: 1.1556 - val_accuracy: 0.4586\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 1.1277 - accuracy: 0.4638 - val_loss: 1.0942 - val_accuracy: 0.4577\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0717 - accuracy: 0.4643 - val_loss: 1.0464 - val_accuracy: 0.4599\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 1.0331 - accuracy: 0.4638 - val_loss: 1.0151 - val_accuracy: 0.4586\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 1.0080 - accuracy: 0.4817 - val_loss: 0.9958 - val_accuracy: 0.4861\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9930 - accuracy: 0.5206 - val_loss: 0.9838 - val_accuracy: 0.5237\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9859 - accuracy: 0.5266 - val_loss: 0.9785 - val_accuracy: 0.5232\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9820 - accuracy: 0.5267 - val_loss: 0.9749 - val_accuracy: 0.5237\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9800 - accuracy: 0.5262 - val_loss: 0.9733 - val_accuracy: 0.5255\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9787 - accuracy: 0.5276 - val_loss: 0.9723 - val_accuracy: 0.5255\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9783 - accuracy: 0.5285 - val_loss: 0.9716 - val_accuracy: 0.5237\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9777 - accuracy: 0.5295 - val_loss: 0.9704 - val_accuracy: 0.5237\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9779 - accuracy: 0.5276 - val_loss: 0.9702 - val_accuracy: 0.5237\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9778 - accuracy: 0.5277 - val_loss: 0.9705 - val_accuracy: 0.5259\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9777 - accuracy: 0.5299 - val_loss: 0.9699 - val_accuracy: 0.5246\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9776 - accuracy: 0.5296 - val_loss: 0.9701 - val_accuracy: 0.5259\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5286 - val_loss: 0.9697 - val_accuracy: 0.5246\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9775 - accuracy: 0.5276 - val_loss: 0.9699 - val_accuracy: 0.5246\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9777 - accuracy: 0.5287 - val_loss: 0.9697 - val_accuracy: 0.5250\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9774 - accuracy: 0.5279 - val_loss: 0.9703 - val_accuracy: 0.5259\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9776 - accuracy: 0.5283 - val_loss: 0.9699 - val_accuracy: 0.5237\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 0.9701 - val_accuracy: 0.5263\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9774 - accuracy: 0.5291 - val_loss: 0.9694 - val_accuracy: 0.5250\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9781 - accuracy: 0.5252 - val_loss: 0.9701 - val_accuracy: 0.5255\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 591us/step - loss: 0.9774 - accuracy: 0.5287 - val_loss: 0.9697 - val_accuracy: 0.5255\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9775 - accuracy: 0.5294 - val_loss: 0.9694 - val_accuracy: 0.5250\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9775 - accuracy: 0.5275 - val_loss: 0.9696 - val_accuracy: 0.5250\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9773 - accuracy: 0.5280 - val_loss: 0.9695 - val_accuracy: 0.5250\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9697 - val_accuracy: 0.5250\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5271 - val_loss: 0.9699 - val_accuracy: 0.5259\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5299 - val_loss: 0.9693 - val_accuracy: 0.5237\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9771 - accuracy: 0.5287 - val_loss: 0.9697 - val_accuracy: 0.5237\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9774 - accuracy: 0.5296 - val_loss: 0.9693 - val_accuracy: 0.5246\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9774 - accuracy: 0.5281 - val_loss: 0.9691 - val_accuracy: 0.5250\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9699 - val_accuracy: 0.5263\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9779 - accuracy: 0.5293 - val_loss: 0.9694 - val_accuracy: 0.5250\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9695 - val_accuracy: 0.5259\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9772 - accuracy: 0.5291 - val_loss: 0.9694 - val_accuracy: 0.5250\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5290 - val_loss: 0.9704 - val_accuracy: 0.5263\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9776 - accuracy: 0.5282 - val_loss: 0.9702 - val_accuracy: 0.5259\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9771 - accuracy: 0.5287 - val_loss: 0.9692 - val_accuracy: 0.5237\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5275 - val_loss: 0.9694 - val_accuracy: 0.5259\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9771 - accuracy: 0.5275 - val_loss: 0.9696 - val_accuracy: 0.5263\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9772 - accuracy: 0.5274 - val_loss: 0.9698 - val_accuracy: 0.5250\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5276 - val_loss: 0.9693 - val_accuracy: 0.5250\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9773 - accuracy: 0.5282 - val_loss: 0.9693 - val_accuracy: 0.5237\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5284 - val_loss: 0.9692 - val_accuracy: 0.5250\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9771 - accuracy: 0.5288 - val_loss: 0.9692 - val_accuracy: 0.5250\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9775 - accuracy: 0.5283 - val_loss: 0.9693 - val_accuracy: 0.5250\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9771 - accuracy: 0.5291 - val_loss: 0.9692 - val_accuracy: 0.5246\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9771 - accuracy: 0.5283 - val_loss: 0.9691 - val_accuracy: 0.5250\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9772 - accuracy: 0.5297 - val_loss: 0.9691 - val_accuracy: 0.5246\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9771 - accuracy: 0.5278 - val_loss: 0.9699 - val_accuracy: 0.5263\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9691 - val_accuracy: 0.5250\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9697 - val_accuracy: 0.5259\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9772 - accuracy: 0.5299 - val_loss: 0.9690 - val_accuracy: 0.5241\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9771 - accuracy: 0.5289 - val_loss: 0.9697 - val_accuracy: 0.5259\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9776 - accuracy: 0.5292 - val_loss: 0.9696 - val_accuracy: 0.5250\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9775 - accuracy: 0.5284 - val_loss: 0.9695 - val_accuracy: 0.5237\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9771 - accuracy: 0.5286 - val_loss: 0.9691 - val_accuracy: 0.5250\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9692 - val_accuracy: 0.5250\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9780 - accuracy: 0.5281 - val_loss: 0.9691 - val_accuracy: 0.5250\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5277 - val_loss: 0.9695 - val_accuracy: 0.5237\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5301 - val_loss: 0.9692 - val_accuracy: 0.5250\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5291 - val_loss: 0.9690 - val_accuracy: 0.5246\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9770 - accuracy: 0.5295 - val_loss: 0.9691 - val_accuracy: 0.5246\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9770 - accuracy: 0.5283 - val_loss: 0.9698 - val_accuracy: 0.5263\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9773 - accuracy: 0.5296 - val_loss: 0.9687 - val_accuracy: 0.5237\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5287 - val_loss: 0.9693 - val_accuracy: 0.5232\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9687 - val_accuracy: 0.5250\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9770 - accuracy: 0.5293 - val_loss: 0.9692 - val_accuracy: 0.5259\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9771 - accuracy: 0.5300 - val_loss: 0.9691 - val_accuracy: 0.5241\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9769 - accuracy: 0.5283 - val_loss: 0.9696 - val_accuracy: 0.5259\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9778 - accuracy: 0.5285 - val_loss: 0.9694 - val_accuracy: 0.5259\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5283 - val_loss: 0.9696 - val_accuracy: 0.5259\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9688 - val_accuracy: 0.5224\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9690 - val_accuracy: 0.5246\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5283 - val_loss: 0.9692 - val_accuracy: 0.5246\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9770 - accuracy: 0.5289 - val_loss: 0.9693 - val_accuracy: 0.5259\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5308 - val_loss: 0.9691 - val_accuracy: 0.5250\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5282 - val_loss: 0.9689 - val_accuracy: 0.5241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9691 - val_accuracy: 0.5237\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5298 - val_loss: 0.9689 - val_accuracy: 0.5246\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9774 - accuracy: 0.5281 - val_loss: 0.9691 - val_accuracy: 0.5232\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9772 - accuracy: 0.5290 - val_loss: 0.9690 - val_accuracy: 0.5246\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5284 - val_loss: 0.9693 - val_accuracy: 0.5246\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9772 - accuracy: 0.5271 - val_loss: 0.9693 - val_accuracy: 0.5246\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9771 - accuracy: 0.5300 - val_loss: 0.9690 - val_accuracy: 0.5246\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9689 - val_accuracy: 0.5246\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9692 - val_accuracy: 0.5237\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9769 - accuracy: 0.5304 - val_loss: 0.9686 - val_accuracy: 0.5237\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9769 - accuracy: 0.5271 - val_loss: 0.9700 - val_accuracy: 0.5263\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9776 - accuracy: 0.5296 - val_loss: 0.9688 - val_accuracy: 0.5237\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9785 - accuracy: 0.5242 - val_loss: 0.9696 - val_accuracy: 0.5237\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9775 - accuracy: 0.5262 - val_loss: 0.9696 - val_accuracy: 0.5224\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9769 - accuracy: 0.5267 - val_loss: 0.9701 - val_accuracy: 0.5250\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9771 - accuracy: 0.5286 - val_loss: 0.9697 - val_accuracy: 0.5250\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9768 - accuracy: 0.5285 - val_loss: 0.9693 - val_accuracy: 0.5241\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9770 - accuracy: 0.5276 - val_loss: 0.9698 - val_accuracy: 0.5259\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9771 - accuracy: 0.5294 - val_loss: 0.9692 - val_accuracy: 0.5250\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9771 - accuracy: 0.5287 - val_loss: 0.9688 - val_accuracy: 0.5237\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9770 - accuracy: 0.5288 - val_loss: 0.9696 - val_accuracy: 0.5246\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5290 - val_loss: 0.9689 - val_accuracy: 0.5250\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9773 - accuracy: 0.5272 - val_loss: 0.9694 - val_accuracy: 0.5241\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5288 - val_loss: 0.9690 - val_accuracy: 0.5250\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9768 - accuracy: 0.5298 - val_loss: 0.9694 - val_accuracy: 0.5232\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9771 - accuracy: 0.5288 - val_loss: 0.9691 - val_accuracy: 0.5237\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9770 - accuracy: 0.5282 - val_loss: 0.9692 - val_accuracy: 0.5246\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9769 - accuracy: 0.5277 - val_loss: 0.9693 - val_accuracy: 0.5237\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9769 - accuracy: 0.5291 - val_loss: 0.9688 - val_accuracy: 0.5250\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9768 - accuracy: 0.5282 - val_loss: 0.9692 - val_accuracy: 0.5237\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9688 - val_accuracy: 0.5250\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9694 - val_accuracy: 0.5232\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9770 - accuracy: 0.5276 - val_loss: 0.9692 - val_accuracy: 0.5232\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9770 - accuracy: 0.5291 - val_loss: 0.9687 - val_accuracy: 0.5237\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5271 - val_loss: 0.9693 - val_accuracy: 0.5237\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5285 - val_loss: 0.9694 - val_accuracy: 0.5232\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9773 - accuracy: 0.5294 - val_loss: 0.9690 - val_accuracy: 0.5237\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9689 - val_accuracy: 0.5237\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5293 - val_loss: 0.9687 - val_accuracy: 0.5250\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9769 - accuracy: 0.5282 - val_loss: 0.9691 - val_accuracy: 0.5232\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9770 - accuracy: 0.5285 - val_loss: 0.9690 - val_accuracy: 0.5246\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9770 - accuracy: 0.5272 - val_loss: 0.9692 - val_accuracy: 0.5241\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9768 - accuracy: 0.5291 - val_loss: 0.9691 - val_accuracy: 0.5237\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9775 - accuracy: 0.5288 - val_loss: 0.9689 - val_accuracy: 0.5250\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9769 - accuracy: 0.5285 - val_loss: 0.9695 - val_accuracy: 0.5241\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9776 - accuracy: 0.5268 - val_loss: 0.9698 - val_accuracy: 0.5246\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9769 - accuracy: 0.5280 - val_loss: 0.9696 - val_accuracy: 0.5246\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5283 - val_loss: 0.9695 - val_accuracy: 0.5246\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9768 - accuracy: 0.5276 - val_loss: 0.9698 - val_accuracy: 0.5259\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9770 - accuracy: 0.5288 - val_loss: 0.9693 - val_accuracy: 0.5232\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9773 - accuracy: 0.5287 - val_loss: 0.9696 - val_accuracy: 0.5246\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5296 - val_loss: 0.9693 - val_accuracy: 0.5250\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9768 - accuracy: 0.5272 - val_loss: 0.9690 - val_accuracy: 0.5237\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9779 - accuracy: 0.5252 - val_loss: 0.9696 - val_accuracy: 0.5224\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9771 - accuracy: 0.5265 - val_loss: 0.9694 - val_accuracy: 0.5237\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9690 - val_accuracy: 0.5224\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 625us/step - loss: 0.9766 - accuracy: 0.5286 - val_loss: 0.9690 - val_accuracy: 0.5250\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5280 - val_loss: 0.9691 - val_accuracy: 0.5250\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9769 - accuracy: 0.5301 - val_loss: 0.9693 - val_accuracy: 0.5241\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9767 - accuracy: 0.5272 - val_loss: 0.9694 - val_accuracy: 0.5246\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9769 - accuracy: 0.5283 - val_loss: 0.9696 - val_accuracy: 0.5259\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5282 - val_loss: 0.9691 - val_accuracy: 0.5237\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9690 - val_accuracy: 0.5241\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9768 - accuracy: 0.5285 - val_loss: 0.9693 - val_accuracy: 0.5259\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5294 - val_loss: 0.9695 - val_accuracy: 0.5246\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9768 - accuracy: 0.5294 - val_loss: 0.9689 - val_accuracy: 0.5237\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9767 - accuracy: 0.5293 - val_loss: 0.9690 - val_accuracy: 0.5232\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9769 - accuracy: 0.5300 - val_loss: 0.9692 - val_accuracy: 0.5246\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9778 - accuracy: 0.5271 - val_loss: 0.9695 - val_accuracy: 0.5241\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5283 - val_loss: 0.9696 - val_accuracy: 0.5232\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9767 - accuracy: 0.5283 - val_loss: 0.9695 - val_accuracy: 0.5232\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9768 - accuracy: 0.5292 - val_loss: 0.9696 - val_accuracy: 0.5232\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9768 - accuracy: 0.5282 - val_loss: 0.9693 - val_accuracy: 0.5232\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 0.9694 - val_accuracy: 0.5232\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9768 - accuracy: 0.5274 - val_loss: 0.9692 - val_accuracy: 0.5232\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9768 - accuracy: 0.5293 - val_loss: 0.9688 - val_accuracy: 0.5241\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9768 - accuracy: 0.5286 - val_loss: 0.9688 - val_accuracy: 0.5237\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9767 - accuracy: 0.5298 - val_loss: 0.9695 - val_accuracy: 0.5232\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9770 - accuracy: 0.5287 - val_loss: 0.9692 - val_accuracy: 0.5232\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9768 - accuracy: 0.5289 - val_loss: 0.9694 - val_accuracy: 0.5259\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9769 - accuracy: 0.5301 - val_loss: 0.9689 - val_accuracy: 0.5241\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9770 - accuracy: 0.5277 - val_loss: 0.9690 - val_accuracy: 0.5241\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9687 - val_accuracy: 0.5246\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9770 - accuracy: 0.5276 - val_loss: 0.9688 - val_accuracy: 0.5250\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9767 - accuracy: 0.5299 - val_loss: 0.9690 - val_accuracy: 0.5250\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9770 - accuracy: 0.5274 - val_loss: 0.9689 - val_accuracy: 0.5237\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9768 - accuracy: 0.5301 - val_loss: 0.9697 - val_accuracy: 0.5259\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9768 - accuracy: 0.5295 - val_loss: 0.9690 - val_accuracy: 0.5237\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9768 - accuracy: 0.5301 - val_loss: 0.9689 - val_accuracy: 0.5241\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9768 - accuracy: 0.5293 - val_loss: 0.9699 - val_accuracy: 0.5259\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9770 - accuracy: 0.5288 - val_loss: 0.9691 - val_accuracy: 0.5232\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9766 - accuracy: 0.5294 - val_loss: 0.9689 - val_accuracy: 0.5241\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9768 - accuracy: 0.5280 - val_loss: 0.9692 - val_accuracy: 0.5259\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5295 - val_loss: 0.9692 - val_accuracy: 0.5232\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9777 - accuracy: 0.5297 - val_loss: 0.9688 - val_accuracy: 0.5237\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9768 - accuracy: 0.5279 - val_loss: 0.9693 - val_accuracy: 0.5259\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9769 - accuracy: 0.5302 - val_loss: 0.9691 - val_accuracy: 0.5232\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9769 - accuracy: 0.5299 - val_loss: 0.9689 - val_accuracy: 0.5237\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9769 - accuracy: 0.5286 - val_loss: 0.9699 - val_accuracy: 0.5281\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9770 - accuracy: 0.5293 - val_loss: 0.9689 - val_accuracy: 0.5237\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9690 - val_accuracy: 0.5228\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9768 - accuracy: 0.5286 - val_loss: 0.9697 - val_accuracy: 0.5263\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9770 - accuracy: 0.5299 - val_loss: 0.9694 - val_accuracy: 0.5232\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9691 - val_accuracy: 0.5232\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5304 - val_loss: 0.9690 - val_accuracy: 0.5246\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9768 - accuracy: 0.5285 - val_loss: 0.9690 - val_accuracy: 0.5237\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9768 - accuracy: 0.5286 - val_loss: 0.9691 - val_accuracy: 0.5237\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9692 - val_accuracy: 0.5232\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9768 - accuracy: 0.5301 - val_loss: 0.9688 - val_accuracy: 0.5246\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9780 - accuracy: 0.5297 - val_loss: 0.9692 - val_accuracy: 0.5250\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9767 - accuracy: 0.5277 - val_loss: 0.9691 - val_accuracy: 0.5241\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9770 - accuracy: 0.5297 - val_loss: 0.9694 - val_accuracy: 0.5241\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 641us/step - loss: 0.9768 - accuracy: 0.5274 - val_loss: 0.9690 - val_accuracy: 0.5241\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5267 - val_loss: 0.9692 - val_accuracy: 0.5250\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9766 - accuracy: 0.5272 - val_loss: 0.9701 - val_accuracy: 0.5232\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5299 - val_loss: 0.9689 - val_accuracy: 0.5246\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 337us/step - loss: 0.9764 - accuracy: 0.5280\n",
      "Accuracy : 0.5280086398124695\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9689 - accuracy: 0.5246\n",
      "Accuracy : 0.5245683789253235\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 2.0234 - accuracy: 0.5101 - val_loss: 1.8665 - val_accuracy: 0.5325\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 1.6245 - accuracy: 0.5193 - val_loss: 1.4488 - val_accuracy: 0.5325\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 1.2562 - accuracy: 0.5166 - val_loss: 1.1125 - val_accuracy: 0.5334\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0494 - accuracy: 0.5235 - val_loss: 0.9974 - val_accuracy: 0.5325\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 1.0028 - accuracy: 0.5304 - val_loss: 0.9760 - val_accuracy: 0.5356\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9921 - accuracy: 0.5299 - val_loss: 0.9679 - val_accuracy: 0.5347\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9861 - accuracy: 0.5297 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9825 - accuracy: 0.5290 - val_loss: 0.9617 - val_accuracy: 0.5321\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9804 - accuracy: 0.5288 - val_loss: 0.9616 - val_accuracy: 0.5321\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9793 - accuracy: 0.5271 - val_loss: 0.9604 - val_accuracy: 0.5317\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9788 - accuracy: 0.5281 - val_loss: 0.9617 - val_accuracy: 0.5321\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9781 - accuracy: 0.5285 - val_loss: 0.9624 - val_accuracy: 0.5277\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9778 - accuracy: 0.5282 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9778 - accuracy: 0.5278 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9776 - accuracy: 0.5286 - val_loss: 0.9630 - val_accuracy: 0.5286\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5275 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9777 - accuracy: 0.5292 - val_loss: 0.9641 - val_accuracy: 0.5317\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9776 - accuracy: 0.5291 - val_loss: 0.9647 - val_accuracy: 0.5277\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9774 - accuracy: 0.5279 - val_loss: 0.9646 - val_accuracy: 0.5321\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9773 - accuracy: 0.5279 - val_loss: 0.9646 - val_accuracy: 0.5321\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9773 - accuracy: 0.5280 - val_loss: 0.9647 - val_accuracy: 0.5321\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9646 - val_accuracy: 0.5321\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9775 - accuracy: 0.5278 - val_loss: 0.9642 - val_accuracy: 0.5321\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9776 - accuracy: 0.5287 - val_loss: 0.9633 - val_accuracy: 0.5299\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9779 - accuracy: 0.5283 - val_loss: 0.9646 - val_accuracy: 0.5299\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9772 - accuracy: 0.5278 - val_loss: 0.9644 - val_accuracy: 0.5277\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9772 - accuracy: 0.5284 - val_loss: 0.9645 - val_accuracy: 0.5299\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9773 - accuracy: 0.5286 - val_loss: 0.9640 - val_accuracy: 0.5321\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9775 - accuracy: 0.5292 - val_loss: 0.9659 - val_accuracy: 0.5321\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9773 - accuracy: 0.5284 - val_loss: 0.9646 - val_accuracy: 0.5277\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9774 - accuracy: 0.5280 - val_loss: 0.9641 - val_accuracy: 0.5321\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9776 - accuracy: 0.5294 - val_loss: 0.9638 - val_accuracy: 0.5277\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9776 - accuracy: 0.5282 - val_loss: 0.9640 - val_accuracy: 0.5321\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9624 - val_accuracy: 0.5317\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 0.9635 - val_accuracy: 0.5321\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5291 - val_loss: 0.9646 - val_accuracy: 0.5263\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9772 - accuracy: 0.5267 - val_loss: 0.9640 - val_accuracy: 0.5317\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9772 - accuracy: 0.5291 - val_loss: 0.9649 - val_accuracy: 0.5277\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9773 - accuracy: 0.5278 - val_loss: 0.9645 - val_accuracy: 0.5277\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9771 - accuracy: 0.5281 - val_loss: 0.9644 - val_accuracy: 0.5321\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9774 - accuracy: 0.5287 - val_loss: 0.9650 - val_accuracy: 0.5299\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9772 - accuracy: 0.5283 - val_loss: 0.9646 - val_accuracy: 0.5321\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9642 - val_accuracy: 0.5321\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9774 - accuracy: 0.5284 - val_loss: 0.9634 - val_accuracy: 0.5299\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9771 - accuracy: 0.5293 - val_loss: 0.9647 - val_accuracy: 0.5277\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9638 - val_accuracy: 0.5321\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9775 - accuracy: 0.5290 - val_loss: 0.9641 - val_accuracy: 0.5299\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9777 - accuracy: 0.5284 - val_loss: 0.9643 - val_accuracy: 0.5277\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9771 - accuracy: 0.5261 - val_loss: 0.9649 - val_accuracy: 0.5321\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9771 - accuracy: 0.5287 - val_loss: 0.9640 - val_accuracy: 0.5317\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9773 - accuracy: 0.5282 - val_loss: 0.9656 - val_accuracy: 0.5299\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 581us/step - loss: 0.9772 - accuracy: 0.5279 - val_loss: 0.9648 - val_accuracy: 0.5255\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9772 - accuracy: 0.5269 - val_loss: 0.9641 - val_accuracy: 0.5277\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9771 - accuracy: 0.5267 - val_loss: 0.9641 - val_accuracy: 0.5321\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9771 - accuracy: 0.5280 - val_loss: 0.9643 - val_accuracy: 0.5321\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9773 - accuracy: 0.5289 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9777 - accuracy: 0.5288 - val_loss: 0.9658 - val_accuracy: 0.5317\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9775 - accuracy: 0.5304 - val_loss: 0.9633 - val_accuracy: 0.5277\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9772 - accuracy: 0.5277 - val_loss: 0.9641 - val_accuracy: 0.5325\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9786 - accuracy: 0.5286 - val_loss: 0.9615 - val_accuracy: 0.5255\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9773 - accuracy: 0.5259 - val_loss: 0.9622 - val_accuracy: 0.5277\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9779 - accuracy: 0.5282 - val_loss: 0.9632 - val_accuracy: 0.5277\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9769 - accuracy: 0.5262 - val_loss: 0.9641 - val_accuracy: 0.5321\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9770 - accuracy: 0.5273 - val_loss: 0.9643 - val_accuracy: 0.5321\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 738us/step - loss: 0.9770 - accuracy: 0.5272 - val_loss: 0.9636 - val_accuracy: 0.5321\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9771 - accuracy: 0.5289 - val_loss: 0.9640 - val_accuracy: 0.5321\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9772 - accuracy: 0.5294 - val_loss: 0.9650 - val_accuracy: 0.5255\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 744us/step - loss: 0.9772 - accuracy: 0.5264 - val_loss: 0.9638 - val_accuracy: 0.5317\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9772 - accuracy: 0.5282 - val_loss: 0.9636 - val_accuracy: 0.5277\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5272 - val_loss: 0.9640 - val_accuracy: 0.5321\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9771 - accuracy: 0.5289 - val_loss: 0.9643 - val_accuracy: 0.5317\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5299 - val_loss: 0.9647 - val_accuracy: 0.5299\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9771 - accuracy: 0.5297 - val_loss: 0.9646 - val_accuracy: 0.5317\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5294 - val_loss: 0.9638 - val_accuracy: 0.5255\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9779 - accuracy: 0.5245 - val_loss: 0.9634 - val_accuracy: 0.5277\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5255 - val_loss: 0.9625 - val_accuracy: 0.5263\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5264 - val_loss: 0.9624 - val_accuracy: 0.5259\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9775 - accuracy: 0.5257 - val_loss: 0.9628 - val_accuracy: 0.5277\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5273 - val_loss: 0.9627 - val_accuracy: 0.5321\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5275 - val_loss: 0.9636 - val_accuracy: 0.5299\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5279 - val_loss: 0.9635 - val_accuracy: 0.5299\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5281 - val_loss: 0.9636 - val_accuracy: 0.5321\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9770 - accuracy: 0.5267 - val_loss: 0.9634 - val_accuracy: 0.5321\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9774 - accuracy: 0.5281 - val_loss: 0.9626 - val_accuracy: 0.5321\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9771 - accuracy: 0.5281 - val_loss: 0.9631 - val_accuracy: 0.5321\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9650 - val_accuracy: 0.5321\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5284 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5280 - val_loss: 0.9644 - val_accuracy: 0.5317\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9771 - accuracy: 0.5292 - val_loss: 0.9651 - val_accuracy: 0.5317\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9770 - accuracy: 0.5269 - val_loss: 0.9645 - val_accuracy: 0.5321\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9770 - accuracy: 0.5281 - val_loss: 0.9643 - val_accuracy: 0.5321\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5291 - val_loss: 0.9637 - val_accuracy: 0.5259\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9776 - accuracy: 0.5278 - val_loss: 0.9624 - val_accuracy: 0.5321\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9794 - accuracy: 0.5286 - val_loss: 0.9607 - val_accuracy: 0.5263\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5263 - val_loss: 0.9613 - val_accuracy: 0.5321\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9775 - accuracy: 0.5294 - val_loss: 0.9618 - val_accuracy: 0.5259\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9771 - accuracy: 0.5261 - val_loss: 0.9617 - val_accuracy: 0.5277\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5274 - val_loss: 0.9619 - val_accuracy: 0.5277\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5278 - val_loss: 0.9634 - val_accuracy: 0.5277\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5273 - val_loss: 0.9629 - val_accuracy: 0.5277\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5273 - val_loss: 0.9632 - val_accuracy: 0.5308\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5282 - val_loss: 0.9642 - val_accuracy: 0.5277\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9770 - accuracy: 0.5287 - val_loss: 0.9642 - val_accuracy: 0.5277\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9768 - accuracy: 0.5275 - val_loss: 0.9641 - val_accuracy: 0.5321\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9770 - accuracy: 0.5287 - val_loss: 0.9650 - val_accuracy: 0.5277\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5272 - val_loss: 0.9643 - val_accuracy: 0.5277\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9769 - accuracy: 0.5257 - val_loss: 0.9639 - val_accuracy: 0.5321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9771 - accuracy: 0.5290 - val_loss: 0.9651 - val_accuracy: 0.5277\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9773 - accuracy: 0.5284 - val_loss: 0.9654 - val_accuracy: 0.5277\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5288 - val_loss: 0.9647 - val_accuracy: 0.5321\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9785 - accuracy: 0.5287 - val_loss: 0.9659 - val_accuracy: 0.5277\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5266 - val_loss: 0.9660 - val_accuracy: 0.5263\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9771 - accuracy: 0.5262 - val_loss: 0.9641 - val_accuracy: 0.5277\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5268 - val_loss: 0.9640 - val_accuracy: 0.5277\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5269 - val_loss: 0.9641 - val_accuracy: 0.5277\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5268 - val_loss: 0.9636 - val_accuracy: 0.5299\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5283 - val_loss: 0.9648 - val_accuracy: 0.5317\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9771 - accuracy: 0.5306 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5280 - val_loss: 0.9645 - val_accuracy: 0.5299\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5285 - val_loss: 0.9651 - val_accuracy: 0.5321\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5297 - val_loss: 0.9646 - val_accuracy: 0.5321\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5284 - val_loss: 0.9639 - val_accuracy: 0.5321\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9652 - val_accuracy: 0.5321\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5280 - val_loss: 0.9642 - val_accuracy: 0.5321\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9648 - val_accuracy: 0.5321\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9771 - accuracy: 0.5287 - val_loss: 0.9638 - val_accuracy: 0.5321\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9647 - val_accuracy: 0.5277\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9771 - accuracy: 0.5267 - val_loss: 0.9640 - val_accuracy: 0.5317\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9772 - accuracy: 0.5283 - val_loss: 0.9648 - val_accuracy: 0.5321\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5277 - val_loss: 0.9643 - val_accuracy: 0.5317\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9773 - accuracy: 0.5282 - val_loss: 0.9639 - val_accuracy: 0.5277\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9773 - accuracy: 0.5283 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5281 - val_loss: 0.9643 - val_accuracy: 0.5255\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9775 - accuracy: 0.5283 - val_loss: 0.9643 - val_accuracy: 0.5299\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5277 - val_loss: 0.9645 - val_accuracy: 0.5321\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 658us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9655 - val_accuracy: 0.5299\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9769 - accuracy: 0.5282 - val_loss: 0.9649 - val_accuracy: 0.5321\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9770 - accuracy: 0.5281 - val_loss: 0.9645 - val_accuracy: 0.5321\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9771 - accuracy: 0.5288 - val_loss: 0.9658 - val_accuracy: 0.5317\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9646 - val_accuracy: 0.5317\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9779 - accuracy: 0.5281 - val_loss: 0.9638 - val_accuracy: 0.5299\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9772 - accuracy: 0.5273 - val_loss: 0.9633 - val_accuracy: 0.5321\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5297 - val_loss: 0.9637 - val_accuracy: 0.5299\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9770 - accuracy: 0.5287 - val_loss: 0.9638 - val_accuracy: 0.5299\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 449us/step - loss: 0.9770 - accuracy: 0.5287 - val_loss: 0.9636 - val_accuracy: 0.5317\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 779us/step - loss: 0.9772 - accuracy: 0.5286 - val_loss: 0.9644 - val_accuracy: 0.5321\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5303 - val_loss: 0.9635 - val_accuracy: 0.5321\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9635 - val_accuracy: 0.5321\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9771 - accuracy: 0.5282 - val_loss: 0.9646 - val_accuracy: 0.5321\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5283 - val_loss: 0.9640 - val_accuracy: 0.5299\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9626 - val_accuracy: 0.5321\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9633 - val_accuracy: 0.5299\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5278 - val_loss: 0.9646 - val_accuracy: 0.5277\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9770 - accuracy: 0.5291 - val_loss: 0.9642 - val_accuracy: 0.5321\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9769 - accuracy: 0.5293 - val_loss: 0.9642 - val_accuracy: 0.5321\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5278 - val_loss: 0.9653 - val_accuracy: 0.5259\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5271 - val_loss: 0.9642 - val_accuracy: 0.5299\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5277 - val_loss: 0.9645 - val_accuracy: 0.5317\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9771 - accuracy: 0.5294 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9785 - accuracy: 0.5287 - val_loss: 0.9653 - val_accuracy: 0.5277\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9770 - accuracy: 0.5275 - val_loss: 0.9644 - val_accuracy: 0.5299\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9770 - accuracy: 0.5291 - val_loss: 0.9657 - val_accuracy: 0.5277\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5275 - val_loss: 0.9644 - val_accuracy: 0.5321\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9657 - val_accuracy: 0.5321\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5286 - val_loss: 0.9643 - val_accuracy: 0.5277\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5284 - val_loss: 0.9648 - val_accuracy: 0.5321\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9770 - accuracy: 0.5299 - val_loss: 0.9641 - val_accuracy: 0.5277\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9770 - accuracy: 0.5276 - val_loss: 0.9638 - val_accuracy: 0.5299\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5278 - val_loss: 0.9645 - val_accuracy: 0.5321\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5299 - val_loss: 0.9645 - val_accuracy: 0.5321\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9770 - accuracy: 0.5272 - val_loss: 0.9660 - val_accuracy: 0.5321\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9770 - accuracy: 0.5295 - val_loss: 0.9643 - val_accuracy: 0.5277\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9771 - accuracy: 0.5282 - val_loss: 0.9641 - val_accuracy: 0.5321\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5294 - val_loss: 0.9641 - val_accuracy: 0.5321\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5289 - val_loss: 0.9657 - val_accuracy: 0.5321\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5296 - val_loss: 0.9641 - val_accuracy: 0.5321\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9779 - accuracy: 0.5273 - val_loss: 0.9631 - val_accuracy: 0.5325\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9782 - accuracy: 0.5285 - val_loss: 0.9614 - val_accuracy: 0.5317\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9781 - accuracy: 0.5290 - val_loss: 0.9616 - val_accuracy: 0.5277\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9770 - accuracy: 0.5294 - val_loss: 0.9638 - val_accuracy: 0.5259\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9771 - accuracy: 0.5267 - val_loss: 0.9626 - val_accuracy: 0.5277\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9770 - accuracy: 0.5271 - val_loss: 0.9638 - val_accuracy: 0.5317\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9768 - accuracy: 0.5298 - val_loss: 0.9644 - val_accuracy: 0.5277\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9648 - val_accuracy: 0.5321\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9641 - val_accuracy: 0.5321\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9646 - val_accuracy: 0.5321\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9768 - accuracy: 0.5288 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9781 - accuracy: 0.5294 - val_loss: 0.9647 - val_accuracy: 0.5321\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9771 - accuracy: 0.5276 - val_loss: 0.9661 - val_accuracy: 0.5299\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9770 - accuracy: 0.5282 - val_loss: 0.9650 - val_accuracy: 0.5321\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9769 - accuracy: 0.5276 - val_loss: 0.9645 - val_accuracy: 0.5321\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9770 - accuracy: 0.5295 - val_loss: 0.9645 - val_accuracy: 0.5317\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9769 - accuracy: 0.5307 - val_loss: 0.9646 - val_accuracy: 0.5277\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9773 - accuracy: 0.5287 - val_loss: 0.9652 - val_accuracy: 0.5321\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 0.9769 - accuracy: 0.5283 - val_loss: 0.9654 - val_accuracy: 0.5321\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9768 - accuracy: 0.5284 - val_loss: 0.9645 - val_accuracy: 0.5321\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9770 - accuracy: 0.5299 - val_loss: 0.9650 - val_accuracy: 0.5277\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9772 - accuracy: 0.5272 - val_loss: 0.9641 - val_accuracy: 0.5321\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 334us/step - loss: 0.9767 - accuracy: 0.5288\n",
      "Accuracy : 0.5287955403327942\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9641 - accuracy: 0.5321\n",
      "Accuracy : 0.5320938229560852\n",
      "\n",
      "The final train accuracy is:0.5287122249603271 \n",
      "\n",
      "The final test accuracy is:0.5289483904838562 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"IW.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data = np.array(df.iloc[:,0:3])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "    \n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "    \n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (3,1)),\n",
    "        keras.layers.Dense(3,activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels,batch_size = 221, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "advised-colon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "resident-station",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demonstrated-admission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-appendix",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
