{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "associate-viking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1.1784 - accuracy: 0.4599 - val_loss: 1.1211 - val_accuracy: 0.4624\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 706us/step - loss: 1.0911 - accuracy: 0.4670 - val_loss: 1.0625 - val_accuracy: 0.4743\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 1.0486 - accuracy: 0.4669 - val_loss: 1.0364 - val_accuracy: 0.4695\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 1.0288 - accuracy: 0.4596 - val_loss: 1.0241 - val_accuracy: 0.4469\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0184 - accuracy: 0.4569 - val_loss: 1.0180 - val_accuracy: 0.4500\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0131 - accuracy: 0.4559 - val_loss: 1.0153 - val_accuracy: 0.4509\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0104 - accuracy: 0.4542 - val_loss: 1.0139 - val_accuracy: 0.4504\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.0088 - accuracy: 0.4563 - val_loss: 1.0128 - val_accuracy: 0.4509\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0076 - accuracy: 0.4560 - val_loss: 1.0118 - val_accuracy: 0.4513\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 1.0062 - accuracy: 0.4577 - val_loss: 1.0105 - val_accuracy: 0.4549\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0043 - accuracy: 0.4634 - val_loss: 1.0088 - val_accuracy: 0.4628\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 1.0018 - accuracy: 0.4741 - val_loss: 1.0071 - val_accuracy: 0.4761\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9993 - accuracy: 0.4945 - val_loss: 1.0053 - val_accuracy: 0.5088\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9975 - accuracy: 0.5190 - val_loss: 1.0035 - val_accuracy: 0.5190\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9960 - accuracy: 0.5264 - val_loss: 1.0023 - val_accuracy: 0.5190\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9948 - accuracy: 0.5280 - val_loss: 1.0010 - val_accuracy: 0.5195\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9936 - accuracy: 0.5275 - val_loss: 0.9997 - val_accuracy: 0.5199\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9925 - accuracy: 0.5283 - val_loss: 0.9985 - val_accuracy: 0.5190\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 538us/step - loss: 0.9914 - accuracy: 0.5281 - val_loss: 0.9972 - val_accuracy: 0.5181\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9903 - accuracy: 0.5264 - val_loss: 0.9960 - val_accuracy: 0.5181\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9889 - accuracy: 0.5269 - val_loss: 0.9945 - val_accuracy: 0.5190\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 0.9874 - accuracy: 0.5278 - val_loss: 0.9931 - val_accuracy: 0.5181\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9856 - accuracy: 0.5274 - val_loss: 0.9917 - val_accuracy: 0.5181\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9839 - accuracy: 0.5271 - val_loss: 0.9907 - val_accuracy: 0.5181\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9826 - accuracy: 0.5275 - val_loss: 0.9901 - val_accuracy: 0.5181\n",
      "Epoch 26/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9817 - accuracy: 0.5271 - val_loss: 0.9898 - val_accuracy: 0.5181\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9811 - accuracy: 0.5274 - val_loss: 0.9896 - val_accuracy: 0.5190\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9807 - accuracy: 0.5279 - val_loss: 0.9894 - val_accuracy: 0.5190\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9804 - accuracy: 0.5263 - val_loss: 0.9893 - val_accuracy: 0.5199\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9800 - accuracy: 0.5280 - val_loss: 0.9891 - val_accuracy: 0.5190\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9797 - accuracy: 0.5276 - val_loss: 0.9890 - val_accuracy: 0.5186\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9795 - accuracy: 0.5275 - val_loss: 0.9890 - val_accuracy: 0.5190\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9793 - accuracy: 0.5282 - val_loss: 0.9888 - val_accuracy: 0.5190\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9791 - accuracy: 0.5276 - val_loss: 0.9887 - val_accuracy: 0.5190\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 532us/step - loss: 0.9789 - accuracy: 0.5279 - val_loss: 0.9887 - val_accuracy: 0.5195\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9786 - accuracy: 0.5279 - val_loss: 0.9886 - val_accuracy: 0.5190\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9785 - accuracy: 0.5278 - val_loss: 0.9885 - val_accuracy: 0.5195\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9784 - accuracy: 0.5281 - val_loss: 0.9886 - val_accuracy: 0.5195\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9782 - accuracy: 0.5276 - val_loss: 0.9883 - val_accuracy: 0.5195\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 572us/step - loss: 0.9781 - accuracy: 0.5281 - val_loss: 0.9884 - val_accuracy: 0.5190\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9780 - accuracy: 0.5277 - val_loss: 0.9882 - val_accuracy: 0.5195\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9779 - accuracy: 0.5287 - val_loss: 0.9882 - val_accuracy: 0.5195\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9777 - accuracy: 0.5280 - val_loss: 0.9884 - val_accuracy: 0.5195\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9777 - accuracy: 0.5277 - val_loss: 0.9881 - val_accuracy: 0.5190\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 590us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9880 - val_accuracy: 0.5190\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 547us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9878 - val_accuracy: 0.5190\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9879 - val_accuracy: 0.5190\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9878 - val_accuracy: 0.5199\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9771 - accuracy: 0.5286 - val_loss: 0.9878 - val_accuracy: 0.5190\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9770 - accuracy: 0.5291 - val_loss: 0.9875 - val_accuracy: 0.5190\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9875 - val_accuracy: 0.5199\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9768 - accuracy: 0.5282 - val_loss: 0.9876 - val_accuracy: 0.5190\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9767 - accuracy: 0.5284 - val_loss: 0.9875 - val_accuracy: 0.5190\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9767 - accuracy: 0.5286 - val_loss: 0.9872 - val_accuracy: 0.5199\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9872 - val_accuracy: 0.5190\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9765 - accuracy: 0.5286 - val_loss: 0.9871 - val_accuracy: 0.5199\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9764 - accuracy: 0.5284 - val_loss: 0.9871 - val_accuracy: 0.5190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9762 - accuracy: 0.5292 - val_loss: 0.9870 - val_accuracy: 0.5190\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9762 - accuracy: 0.5293 - val_loss: 0.9871 - val_accuracy: 0.5190\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9762 - accuracy: 0.5295 - val_loss: 0.9869 - val_accuracy: 0.5190\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9760 - accuracy: 0.5292 - val_loss: 0.9867 - val_accuracy: 0.5204\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9760 - accuracy: 0.5296 - val_loss: 0.9867 - val_accuracy: 0.5195\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9759 - accuracy: 0.5294 - val_loss: 0.9867 - val_accuracy: 0.5190\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9758 - accuracy: 0.5288 - val_loss: 0.9865 - val_accuracy: 0.5212\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9757 - accuracy: 0.5290 - val_loss: 0.9866 - val_accuracy: 0.5190\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 542us/step - loss: 0.9757 - accuracy: 0.5286 - val_loss: 0.9867 - val_accuracy: 0.5190\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9755 - accuracy: 0.5295 - val_loss: 0.9868 - val_accuracy: 0.5190\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9865 - val_accuracy: 0.5190\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9754 - accuracy: 0.5287 - val_loss: 0.9861 - val_accuracy: 0.5212\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9753 - accuracy: 0.5290 - val_loss: 0.9862 - val_accuracy: 0.5190\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9754 - accuracy: 0.5289 - val_loss: 0.9863 - val_accuracy: 0.5190\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9753 - accuracy: 0.5293 - val_loss: 0.9862 - val_accuracy: 0.5195\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 604us/step - loss: 0.9753 - accuracy: 0.5301 - val_loss: 0.9861 - val_accuracy: 0.5190\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9751 - accuracy: 0.5297 - val_loss: 0.9859 - val_accuracy: 0.5217\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9751 - accuracy: 0.5291 - val_loss: 0.9858 - val_accuracy: 0.5208\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9859 - val_accuracy: 0.5217\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 0.9749 - accuracy: 0.5291 - val_loss: 0.9859 - val_accuracy: 0.5217\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9748 - accuracy: 0.5294 - val_loss: 0.9857 - val_accuracy: 0.5204\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 604us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 0.9857 - val_accuracy: 0.5199\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9747 - accuracy: 0.5296 - val_loss: 0.9857 - val_accuracy: 0.5204\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9746 - accuracy: 0.5296 - val_loss: 0.9855 - val_accuracy: 0.5217\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9854 - val_accuracy: 0.5217\n",
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 0.9745 - accuracy: 0.5293 - val_loss: 0.9855 - val_accuracy: 0.5208\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 538us/step - loss: 0.9745 - accuracy: 0.5309 - val_loss: 0.9854 - val_accuracy: 0.5212\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9745 - accuracy: 0.5295 - val_loss: 0.9854 - val_accuracy: 0.5204\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9744 - accuracy: 0.5301 - val_loss: 0.9853 - val_accuracy: 0.5204\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9743 - accuracy: 0.5324 - val_loss: 0.9853 - val_accuracy: 0.5217\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9742 - accuracy: 0.5296 - val_loss: 0.9852 - val_accuracy: 0.5204\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9742 - accuracy: 0.5300 - val_loss: 0.9851 - val_accuracy: 0.5204\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9741 - accuracy: 0.5294 - val_loss: 0.9851 - val_accuracy: 0.5217\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9742 - accuracy: 0.5315 - val_loss: 0.9850 - val_accuracy: 0.5204\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9740 - accuracy: 0.5311 - val_loss: 0.9849 - val_accuracy: 0.5226\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9740 - accuracy: 0.5315 - val_loss: 0.9848 - val_accuracy: 0.5204\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9739 - accuracy: 0.5293 - val_loss: 0.9849 - val_accuracy: 0.5212\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9739 - accuracy: 0.5306 - val_loss: 0.9848 - val_accuracy: 0.5217\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9739 - accuracy: 0.5304 - val_loss: 0.9849 - val_accuracy: 0.5270\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9738 - accuracy: 0.5320 - val_loss: 0.9847 - val_accuracy: 0.5204\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9737 - accuracy: 0.5311 - val_loss: 0.9847 - val_accuracy: 0.5204\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 0.9846 - val_accuracy: 0.5261\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9737 - accuracy: 0.5314 - val_loss: 0.9845 - val_accuracy: 0.5239\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9844 - val_accuracy: 0.5239\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9846 - val_accuracy: 0.5212\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9735 - accuracy: 0.5322 - val_loss: 0.9844 - val_accuracy: 0.5239\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9736 - accuracy: 0.5305 - val_loss: 0.9844 - val_accuracy: 0.5239\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 589us/step - loss: 0.9734 - accuracy: 0.5314 - val_loss: 0.9844 - val_accuracy: 0.5212\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 595us/step - loss: 0.9734 - accuracy: 0.5316 - val_loss: 0.9843 - val_accuracy: 0.5217\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 540us/step - loss: 0.9733 - accuracy: 0.5313 - val_loss: 0.9842 - val_accuracy: 0.5257\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9734 - accuracy: 0.5311 - val_loss: 0.9842 - val_accuracy: 0.5199\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9733 - accuracy: 0.5327 - val_loss: 0.9841 - val_accuracy: 0.5261\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9732 - accuracy: 0.5317 - val_loss: 0.9844 - val_accuracy: 0.5217\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9732 - accuracy: 0.5318 - val_loss: 0.9840 - val_accuracy: 0.5261\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 0.9732 - accuracy: 0.5302 - val_loss: 0.9844 - val_accuracy: 0.5212\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9731 - accuracy: 0.5305 - val_loss: 0.9840 - val_accuracy: 0.5261\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 0.9840 - val_accuracy: 0.5257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9731 - accuracy: 0.5313 - val_loss: 0.9839 - val_accuracy: 0.5261\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9730 - accuracy: 0.5319 - val_loss: 0.9839 - val_accuracy: 0.5261\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9730 - accuracy: 0.5317 - val_loss: 0.9838 - val_accuracy: 0.5243\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9729 - accuracy: 0.5318 - val_loss: 0.9838 - val_accuracy: 0.5261\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9729 - accuracy: 0.5321 - val_loss: 0.9837 - val_accuracy: 0.5274\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9729 - accuracy: 0.5317 - val_loss: 0.9837 - val_accuracy: 0.5265\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9729 - accuracy: 0.5327 - val_loss: 0.9836 - val_accuracy: 0.5274\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9728 - accuracy: 0.5325 - val_loss: 0.9837 - val_accuracy: 0.5257\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9728 - accuracy: 0.5317 - val_loss: 0.9836 - val_accuracy: 0.5265\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 607us/step - loss: 0.9728 - accuracy: 0.5314 - val_loss: 0.9835 - val_accuracy: 0.5265\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9728 - accuracy: 0.5320 - val_loss: 0.9835 - val_accuracy: 0.5252\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9727 - accuracy: 0.5317 - val_loss: 0.9835 - val_accuracy: 0.5265\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9727 - accuracy: 0.5328 - val_loss: 0.9835 - val_accuracy: 0.5261\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9726 - accuracy: 0.5323 - val_loss: 0.9834 - val_accuracy: 0.5257\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9726 - accuracy: 0.5319 - val_loss: 0.9834 - val_accuracy: 0.5257\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9725 - accuracy: 0.5325 - val_loss: 0.9834 - val_accuracy: 0.5270\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9727 - accuracy: 0.5331 - val_loss: 0.9833 - val_accuracy: 0.5270\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9724 - accuracy: 0.5314 - val_loss: 0.9834 - val_accuracy: 0.5230\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9725 - accuracy: 0.5317 - val_loss: 0.9835 - val_accuracy: 0.5217\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9725 - accuracy: 0.5325 - val_loss: 0.9833 - val_accuracy: 0.5261\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 572us/step - loss: 0.9724 - accuracy: 0.5331 - val_loss: 0.9832 - val_accuracy: 0.5279\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9724 - accuracy: 0.5326 - val_loss: 0.9832 - val_accuracy: 0.5252\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9723 - accuracy: 0.5323 - val_loss: 0.9832 - val_accuracy: 0.5279\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9724 - accuracy: 0.5327 - val_loss: 0.9832 - val_accuracy: 0.5261\n",
      "Epoch 139/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9723 - accuracy: 0.5324 - val_loss: 0.9830 - val_accuracy: 0.5270\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9723 - accuracy: 0.5333 - val_loss: 0.9830 - val_accuracy: 0.5283\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 0.9722 - accuracy: 0.5334 - val_loss: 0.9832 - val_accuracy: 0.5261\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 546us/step - loss: 0.9723 - accuracy: 0.5321 - val_loss: 0.9830 - val_accuracy: 0.5270\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9722 - accuracy: 0.5331 - val_loss: 0.9830 - val_accuracy: 0.5243\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9722 - accuracy: 0.5320 - val_loss: 0.9831 - val_accuracy: 0.5230\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9722 - accuracy: 0.5333 - val_loss: 0.9830 - val_accuracy: 0.5270\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9722 - accuracy: 0.5324 - val_loss: 0.9829 - val_accuracy: 0.5252\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9721 - accuracy: 0.5331 - val_loss: 0.9830 - val_accuracy: 0.5261\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 564us/step - loss: 0.9721 - accuracy: 0.5336 - val_loss: 0.9829 - val_accuracy: 0.5212\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9828 - val_accuracy: 0.5274\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9721 - accuracy: 0.5327 - val_loss: 0.9827 - val_accuracy: 0.5239\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9720 - accuracy: 0.5329 - val_loss: 0.9827 - val_accuracy: 0.5274\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9721 - accuracy: 0.5323 - val_loss: 0.9829 - val_accuracy: 0.5243\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9720 - accuracy: 0.5327 - val_loss: 0.9826 - val_accuracy: 0.5274\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 0.9719 - accuracy: 0.5326 - val_loss: 0.9827 - val_accuracy: 0.5235\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 532us/step - loss: 0.9720 - accuracy: 0.5328 - val_loss: 0.9826 - val_accuracy: 0.5265\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9719 - accuracy: 0.5334 - val_loss: 0.9830 - val_accuracy: 0.5270\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9719 - accuracy: 0.5325 - val_loss: 0.9827 - val_accuracy: 0.5217\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9719 - accuracy: 0.5322 - val_loss: 0.9829 - val_accuracy: 0.5270\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9719 - accuracy: 0.5327 - val_loss: 0.9827 - val_accuracy: 0.5265\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9719 - accuracy: 0.5326 - val_loss: 0.9826 - val_accuracy: 0.5230\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9719 - accuracy: 0.5332 - val_loss: 0.9826 - val_accuracy: 0.5217\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9719 - accuracy: 0.5320 - val_loss: 0.9826 - val_accuracy: 0.5221\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9718 - accuracy: 0.5334 - val_loss: 0.9827 - val_accuracy: 0.5230\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9719 - accuracy: 0.5334 - val_loss: 0.9826 - val_accuracy: 0.5217\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9718 - accuracy: 0.5327 - val_loss: 0.9825 - val_accuracy: 0.5265\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 568us/step - loss: 0.9717 - accuracy: 0.5334 - val_loss: 0.9824 - val_accuracy: 0.5261\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 534us/step - loss: 0.9718 - accuracy: 0.5329 - val_loss: 0.9827 - val_accuracy: 0.5261\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9717 - accuracy: 0.5322 - val_loss: 0.9824 - val_accuracy: 0.5221\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9717 - accuracy: 0.5335 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9717 - accuracy: 0.5333 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 554us/step - loss: 0.9717 - accuracy: 0.5324 - val_loss: 0.9824 - val_accuracy: 0.5261\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9717 - accuracy: 0.5329 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9716 - accuracy: 0.5327 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 572us/step - loss: 0.9716 - accuracy: 0.5327 - val_loss: 0.9825 - val_accuracy: 0.5265\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9716 - accuracy: 0.5337 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9716 - accuracy: 0.5329 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9716 - accuracy: 0.5340 - val_loss: 0.9822 - val_accuracy: 0.5248\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9716 - accuracy: 0.5329 - val_loss: 0.9824 - val_accuracy: 0.5221\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9715 - accuracy: 0.5328 - val_loss: 0.9823 - val_accuracy: 0.5270\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9715 - accuracy: 0.5329 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9715 - accuracy: 0.5328 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9716 - accuracy: 0.5328 - val_loss: 0.9821 - val_accuracy: 0.5248\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9714 - accuracy: 0.5332 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9716 - accuracy: 0.5329 - val_loss: 0.9821 - val_accuracy: 0.5248\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9715 - accuracy: 0.5321 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9715 - accuracy: 0.5332 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9714 - accuracy: 0.5335 - val_loss: 0.9821 - val_accuracy: 0.5257\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9714 - accuracy: 0.5327 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9715 - accuracy: 0.5336 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9714 - accuracy: 0.5338 - val_loss: 0.9820 - val_accuracy: 0.5221\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9714 - accuracy: 0.5336 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9714 - accuracy: 0.5330 - val_loss: 0.9820 - val_accuracy: 0.5261\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9714 - accuracy: 0.5334 - val_loss: 0.9819 - val_accuracy: 0.5226\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9713 - accuracy: 0.5332 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 195/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9714 - accuracy: 0.5329 - val_loss: 0.9821 - val_accuracy: 0.5221\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9714 - accuracy: 0.5337 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 537us/step - loss: 0.9713 - accuracy: 0.5322 - val_loss: 0.9819 - val_accuracy: 0.5226\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9713 - accuracy: 0.5328 - val_loss: 0.9819 - val_accuracy: 0.5257\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9713 - accuracy: 0.5334 - val_loss: 0.9819 - val_accuracy: 0.5226\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9713 - accuracy: 0.5331 - val_loss: 0.9819 - val_accuracy: 0.5252\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 333us/step - loss: 0.9712 - accuracy: 0.5331\n",
      "Accuracy : 0.5330513715744019\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9819 - accuracy: 0.5252\n",
      "Accuracy : 0.5252212285995483\n",
      "\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3642 - accuracy: 0.2530 - val_loss: 2.2578 - val_accuracy: 0.2531\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 1.9182 - accuracy: 0.2491 - val_loss: 1.8465 - val_accuracy: 0.2442\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.6075 - accuracy: 0.2464 - val_loss: 1.5526 - val_accuracy: 0.2403\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 1.3890 - accuracy: 0.2563 - val_loss: 1.3462 - val_accuracy: 0.2659\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.2411 - accuracy: 0.3012 - val_loss: 1.2149 - val_accuracy: 0.3013\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.1457 - accuracy: 0.3552 - val_loss: 1.1194 - val_accuracy: 0.3730\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0663 - accuracy: 0.4494 - val_loss: 1.0362 - val_accuracy: 0.4619\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0207 - accuracy: 0.4803 - val_loss: 1.0070 - val_accuracy: 0.4779\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 575us/step - loss: 1.0014 - accuracy: 0.4947 - val_loss: 0.9930 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9914 - accuracy: 0.5058 - val_loss: 0.9856 - val_accuracy: 0.5159\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9859 - accuracy: 0.5120 - val_loss: 0.9821 - val_accuracy: 0.5164\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9828 - accuracy: 0.5179 - val_loss: 0.9808 - val_accuracy: 0.5199\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9810 - accuracy: 0.5218 - val_loss: 0.9799 - val_accuracy: 0.5243\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 572us/step - loss: 0.9800 - accuracy: 0.5251 - val_loss: 0.9799 - val_accuracy: 0.5270\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 538us/step - loss: 0.9795 - accuracy: 0.5266 - val_loss: 0.9798 - val_accuracy: 0.5279\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9791 - accuracy: 0.5274 - val_loss: 0.9802 - val_accuracy: 0.5296\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9789 - accuracy: 0.5276 - val_loss: 0.9805 - val_accuracy: 0.5301\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9788 - accuracy: 0.5273 - val_loss: 0.9804 - val_accuracy: 0.5310\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9787 - accuracy: 0.5285 - val_loss: 0.9804 - val_accuracy: 0.5314\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9787 - accuracy: 0.5279 - val_loss: 0.9810 - val_accuracy: 0.5310\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9785 - accuracy: 0.5287 - val_loss: 0.9811 - val_accuracy: 0.5314\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9785 - accuracy: 0.5279 - val_loss: 0.9807 - val_accuracy: 0.5314\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9784 - accuracy: 0.5283 - val_loss: 0.9812 - val_accuracy: 0.5314\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9784 - accuracy: 0.5281 - val_loss: 0.9810 - val_accuracy: 0.5314\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9784 - accuracy: 0.5281 - val_loss: 0.9817 - val_accuracy: 0.5310\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 550us/step - loss: 0.9783 - accuracy: 0.5286 - val_loss: 0.9815 - val_accuracy: 0.5314\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9783 - accuracy: 0.5281 - val_loss: 0.9810 - val_accuracy: 0.5314\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9782 - accuracy: 0.5288 - val_loss: 0.9815 - val_accuracy: 0.5314\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9781 - accuracy: 0.5282 - val_loss: 0.9808 - val_accuracy: 0.5327\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9781 - accuracy: 0.5284 - val_loss: 0.9808 - val_accuracy: 0.5323\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9781 - accuracy: 0.5284 - val_loss: 0.9814 - val_accuracy: 0.5314\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9780 - accuracy: 0.5288 - val_loss: 0.9815 - val_accuracy: 0.5314\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9779 - accuracy: 0.5285 - val_loss: 0.9808 - val_accuracy: 0.5323\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9779 - accuracy: 0.5283 - val_loss: 0.9806 - val_accuracy: 0.5323\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9778 - accuracy: 0.5286 - val_loss: 0.9816 - val_accuracy: 0.5314\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 0.9779 - accuracy: 0.5289 - val_loss: 0.9809 - val_accuracy: 0.5323\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 645us/step - loss: 0.9778 - accuracy: 0.5287 - val_loss: 0.9811 - val_accuracy: 0.5319\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9778 - accuracy: 0.5287 - val_loss: 0.9809 - val_accuracy: 0.5327\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9778 - accuracy: 0.5292 - val_loss: 0.9806 - val_accuracy: 0.5319\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9776 - accuracy: 0.5287 - val_loss: 0.9813 - val_accuracy: 0.5314\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9776 - accuracy: 0.5291 - val_loss: 0.9807 - val_accuracy: 0.5323\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9813 - val_accuracy: 0.5323\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9776 - accuracy: 0.5280 - val_loss: 0.9803 - val_accuracy: 0.5314\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9774 - accuracy: 0.5289 - val_loss: 0.9805 - val_accuracy: 0.5323\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9775 - accuracy: 0.5290 - val_loss: 0.9809 - val_accuracy: 0.5319\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9813 - val_accuracy: 0.5314\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9775 - accuracy: 0.5288 - val_loss: 0.9809 - val_accuracy: 0.5314\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9773 - accuracy: 0.5282 - val_loss: 0.9809 - val_accuracy: 0.5319\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9772 - accuracy: 0.5293 - val_loss: 0.9809 - val_accuracy: 0.5323\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9773 - accuracy: 0.5290 - val_loss: 0.9812 - val_accuracy: 0.5314\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9797 - val_accuracy: 0.5314\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9772 - accuracy: 0.5284 - val_loss: 0.9803 - val_accuracy: 0.5323\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9771 - accuracy: 0.5297 - val_loss: 0.9812 - val_accuracy: 0.5314\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9797 - val_accuracy: 0.5319\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9771 - accuracy: 0.5294 - val_loss: 0.9800 - val_accuracy: 0.5319\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9805 - val_accuracy: 0.5319\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9769 - accuracy: 0.5290 - val_loss: 0.9801 - val_accuracy: 0.5319\n",
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9768 - accuracy: 0.5293 - val_loss: 0.9804 - val_accuracy: 0.5327\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9807 - val_accuracy: 0.5319\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9769 - accuracy: 0.5291 - val_loss: 0.9799 - val_accuracy: 0.5319\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9767 - accuracy: 0.5292 - val_loss: 0.9796 - val_accuracy: 0.5319\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9768 - accuracy: 0.5289 - val_loss: 0.9797 - val_accuracy: 0.5319\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9801 - val_accuracy: 0.5319\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9767 - accuracy: 0.5286 - val_loss: 0.9794 - val_accuracy: 0.5319\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9801 - val_accuracy: 0.5319\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 0.9766 - accuracy: 0.5283 - val_loss: 0.9796 - val_accuracy: 0.5319\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9802 - val_accuracy: 0.5319\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9765 - accuracy: 0.5287 - val_loss: 0.9796 - val_accuracy: 0.5319\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9765 - accuracy: 0.5293 - val_loss: 0.9801 - val_accuracy: 0.5319\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9764 - accuracy: 0.5293 - val_loss: 0.9791 - val_accuracy: 0.5314\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9764 - accuracy: 0.5298 - val_loss: 0.9793 - val_accuracy: 0.5319\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9763 - accuracy: 0.5291 - val_loss: 0.9790 - val_accuracy: 0.5319\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9762 - accuracy: 0.5293 - val_loss: 0.9795 - val_accuracy: 0.5319\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9762 - accuracy: 0.5289 - val_loss: 0.9789 - val_accuracy: 0.5327\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9763 - accuracy: 0.5297 - val_loss: 0.9791 - val_accuracy: 0.5319\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9761 - accuracy: 0.5290 - val_loss: 0.9798 - val_accuracy: 0.5319\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 579us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9790 - val_accuracy: 0.5319\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 547us/step - loss: 0.9761 - accuracy: 0.5297 - val_loss: 0.9789 - val_accuracy: 0.5319\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9761 - accuracy: 0.5289 - val_loss: 0.9787 - val_accuracy: 0.5327\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9789 - val_accuracy: 0.5323\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9759 - accuracy: 0.5298 - val_loss: 0.9785 - val_accuracy: 0.5332\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.9759 - accuracy: 0.5296 - val_loss: 0.9786 - val_accuracy: 0.5327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 568us/step - loss: 0.9759 - accuracy: 0.5295 - val_loss: 0.9783 - val_accuracy: 0.5332\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9758 - accuracy: 0.5293 - val_loss: 0.9786 - val_accuracy: 0.5314\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9758 - accuracy: 0.5297 - val_loss: 0.9787 - val_accuracy: 0.5314\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9781 - val_accuracy: 0.5336\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5293 - val_loss: 0.9781 - val_accuracy: 0.5336\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 605us/step - loss: 0.9757 - accuracy: 0.5294 - val_loss: 0.9783 - val_accuracy: 0.5332\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9785 - val_accuracy: 0.5314\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9755 - accuracy: 0.5296 - val_loss: 0.9783 - val_accuracy: 0.5332\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9784 - val_accuracy: 0.5314\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9755 - accuracy: 0.5300 - val_loss: 0.9779 - val_accuracy: 0.5332\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9783 - val_accuracy: 0.5314\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9781 - val_accuracy: 0.5327\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9782 - val_accuracy: 0.5314\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9754 - accuracy: 0.5296 - val_loss: 0.9782 - val_accuracy: 0.5341\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9755 - accuracy: 0.5296 - val_loss: 0.9773 - val_accuracy: 0.5332\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9754 - accuracy: 0.5299 - val_loss: 0.9776 - val_accuracy: 0.5332\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 540us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9774 - val_accuracy: 0.5332\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9779 - val_accuracy: 0.5327\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9752 - accuracy: 0.5300 - val_loss: 0.9774 - val_accuracy: 0.5332\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9776 - val_accuracy: 0.5327\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9751 - accuracy: 0.5296 - val_loss: 0.9772 - val_accuracy: 0.5332\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9773 - val_accuracy: 0.5332\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9781 - val_accuracy: 0.5314\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9751 - accuracy: 0.5303 - val_loss: 0.9775 - val_accuracy: 0.5332\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9750 - accuracy: 0.5299 - val_loss: 0.9772 - val_accuracy: 0.5332\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9749 - accuracy: 0.5298 - val_loss: 0.9772 - val_accuracy: 0.5332\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9748 - accuracy: 0.5302 - val_loss: 0.9772 - val_accuracy: 0.5336\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5299 - val_loss: 0.9778 - val_accuracy: 0.5319\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 579us/step - loss: 0.9750 - accuracy: 0.5300 - val_loss: 0.9775 - val_accuracy: 0.5332\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9748 - accuracy: 0.5294 - val_loss: 0.9781 - val_accuracy: 0.5323\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9748 - accuracy: 0.5298 - val_loss: 0.9771 - val_accuracy: 0.5327\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9748 - accuracy: 0.5299 - val_loss: 0.9770 - val_accuracy: 0.5336\n",
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9748 - accuracy: 0.5295 - val_loss: 0.9765 - val_accuracy: 0.5336\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9748 - accuracy: 0.5302 - val_loss: 0.9768 - val_accuracy: 0.5332\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 0.9747 - accuracy: 0.5307 - val_loss: 0.9769 - val_accuracy: 0.5336\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9747 - accuracy: 0.5305 - val_loss: 0.9777 - val_accuracy: 0.5327\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9767 - val_accuracy: 0.5332\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9746 - accuracy: 0.5306 - val_loss: 0.9765 - val_accuracy: 0.5332\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9746 - accuracy: 0.5299 - val_loss: 0.9764 - val_accuracy: 0.5332\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9746 - accuracy: 0.5296 - val_loss: 0.9772 - val_accuracy: 0.5327\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9769 - val_accuracy: 0.5327\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9768 - val_accuracy: 0.5327\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9743 - accuracy: 0.5300 - val_loss: 0.9770 - val_accuracy: 0.5327\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9745 - accuracy: 0.5305 - val_loss: 0.9768 - val_accuracy: 0.5336\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 564us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9760 - val_accuracy: 0.5332\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 541us/step - loss: 0.9743 - accuracy: 0.5301 - val_loss: 0.9763 - val_accuracy: 0.5332\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9744 - accuracy: 0.5300 - val_loss: 0.9763 - val_accuracy: 0.5336\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9743 - accuracy: 0.5312 - val_loss: 0.9771 - val_accuracy: 0.5327\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9746 - accuracy: 0.5302 - val_loss: 0.9767 - val_accuracy: 0.5327\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9743 - accuracy: 0.5309 - val_loss: 0.9772 - val_accuracy: 0.5327\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9743 - accuracy: 0.5302 - val_loss: 0.9761 - val_accuracy: 0.5332\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9743 - accuracy: 0.5300 - val_loss: 0.9764 - val_accuracy: 0.5336\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9743 - accuracy: 0.5298 - val_loss: 0.9764 - val_accuracy: 0.5336\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9743 - accuracy: 0.5302 - val_loss: 0.9760 - val_accuracy: 0.5332\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9762 - val_accuracy: 0.5332\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9740 - accuracy: 0.5298 - val_loss: 0.9758 - val_accuracy: 0.5336\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 550us/step - loss: 0.9742 - accuracy: 0.5310 - val_loss: 0.9758 - val_accuracy: 0.5332\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9741 - accuracy: 0.5300 - val_loss: 0.9760 - val_accuracy: 0.5332\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9739 - accuracy: 0.5309 - val_loss: 0.9762 - val_accuracy: 0.5332\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9741 - accuracy: 0.5312 - val_loss: 0.9758 - val_accuracy: 0.5336\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9739 - accuracy: 0.5305 - val_loss: 0.9774 - val_accuracy: 0.5319\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9741 - accuracy: 0.5301 - val_loss: 0.9759 - val_accuracy: 0.5332\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9739 - accuracy: 0.5291 - val_loss: 0.9757 - val_accuracy: 0.5336\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9739 - accuracy: 0.5308 - val_loss: 0.9755 - val_accuracy: 0.5336\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9739 - accuracy: 0.5301 - val_loss: 0.9760 - val_accuracy: 0.5336\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9740 - accuracy: 0.5300 - val_loss: 0.9770 - val_accuracy: 0.5323\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9740 - accuracy: 0.5304 - val_loss: 0.9764 - val_accuracy: 0.5327\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9739 - accuracy: 0.5306 - val_loss: 0.9760 - val_accuracy: 0.5332\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9737 - accuracy: 0.5303 - val_loss: 0.9755 - val_accuracy: 0.5336\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9759 - val_accuracy: 0.5332\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9737 - accuracy: 0.5301 - val_loss: 0.9755 - val_accuracy: 0.5327\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9738 - accuracy: 0.5300 - val_loss: 0.9759 - val_accuracy: 0.5336\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9738 - accuracy: 0.5304 - val_loss: 0.9754 - val_accuracy: 0.5332\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 0.9761 - val_accuracy: 0.5336\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9737 - accuracy: 0.5301 - val_loss: 0.9760 - val_accuracy: 0.5327\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.9736 - accuracy: 0.5306 - val_loss: 0.9756 - val_accuracy: 0.5327\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9738 - accuracy: 0.5310 - val_loss: 0.9754 - val_accuracy: 0.5327\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9736 - accuracy: 0.5309 - val_loss: 0.9755 - val_accuracy: 0.5341\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9736 - accuracy: 0.5306 - val_loss: 0.9753 - val_accuracy: 0.5332\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 598us/step - loss: 0.9736 - accuracy: 0.5310 - val_loss: 0.9757 - val_accuracy: 0.5332\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 582us/step - loss: 0.9736 - accuracy: 0.5303 - val_loss: 0.9755 - val_accuracy: 0.5327\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9736 - accuracy: 0.5299 - val_loss: 0.9759 - val_accuracy: 0.5327\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 624us/step - loss: 0.9735 - accuracy: 0.5305 - val_loss: 0.9759 - val_accuracy: 0.5336\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 589us/step - loss: 0.9734 - accuracy: 0.5297 - val_loss: 0.9750 - val_accuracy: 0.5336\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 579us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9756 - val_accuracy: 0.5327\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9735 - accuracy: 0.5313 - val_loss: 0.9757 - val_accuracy: 0.5332\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 590us/step - loss: 0.9736 - accuracy: 0.5306 - val_loss: 0.9749 - val_accuracy: 0.5341\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 575us/step - loss: 0.9735 - accuracy: 0.5299 - val_loss: 0.9750 - val_accuracy: 0.5332\n",
      "Epoch 171/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9734 - accuracy: 0.5307 - val_loss: 0.9750 - val_accuracy: 0.5332\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9734 - accuracy: 0.5298 - val_loss: 0.9749 - val_accuracy: 0.5332\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9734 - accuracy: 0.5303 - val_loss: 0.9755 - val_accuracy: 0.5327\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9734 - accuracy: 0.5307 - val_loss: 0.9748 - val_accuracy: 0.5336\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9734 - accuracy: 0.5309 - val_loss: 0.9753 - val_accuracy: 0.5332\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9736 - accuracy: 0.5305 - val_loss: 0.9750 - val_accuracy: 0.5332\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9733 - accuracy: 0.5301 - val_loss: 0.9748 - val_accuracy: 0.5336\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9732 - accuracy: 0.5317 - val_loss: 0.9757 - val_accuracy: 0.5336\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9732 - accuracy: 0.5312 - val_loss: 0.9753 - val_accuracy: 0.5332\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9732 - accuracy: 0.5305 - val_loss: 0.9749 - val_accuracy: 0.5332\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9733 - accuracy: 0.5305 - val_loss: 0.9746 - val_accuracy: 0.5350\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9734 - accuracy: 0.5309 - val_loss: 0.9747 - val_accuracy: 0.5336\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9750 - val_accuracy: 0.5327\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9733 - accuracy: 0.5307 - val_loss: 0.9751 - val_accuracy: 0.5327\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9732 - accuracy: 0.5299 - val_loss: 0.9748 - val_accuracy: 0.5336\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9732 - accuracy: 0.5305 - val_loss: 0.9749 - val_accuracy: 0.5327\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9732 - accuracy: 0.5310 - val_loss: 0.9748 - val_accuracy: 0.5350\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9732 - accuracy: 0.5311 - val_loss: 0.9756 - val_accuracy: 0.5336\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9732 - accuracy: 0.5315 - val_loss: 0.9746 - val_accuracy: 0.5350\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9730 - accuracy: 0.5304 - val_loss: 0.9746 - val_accuracy: 0.5341\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 614us/step - loss: 0.9733 - accuracy: 0.5299 - val_loss: 0.9748 - val_accuracy: 0.5332\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 603us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 0.9748 - val_accuracy: 0.5341\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 545us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9744 - val_accuracy: 0.5341\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 0.9765 - val_accuracy: 0.5327\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 554us/step - loss: 0.9734 - accuracy: 0.5310 - val_loss: 0.9743 - val_accuracy: 0.5358\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 581us/step - loss: 0.9731 - accuracy: 0.5313 - val_loss: 0.9748 - val_accuracy: 0.5332\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9730 - accuracy: 0.5300 - val_loss: 0.9748 - val_accuracy: 0.5332\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9730 - accuracy: 0.5312 - val_loss: 0.9744 - val_accuracy: 0.5341\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9730 - accuracy: 0.5307 - val_loss: 0.9745 - val_accuracy: 0.5341\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9730 - accuracy: 0.5314 - val_loss: 0.9745 - val_accuracy: 0.5341\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 332us/step - loss: 0.9729 - accuracy: 0.5313\n",
      "Accuracy : 0.5313299298286438\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9745 - accuracy: 0.5341\n",
      "Accuracy : 0.5340707898139954\n",
      "\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.5110 - accuracy: 0.2530 - val_loss: 1.2844 - val_accuracy: 0.2532\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 1.3634 - accuracy: 0.2464 - val_loss: 1.2042 - val_accuracy: 0.2284\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.2577 - accuracy: 0.2164 - val_loss: 1.1456 - val_accuracy: 0.2227\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.1877 - accuracy: 0.2133 - val_loss: 1.1215 - val_accuracy: 0.2253\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 1.1511 - accuracy: 0.2211 - val_loss: 1.1112 - val_accuracy: 0.2395\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.1330 - accuracy: 0.2278 - val_loss: 1.1052 - val_accuracy: 0.2523\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 1.1211 - accuracy: 0.2310 - val_loss: 1.1012 - val_accuracy: 0.2568\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.1130 - accuracy: 0.2328 - val_loss: 1.0981 - val_accuracy: 0.2559\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.1076 - accuracy: 0.2371 - val_loss: 1.0960 - val_accuracy: 0.2643\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.1037 - accuracy: 0.2476 - val_loss: 1.0943 - val_accuracy: 0.2722\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.1006 - accuracy: 0.2573 - val_loss: 1.0927 - val_accuracy: 0.2802\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.0978 - accuracy: 0.2685 - val_loss: 1.0912 - val_accuracy: 0.2842\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 1.0947 - accuracy: 0.2856 - val_loss: 1.0897 - val_accuracy: 0.2877\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0917 - accuracy: 0.2914 - val_loss: 1.0882 - val_accuracy: 0.2877\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 671us/step - loss: 1.0883 - accuracy: 0.2927 - val_loss: 1.0868 - val_accuracy: 0.2877\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.0856 - accuracy: 0.2933 - val_loss: 1.0853 - val_accuracy: 0.2877\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 1.0831 - accuracy: 0.2947 - val_loss: 1.0838 - val_accuracy: 0.2882\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.0813 - accuracy: 0.2962 - val_loss: 1.0828 - val_accuracy: 0.2886\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0800 - accuracy: 0.2973 - val_loss: 1.0821 - val_accuracy: 0.2891\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0788 - accuracy: 0.2987 - val_loss: 1.0813 - val_accuracy: 0.2900\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0778 - accuracy: 0.2999 - val_loss: 1.0807 - val_accuracy: 0.2900\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 1.0771 - accuracy: 0.3006 - val_loss: 1.0801 - val_accuracy: 0.2900\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 1.0765 - accuracy: 0.3014 - val_loss: 1.0798 - val_accuracy: 0.2900\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 1.0759 - accuracy: 0.3021 - val_loss: 1.0793 - val_accuracy: 0.2900\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0753 - accuracy: 0.3044 - val_loss: 1.0791 - val_accuracy: 0.2908\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 1.0748 - accuracy: 0.3067 - val_loss: 1.0787 - val_accuracy: 0.2908\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 1.0744 - accuracy: 0.3075 - val_loss: 1.0786 - val_accuracy: 0.2913\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0741 - accuracy: 0.3078 - val_loss: 1.0785 - val_accuracy: 0.2913\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0738 - accuracy: 0.3091 - val_loss: 1.0781 - val_accuracy: 0.2926\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 1.0735 - accuracy: 0.3160 - val_loss: 1.0779 - val_accuracy: 0.3041\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 1.0732 - accuracy: 0.3338 - val_loss: 1.0775 - val_accuracy: 0.3258\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0729 - accuracy: 0.3845 - val_loss: 1.0775 - val_accuracy: 0.3780\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 1.0726 - accuracy: 0.4111 - val_loss: 1.0772 - val_accuracy: 0.3980\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 1.0722 - accuracy: 0.4399 - val_loss: 1.0770 - val_accuracy: 0.4312\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0720 - accuracy: 0.4566 - val_loss: 1.0771 - val_accuracy: 0.4670\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0714 - accuracy: 0.4874 - val_loss: 1.0766 - val_accuracy: 0.4701\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0708 - accuracy: 0.5007 - val_loss: 1.0760 - val_accuracy: 0.5219\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 1.0701 - accuracy: 0.5284 - val_loss: 1.0751 - val_accuracy: 0.5228\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0686 - accuracy: 0.5285 - val_loss: 1.0733 - val_accuracy: 0.5228\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0658 - accuracy: 0.5308 - val_loss: 1.0695 - val_accuracy: 0.5122\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0585 - accuracy: 0.5203 - val_loss: 1.0579 - val_accuracy: 0.4905\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0327 - accuracy: 0.5165 - val_loss: 1.0314 - val_accuracy: 0.4905\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 1.0088 - accuracy: 0.5172 - val_loss: 1.0166 - val_accuracy: 0.4927\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9946 - accuracy: 0.5239 - val_loss: 1.0113 - val_accuracy: 0.5122\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9850 - accuracy: 0.5291 - val_loss: 1.0096 - val_accuracy: 0.5135\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9819 - accuracy: 0.5305 - val_loss: 1.0089 - val_accuracy: 0.5162\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9796 - accuracy: 0.5310 - val_loss: 1.0074 - val_accuracy: 0.5144\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9782 - accuracy: 0.5313 - val_loss: 1.0062 - val_accuracy: 0.5201\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9765 - accuracy: 0.5320 - val_loss: 1.0056 - val_accuracy: 0.5228\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 612us/step - loss: 0.9754 - accuracy: 0.5306 - val_loss: 1.0056 - val_accuracy: 0.5215\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9748 - accuracy: 0.5320 - val_loss: 1.0051 - val_accuracy: 0.5228\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9743 - accuracy: 0.5309 - val_loss: 1.0046 - val_accuracy: 0.5237\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9740 - accuracy: 0.5290 - val_loss: 1.0054 - val_accuracy: 0.5219\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9737 - accuracy: 0.5311 - val_loss: 1.0046 - val_accuracy: 0.5250\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9734 - accuracy: 0.5297 - val_loss: 1.0046 - val_accuracy: 0.5250\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9734 - accuracy: 0.5287 - val_loss: 1.0051 - val_accuracy: 0.5206\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9731 - accuracy: 0.5290 - val_loss: 1.0047 - val_accuracy: 0.5250\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9729 - accuracy: 0.5291 - val_loss: 1.0046 - val_accuracy: 0.5250\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9732 - accuracy: 0.5324 - val_loss: 1.0050 - val_accuracy: 0.5224\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9737 - accuracy: 0.5311 - val_loss: 1.0054 - val_accuracy: 0.5237\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9729 - accuracy: 0.5296 - val_loss: 1.0048 - val_accuracy: 0.5232\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9730 - accuracy: 0.5286 - val_loss: 1.0045 - val_accuracy: 0.5237\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9728 - accuracy: 0.5287 - val_loss: 1.0047 - val_accuracy: 0.5237\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9730 - accuracy: 0.5283 - val_loss: 1.0047 - val_accuracy: 0.5246\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9729 - accuracy: 0.5285 - val_loss: 1.0047 - val_accuracy: 0.5241\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9726 - accuracy: 0.5315 - val_loss: 1.0046 - val_accuracy: 0.5241\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9726 - accuracy: 0.5305 - val_loss: 1.0046 - val_accuracy: 0.5241\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 1.0042 - val_accuracy: 0.5250\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9725 - accuracy: 0.5287 - val_loss: 1.0044 - val_accuracy: 0.5237\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 664us/step - loss: 0.9724 - accuracy: 0.5302 - val_loss: 1.0040 - val_accuracy: 0.5237\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9728 - accuracy: 0.5290 - val_loss: 1.0037 - val_accuracy: 0.5255\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9724 - accuracy: 0.5286 - val_loss: 1.0039 - val_accuracy: 0.5246\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9724 - accuracy: 0.5325 - val_loss: 1.0039 - val_accuracy: 0.5250\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9728 - accuracy: 0.5293 - val_loss: 1.0044 - val_accuracy: 0.5246\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9723 - accuracy: 0.5319 - val_loss: 1.0041 - val_accuracy: 0.5255\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9723 - accuracy: 0.5302 - val_loss: 1.0041 - val_accuracy: 0.5246\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9723 - accuracy: 0.5295 - val_loss: 1.0041 - val_accuracy: 0.5246\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9723 - accuracy: 0.5317 - val_loss: 1.0038 - val_accuracy: 0.5259\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9722 - accuracy: 0.5310 - val_loss: 1.0036 - val_accuracy: 0.5232\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9722 - accuracy: 0.5308 - val_loss: 1.0036 - val_accuracy: 0.5232\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9722 - accuracy: 0.5294 - val_loss: 1.0041 - val_accuracy: 0.5246\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 1.0044 - val_accuracy: 0.5241\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9724 - accuracy: 0.5303 - val_loss: 1.0041 - val_accuracy: 0.5272\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9724 - accuracy: 0.5294 - val_loss: 1.0039 - val_accuracy: 0.5237\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9721 - accuracy: 0.5310 - val_loss: 1.0039 - val_accuracy: 0.5237\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9722 - accuracy: 0.5307 - val_loss: 1.0035 - val_accuracy: 0.5232\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9722 - accuracy: 0.5288 - val_loss: 1.0035 - val_accuracy: 0.5263\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9719 - accuracy: 0.5327 - val_loss: 1.0035 - val_accuracy: 0.5241\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9719 - accuracy: 0.5312 - val_loss: 1.0035 - val_accuracy: 0.5241\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9719 - accuracy: 0.5331 - val_loss: 1.0033 - val_accuracy: 0.5268\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9719 - accuracy: 0.5292 - val_loss: 1.0033 - val_accuracy: 0.5246\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9720 - accuracy: 0.5317 - val_loss: 1.0031 - val_accuracy: 0.5272\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9723 - accuracy: 0.5298 - val_loss: 1.0038 - val_accuracy: 0.5219\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9717 - accuracy: 0.5327 - val_loss: 1.0035 - val_accuracy: 0.5228\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9719 - accuracy: 0.5322 - val_loss: 1.0033 - val_accuracy: 0.5263\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9718 - accuracy: 0.5289 - val_loss: 1.0032 - val_accuracy: 0.5255\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9720 - accuracy: 0.5318 - val_loss: 1.0033 - val_accuracy: 0.5232\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9719 - accuracy: 0.5336 - val_loss: 1.0032 - val_accuracy: 0.5232\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9719 - accuracy: 0.5306 - val_loss: 1.0031 - val_accuracy: 0.5241\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9719 - accuracy: 0.5311 - val_loss: 1.0031 - val_accuracy: 0.5263\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9717 - accuracy: 0.5332 - val_loss: 1.0030 - val_accuracy: 0.5263\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9717 - accuracy: 0.5310 - val_loss: 1.0027 - val_accuracy: 0.5263\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9721 - accuracy: 0.5296 - val_loss: 1.0027 - val_accuracy: 0.5272\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9717 - accuracy: 0.5307 - val_loss: 1.0030 - val_accuracy: 0.5277\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9717 - accuracy: 0.5324 - val_loss: 1.0031 - val_accuracy: 0.5250\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9716 - accuracy: 0.5321 - val_loss: 1.0033 - val_accuracy: 0.5232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 563us/step - loss: 0.9716 - accuracy: 0.5326 - val_loss: 1.0031 - val_accuracy: 0.5246\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9716 - accuracy: 0.5331 - val_loss: 1.0031 - val_accuracy: 0.5232\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9716 - accuracy: 0.5329 - val_loss: 1.0028 - val_accuracy: 0.5250\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9718 - accuracy: 0.5307 - val_loss: 1.0027 - val_accuracy: 0.5263\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9716 - accuracy: 0.5300 - val_loss: 1.0030 - val_accuracy: 0.5237\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9716 - accuracy: 0.5313 - val_loss: 1.0028 - val_accuracy: 0.5272\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9715 - accuracy: 0.5299 - val_loss: 1.0027 - val_accuracy: 0.5268\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9714 - accuracy: 0.5313 - val_loss: 1.0026 - val_accuracy: 0.5268\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9715 - accuracy: 0.5332 - val_loss: 1.0025 - val_accuracy: 0.5272\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9714 - accuracy: 0.5312 - val_loss: 1.0024 - val_accuracy: 0.5263\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9714 - accuracy: 0.5332 - val_loss: 1.0028 - val_accuracy: 0.5241\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9713 - accuracy: 0.5328 - val_loss: 1.0026 - val_accuracy: 0.5259\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9714 - accuracy: 0.5332 - val_loss: 1.0028 - val_accuracy: 0.5228\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9714 - accuracy: 0.5330 - val_loss: 1.0029 - val_accuracy: 0.5246\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9712 - accuracy: 0.5323 - val_loss: 1.0027 - val_accuracy: 0.5250\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 565us/step - loss: 0.9713 - accuracy: 0.5315 - val_loss: 1.0028 - val_accuracy: 0.5232\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9713 - accuracy: 0.5317 - val_loss: 1.0026 - val_accuracy: 0.5237\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9717 - accuracy: 0.5310 - val_loss: 1.0030 - val_accuracy: 0.5219\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9713 - accuracy: 0.5324 - val_loss: 1.0029 - val_accuracy: 0.5232\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9713 - accuracy: 0.5325 - val_loss: 1.0025 - val_accuracy: 0.5237\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9712 - accuracy: 0.5312 - val_loss: 1.0022 - val_accuracy: 0.5277\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9714 - accuracy: 0.5305 - val_loss: 1.0025 - val_accuracy: 0.5263\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9712 - accuracy: 0.5336 - val_loss: 1.0025 - val_accuracy: 0.5250\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9714 - accuracy: 0.5313 - val_loss: 1.0024 - val_accuracy: 0.5277\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9712 - accuracy: 0.5319 - val_loss: 1.0027 - val_accuracy: 0.5228\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9711 - accuracy: 0.5334 - val_loss: 1.0026 - val_accuracy: 0.5237\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9715 - accuracy: 0.5311 - val_loss: 1.0030 - val_accuracy: 0.5224\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9712 - accuracy: 0.5331 - val_loss: 1.0026 - val_accuracy: 0.5237\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9711 - accuracy: 0.5323 - val_loss: 1.0023 - val_accuracy: 0.5268\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9712 - accuracy: 0.5329 - val_loss: 1.0022 - val_accuracy: 0.5259\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9714 - accuracy: 0.5308 - val_loss: 1.0023 - val_accuracy: 0.5277\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9710 - accuracy: 0.5329 - val_loss: 1.0024 - val_accuracy: 0.5255\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9711 - accuracy: 0.5327 - val_loss: 1.0024 - val_accuracy: 0.5277\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9713 - accuracy: 0.5333 - val_loss: 1.0024 - val_accuracy: 0.5263\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9711 - accuracy: 0.5327 - val_loss: 1.0021 - val_accuracy: 0.5268\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 749us/step - loss: 0.9710 - accuracy: 0.5326 - val_loss: 1.0022 - val_accuracy: 0.5263\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9711 - accuracy: 0.5313 - val_loss: 1.0020 - val_accuracy: 0.5268\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9709 - accuracy: 0.5336 - val_loss: 1.0021 - val_accuracy: 0.5246\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9710 - accuracy: 0.5325 - val_loss: 1.0022 - val_accuracy: 0.5263\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9710 - accuracy: 0.5333 - val_loss: 1.0023 - val_accuracy: 0.5246\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9709 - accuracy: 0.5333 - val_loss: 1.0023 - val_accuracy: 0.5246\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9712 - accuracy: 0.5331 - val_loss: 1.0026 - val_accuracy: 0.5246\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9709 - accuracy: 0.5332 - val_loss: 1.0022 - val_accuracy: 0.5263\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9710 - accuracy: 0.5314 - val_loss: 1.0022 - val_accuracy: 0.5246\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9709 - accuracy: 0.5332 - val_loss: 1.0021 - val_accuracy: 0.5246\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9710 - accuracy: 0.5315 - val_loss: 1.0022 - val_accuracy: 0.5263\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9712 - accuracy: 0.5329 - val_loss: 1.0021 - val_accuracy: 0.5246\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9709 - accuracy: 0.5323 - val_loss: 1.0020 - val_accuracy: 0.5263\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9708 - accuracy: 0.5329 - val_loss: 1.0020 - val_accuracy: 0.5246\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9707 - accuracy: 0.5335 - val_loss: 1.0021 - val_accuracy: 0.5224\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9710 - accuracy: 0.5310 - val_loss: 1.0020 - val_accuracy: 0.5255\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9708 - accuracy: 0.5329 - val_loss: 1.0019 - val_accuracy: 0.5246\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9708 - accuracy: 0.5318 - val_loss: 1.0019 - val_accuracy: 0.5250\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9708 - accuracy: 0.5324 - val_loss: 1.0019 - val_accuracy: 0.5246\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9710 - accuracy: 0.5327 - val_loss: 1.0017 - val_accuracy: 0.5263\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9709 - accuracy: 0.5330 - val_loss: 1.0017 - val_accuracy: 0.5277\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 592us/step - loss: 0.9710 - accuracy: 0.5333 - val_loss: 1.0017 - val_accuracy: 0.5268\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9708 - accuracy: 0.5332 - val_loss: 1.0017 - val_accuracy: 0.5246\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9707 - accuracy: 0.5326 - val_loss: 1.0019 - val_accuracy: 0.5228\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9708 - accuracy: 0.5324 - val_loss: 1.0017 - val_accuracy: 0.5246\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9708 - accuracy: 0.5328 - val_loss: 1.0018 - val_accuracy: 0.5259\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9707 - accuracy: 0.5325 - val_loss: 1.0019 - val_accuracy: 0.5246\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9707 - accuracy: 0.5324 - val_loss: 1.0020 - val_accuracy: 0.5241\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9709 - accuracy: 0.5323 - val_loss: 1.0018 - val_accuracy: 0.5246\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9706 - accuracy: 0.5324 - val_loss: 1.0017 - val_accuracy: 0.5259\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9705 - accuracy: 0.5333 - val_loss: 1.0018 - val_accuracy: 0.5246\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9707 - accuracy: 0.5333 - val_loss: 1.0016 - val_accuracy: 0.5281\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9708 - accuracy: 0.5308 - val_loss: 1.0018 - val_accuracy: 0.5246\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9707 - accuracy: 0.5334 - val_loss: 1.0017 - val_accuracy: 0.5259\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9707 - accuracy: 0.5323 - val_loss: 1.0017 - val_accuracy: 0.5246\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9705 - accuracy: 0.5337 - val_loss: 1.0016 - val_accuracy: 0.5232\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 565us/step - loss: 0.9706 - accuracy: 0.5331 - val_loss: 1.0015 - val_accuracy: 0.5259\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9706 - accuracy: 0.5335 - val_loss: 1.0016 - val_accuracy: 0.5259\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9705 - accuracy: 0.5337 - val_loss: 1.0011 - val_accuracy: 0.5277\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9706 - accuracy: 0.5324 - val_loss: 1.0011 - val_accuracy: 0.5272\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9706 - accuracy: 0.5340 - val_loss: 1.0014 - val_accuracy: 0.5246\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9706 - accuracy: 0.5335 - val_loss: 1.0016 - val_accuracy: 0.5255\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9705 - accuracy: 0.5317 - val_loss: 1.0015 - val_accuracy: 0.5268\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9704 - accuracy: 0.5330 - val_loss: 1.0018 - val_accuracy: 0.5241\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9710 - accuracy: 0.5331 - val_loss: 1.0015 - val_accuracy: 0.5277\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9706 - accuracy: 0.5331 - val_loss: 1.0017 - val_accuracy: 0.5241\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9706 - accuracy: 0.5330 - val_loss: 1.0017 - val_accuracy: 0.5259\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9711 - accuracy: 0.5326 - val_loss: 1.0017 - val_accuracy: 0.5281\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9704 - accuracy: 0.5323 - val_loss: 1.0017 - val_accuracy: 0.5219\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 665us/step - loss: 0.9704 - accuracy: 0.5316 - val_loss: 1.0017 - val_accuracy: 0.5250\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9707 - accuracy: 0.5329 - val_loss: 1.0020 - val_accuracy: 0.5219\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9704 - accuracy: 0.5321 - val_loss: 1.0016 - val_accuracy: 0.5241\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9704 - accuracy: 0.5327 - val_loss: 1.0015 - val_accuracy: 0.5219\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9705 - accuracy: 0.5318 - val_loss: 1.0015 - val_accuracy: 0.5219\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9704 - accuracy: 0.5323 - val_loss: 1.0013 - val_accuracy: 0.5281\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9704 - accuracy: 0.5331 - val_loss: 1.0012 - val_accuracy: 0.5259\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9706 - accuracy: 0.5307 - val_loss: 1.0017 - val_accuracy: 0.5228\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9704 - accuracy: 0.5332 - val_loss: 1.0014 - val_accuracy: 0.5219\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9703 - accuracy: 0.5329 - val_loss: 1.0012 - val_accuracy: 0.5255\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 332us/step - loss: 0.9702 - accuracy: 0.5335\n",
      "Accuracy : 0.5335169434547424\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0012 - accuracy: 0.5255\n",
      "Accuracy : 0.5254537463188171\n",
      "\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.5594 - accuracy: 0.3086 - val_loss: 1.2352 - val_accuracy: 0.3010\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 699us/step - loss: 1.1042 - accuracy: 0.3787 - val_loss: 1.0438 - val_accuracy: 0.4679\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 565us/step - loss: 1.0072 - accuracy: 0.5236 - val_loss: 1.0249 - val_accuracy: 0.5069\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9993 - accuracy: 0.5332 - val_loss: 1.0218 - val_accuracy: 0.5082\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9970 - accuracy: 0.5347 - val_loss: 1.0201 - val_accuracy: 0.5095\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9955 - accuracy: 0.5345 - val_loss: 1.0189 - val_accuracy: 0.5095\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9945 - accuracy: 0.5338 - val_loss: 1.0181 - val_accuracy: 0.5104\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9933 - accuracy: 0.5342 - val_loss: 1.0174 - val_accuracy: 0.5104\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9925 - accuracy: 0.5347 - val_loss: 1.0168 - val_accuracy: 0.5077\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9918 - accuracy: 0.5323 - val_loss: 1.0163 - val_accuracy: 0.5073\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9909 - accuracy: 0.5356 - val_loss: 1.0160 - val_accuracy: 0.5100\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9900 - accuracy: 0.5344 - val_loss: 1.0155 - val_accuracy: 0.5077\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9888 - accuracy: 0.5331 - val_loss: 1.0147 - val_accuracy: 0.5073\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9878 - accuracy: 0.5335 - val_loss: 1.0142 - val_accuracy: 0.5060\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9863 - accuracy: 0.5332 - val_loss: 1.0141 - val_accuracy: 0.5060\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9849 - accuracy: 0.5331 - val_loss: 1.0136 - val_accuracy: 0.5011\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9834 - accuracy: 0.5311 - val_loss: 1.0134 - val_accuracy: 0.4958\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 685us/step - loss: 0.9824 - accuracy: 0.5312 - val_loss: 1.0127 - val_accuracy: 0.5007\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9813 - accuracy: 0.5306 - val_loss: 1.0126 - val_accuracy: 0.5007\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9803 - accuracy: 0.5302 - val_loss: 1.0119 - val_accuracy: 0.5011\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 699us/step - loss: 0.9795 - accuracy: 0.5319 - val_loss: 1.0117 - val_accuracy: 0.5011\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9787 - accuracy: 0.5315 - val_loss: 1.0112 - val_accuracy: 0.5060\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9781 - accuracy: 0.5330 - val_loss: 1.0109 - val_accuracy: 0.5060\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9774 - accuracy: 0.5324 - val_loss: 1.0111 - val_accuracy: 0.5055\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9775 - accuracy: 0.5315 - val_loss: 1.0103 - val_accuracy: 0.5100\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 473us/step - loss: 0.9769 - accuracy: 0.5343 - val_loss: 1.0105 - val_accuracy: 0.5082\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 737us/step - loss: 0.9769 - accuracy: 0.5340 - val_loss: 1.0097 - val_accuracy: 0.5082\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5346 - val_loss: 1.0098 - val_accuracy: 0.5095\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9757 - accuracy: 0.5343 - val_loss: 1.0098 - val_accuracy: 0.5082\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9754 - accuracy: 0.5358 - val_loss: 1.0093 - val_accuracy: 0.5095\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9752 - accuracy: 0.5338 - val_loss: 1.0096 - val_accuracy: 0.5082\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9751 - accuracy: 0.5342 - val_loss: 1.0087 - val_accuracy: 0.5082\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9748 - accuracy: 0.5346 - val_loss: 1.0087 - val_accuracy: 0.5082\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9746 - accuracy: 0.5351 - val_loss: 1.0090 - val_accuracy: 0.5086\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9746 - accuracy: 0.5347 - val_loss: 1.0084 - val_accuracy: 0.5095\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9740 - accuracy: 0.5347 - val_loss: 1.0088 - val_accuracy: 0.5091\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9749 - accuracy: 0.5338 - val_loss: 1.0084 - val_accuracy: 0.5073\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9739 - accuracy: 0.5338 - val_loss: 1.0080 - val_accuracy: 0.5091\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9735 - accuracy: 0.5350 - val_loss: 1.0081 - val_accuracy: 0.5091\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9735 - accuracy: 0.5337 - val_loss: 1.0077 - val_accuracy: 0.5095\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9733 - accuracy: 0.5341 - val_loss: 1.0082 - val_accuracy: 0.5082\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9735 - accuracy: 0.5341 - val_loss: 1.0075 - val_accuracy: 0.5064\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9729 - accuracy: 0.5341 - val_loss: 1.0074 - val_accuracy: 0.5091\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9728 - accuracy: 0.5342 - val_loss: 1.0075 - val_accuracy: 0.5069\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9729 - accuracy: 0.5357 - val_loss: 1.0072 - val_accuracy: 0.5086\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9736 - accuracy: 0.5340 - val_loss: 1.0070 - val_accuracy: 0.5104\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5325 - val_loss: 1.0069 - val_accuracy: 0.5073\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9724 - accuracy: 0.5346 - val_loss: 1.0073 - val_accuracy: 0.5064\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9725 - accuracy: 0.5339 - val_loss: 1.0069 - val_accuracy: 0.5077\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9724 - accuracy: 0.5329 - val_loss: 1.0067 - val_accuracy: 0.5073\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9721 - accuracy: 0.5344 - val_loss: 1.0070 - val_accuracy: 0.5073\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9720 - accuracy: 0.5346 - val_loss: 1.0072 - val_accuracy: 0.5077\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9728 - accuracy: 0.5335 - val_loss: 1.0069 - val_accuracy: 0.5100\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9720 - accuracy: 0.5343 - val_loss: 1.0064 - val_accuracy: 0.5077\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9719 - accuracy: 0.5335 - val_loss: 1.0068 - val_accuracy: 0.5100\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9720 - accuracy: 0.5335 - val_loss: 1.0062 - val_accuracy: 0.5073\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9720 - accuracy: 0.5345 - val_loss: 1.0063 - val_accuracy: 0.5077\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9719 - accuracy: 0.5335 - val_loss: 1.0061 - val_accuracy: 0.5064\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9718 - accuracy: 0.5344 - val_loss: 1.0063 - val_accuracy: 0.5073\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9724 - accuracy: 0.5337 - val_loss: 1.0059 - val_accuracy: 0.5100\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9718 - accuracy: 0.5342 - val_loss: 1.0060 - val_accuracy: 0.5077\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9715 - accuracy: 0.5317 - val_loss: 1.0059 - val_accuracy: 0.5104\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9715 - accuracy: 0.5338 - val_loss: 1.0058 - val_accuracy: 0.5069\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9714 - accuracy: 0.5338 - val_loss: 1.0064 - val_accuracy: 0.5064\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9729 - accuracy: 0.5335 - val_loss: 1.0059 - val_accuracy: 0.5082\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 760us/step - loss: 0.9714 - accuracy: 0.5327 - val_loss: 1.0058 - val_accuracy: 0.5104\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9714 - accuracy: 0.5322 - val_loss: 1.0059 - val_accuracy: 0.5104\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9713 - accuracy: 0.5326 - val_loss: 1.0056 - val_accuracy: 0.5073\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9712 - accuracy: 0.5330 - val_loss: 1.0061 - val_accuracy: 0.5100\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9714 - accuracy: 0.5330 - val_loss: 1.0055 - val_accuracy: 0.5104\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9716 - accuracy: 0.5320 - val_loss: 1.0060 - val_accuracy: 0.5100\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9711 - accuracy: 0.5332 - val_loss: 1.0056 - val_accuracy: 0.5069\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9713 - accuracy: 0.5333 - val_loss: 1.0051 - val_accuracy: 0.5069\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9712 - accuracy: 0.5344 - val_loss: 1.0056 - val_accuracy: 0.5069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9713 - accuracy: 0.5335 - val_loss: 1.0056 - val_accuracy: 0.5069\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9712 - accuracy: 0.5338 - val_loss: 1.0052 - val_accuracy: 0.5064\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9711 - accuracy: 0.5341 - val_loss: 1.0052 - val_accuracy: 0.5069\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9711 - accuracy: 0.5344 - val_loss: 1.0054 - val_accuracy: 0.5082\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9713 - accuracy: 0.5321 - val_loss: 1.0054 - val_accuracy: 0.5104\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9713 - accuracy: 0.5332 - val_loss: 1.0054 - val_accuracy: 0.5117\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9710 - accuracy: 0.5331 - val_loss: 1.0056 - val_accuracy: 0.5064\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9712 - accuracy: 0.5338 - val_loss: 1.0048 - val_accuracy: 0.5077\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9711 - accuracy: 0.5334 - val_loss: 1.0052 - val_accuracy: 0.5104\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9710 - accuracy: 0.5338 - val_loss: 1.0050 - val_accuracy: 0.5073\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9710 - accuracy: 0.5331 - val_loss: 1.0054 - val_accuracy: 0.5064\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9713 - accuracy: 0.5332 - val_loss: 1.0054 - val_accuracy: 0.5100\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9711 - accuracy: 0.5336 - val_loss: 1.0050 - val_accuracy: 0.5064\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9711 - accuracy: 0.5336 - val_loss: 1.0047 - val_accuracy: 0.5064\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9710 - accuracy: 0.5332 - val_loss: 1.0051 - val_accuracy: 0.5108\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9710 - accuracy: 0.5325 - val_loss: 1.0050 - val_accuracy: 0.5069\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9710 - accuracy: 0.5331 - val_loss: 1.0047 - val_accuracy: 0.5082\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9709 - accuracy: 0.5317 - val_loss: 1.0046 - val_accuracy: 0.5082\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9709 - accuracy: 0.5333 - val_loss: 1.0045 - val_accuracy: 0.5077\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9708 - accuracy: 0.5341 - val_loss: 1.0047 - val_accuracy: 0.5104\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9709 - accuracy: 0.5323 - val_loss: 1.0046 - val_accuracy: 0.5082\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9708 - accuracy: 0.5334 - val_loss: 1.0045 - val_accuracy: 0.5082\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9706 - accuracy: 0.5330 - val_loss: 1.0052 - val_accuracy: 0.5069\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9707 - accuracy: 0.5336 - val_loss: 1.0044 - val_accuracy: 0.5073\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9708 - accuracy: 0.5331 - val_loss: 1.0043 - val_accuracy: 0.5069\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9708 - accuracy: 0.5331 - val_loss: 1.0041 - val_accuracy: 0.5064\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9711 - accuracy: 0.5346 - val_loss: 1.0043 - val_accuracy: 0.5082\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 1.0043 - val_accuracy: 0.5104\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9708 - accuracy: 0.5329 - val_loss: 1.0041 - val_accuracy: 0.5104\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9710 - accuracy: 0.5330 - val_loss: 1.0042 - val_accuracy: 0.5113\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9707 - accuracy: 0.5329 - val_loss: 1.0041 - val_accuracy: 0.5082\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9707 - accuracy: 0.5326 - val_loss: 1.0046 - val_accuracy: 0.5069\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9708 - accuracy: 0.5329 - val_loss: 1.0041 - val_accuracy: 0.5082\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9706 - accuracy: 0.5338 - val_loss: 1.0041 - val_accuracy: 0.5069\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9713 - accuracy: 0.5334 - val_loss: 1.0042 - val_accuracy: 0.5077\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9707 - accuracy: 0.5323 - val_loss: 1.0042 - val_accuracy: 0.5117\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9707 - accuracy: 0.5339 - val_loss: 1.0038 - val_accuracy: 0.5064\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9707 - accuracy: 0.5348 - val_loss: 1.0041 - val_accuracy: 0.5069\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9706 - accuracy: 0.5329 - val_loss: 1.0042 - val_accuracy: 0.5064\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9704 - accuracy: 0.5335 - val_loss: 1.0038 - val_accuracy: 0.5069\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9704 - accuracy: 0.5341 - val_loss: 1.0041 - val_accuracy: 0.5064\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9704 - accuracy: 0.5333 - val_loss: 1.0042 - val_accuracy: 0.5117\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9705 - accuracy: 0.5327 - val_loss: 1.0038 - val_accuracy: 0.5082\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9703 - accuracy: 0.5335 - val_loss: 1.0040 - val_accuracy: 0.5082\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9710 - accuracy: 0.5330 - val_loss: 1.0039 - val_accuracy: 0.5073\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9705 - accuracy: 0.5333 - val_loss: 1.0040 - val_accuracy: 0.5077\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9705 - accuracy: 0.5345 - val_loss: 1.0038 - val_accuracy: 0.5073\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9704 - accuracy: 0.5330 - val_loss: 1.0039 - val_accuracy: 0.5069\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9704 - accuracy: 0.5342 - val_loss: 1.0042 - val_accuracy: 0.5082\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9706 - accuracy: 0.5330 - val_loss: 1.0039 - val_accuracy: 0.5064\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9703 - accuracy: 0.5331 - val_loss: 1.0036 - val_accuracy: 0.5077\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9703 - accuracy: 0.5334 - val_loss: 1.0037 - val_accuracy: 0.5104\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9705 - accuracy: 0.5323 - val_loss: 1.0041 - val_accuracy: 0.5100\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9709 - accuracy: 0.5327 - val_loss: 1.0038 - val_accuracy: 0.5077\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9710 - accuracy: 0.5343 - val_loss: 1.0034 - val_accuracy: 0.5082\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9703 - accuracy: 0.5328 - val_loss: 1.0035 - val_accuracy: 0.5069\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9703 - accuracy: 0.5329 - val_loss: 1.0038 - val_accuracy: 0.5073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9707 - accuracy: 0.5333 - val_loss: 1.0034 - val_accuracy: 0.5069\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9703 - accuracy: 0.5335 - val_loss: 1.0034 - val_accuracy: 0.5104\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9702 - accuracy: 0.5332 - val_loss: 1.0036 - val_accuracy: 0.5104\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9702 - accuracy: 0.5326 - val_loss: 1.0036 - val_accuracy: 0.5082\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9701 - accuracy: 0.5327 - val_loss: 1.0035 - val_accuracy: 0.5064\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9703 - accuracy: 0.5330 - val_loss: 1.0036 - val_accuracy: 0.5104\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9702 - accuracy: 0.5331 - val_loss: 1.0035 - val_accuracy: 0.5073\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9701 - accuracy: 0.5337 - val_loss: 1.0041 - val_accuracy: 0.5069\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9712 - accuracy: 0.5338 - val_loss: 1.0032 - val_accuracy: 0.5073\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9701 - accuracy: 0.5326 - val_loss: 1.0034 - val_accuracy: 0.5073\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9703 - accuracy: 0.5335 - val_loss: 1.0034 - val_accuracy: 0.5113\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9704 - accuracy: 0.5324 - val_loss: 1.0033 - val_accuracy: 0.5117\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9702 - accuracy: 0.5330 - val_loss: 1.0031 - val_accuracy: 0.5064\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9702 - accuracy: 0.5338 - val_loss: 1.0035 - val_accuracy: 0.5117\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9704 - accuracy: 0.5326 - val_loss: 1.0030 - val_accuracy: 0.5069\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9702 - accuracy: 0.5322 - val_loss: 1.0032 - val_accuracy: 0.5073\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9702 - accuracy: 0.5335 - val_loss: 1.0028 - val_accuracy: 0.5069\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9702 - accuracy: 0.5334 - val_loss: 1.0034 - val_accuracy: 0.5082\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9704 - accuracy: 0.5339 - val_loss: 1.0034 - val_accuracy: 0.5104\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9701 - accuracy: 0.5330 - val_loss: 1.0031 - val_accuracy: 0.5069\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9702 - accuracy: 0.5338 - val_loss: 1.0030 - val_accuracy: 0.5077\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9701 - accuracy: 0.5335 - val_loss: 1.0029 - val_accuracy: 0.5095\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9704 - accuracy: 0.5345 - val_loss: 1.0030 - val_accuracy: 0.5095\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9702 - accuracy: 0.5346 - val_loss: 1.0029 - val_accuracy: 0.5073\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9701 - accuracy: 0.5338 - val_loss: 1.0034 - val_accuracy: 0.5073\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9705 - accuracy: 0.5331 - val_loss: 1.0030 - val_accuracy: 0.5082\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9701 - accuracy: 0.5328 - val_loss: 1.0027 - val_accuracy: 0.5100\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9703 - accuracy: 0.5339 - val_loss: 1.0030 - val_accuracy: 0.5082\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9702 - accuracy: 0.5334 - val_loss: 1.0026 - val_accuracy: 0.5077\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9702 - accuracy: 0.5334 - val_loss: 1.0025 - val_accuracy: 0.5069\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9700 - accuracy: 0.5342 - val_loss: 1.0029 - val_accuracy: 0.5064\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9702 - accuracy: 0.5347 - val_loss: 1.0029 - val_accuracy: 0.5073\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9699 - accuracy: 0.5336 - val_loss: 1.0028 - val_accuracy: 0.5064\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9701 - accuracy: 0.5346 - val_loss: 1.0025 - val_accuracy: 0.5077\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9700 - accuracy: 0.5332 - val_loss: 1.0028 - val_accuracy: 0.5073\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9698 - accuracy: 0.5325 - val_loss: 1.0029 - val_accuracy: 0.5073\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9704 - accuracy: 0.5345 - val_loss: 1.0026 - val_accuracy: 0.5077\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9699 - accuracy: 0.5336 - val_loss: 1.0024 - val_accuracy: 0.5077\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9701 - accuracy: 0.5342 - val_loss: 1.0028 - val_accuracy: 0.5082\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9700 - accuracy: 0.5337 - val_loss: 1.0029 - val_accuracy: 0.5095\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9698 - accuracy: 0.5340 - val_loss: 1.0026 - val_accuracy: 0.5104\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9702 - accuracy: 0.5330 - val_loss: 1.0024 - val_accuracy: 0.5073\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9702 - accuracy: 0.5341 - val_loss: 1.0028 - val_accuracy: 0.5064\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9699 - accuracy: 0.5339 - val_loss: 1.0025 - val_accuracy: 0.5104\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9699 - accuracy: 0.5332 - val_loss: 1.0023 - val_accuracy: 0.5077\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9700 - accuracy: 0.5335 - val_loss: 1.0026 - val_accuracy: 0.5069\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9701 - accuracy: 0.5334 - val_loss: 1.0023 - val_accuracy: 0.5082\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9700 - accuracy: 0.5336 - val_loss: 1.0028 - val_accuracy: 0.5117\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9699 - accuracy: 0.5331 - val_loss: 1.0023 - val_accuracy: 0.5073\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9700 - accuracy: 0.5322 - val_loss: 1.0022 - val_accuracy: 0.5082\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9701 - accuracy: 0.5342 - val_loss: 1.0025 - val_accuracy: 0.5082\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9701 - accuracy: 0.5340 - val_loss: 1.0023 - val_accuracy: 0.5073\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9700 - accuracy: 0.5339 - val_loss: 1.0023 - val_accuracy: 0.5073\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9699 - accuracy: 0.5332 - val_loss: 1.0032 - val_accuracy: 0.5082\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9703 - accuracy: 0.5332 - val_loss: 1.0026 - val_accuracy: 0.5069\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9699 - accuracy: 0.5336 - val_loss: 1.0023 - val_accuracy: 0.5077\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 603us/step - loss: 0.9699 - accuracy: 0.5341 - val_loss: 1.0023 - val_accuracy: 0.5077\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9700 - accuracy: 0.5331 - val_loss: 1.0022 - val_accuracy: 0.5077\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9700 - accuracy: 0.5327 - val_loss: 1.0026 - val_accuracy: 0.5082\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9700 - accuracy: 0.5329 - val_loss: 1.0024 - val_accuracy: 0.5064\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9698 - accuracy: 0.5339 - val_loss: 1.0024 - val_accuracy: 0.5073\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9698 - accuracy: 0.5328 - val_loss: 1.0023 - val_accuracy: 0.5086\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9698 - accuracy: 0.5324 - val_loss: 1.0026 - val_accuracy: 0.5082\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9695 - accuracy: 0.5319 - val_loss: 1.0027 - val_accuracy: 0.5086\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9711 - accuracy: 0.5341 - val_loss: 1.0024 - val_accuracy: 0.5117\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9700 - accuracy: 0.5322 - val_loss: 1.0020 - val_accuracy: 0.5104\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9698 - accuracy: 0.5345 - val_loss: 1.0021 - val_accuracy: 0.5073\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9696 - accuracy: 0.5343 - val_loss: 1.0026 - val_accuracy: 0.5104\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9701 - accuracy: 0.5326 - val_loss: 1.0024 - val_accuracy: 0.5104\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 332us/step - loss: 0.9695 - accuracy: 0.5325\n",
      "Accuracy : 0.5324841141700745\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0024 - accuracy: 0.5104\n",
      "Accuracy : 0.5104028582572937\n",
      "\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.1841 - accuracy: 0.4657 - val_loss: 1.1316 - val_accuracy: 0.4599\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 1.0830 - accuracy: 0.4702 - val_loss: 1.0578 - val_accuracy: 0.4714\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0211 - accuracy: 0.4919 - val_loss: 1.0178 - val_accuracy: 0.4962\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9932 - accuracy: 0.5167 - val_loss: 1.0014 - val_accuracy: 0.5272\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9809 - accuracy: 0.5327 - val_loss: 0.9947 - val_accuracy: 0.5294\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9762 - accuracy: 0.5319 - val_loss: 0.9923 - val_accuracy: 0.5303\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9745 - accuracy: 0.5325 - val_loss: 0.9915 - val_accuracy: 0.5277\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9912 - val_accuracy: 0.5303\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9745 - accuracy: 0.5292 - val_loss: 0.9910 - val_accuracy: 0.5312\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9739 - accuracy: 0.5313 - val_loss: 0.9908 - val_accuracy: 0.5303\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9738 - accuracy: 0.5318 - val_loss: 0.9907 - val_accuracy: 0.5312\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 0.9907 - val_accuracy: 0.5303\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9737 - accuracy: 0.5317 - val_loss: 0.9907 - val_accuracy: 0.5312\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9908 - val_accuracy: 0.5286\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9735 - accuracy: 0.5319 - val_loss: 0.9906 - val_accuracy: 0.5308\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9906 - val_accuracy: 0.5308\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9737 - accuracy: 0.5313 - val_loss: 0.9905 - val_accuracy: 0.5308\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9734 - accuracy: 0.5315 - val_loss: 0.9904 - val_accuracy: 0.5312\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9738 - accuracy: 0.5335 - val_loss: 0.9904 - val_accuracy: 0.5308\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9735 - accuracy: 0.5328 - val_loss: 0.9904 - val_accuracy: 0.5294\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9733 - accuracy: 0.5310 - val_loss: 0.9904 - val_accuracy: 0.5308\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9744 - accuracy: 0.5315 - val_loss: 0.9902 - val_accuracy: 0.5303\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9733 - accuracy: 0.5308 - val_loss: 0.9903 - val_accuracy: 0.5290\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9735 - accuracy: 0.5323 - val_loss: 0.9903 - val_accuracy: 0.5317\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9733 - accuracy: 0.5318 - val_loss: 0.9903 - val_accuracy: 0.5312\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9734 - accuracy: 0.5294 - val_loss: 0.9902 - val_accuracy: 0.5312\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9733 - accuracy: 0.5298 - val_loss: 0.9902 - val_accuracy: 0.5312\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9902 - val_accuracy: 0.5303\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9731 - accuracy: 0.5309 - val_loss: 0.9903 - val_accuracy: 0.5281\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9732 - accuracy: 0.5329 - val_loss: 0.9902 - val_accuracy: 0.5312\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9732 - accuracy: 0.5311 - val_loss: 0.9904 - val_accuracy: 0.5308\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9902 - val_accuracy: 0.5299\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9733 - accuracy: 0.5295 - val_loss: 0.9902 - val_accuracy: 0.5308\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9733 - accuracy: 0.5290 - val_loss: 0.9901 - val_accuracy: 0.5308\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9730 - accuracy: 0.5296 - val_loss: 0.9899 - val_accuracy: 0.5317\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9732 - accuracy: 0.5296 - val_loss: 0.9900 - val_accuracy: 0.5299\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9901 - val_accuracy: 0.5281\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9737 - accuracy: 0.5328 - val_loss: 0.9899 - val_accuracy: 0.5317\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 670us/step - loss: 0.9731 - accuracy: 0.5301 - val_loss: 0.9899 - val_accuracy: 0.5317\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9731 - accuracy: 0.5300 - val_loss: 0.9900 - val_accuracy: 0.5312\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 0.9899 - val_accuracy: 0.5312\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 0.9900 - val_accuracy: 0.5308\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 611us/step - loss: 0.9732 - accuracy: 0.5314 - val_loss: 0.9900 - val_accuracy: 0.5308\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9731 - accuracy: 0.5298 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9731 - accuracy: 0.5312 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9729 - accuracy: 0.5307 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9729 - accuracy: 0.5303 - val_loss: 0.9899 - val_accuracy: 0.5308\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9729 - accuracy: 0.5304 - val_loss: 0.9899 - val_accuracy: 0.5317\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9733 - accuracy: 0.5314 - val_loss: 0.9902 - val_accuracy: 0.5263\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9738 - accuracy: 0.5309 - val_loss: 0.9899 - val_accuracy: 0.5312\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9734 - accuracy: 0.5323 - val_loss: 0.9899 - val_accuracy: 0.5308\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9732 - accuracy: 0.5301 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9731 - accuracy: 0.5305 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9731 - accuracy: 0.5320 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9727 - accuracy: 0.5304 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9729 - accuracy: 0.5302 - val_loss: 0.9897 - val_accuracy: 0.5312\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9731 - accuracy: 0.5324 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9728 - accuracy: 0.5301 - val_loss: 0.9897 - val_accuracy: 0.5312\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 0.9898 - val_accuracy: 0.5312\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9731 - accuracy: 0.5301 - val_loss: 0.9899 - val_accuracy: 0.5312\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9732 - accuracy: 0.5309 - val_loss: 0.9899 - val_accuracy: 0.5281\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9733 - accuracy: 0.5316 - val_loss: 0.9903 - val_accuracy: 0.5268\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9754 - accuracy: 0.5315 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9732 - accuracy: 0.5300 - val_loss: 0.9898 - val_accuracy: 0.5294\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9735 - accuracy: 0.5305 - val_loss: 0.9898 - val_accuracy: 0.5312\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9728 - accuracy: 0.5304 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9734 - accuracy: 0.5318 - val_loss: 0.9898 - val_accuracy: 0.5312\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9728 - accuracy: 0.5301 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9728 - accuracy: 0.5312 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9728 - accuracy: 0.5303 - val_loss: 0.9899 - val_accuracy: 0.5312\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9728 - accuracy: 0.5322 - val_loss: 0.9899 - val_accuracy: 0.5308\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9732 - accuracy: 0.5310 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9728 - accuracy: 0.5301 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9727 - accuracy: 0.5306 - val_loss: 0.9898 - val_accuracy: 0.5294\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9729 - accuracy: 0.5287 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9729 - accuracy: 0.5305 - val_loss: 0.9899 - val_accuracy: 0.5294\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9729 - accuracy: 0.5305 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9727 - accuracy: 0.5304 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9726 - accuracy: 0.5317 - val_loss: 0.9900 - val_accuracy: 0.5294\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9729 - accuracy: 0.5309 - val_loss: 0.9900 - val_accuracy: 0.5263\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9734 - accuracy: 0.5317 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9897 - val_accuracy: 0.5290\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9727 - accuracy: 0.5298 - val_loss: 0.9898 - val_accuracy: 0.5312\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9727 - accuracy: 0.5310 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9734 - accuracy: 0.5304 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9728 - accuracy: 0.5299 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 770us/step - loss: 0.9728 - accuracy: 0.5302 - val_loss: 0.9896 - val_accuracy: 0.5299\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9728 - accuracy: 0.5317 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 566us/step - loss: 0.9727 - accuracy: 0.5305 - val_loss: 0.9896 - val_accuracy: 0.5312\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9727 - accuracy: 0.5305 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9726 - accuracy: 0.5308 - val_loss: 0.9896 - val_accuracy: 0.5299\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9727 - accuracy: 0.5309 - val_loss: 0.9898 - val_accuracy: 0.5290\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9729 - accuracy: 0.5300 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9728 - accuracy: 0.5304 - val_loss: 0.9899 - val_accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9727 - accuracy: 0.5315 - val_loss: 0.9901 - val_accuracy: 0.5312\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9731 - accuracy: 0.5306 - val_loss: 0.9896 - val_accuracy: 0.5308\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9728 - accuracy: 0.5325 - val_loss: 0.9898 - val_accuracy: 0.5312\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9726 - accuracy: 0.5295 - val_loss: 0.9896 - val_accuracy: 0.5312\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9731 - accuracy: 0.5319 - val_loss: 0.9896 - val_accuracy: 0.5299\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9727 - accuracy: 0.5308 - val_loss: 0.9898 - val_accuracy: 0.5303\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9729 - accuracy: 0.5322 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9726 - accuracy: 0.5297 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 0.9899 - val_accuracy: 0.5308\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9727 - accuracy: 0.5308 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5303 - val_loss: 0.9896 - val_accuracy: 0.5299\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9726 - accuracy: 0.5301 - val_loss: 0.9896 - val_accuracy: 0.5299\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9727 - accuracy: 0.5309 - val_loss: 0.9900 - val_accuracy: 0.5294\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9726 - accuracy: 0.5312 - val_loss: 0.9900 - val_accuracy: 0.5312\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9896 - val_accuracy: 0.5290\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9899 - val_accuracy: 0.5308\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9726 - accuracy: 0.5300 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 0.9901 - val_accuracy: 0.5312\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9734 - accuracy: 0.5299 - val_loss: 0.9898 - val_accuracy: 0.5303\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9731 - accuracy: 0.5320 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9727 - accuracy: 0.5307 - val_loss: 0.9896 - val_accuracy: 0.5308\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9726 - accuracy: 0.5307 - val_loss: 0.9897 - val_accuracy: 0.5290\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5305 - val_loss: 0.9897 - val_accuracy: 0.5303\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9728 - accuracy: 0.5320 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9726 - accuracy: 0.5307 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9727 - accuracy: 0.5301 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9726 - accuracy: 0.5325 - val_loss: 0.9897 - val_accuracy: 0.5290\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5313 - val_loss: 0.9899 - val_accuracy: 0.5299\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9728 - accuracy: 0.5302 - val_loss: 0.9897 - val_accuracy: 0.5294\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5314 - val_loss: 0.9898 - val_accuracy: 0.5312\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9727 - accuracy: 0.5322 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9727 - accuracy: 0.5320 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9726 - accuracy: 0.5320 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9726 - accuracy: 0.5302 - val_loss: 0.9899 - val_accuracy: 0.5299\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9725 - accuracy: 0.5301 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9725 - accuracy: 0.5314 - val_loss: 0.9898 - val_accuracy: 0.5303\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9727 - accuracy: 0.5310 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9726 - accuracy: 0.5303 - val_loss: 0.9898 - val_accuracy: 0.5312\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9726 - accuracy: 0.5297 - val_loss: 0.9898 - val_accuracy: 0.5294\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9726 - accuracy: 0.5294 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9726 - accuracy: 0.5303 - val_loss: 0.9901 - val_accuracy: 0.5277\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9727 - accuracy: 0.5297 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9725 - accuracy: 0.5299 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9727 - accuracy: 0.5309 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9725 - accuracy: 0.5302 - val_loss: 0.9897 - val_accuracy: 0.5312\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9728 - accuracy: 0.5321 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9725 - accuracy: 0.5301 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9724 - accuracy: 0.5318 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9725 - accuracy: 0.5296 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9725 - accuracy: 0.5294 - val_loss: 0.9897 - val_accuracy: 0.5294\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9725 - accuracy: 0.5310 - val_loss: 0.9897 - val_accuracy: 0.5303\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9725 - accuracy: 0.5310 - val_loss: 0.9898 - val_accuracy: 0.5303\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9725 - accuracy: 0.5305 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9726 - accuracy: 0.5305 - val_loss: 0.9898 - val_accuracy: 0.5303\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9726 - accuracy: 0.5299 - val_loss: 0.9898 - val_accuracy: 0.5312\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9725 - accuracy: 0.5294 - val_loss: 0.9902 - val_accuracy: 0.5312\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 623us/step - loss: 0.9731 - accuracy: 0.5304 - val_loss: 0.9900 - val_accuracy: 0.5321\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9751 - accuracy: 0.5316 - val_loss: 0.9896 - val_accuracy: 0.5299\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9726 - accuracy: 0.5291 - val_loss: 0.9896 - val_accuracy: 0.5308\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9726 - accuracy: 0.5296 - val_loss: 0.9897 - val_accuracy: 0.5303\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9732 - accuracy: 0.5312 - val_loss: 0.9897 - val_accuracy: 0.5290\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9726 - accuracy: 0.5300 - val_loss: 0.9897 - val_accuracy: 0.5294\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9724 - accuracy: 0.5301 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9725 - accuracy: 0.5318 - val_loss: 0.9897 - val_accuracy: 0.5299\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9724 - accuracy: 0.5300 - val_loss: 0.9900 - val_accuracy: 0.5294\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9726 - accuracy: 0.5313 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9727 - accuracy: 0.5298 - val_loss: 0.9895 - val_accuracy: 0.5299\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9727 - accuracy: 0.5293 - val_loss: 0.9898 - val_accuracy: 0.5294\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9725 - accuracy: 0.5305 - val_loss: 0.9896 - val_accuracy: 0.5308\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9724 - accuracy: 0.5299 - val_loss: 0.9899 - val_accuracy: 0.5294\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9727 - accuracy: 0.5299 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9727 - accuracy: 0.5317 - val_loss: 0.9897 - val_accuracy: 0.5294\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9724 - accuracy: 0.5294 - val_loss: 0.9897 - val_accuracy: 0.5303\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9724 - accuracy: 0.5305 - val_loss: 0.9899 - val_accuracy: 0.5308\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9725 - accuracy: 0.5299 - val_loss: 0.9898 - val_accuracy: 0.5303\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9725 - accuracy: 0.5311 - val_loss: 0.9897 - val_accuracy: 0.5303\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9725 - accuracy: 0.5302 - val_loss: 0.9902 - val_accuracy: 0.5299\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9728 - accuracy: 0.5309 - val_loss: 0.9899 - val_accuracy: 0.5294\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9725 - accuracy: 0.5315 - val_loss: 0.9899 - val_accuracy: 0.5308\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9725 - accuracy: 0.5320 - val_loss: 0.9899 - val_accuracy: 0.5294\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9726 - accuracy: 0.5290 - val_loss: 0.9898 - val_accuracy: 0.5303\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9725 - accuracy: 0.5311 - val_loss: 0.9897 - val_accuracy: 0.5290\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 0.9898 - val_accuracy: 0.5303\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9726 - accuracy: 0.5318 - val_loss: 0.9900 - val_accuracy: 0.5312\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 0.9898 - val_accuracy: 0.5294\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9724 - accuracy: 0.5295 - val_loss: 0.9897 - val_accuracy: 0.5303\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9723 - accuracy: 0.5307 - val_loss: 0.9898 - val_accuracy: 0.5299\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9725 - accuracy: 0.5301 - val_loss: 0.9898 - val_accuracy: 0.5294\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9727 - accuracy: 0.5295 - val_loss: 0.9897 - val_accuracy: 0.5303\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9726 - accuracy: 0.5324 - val_loss: 0.9898 - val_accuracy: 0.5308\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9725 - accuracy: 0.5297 - val_loss: 0.9897 - val_accuracy: 0.5308\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9724 - accuracy: 0.5306 - val_loss: 0.9897 - val_accuracy: 0.5312\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9897 - val_accuracy: 0.5294\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9727 - accuracy: 0.5311 - val_loss: 0.9897 - val_accuracy: 0.5303\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 0.9897 - val_accuracy: 0.5294\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9724 - accuracy: 0.5306 - val_loss: 0.9899 - val_accuracy: 0.5308\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9726 - accuracy: 0.5313 - val_loss: 0.9898 - val_accuracy: 0.5303\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9725 - accuracy: 0.5309 - val_loss: 0.9898 - val_accuracy: 0.5303\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9725 - accuracy: 0.5308 - val_loss: 0.9898 - val_accuracy: 0.5312\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 338us/step - loss: 0.9721 - accuracy: 0.5315\n",
      "Accuracy : 0.531500518321991\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9898 - accuracy: 0.5312\n",
      "Accuracy : 0.5312085151672363\n",
      "\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0781 - accuracy: 0.4591 - val_loss: 1.0521 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 1.0260 - accuracy: 0.4591 - val_loss: 1.0230 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0133 - accuracy: 0.4591 - val_loss: 1.0143 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0093 - accuracy: 0.4598 - val_loss: 1.0097 - val_accuracy: 0.4622\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 1.0047 - accuracy: 0.5008 - val_loss: 1.0026 - val_accuracy: 0.5193\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9979 - accuracy: 0.5229 - val_loss: 0.9951 - val_accuracy: 0.5387\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9931 - accuracy: 0.5268 - val_loss: 0.9912 - val_accuracy: 0.5387\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9896 - accuracy: 0.5262 - val_loss: 0.9868 - val_accuracy: 0.5387\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9874 - accuracy: 0.5267 - val_loss: 0.9841 - val_accuracy: 0.5387\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9852 - accuracy: 0.5268 - val_loss: 0.9823 - val_accuracy: 0.5387\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 609us/step - loss: 0.9840 - accuracy: 0.5269 - val_loss: 0.9808 - val_accuracy: 0.5387\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9834 - accuracy: 0.5267 - val_loss: 0.9800 - val_accuracy: 0.5387\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9830 - accuracy: 0.5267 - val_loss: 0.9792 - val_accuracy: 0.5387\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9826 - accuracy: 0.5266 - val_loss: 0.9790 - val_accuracy: 0.5387\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9824 - accuracy: 0.5270 - val_loss: 0.9788 - val_accuracy: 0.5387\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9822 - accuracy: 0.5265 - val_loss: 0.9784 - val_accuracy: 0.5387\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9820 - accuracy: 0.5269 - val_loss: 0.9785 - val_accuracy: 0.5387\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9818 - accuracy: 0.5264 - val_loss: 0.9781 - val_accuracy: 0.5392\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9817 - accuracy: 0.5254 - val_loss: 0.9781 - val_accuracy: 0.5387\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9815 - accuracy: 0.5259 - val_loss: 0.9778 - val_accuracy: 0.5396\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9814 - accuracy: 0.5267 - val_loss: 0.9773 - val_accuracy: 0.5392\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9812 - accuracy: 0.5267 - val_loss: 0.9775 - val_accuracy: 0.5392\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 694us/step - loss: 0.9813 - accuracy: 0.5268 - val_loss: 0.9778 - val_accuracy: 0.5378\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9811 - accuracy: 0.5265 - val_loss: 0.9773 - val_accuracy: 0.5378\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9810 - accuracy: 0.5266 - val_loss: 0.9776 - val_accuracy: 0.5392\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9817 - accuracy: 0.5269 - val_loss: 0.9786 - val_accuracy: 0.5392\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9810 - accuracy: 0.5262 - val_loss: 0.9772 - val_accuracy: 0.5370\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9820 - accuracy: 0.5268 - val_loss: 0.9770 - val_accuracy: 0.5392\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9811 - accuracy: 0.5262 - val_loss: 0.9766 - val_accuracy: 0.5378\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9808 - accuracy: 0.5261 - val_loss: 0.9765 - val_accuracy: 0.5387\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9808 - accuracy: 0.5270 - val_loss: 0.9765 - val_accuracy: 0.5378\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9806 - accuracy: 0.5262 - val_loss: 0.9765 - val_accuracy: 0.5378\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9807 - accuracy: 0.5265 - val_loss: 0.9766 - val_accuracy: 0.5405\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9807 - accuracy: 0.5249 - val_loss: 0.9768 - val_accuracy: 0.5387\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9805 - accuracy: 0.5260 - val_loss: 0.9765 - val_accuracy: 0.5387\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9805 - accuracy: 0.5267 - val_loss: 0.9766 - val_accuracy: 0.5387\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9804 - accuracy: 0.5263 - val_loss: 0.9765 - val_accuracy: 0.5396\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9803 - accuracy: 0.5276 - val_loss: 0.9765 - val_accuracy: 0.5370\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9803 - accuracy: 0.5271 - val_loss: 0.9769 - val_accuracy: 0.5387\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9809 - accuracy: 0.5244 - val_loss: 0.9776 - val_accuracy: 0.5401\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9804 - accuracy: 0.5266 - val_loss: 0.9773 - val_accuracy: 0.5392\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9802 - accuracy: 0.5271 - val_loss: 0.9770 - val_accuracy: 0.5418\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9801 - accuracy: 0.5260 - val_loss: 0.9766 - val_accuracy: 0.5392\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9800 - accuracy: 0.5266 - val_loss: 0.9763 - val_accuracy: 0.5374\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9799 - accuracy: 0.5269 - val_loss: 0.9759 - val_accuracy: 0.5392\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9799 - accuracy: 0.5270 - val_loss: 0.9759 - val_accuracy: 0.5392\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9798 - accuracy: 0.5269 - val_loss: 0.9759 - val_accuracy: 0.5392\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9797 - accuracy: 0.5273 - val_loss: 0.9758 - val_accuracy: 0.5378\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9797 - accuracy: 0.5268 - val_loss: 0.9757 - val_accuracy: 0.5378\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9798 - accuracy: 0.5270 - val_loss: 0.9757 - val_accuracy: 0.5387\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9797 - accuracy: 0.5266 - val_loss: 0.9756 - val_accuracy: 0.5392\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9795 - accuracy: 0.5266 - val_loss: 0.9761 - val_accuracy: 0.5392\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9796 - accuracy: 0.5262 - val_loss: 0.9754 - val_accuracy: 0.5392\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9796 - accuracy: 0.5279 - val_loss: 0.9755 - val_accuracy: 0.5392\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9794 - accuracy: 0.5271 - val_loss: 0.9756 - val_accuracy: 0.5396\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9795 - accuracy: 0.5271 - val_loss: 0.9758 - val_accuracy: 0.5396\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5278 - val_loss: 0.9756 - val_accuracy: 0.5387\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9793 - accuracy: 0.5282 - val_loss: 0.9753 - val_accuracy: 0.5392\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9791 - accuracy: 0.5265 - val_loss: 0.9751 - val_accuracy: 0.5387\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9791 - accuracy: 0.5278 - val_loss: 0.9753 - val_accuracy: 0.5392\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9791 - accuracy: 0.5276 - val_loss: 0.9750 - val_accuracy: 0.5392\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9790 - accuracy: 0.5281 - val_loss: 0.9750 - val_accuracy: 0.5392\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9790 - accuracy: 0.5272 - val_loss: 0.9751 - val_accuracy: 0.5392\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9790 - accuracy: 0.5273 - val_loss: 0.9748 - val_accuracy: 0.5387\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9789 - accuracy: 0.5265 - val_loss: 0.9747 - val_accuracy: 0.5392\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9787 - accuracy: 0.5267 - val_loss: 0.9748 - val_accuracy: 0.5387\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9787 - accuracy: 0.5276 - val_loss: 0.9746 - val_accuracy: 0.5396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9787 - accuracy: 0.5275 - val_loss: 0.9747 - val_accuracy: 0.5387\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9786 - accuracy: 0.5279 - val_loss: 0.9744 - val_accuracy: 0.5396\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9786 - accuracy: 0.5272 - val_loss: 0.9743 - val_accuracy: 0.5405\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9785 - accuracy: 0.5287 - val_loss: 0.9745 - val_accuracy: 0.5427\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9784 - accuracy: 0.5277 - val_loss: 0.9746 - val_accuracy: 0.5396\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9783 - accuracy: 0.5285 - val_loss: 0.9743 - val_accuracy: 0.5401\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9785 - accuracy: 0.5275 - val_loss: 0.9745 - val_accuracy: 0.5396\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9782 - accuracy: 0.5266 - val_loss: 0.9743 - val_accuracy: 0.5418\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9782 - accuracy: 0.5283 - val_loss: 0.9743 - val_accuracy: 0.5396\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9782 - accuracy: 0.5266 - val_loss: 0.9739 - val_accuracy: 0.5418\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9782 - accuracy: 0.5275 - val_loss: 0.9742 - val_accuracy: 0.5396\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9781 - accuracy: 0.5273 - val_loss: 0.9741 - val_accuracy: 0.5436\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9784 - accuracy: 0.5273 - val_loss: 0.9750 - val_accuracy: 0.5370\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9781 - accuracy: 0.5285 - val_loss: 0.9744 - val_accuracy: 0.5432\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9780 - accuracy: 0.5274 - val_loss: 0.9741 - val_accuracy: 0.5396\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9779 - accuracy: 0.5293 - val_loss: 0.9738 - val_accuracy: 0.5436\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9779 - accuracy: 0.5299 - val_loss: 0.9740 - val_accuracy: 0.5432\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9779 - accuracy: 0.5271 - val_loss: 0.9737 - val_accuracy: 0.5405\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9777 - accuracy: 0.5288 - val_loss: 0.9738 - val_accuracy: 0.5396\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9779 - accuracy: 0.5270 - val_loss: 0.9741 - val_accuracy: 0.5405\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9777 - accuracy: 0.5268 - val_loss: 0.9734 - val_accuracy: 0.5401\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9777 - accuracy: 0.5277 - val_loss: 0.9733 - val_accuracy: 0.5405\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9776 - accuracy: 0.5274 - val_loss: 0.9735 - val_accuracy: 0.5405\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9775 - accuracy: 0.5280 - val_loss: 0.9732 - val_accuracy: 0.5405\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9775 - accuracy: 0.5265 - val_loss: 0.9731 - val_accuracy: 0.5396\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9775 - accuracy: 0.5269 - val_loss: 0.9731 - val_accuracy: 0.5392\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9781 - accuracy: 0.5268 - val_loss: 0.9739 - val_accuracy: 0.5401\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9775 - accuracy: 0.5277 - val_loss: 0.9733 - val_accuracy: 0.5418\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9773 - accuracy: 0.5267 - val_loss: 0.9728 - val_accuracy: 0.5405\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9772 - accuracy: 0.5267 - val_loss: 0.9727 - val_accuracy: 0.5401\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5310 - val_loss: 0.9726 - val_accuracy: 0.5418\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9728 - val_accuracy: 0.5405\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9774 - accuracy: 0.5275 - val_loss: 0.9728 - val_accuracy: 0.5401\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9772 - accuracy: 0.5271 - val_loss: 0.9724 - val_accuracy: 0.5392\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9772 - accuracy: 0.5267 - val_loss: 0.9721 - val_accuracy: 0.5405\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9772 - accuracy: 0.5274 - val_loss: 0.9722 - val_accuracy: 0.5401\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9772 - accuracy: 0.5269 - val_loss: 0.9725 - val_accuracy: 0.5405\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5271 - val_loss: 0.9720 - val_accuracy: 0.5401\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9772 - accuracy: 0.5275 - val_loss: 0.9727 - val_accuracy: 0.5427\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9769 - accuracy: 0.5304 - val_loss: 0.9723 - val_accuracy: 0.5414\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9769 - accuracy: 0.5299 - val_loss: 0.9722 - val_accuracy: 0.5432\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9770 - accuracy: 0.5293 - val_loss: 0.9721 - val_accuracy: 0.5401\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5284 - val_loss: 0.9721 - val_accuracy: 0.5405\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9767 - accuracy: 0.5284 - val_loss: 0.9719 - val_accuracy: 0.5432\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9768 - accuracy: 0.5306 - val_loss: 0.9719 - val_accuracy: 0.5432\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9768 - accuracy: 0.5292 - val_loss: 0.9719 - val_accuracy: 0.5409\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9768 - accuracy: 0.5276 - val_loss: 0.9717 - val_accuracy: 0.5423\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9766 - accuracy: 0.5302 - val_loss: 0.9717 - val_accuracy: 0.5427\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9766 - accuracy: 0.5301 - val_loss: 0.9718 - val_accuracy: 0.5432\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9771 - accuracy: 0.5296 - val_loss: 0.9725 - val_accuracy: 0.5383\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9767 - accuracy: 0.5299 - val_loss: 0.9723 - val_accuracy: 0.5432\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9766 - accuracy: 0.5275 - val_loss: 0.9719 - val_accuracy: 0.5440\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9765 - accuracy: 0.5308 - val_loss: 0.9719 - val_accuracy: 0.5418\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9765 - accuracy: 0.5313 - val_loss: 0.9715 - val_accuracy: 0.5427\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9765 - accuracy: 0.5304 - val_loss: 0.9719 - val_accuracy: 0.5414\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9766 - accuracy: 0.5269 - val_loss: 0.9718 - val_accuracy: 0.5405\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9764 - accuracy: 0.5274 - val_loss: 0.9713 - val_accuracy: 0.5414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9762 - accuracy: 0.5275 - val_loss: 0.9709 - val_accuracy: 0.5440\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9763 - accuracy: 0.5303 - val_loss: 0.9711 - val_accuracy: 0.5427\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9762 - accuracy: 0.5304 - val_loss: 0.9713 - val_accuracy: 0.5436\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9767 - accuracy: 0.5289 - val_loss: 0.9722 - val_accuracy: 0.5427\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9763 - accuracy: 0.5313 - val_loss: 0.9719 - val_accuracy: 0.5423\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9762 - accuracy: 0.5296 - val_loss: 0.9717 - val_accuracy: 0.5409\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 682us/step - loss: 0.9762 - accuracy: 0.5311 - val_loss: 0.9714 - val_accuracy: 0.5423\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9762 - accuracy: 0.5312 - val_loss: 0.9717 - val_accuracy: 0.5440\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9762 - accuracy: 0.5283 - val_loss: 0.9710 - val_accuracy: 0.5427\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9761 - accuracy: 0.5302 - val_loss: 0.9710 - val_accuracy: 0.5427\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9760 - accuracy: 0.5289 - val_loss: 0.9707 - val_accuracy: 0.5445\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9759 - accuracy: 0.5290 - val_loss: 0.9704 - val_accuracy: 0.5436\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9705 - val_accuracy: 0.5427\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9758 - accuracy: 0.5308 - val_loss: 0.9704 - val_accuracy: 0.5436\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9759 - accuracy: 0.5300 - val_loss: 0.9706 - val_accuracy: 0.5409\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9758 - accuracy: 0.5306 - val_loss: 0.9706 - val_accuracy: 0.5409\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9759 - accuracy: 0.5306 - val_loss: 0.9706 - val_accuracy: 0.5409\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9760 - accuracy: 0.5313 - val_loss: 0.9705 - val_accuracy: 0.5436\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9706 - val_accuracy: 0.5401\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9762 - accuracy: 0.5303 - val_loss: 0.9711 - val_accuracy: 0.5418\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9757 - accuracy: 0.5302 - val_loss: 0.9706 - val_accuracy: 0.5436\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9757 - accuracy: 0.5308 - val_loss: 0.9704 - val_accuracy: 0.5409\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9757 - accuracy: 0.5310 - val_loss: 0.9708 - val_accuracy: 0.5432\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9757 - accuracy: 0.5269 - val_loss: 0.9705 - val_accuracy: 0.5432\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9755 - accuracy: 0.5301 - val_loss: 0.9705 - val_accuracy: 0.5436\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9755 - accuracy: 0.5312 - val_loss: 0.9701 - val_accuracy: 0.5401\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9761 - accuracy: 0.5316 - val_loss: 0.9703 - val_accuracy: 0.5423\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9756 - accuracy: 0.5282 - val_loss: 0.9702 - val_accuracy: 0.5409\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9757 - accuracy: 0.5305 - val_loss: 0.9707 - val_accuracy: 0.5414\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 709us/step - loss: 0.9755 - accuracy: 0.5315 - val_loss: 0.9708 - val_accuracy: 0.5401\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9755 - accuracy: 0.5304 - val_loss: 0.9704 - val_accuracy: 0.5418\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9753 - accuracy: 0.5308 - val_loss: 0.9702 - val_accuracy: 0.5432\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 688us/step - loss: 0.9753 - accuracy: 0.5310 - val_loss: 0.9701 - val_accuracy: 0.5418\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9754 - accuracy: 0.5309 - val_loss: 0.9701 - val_accuracy: 0.5432\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9754 - accuracy: 0.5307 - val_loss: 0.9706 - val_accuracy: 0.5423\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9754 - accuracy: 0.5312 - val_loss: 0.9704 - val_accuracy: 0.5401\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9752 - accuracy: 0.5310 - val_loss: 0.9703 - val_accuracy: 0.5418\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9753 - accuracy: 0.5308 - val_loss: 0.9702 - val_accuracy: 0.5414\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9752 - accuracy: 0.5315 - val_loss: 0.9702 - val_accuracy: 0.5418\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9752 - accuracy: 0.5308 - val_loss: 0.9706 - val_accuracy: 0.5445\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9752 - accuracy: 0.5311 - val_loss: 0.9703 - val_accuracy: 0.5418\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9756 - accuracy: 0.5284 - val_loss: 0.9704 - val_accuracy: 0.5409\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9753 - accuracy: 0.5319 - val_loss: 0.9700 - val_accuracy: 0.5396\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9700 - val_accuracy: 0.5414\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9750 - accuracy: 0.5315 - val_loss: 0.9696 - val_accuracy: 0.5401\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9749 - accuracy: 0.5303 - val_loss: 0.9694 - val_accuracy: 0.5392\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9750 - accuracy: 0.5311 - val_loss: 0.9692 - val_accuracy: 0.5396\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9750 - accuracy: 0.5292 - val_loss: 0.9693 - val_accuracy: 0.5418\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9693 - val_accuracy: 0.5401\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9749 - accuracy: 0.5301 - val_loss: 0.9692 - val_accuracy: 0.5409\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9749 - accuracy: 0.5311 - val_loss: 0.9690 - val_accuracy: 0.5405\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9750 - accuracy: 0.5314 - val_loss: 0.9691 - val_accuracy: 0.5418\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9749 - accuracy: 0.5315 - val_loss: 0.9689 - val_accuracy: 0.5405\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9749 - accuracy: 0.5304 - val_loss: 0.9693 - val_accuracy: 0.5423\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9749 - accuracy: 0.5311 - val_loss: 0.9696 - val_accuracy: 0.5423\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9749 - accuracy: 0.5306 - val_loss: 0.9693 - val_accuracy: 0.5418\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 601us/step - loss: 0.9749 - accuracy: 0.5308 - val_loss: 0.9691 - val_accuracy: 0.5392\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9749 - accuracy: 0.5313 - val_loss: 0.9690 - val_accuracy: 0.5409\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9748 - accuracy: 0.5316 - val_loss: 0.9690 - val_accuracy: 0.5409\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9747 - accuracy: 0.5312 - val_loss: 0.9689 - val_accuracy: 0.5418\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9746 - accuracy: 0.5309 - val_loss: 0.9689 - val_accuracy: 0.5418\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9749 - accuracy: 0.5298 - val_loss: 0.9688 - val_accuracy: 0.5409\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9748 - accuracy: 0.5303 - val_loss: 0.9686 - val_accuracy: 0.5418\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9746 - accuracy: 0.5306 - val_loss: 0.9687 - val_accuracy: 0.5418\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9746 - accuracy: 0.5281 - val_loss: 0.9683 - val_accuracy: 0.5401\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9686 - val_accuracy: 0.5401\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9746 - accuracy: 0.5311 - val_loss: 0.9689 - val_accuracy: 0.5401\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9747 - accuracy: 0.5315 - val_loss: 0.9689 - val_accuracy: 0.5414\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9747 - accuracy: 0.5315 - val_loss: 0.9691 - val_accuracy: 0.5414\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9747 - accuracy: 0.5309 - val_loss: 0.9689 - val_accuracy: 0.5414\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9745 - accuracy: 0.5315 - val_loss: 0.9687 - val_accuracy: 0.5414\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9746 - accuracy: 0.5315 - val_loss: 0.9689 - val_accuracy: 0.5414\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9744 - accuracy: 0.5310 - val_loss: 0.9689 - val_accuracy: 0.5409\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9746 - accuracy: 0.5315 - val_loss: 0.9687 - val_accuracy: 0.5414\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9744 - accuracy: 0.5306 - val_loss: 0.9689 - val_accuracy: 0.5405\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9744 - accuracy: 0.5303 - val_loss: 0.9686 - val_accuracy: 0.5414\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 354us/step - loss: 0.9742 - accuracy: 0.5318\n",
      "Accuracy : 0.5317956209182739\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9686 - accuracy: 0.5414\n",
      "Accuracy : 0.5413900017738342\n",
      "\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 3.2648 - accuracy: 0.2352 - val_loss: 3.1870 - val_accuracy: 0.2098\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 2.6606 - accuracy: 0.2256 - val_loss: 2.6555 - val_accuracy: 0.2045\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 2.2542 - accuracy: 0.2252 - val_loss: 2.2823 - val_accuracy: 0.2010\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 1.9630 - accuracy: 0.2336 - val_loss: 1.9724 - val_accuracy: 0.2134\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 1.7217 - accuracy: 0.2591 - val_loss: 1.7057 - val_accuracy: 0.2293\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.5252 - accuracy: 0.2633 - val_loss: 1.4998 - val_accuracy: 0.2328\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.3764 - accuracy: 0.2631 - val_loss: 1.3555 - val_accuracy: 0.2275\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.2800 - accuracy: 0.2482 - val_loss: 1.2664 - val_accuracy: 0.2041\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.2171 - accuracy: 0.2286 - val_loss: 1.2088 - val_accuracy: 0.2001\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 1.1744 - accuracy: 0.2213 - val_loss: 1.1719 - val_accuracy: 0.2010\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.1492 - accuracy: 0.2210 - val_loss: 1.1503 - val_accuracy: 0.2010\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.1334 - accuracy: 0.2206 - val_loss: 1.1364 - val_accuracy: 0.2023\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 1.1229 - accuracy: 0.2205 - val_loss: 1.1267 - val_accuracy: 0.2032\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.1161 - accuracy: 0.2203 - val_loss: 1.1205 - val_accuracy: 0.2032\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 1.1112 - accuracy: 0.2194 - val_loss: 1.1159 - val_accuracy: 0.2032\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 1.1072 - accuracy: 0.2206 - val_loss: 1.1119 - val_accuracy: 0.2032\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 1.1041 - accuracy: 0.2204 - val_loss: 1.1085 - val_accuracy: 0.2023\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.1015 - accuracy: 0.2204 - val_loss: 1.1060 - val_accuracy: 0.2023\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0993 - accuracy: 0.2208 - val_loss: 1.1036 - val_accuracy: 0.2023\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0973 - accuracy: 0.2208 - val_loss: 1.1020 - val_accuracy: 0.2010\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0956 - accuracy: 0.2210 - val_loss: 1.1005 - val_accuracy: 0.2005\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 1.0940 - accuracy: 0.2225 - val_loss: 1.0991 - val_accuracy: 0.2001\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 1.0924 - accuracy: 0.2274 - val_loss: 1.0978 - val_accuracy: 0.2032\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 1.0909 - accuracy: 0.2436 - val_loss: 1.0961 - val_accuracy: 0.2125\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0893 - accuracy: 0.2570 - val_loss: 1.0951 - val_accuracy: 0.2315\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 1.0877 - accuracy: 0.2731 - val_loss: 1.0941 - val_accuracy: 0.2373\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 1.0860 - accuracy: 0.3170 - val_loss: 1.0922 - val_accuracy: 0.2966\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0836 - accuracy: 0.4017 - val_loss: 1.0891 - val_accuracy: 0.4591\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0786 - accuracy: 0.4591 - val_loss: 1.0797 - val_accuracy: 0.4591\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0527 - accuracy: 0.4591 - val_loss: 1.0176 - val_accuracy: 0.4591\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 1.0175 - accuracy: 0.4591 - val_loss: 1.0080 - val_accuracy: 0.4591\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0129 - accuracy: 0.4591 - val_loss: 1.0052 - val_accuracy: 0.4591\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0109 - accuracy: 0.4590 - val_loss: 1.0026 - val_accuracy: 0.4591\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0095 - accuracy: 0.4591 - val_loss: 1.0019 - val_accuracy: 0.4591\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0086 - accuracy: 0.4592 - val_loss: 1.0007 - val_accuracy: 0.4591\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 620us/step - loss: 1.0079 - accuracy: 0.4593 - val_loss: 0.9994 - val_accuracy: 0.4591\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 1.0075 - accuracy: 0.4595 - val_loss: 0.9992 - val_accuracy: 0.4591\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 1.0073 - accuracy: 0.4596 - val_loss: 0.9979 - val_accuracy: 0.4599\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.0066 - accuracy: 0.4597 - val_loss: 0.9987 - val_accuracy: 0.4599\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0065 - accuracy: 0.4597 - val_loss: 0.9978 - val_accuracy: 0.4599\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 1.0064 - accuracy: 0.4600 - val_loss: 0.9978 - val_accuracy: 0.4604\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.0061 - accuracy: 0.4601 - val_loss: 0.9976 - val_accuracy: 0.4604\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 1.0059 - accuracy: 0.4603 - val_loss: 0.9978 - val_accuracy: 0.4604\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 1.0058 - accuracy: 0.4605 - val_loss: 0.9970 - val_accuracy: 0.4599\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 1.0057 - accuracy: 0.4609 - val_loss: 0.9967 - val_accuracy: 0.4599\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0055 - accuracy: 0.4610 - val_loss: 0.9967 - val_accuracy: 0.4599\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0054 - accuracy: 0.4610 - val_loss: 0.9969 - val_accuracy: 0.4599\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 1.0054 - accuracy: 0.4608 - val_loss: 0.9958 - val_accuracy: 0.4604\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0053 - accuracy: 0.4608 - val_loss: 0.9959 - val_accuracy: 0.4608\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 1.0051 - accuracy: 0.4611 - val_loss: 0.9955 - val_accuracy: 0.4613\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 1.0053 - accuracy: 0.4623 - val_loss: 0.9949 - val_accuracy: 0.4622\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0050 - accuracy: 0.4626 - val_loss: 0.9951 - val_accuracy: 0.4630\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0048 - accuracy: 0.4627 - val_loss: 0.9958 - val_accuracy: 0.4626\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.0047 - accuracy: 0.4626 - val_loss: 0.9940 - val_accuracy: 0.4622\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 1.0047 - accuracy: 0.4635 - val_loss: 0.9949 - val_accuracy: 0.4630\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0044 - accuracy: 0.4634 - val_loss: 0.9953 - val_accuracy: 0.4635\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 1.0043 - accuracy: 0.4639 - val_loss: 0.9943 - val_accuracy: 0.4635\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 1.0041 - accuracy: 0.4653 - val_loss: 0.9941 - val_accuracy: 0.4688\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 1.0039 - accuracy: 0.4759 - val_loss: 0.9936 - val_accuracy: 0.4861\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 1.0036 - accuracy: 0.4746 - val_loss: 0.9932 - val_accuracy: 0.4838\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0033 - accuracy: 0.4758 - val_loss: 0.9934 - val_accuracy: 0.4887\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 1.0029 - accuracy: 0.4776 - val_loss: 0.9929 - val_accuracy: 0.4896\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0023 - accuracy: 0.4778 - val_loss: 0.9912 - val_accuracy: 0.4940\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 1.0015 - accuracy: 0.4799 - val_loss: 0.9893 - val_accuracy: 0.4945\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0001 - accuracy: 0.4950 - val_loss: 0.9872 - val_accuracy: 0.5139\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9981 - accuracy: 0.4954 - val_loss: 0.9853 - val_accuracy: 0.5268\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9955 - accuracy: 0.4989 - val_loss: 0.9826 - val_accuracy: 0.5268\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9938 - accuracy: 0.4979 - val_loss: 0.9814 - val_accuracy: 0.5263\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9931 - accuracy: 0.4977 - val_loss: 0.9805 - val_accuracy: 0.5250\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9926 - accuracy: 0.4982 - val_loss: 0.9800 - val_accuracy: 0.5303\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9915 - accuracy: 0.5083 - val_loss: 0.9792 - val_accuracy: 0.5356\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9913 - accuracy: 0.5074 - val_loss: 0.9794 - val_accuracy: 0.5317\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9907 - accuracy: 0.5143 - val_loss: 0.9788 - val_accuracy: 0.5401\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9903 - accuracy: 0.5204 - val_loss: 0.9784 - val_accuracy: 0.5378\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9900 - accuracy: 0.5238 - val_loss: 0.9781 - val_accuracy: 0.5418\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9898 - accuracy: 0.5255 - val_loss: 0.9773 - val_accuracy: 0.5467\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9896 - accuracy: 0.5276 - val_loss: 0.9779 - val_accuracy: 0.5432\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9893 - accuracy: 0.5289 - val_loss: 0.9768 - val_accuracy: 0.5432\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9893 - accuracy: 0.5294 - val_loss: 0.9765 - val_accuracy: 0.5405\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9888 - accuracy: 0.5311 - val_loss: 0.9766 - val_accuracy: 0.5414\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9885 - accuracy: 0.5306 - val_loss: 0.9767 - val_accuracy: 0.5405\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9883 - accuracy: 0.5317 - val_loss: 0.9761 - val_accuracy: 0.5418\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9881 - accuracy: 0.5309 - val_loss: 0.9760 - val_accuracy: 0.5414\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9880 - accuracy: 0.5301 - val_loss: 0.9757 - val_accuracy: 0.5401\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9875 - accuracy: 0.5319 - val_loss: 0.9745 - val_accuracy: 0.5405\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9873 - accuracy: 0.5309 - val_loss: 0.9743 - val_accuracy: 0.5418\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9871 - accuracy: 0.5322 - val_loss: 0.9732 - val_accuracy: 0.5405\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9869 - accuracy: 0.5316 - val_loss: 0.9738 - val_accuracy: 0.5440\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9865 - accuracy: 0.5301 - val_loss: 0.9731 - val_accuracy: 0.5405\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9859 - accuracy: 0.5314 - val_loss: 0.9728 - val_accuracy: 0.5414\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9854 - accuracy: 0.5306 - val_loss: 0.9713 - val_accuracy: 0.5436\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9852 - accuracy: 0.5305 - val_loss: 0.9714 - val_accuracy: 0.5414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9849 - accuracy: 0.5301 - val_loss: 0.9707 - val_accuracy: 0.5414\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9844 - accuracy: 0.5317 - val_loss: 0.9705 - val_accuracy: 0.5418\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9840 - accuracy: 0.5298 - val_loss: 0.9705 - val_accuracy: 0.5423\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9835 - accuracy: 0.5313 - val_loss: 0.9696 - val_accuracy: 0.5418\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9828 - accuracy: 0.5315 - val_loss: 0.9694 - val_accuracy: 0.5418\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9824 - accuracy: 0.5315 - val_loss: 0.9680 - val_accuracy: 0.5418\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9820 - accuracy: 0.5322 - val_loss: 0.9676 - val_accuracy: 0.5423\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9812 - accuracy: 0.5308 - val_loss: 0.9676 - val_accuracy: 0.5418\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9804 - accuracy: 0.5316 - val_loss: 0.9666 - val_accuracy: 0.5409\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9798 - accuracy: 0.5320 - val_loss: 0.9659 - val_accuracy: 0.5440\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9793 - accuracy: 0.5312 - val_loss: 0.9659 - val_accuracy: 0.5409\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9785 - accuracy: 0.5311 - val_loss: 0.9641 - val_accuracy: 0.5440\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9782 - accuracy: 0.5309 - val_loss: 0.9643 - val_accuracy: 0.5445\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9785 - accuracy: 0.5287 - val_loss: 0.9641 - val_accuracy: 0.5418\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5310 - val_loss: 0.9642 - val_accuracy: 0.5432\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9772 - accuracy: 0.5310 - val_loss: 0.9652 - val_accuracy: 0.5423\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9769 - accuracy: 0.5311 - val_loss: 0.9640 - val_accuracy: 0.5418\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9766 - accuracy: 0.5296 - val_loss: 0.9631 - val_accuracy: 0.5423\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9634 - val_accuracy: 0.5427\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 791us/step - loss: 0.9763 - accuracy: 0.5303 - val_loss: 0.9616 - val_accuracy: 0.5418\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9768 - accuracy: 0.5308 - val_loss: 0.9636 - val_accuracy: 0.5463\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9763 - accuracy: 0.5294 - val_loss: 0.9631 - val_accuracy: 0.5440\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9761 - accuracy: 0.5305 - val_loss: 0.9632 - val_accuracy: 0.5463\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9762 - accuracy: 0.5301 - val_loss: 0.9638 - val_accuracy: 0.5458\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 673us/step - loss: 0.9760 - accuracy: 0.5304 - val_loss: 0.9631 - val_accuracy: 0.5449\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9760 - accuracy: 0.5293 - val_loss: 0.9629 - val_accuracy: 0.5458\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9759 - accuracy: 0.5289 - val_loss: 0.9632 - val_accuracy: 0.5467\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9758 - accuracy: 0.5290 - val_loss: 0.9628 - val_accuracy: 0.5467\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9757 - accuracy: 0.5306 - val_loss: 0.9629 - val_accuracy: 0.5458\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9757 - accuracy: 0.5290 - val_loss: 0.9626 - val_accuracy: 0.5440\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 0.9626 - val_accuracy: 0.5458\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9632 - val_accuracy: 0.5458\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9629 - val_accuracy: 0.5467\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9756 - accuracy: 0.5294 - val_loss: 0.9623 - val_accuracy: 0.5467\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9760 - accuracy: 0.5296 - val_loss: 0.9621 - val_accuracy: 0.5458\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9752 - accuracy: 0.5287 - val_loss: 0.9625 - val_accuracy: 0.5432\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9753 - accuracy: 0.5311 - val_loss: 0.9621 - val_accuracy: 0.5449\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9754 - accuracy: 0.5297 - val_loss: 0.9625 - val_accuracy: 0.5449\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9752 - accuracy: 0.5310 - val_loss: 0.9627 - val_accuracy: 0.5432\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9752 - accuracy: 0.5308 - val_loss: 0.9628 - val_accuracy: 0.5471\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9750 - accuracy: 0.5295 - val_loss: 0.9620 - val_accuracy: 0.5423\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9752 - accuracy: 0.5312 - val_loss: 0.9624 - val_accuracy: 0.5440\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9751 - accuracy: 0.5310 - val_loss: 0.9630 - val_accuracy: 0.5449\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9753 - accuracy: 0.5307 - val_loss: 0.9631 - val_accuracy: 0.5458\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9625 - val_accuracy: 0.5463\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9750 - accuracy: 0.5296 - val_loss: 0.9622 - val_accuracy: 0.5449\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9749 - accuracy: 0.5294 - val_loss: 0.9623 - val_accuracy: 0.5463\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9750 - accuracy: 0.5288 - val_loss: 0.9629 - val_accuracy: 0.5458\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9750 - accuracy: 0.5287 - val_loss: 0.9628 - val_accuracy: 0.5458\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9753 - accuracy: 0.5280 - val_loss: 0.9627 - val_accuracy: 0.5458\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9630 - val_accuracy: 0.5423\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9749 - accuracy: 0.5289 - val_loss: 0.9622 - val_accuracy: 0.5458\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9748 - accuracy: 0.5288 - val_loss: 0.9619 - val_accuracy: 0.5458\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9749 - accuracy: 0.5296 - val_loss: 0.9622 - val_accuracy: 0.5463\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9749 - accuracy: 0.5291 - val_loss: 0.9616 - val_accuracy: 0.5463\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9758 - accuracy: 0.5300 - val_loss: 0.9612 - val_accuracy: 0.5458\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 586us/step - loss: 0.9749 - accuracy: 0.5286 - val_loss: 0.9617 - val_accuracy: 0.5458\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9748 - accuracy: 0.5294 - val_loss: 0.9621 - val_accuracy: 0.5458\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9751 - accuracy: 0.5286 - val_loss: 0.9622 - val_accuracy: 0.5405\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9746 - accuracy: 0.5293 - val_loss: 0.9613 - val_accuracy: 0.5440\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9747 - accuracy: 0.5303 - val_loss: 0.9620 - val_accuracy: 0.5449\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9748 - accuracy: 0.5307 - val_loss: 0.9620 - val_accuracy: 0.5463\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9746 - accuracy: 0.5302 - val_loss: 0.9627 - val_accuracy: 0.5458\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9747 - accuracy: 0.5286 - val_loss: 0.9624 - val_accuracy: 0.5463\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9746 - accuracy: 0.5295 - val_loss: 0.9623 - val_accuracy: 0.5440\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9747 - accuracy: 0.5304 - val_loss: 0.9620 - val_accuracy: 0.5432\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9747 - accuracy: 0.5306 - val_loss: 0.9620 - val_accuracy: 0.5471\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9746 - accuracy: 0.5295 - val_loss: 0.9618 - val_accuracy: 0.5467\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9747 - accuracy: 0.5303 - val_loss: 0.9619 - val_accuracy: 0.5458\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9746 - accuracy: 0.5308 - val_loss: 0.9623 - val_accuracy: 0.5463\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9747 - accuracy: 0.5291 - val_loss: 0.9613 - val_accuracy: 0.5467\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9747 - accuracy: 0.5313 - val_loss: 0.9622 - val_accuracy: 0.5463\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9746 - accuracy: 0.5293 - val_loss: 0.9620 - val_accuracy: 0.5463\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9747 - accuracy: 0.5294 - val_loss: 0.9618 - val_accuracy: 0.5458\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9745 - accuracy: 0.5296 - val_loss: 0.9619 - val_accuracy: 0.5467\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9744 - accuracy: 0.5294 - val_loss: 0.9618 - val_accuracy: 0.5427\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9745 - accuracy: 0.5296 - val_loss: 0.9622 - val_accuracy: 0.5458\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9746 - accuracy: 0.5285 - val_loss: 0.9625 - val_accuracy: 0.5467\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9746 - accuracy: 0.5314 - val_loss: 0.9617 - val_accuracy: 0.5458\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9746 - accuracy: 0.5299 - val_loss: 0.9614 - val_accuracy: 0.5449\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9744 - accuracy: 0.5296 - val_loss: 0.9622 - val_accuracy: 0.5458\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9749 - accuracy: 0.5287 - val_loss: 0.9614 - val_accuracy: 0.5427\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9747 - accuracy: 0.5294 - val_loss: 0.9613 - val_accuracy: 0.5458\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9617 - val_accuracy: 0.5458\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9744 - accuracy: 0.5295 - val_loss: 0.9615 - val_accuracy: 0.5440\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9744 - accuracy: 0.5299 - val_loss: 0.9621 - val_accuracy: 0.5463\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9744 - accuracy: 0.5290 - val_loss: 0.9616 - val_accuracy: 0.5449\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9743 - accuracy: 0.5298 - val_loss: 0.9624 - val_accuracy: 0.5432\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9744 - accuracy: 0.5295 - val_loss: 0.9619 - val_accuracy: 0.5463\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9745 - accuracy: 0.5294 - val_loss: 0.9614 - val_accuracy: 0.5432\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9745 - accuracy: 0.5311 - val_loss: 0.9612 - val_accuracy: 0.5432\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9749 - accuracy: 0.5303 - val_loss: 0.9619 - val_accuracy: 0.5458\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9745 - accuracy: 0.5290 - val_loss: 0.9617 - val_accuracy: 0.5458\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9744 - accuracy: 0.5282 - val_loss: 0.9612 - val_accuracy: 0.5467\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9745 - accuracy: 0.5296 - val_loss: 0.9614 - val_accuracy: 0.5454\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9746 - accuracy: 0.5303 - val_loss: 0.9618 - val_accuracy: 0.5449\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9744 - accuracy: 0.5290 - val_loss: 0.9621 - val_accuracy: 0.5458\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9744 - accuracy: 0.5292 - val_loss: 0.9616 - val_accuracy: 0.5467\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9745 - accuracy: 0.5304 - val_loss: 0.9620 - val_accuracy: 0.5463\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9743 - accuracy: 0.5299 - val_loss: 0.9611 - val_accuracy: 0.5458\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9743 - accuracy: 0.5294 - val_loss: 0.9616 - val_accuracy: 0.5467\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9743 - accuracy: 0.5293 - val_loss: 0.9620 - val_accuracy: 0.5432\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9743 - accuracy: 0.5315 - val_loss: 0.9608 - val_accuracy: 0.5423\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9744 - accuracy: 0.5307 - val_loss: 0.9610 - val_accuracy: 0.5427\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9610 - val_accuracy: 0.5467\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9744 - accuracy: 0.5304 - val_loss: 0.9613 - val_accuracy: 0.5467\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9743 - accuracy: 0.5307 - val_loss: 0.9607 - val_accuracy: 0.5449\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9752 - accuracy: 0.5298 - val_loss: 0.9605 - val_accuracy: 0.5463\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 337us/step - loss: 0.9742 - accuracy: 0.5295\n",
      "Accuracy : 0.5294840931892395\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9605 - accuracy: 0.5463\n",
      "Accuracy : 0.5462594032287598\n",
      "\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.1961 - accuracy: 0.3785 - val_loss: 1.0739 - val_accuracy: 0.4307\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 811us/step - loss: 1.0710 - accuracy: 0.4402 - val_loss: 0.9706 - val_accuracy: 0.5007\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 1.0058 - accuracy: 0.4924 - val_loss: 0.9538 - val_accuracy: 0.5463\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 624us/step - loss: 0.9938 - accuracy: 0.5240 - val_loss: 0.9517 - val_accuracy: 0.5423\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9909 - accuracy: 0.5276 - val_loss: 0.9499 - val_accuracy: 0.5436\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 720us/step - loss: 0.9883 - accuracy: 0.5289 - val_loss: 0.9477 - val_accuracy: 0.5423\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9869 - accuracy: 0.5286 - val_loss: 0.9461 - val_accuracy: 0.5423\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9852 - accuracy: 0.5289 - val_loss: 0.9443 - val_accuracy: 0.5445\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9839 - accuracy: 0.5291 - val_loss: 0.9427 - val_accuracy: 0.5436\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 737us/step - loss: 0.9829 - accuracy: 0.5290 - val_loss: 0.9417 - val_accuracy: 0.5445\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9822 - accuracy: 0.5295 - val_loss: 0.9414 - val_accuracy: 0.5476\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9818 - accuracy: 0.5296 - val_loss: 0.9412 - val_accuracy: 0.5458\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9818 - accuracy: 0.5295 - val_loss: 0.9409 - val_accuracy: 0.5476\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9814 - accuracy: 0.5289 - val_loss: 0.9406 - val_accuracy: 0.5463\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9813 - accuracy: 0.5292 - val_loss: 0.9407 - val_accuracy: 0.5476\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9815 - accuracy: 0.5284 - val_loss: 0.9409 - val_accuracy: 0.5423\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9812 - accuracy: 0.5290 - val_loss: 0.9404 - val_accuracy: 0.5427\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9809 - accuracy: 0.5292 - val_loss: 0.9402 - val_accuracy: 0.5440\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9807 - accuracy: 0.5290 - val_loss: 0.9402 - val_accuracy: 0.5445\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9807 - accuracy: 0.5293 - val_loss: 0.9401 - val_accuracy: 0.5445\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9807 - accuracy: 0.5287 - val_loss: 0.9401 - val_accuracy: 0.5436\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9805 - accuracy: 0.5295 - val_loss: 0.9403 - val_accuracy: 0.5445\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9805 - accuracy: 0.5290 - val_loss: 0.9403 - val_accuracy: 0.5440\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9804 - accuracy: 0.5290 - val_loss: 0.9400 - val_accuracy: 0.5445\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9804 - accuracy: 0.5295 - val_loss: 0.9402 - val_accuracy: 0.5440\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9804 - accuracy: 0.5289 - val_loss: 0.9402 - val_accuracy: 0.5445\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9802 - accuracy: 0.5289 - val_loss: 0.9399 - val_accuracy: 0.5440\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9804 - accuracy: 0.5283 - val_loss: 0.9400 - val_accuracy: 0.5440\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9802 - accuracy: 0.5296 - val_loss: 0.9398 - val_accuracy: 0.5418\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9804 - accuracy: 0.5277 - val_loss: 0.9402 - val_accuracy: 0.5423\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9801 - accuracy: 0.5292 - val_loss: 0.9393 - val_accuracy: 0.5418\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9804 - accuracy: 0.5277 - val_loss: 0.9398 - val_accuracy: 0.5432\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9800 - accuracy: 0.5287 - val_loss: 0.9399 - val_accuracy: 0.5423\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9800 - accuracy: 0.5282 - val_loss: 0.9398 - val_accuracy: 0.5423\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9799 - accuracy: 0.5290 - val_loss: 0.9396 - val_accuracy: 0.5423\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9802 - accuracy: 0.5293 - val_loss: 0.9397 - val_accuracy: 0.5423\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9799 - accuracy: 0.5291 - val_loss: 0.9398 - val_accuracy: 0.5423\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9798 - accuracy: 0.5289 - val_loss: 0.9404 - val_accuracy: 0.5445\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9798 - accuracy: 0.5293 - val_loss: 0.9396 - val_accuracy: 0.5423\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9797 - accuracy: 0.5288 - val_loss: 0.9401 - val_accuracy: 0.5440\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9797 - accuracy: 0.5287 - val_loss: 0.9405 - val_accuracy: 0.5440\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9802 - accuracy: 0.5293 - val_loss: 0.9399 - val_accuracy: 0.5423\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9797 - accuracy: 0.5289 - val_loss: 0.9396 - val_accuracy: 0.5427\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9799 - accuracy: 0.5292 - val_loss: 0.9391 - val_accuracy: 0.5423\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9796 - accuracy: 0.5290 - val_loss: 0.9394 - val_accuracy: 0.5423\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9796 - accuracy: 0.5293 - val_loss: 0.9399 - val_accuracy: 0.5440\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9796 - accuracy: 0.5285 - val_loss: 0.9398 - val_accuracy: 0.5423\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9795 - accuracy: 0.5292 - val_loss: 0.9407 - val_accuracy: 0.5436\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9797 - accuracy: 0.5291 - val_loss: 0.9395 - val_accuracy: 0.5423\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9797 - accuracy: 0.5291 - val_loss: 0.9397 - val_accuracy: 0.5423\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9796 - accuracy: 0.5288 - val_loss: 0.9397 - val_accuracy: 0.5440\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9794 - accuracy: 0.5290 - val_loss: 0.9391 - val_accuracy: 0.5423\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5288 - val_loss: 0.9395 - val_accuracy: 0.5440\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9393 - val_accuracy: 0.5440\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9795 - accuracy: 0.5293 - val_loss: 0.9391 - val_accuracy: 0.5423\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9793 - accuracy: 0.5282 - val_loss: 0.9391 - val_accuracy: 0.5423\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9793 - accuracy: 0.5291 - val_loss: 0.9396 - val_accuracy: 0.5440\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9795 - accuracy: 0.5295 - val_loss: 0.9395 - val_accuracy: 0.5423\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9791 - accuracy: 0.5290 - val_loss: 0.9394 - val_accuracy: 0.5427\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9797 - accuracy: 0.5297 - val_loss: 0.9403 - val_accuracy: 0.5440\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 638us/step - loss: 0.9792 - accuracy: 0.5293 - val_loss: 0.9394 - val_accuracy: 0.5423\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9794 - accuracy: 0.5291 - val_loss: 0.9391 - val_accuracy: 0.5423\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9792 - accuracy: 0.5292 - val_loss: 0.9392 - val_accuracy: 0.5440\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9791 - accuracy: 0.5289 - val_loss: 0.9397 - val_accuracy: 0.5445\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9793 - accuracy: 0.5296 - val_loss: 0.9394 - val_accuracy: 0.5427\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9791 - accuracy: 0.5290 - val_loss: 0.9391 - val_accuracy: 0.5423\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9790 - accuracy: 0.5289 - val_loss: 0.9396 - val_accuracy: 0.5440\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9791 - accuracy: 0.5293 - val_loss: 0.9390 - val_accuracy: 0.5423\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9790 - accuracy: 0.5290 - val_loss: 0.9387 - val_accuracy: 0.5423\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9789 - accuracy: 0.5287 - val_loss: 0.9391 - val_accuracy: 0.5423\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9789 - accuracy: 0.5283 - val_loss: 0.9391 - val_accuracy: 0.5423\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9794 - accuracy: 0.5292 - val_loss: 0.9393 - val_accuracy: 0.5423\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9789 - accuracy: 0.5293 - val_loss: 0.9390 - val_accuracy: 0.5423\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9789 - accuracy: 0.5288 - val_loss: 0.9389 - val_accuracy: 0.5423\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9788 - accuracy: 0.5289 - val_loss: 0.9389 - val_accuracy: 0.5423\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9790 - accuracy: 0.5281 - val_loss: 0.9394 - val_accuracy: 0.5423\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9788 - accuracy: 0.5291 - val_loss: 0.9391 - val_accuracy: 0.5427\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9788 - accuracy: 0.5290 - val_loss: 0.9389 - val_accuracy: 0.5427\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9787 - accuracy: 0.5288 - val_loss: 0.9389 - val_accuracy: 0.5427\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 664us/step - loss: 0.9789 - accuracy: 0.5291 - val_loss: 0.9384 - val_accuracy: 0.5423\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9787 - accuracy: 0.5289 - val_loss: 0.9387 - val_accuracy: 0.5445\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9788 - accuracy: 0.5287 - val_loss: 0.9391 - val_accuracy: 0.5436\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9788 - accuracy: 0.5296 - val_loss: 0.9390 - val_accuracy: 0.5440\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9787 - accuracy: 0.5287 - val_loss: 0.9383 - val_accuracy: 0.5423\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9786 - accuracy: 0.5290 - val_loss: 0.9382 - val_accuracy: 0.5418\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9787 - accuracy: 0.5277 - val_loss: 0.9388 - val_accuracy: 0.5423\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9786 - accuracy: 0.5293 - val_loss: 0.9386 - val_accuracy: 0.5440\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9786 - accuracy: 0.5294 - val_loss: 0.9391 - val_accuracy: 0.5445\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9789 - accuracy: 0.5289 - val_loss: 0.9391 - val_accuracy: 0.5436\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9784 - accuracy: 0.5296 - val_loss: 0.9386 - val_accuracy: 0.5427\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9785 - accuracy: 0.5298 - val_loss: 0.9390 - val_accuracy: 0.5436\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9787 - accuracy: 0.5288 - val_loss: 0.9389 - val_accuracy: 0.5423\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9785 - accuracy: 0.5289 - val_loss: 0.9387 - val_accuracy: 0.5440\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9786 - accuracy: 0.5291 - val_loss: 0.9382 - val_accuracy: 0.5423\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9783 - accuracy: 0.5295 - val_loss: 0.9383 - val_accuracy: 0.5440\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9786 - accuracy: 0.5293 - val_loss: 0.9386 - val_accuracy: 0.5445\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9784 - accuracy: 0.5292 - val_loss: 0.9390 - val_accuracy: 0.5436\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9787 - accuracy: 0.5301 - val_loss: 0.9387 - val_accuracy: 0.5427\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9785 - accuracy: 0.5289 - val_loss: 0.9384 - val_accuracy: 0.5427\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9784 - accuracy: 0.5288 - val_loss: 0.9382 - val_accuracy: 0.5440\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9783 - accuracy: 0.5294 - val_loss: 0.9389 - val_accuracy: 0.5449\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9783 - accuracy: 0.5291 - val_loss: 0.9382 - val_accuracy: 0.5423\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9784 - accuracy: 0.5290 - val_loss: 0.9382 - val_accuracy: 0.5423\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9786 - accuracy: 0.5286 - val_loss: 0.9389 - val_accuracy: 0.5445\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9784 - accuracy: 0.5290 - val_loss: 0.9391 - val_accuracy: 0.5436\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9782 - accuracy: 0.5294 - val_loss: 0.9386 - val_accuracy: 0.5445\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9781 - accuracy: 0.5292 - val_loss: 0.9383 - val_accuracy: 0.5440\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9782 - accuracy: 0.5290 - val_loss: 0.9383 - val_accuracy: 0.5427\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9782 - accuracy: 0.5291 - val_loss: 0.9386 - val_accuracy: 0.5445\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9784 - accuracy: 0.5300 - val_loss: 0.9384 - val_accuracy: 0.5445\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9780 - accuracy: 0.5293 - val_loss: 0.9384 - val_accuracy: 0.5449\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9781 - accuracy: 0.5294 - val_loss: 0.9382 - val_accuracy: 0.5436\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9784 - accuracy: 0.5289 - val_loss: 0.9386 - val_accuracy: 0.5436\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9781 - accuracy: 0.5289 - val_loss: 0.9380 - val_accuracy: 0.5427\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9780 - accuracy: 0.5285 - val_loss: 0.9387 - val_accuracy: 0.5436\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9781 - accuracy: 0.5294 - val_loss: 0.9388 - val_accuracy: 0.5463\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9780 - accuracy: 0.5288 - val_loss: 0.9383 - val_accuracy: 0.5445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9780 - accuracy: 0.5296 - val_loss: 0.9393 - val_accuracy: 0.5476\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9780 - accuracy: 0.5297 - val_loss: 0.9381 - val_accuracy: 0.5445\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9780 - accuracy: 0.5293 - val_loss: 0.9378 - val_accuracy: 0.5423\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9780 - accuracy: 0.5287 - val_loss: 0.9382 - val_accuracy: 0.5445\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9780 - accuracy: 0.5301 - val_loss: 0.9385 - val_accuracy: 0.5463\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9779 - accuracy: 0.5297 - val_loss: 0.9387 - val_accuracy: 0.5476\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9779 - accuracy: 0.5295 - val_loss: 0.9384 - val_accuracy: 0.5463\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9779 - accuracy: 0.5291 - val_loss: 0.9379 - val_accuracy: 0.5445\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9778 - accuracy: 0.5295 - val_loss: 0.9386 - val_accuracy: 0.5476\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9779 - accuracy: 0.5294 - val_loss: 0.9383 - val_accuracy: 0.5436\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9778 - accuracy: 0.5294 - val_loss: 0.9379 - val_accuracy: 0.5436\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9778 - accuracy: 0.5278 - val_loss: 0.9384 - val_accuracy: 0.5463\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9786 - accuracy: 0.5292 - val_loss: 0.9389 - val_accuracy: 0.5436\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9779 - accuracy: 0.5293 - val_loss: 0.9386 - val_accuracy: 0.5463\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9777 - accuracy: 0.5292 - val_loss: 0.9381 - val_accuracy: 0.5436\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9778 - accuracy: 0.5292 - val_loss: 0.9380 - val_accuracy: 0.5445\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9778 - accuracy: 0.5301 - val_loss: 0.9380 - val_accuracy: 0.5463\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9777 - accuracy: 0.5288 - val_loss: 0.9381 - val_accuracy: 0.5476\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9777 - accuracy: 0.5293 - val_loss: 0.9382 - val_accuracy: 0.5463\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9777 - accuracy: 0.5298 - val_loss: 0.9380 - val_accuracy: 0.5445\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9778 - accuracy: 0.5291 - val_loss: 0.9381 - val_accuracy: 0.5445\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9777 - accuracy: 0.5284 - val_loss: 0.9382 - val_accuracy: 0.5436\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9779 - accuracy: 0.5296 - val_loss: 0.9385 - val_accuracy: 0.5463\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9776 - accuracy: 0.5304 - val_loss: 0.9380 - val_accuracy: 0.5436\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9777 - accuracy: 0.5290 - val_loss: 0.9382 - val_accuracy: 0.5458\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9380 - val_accuracy: 0.5463\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9778 - accuracy: 0.5285 - val_loss: 0.9377 - val_accuracy: 0.5436\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9775 - accuracy: 0.5292 - val_loss: 0.9382 - val_accuracy: 0.5463\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9784 - accuracy: 0.5292 - val_loss: 0.9387 - val_accuracy: 0.5423\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9777 - accuracy: 0.5290 - val_loss: 0.9387 - val_accuracy: 0.5436\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9776 - accuracy: 0.5288 - val_loss: 0.9385 - val_accuracy: 0.5436\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9780 - accuracy: 0.5297 - val_loss: 0.9385 - val_accuracy: 0.5427\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9379 - val_accuracy: 0.5445\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9777 - accuracy: 0.5290 - val_loss: 0.9383 - val_accuracy: 0.5436\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9775 - accuracy: 0.5298 - val_loss: 0.9381 - val_accuracy: 0.5454\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9777 - accuracy: 0.5294 - val_loss: 0.9385 - val_accuracy: 0.5476\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9777 - accuracy: 0.5298 - val_loss: 0.9379 - val_accuracy: 0.5436\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9775 - accuracy: 0.5288 - val_loss: 0.9379 - val_accuracy: 0.5436\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9775 - accuracy: 0.5295 - val_loss: 0.9375 - val_accuracy: 0.5445\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9774 - accuracy: 0.5293 - val_loss: 0.9375 - val_accuracy: 0.5427\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9774 - accuracy: 0.5290 - val_loss: 0.9378 - val_accuracy: 0.5463\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9779 - accuracy: 0.5299 - val_loss: 0.9381 - val_accuracy: 0.5423\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9381 - val_accuracy: 0.5436\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9775 - accuracy: 0.5302 - val_loss: 0.9383 - val_accuracy: 0.5476\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5289 - val_loss: 0.9376 - val_accuracy: 0.5436\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9774 - accuracy: 0.5288 - val_loss: 0.9380 - val_accuracy: 0.5476\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9774 - accuracy: 0.5296 - val_loss: 0.9375 - val_accuracy: 0.5436\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9775 - accuracy: 0.5290 - val_loss: 0.9378 - val_accuracy: 0.5463\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9773 - accuracy: 0.5302 - val_loss: 0.9379 - val_accuracy: 0.5476\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9774 - accuracy: 0.5299 - val_loss: 0.9377 - val_accuracy: 0.5476\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9773 - accuracy: 0.5294 - val_loss: 0.9374 - val_accuracy: 0.5436\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9773 - accuracy: 0.5291 - val_loss: 0.9375 - val_accuracy: 0.5423\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9381 - val_accuracy: 0.5476\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9776 - accuracy: 0.5297 - val_loss: 0.9384 - val_accuracy: 0.5476\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9774 - accuracy: 0.5297 - val_loss: 0.9381 - val_accuracy: 0.5476\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9773 - accuracy: 0.5292 - val_loss: 0.9380 - val_accuracy: 0.5476\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 610us/step - loss: 0.9775 - accuracy: 0.5297 - val_loss: 0.9378 - val_accuracy: 0.5463\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9772 - accuracy: 0.5295 - val_loss: 0.9377 - val_accuracy: 0.5463\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5301 - val_loss: 0.9378 - val_accuracy: 0.5463\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9772 - accuracy: 0.5294 - val_loss: 0.9374 - val_accuracy: 0.5436\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5305 - val_loss: 0.9376 - val_accuracy: 0.5463\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9772 - accuracy: 0.5288 - val_loss: 0.9379 - val_accuracy: 0.5476\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9377 - val_accuracy: 0.5436\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5282 - val_loss: 0.9379 - val_accuracy: 0.5423\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9772 - accuracy: 0.5284 - val_loss: 0.9380 - val_accuracy: 0.5454\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9772 - accuracy: 0.5289 - val_loss: 0.9377 - val_accuracy: 0.5436\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9773 - accuracy: 0.5299 - val_loss: 0.9381 - val_accuracy: 0.5476\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9771 - accuracy: 0.5293 - val_loss: 0.9369 - val_accuracy: 0.5423\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9771 - accuracy: 0.5298 - val_loss: 0.9375 - val_accuracy: 0.5463\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9774 - accuracy: 0.5295 - val_loss: 0.9371 - val_accuracy: 0.5436\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9773 - accuracy: 0.5293 - val_loss: 0.9370 - val_accuracy: 0.5445\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9374 - val_accuracy: 0.5454\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9771 - accuracy: 0.5297 - val_loss: 0.9376 - val_accuracy: 0.5476\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9774 - accuracy: 0.5292 - val_loss: 0.9373 - val_accuracy: 0.5463\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9771 - accuracy: 0.5293 - val_loss: 0.9372 - val_accuracy: 0.5436\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9771 - accuracy: 0.5297 - val_loss: 0.9372 - val_accuracy: 0.5436\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9771 - accuracy: 0.5302 - val_loss: 0.9379 - val_accuracy: 0.5476\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9768 - accuracy: 0.5292 - val_loss: 0.9374 - val_accuracy: 0.5476\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9373 - val_accuracy: 0.5436\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9771 - accuracy: 0.5292 - val_loss: 0.9376 - val_accuracy: 0.5463\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9770 - accuracy: 0.5304 - val_loss: 0.9381 - val_accuracy: 0.5489\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9777 - accuracy: 0.5297 - val_loss: 0.9382 - val_accuracy: 0.5463\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9770 - accuracy: 0.5293 - val_loss: 0.9372 - val_accuracy: 0.5445\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 334us/step - loss: 0.9769 - accuracy: 0.5291\n",
      "Accuracy : 0.5290906429290771\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9372 - accuracy: 0.5445\n",
      "Accuracy : 0.5444887280464172\n",
      "\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 2.8236 - accuracy: 0.2879 - val_loss: 2.4687 - val_accuracy: 0.2882\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 736us/step - loss: 2.2923 - accuracy: 0.2879 - val_loss: 1.9795 - val_accuracy: 0.2882\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.8022 - accuracy: 0.2879 - val_loss: 1.5494 - val_accuracy: 0.2882\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.4166 - accuracy: 0.2855 - val_loss: 1.2594 - val_accuracy: 0.2882\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 1.1933 - accuracy: 0.2864 - val_loss: 1.1126 - val_accuracy: 0.2793\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0664 - accuracy: 0.4103 - val_loss: 1.0193 - val_accuracy: 0.5029\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0030 - accuracy: 0.5072 - val_loss: 0.9907 - val_accuracy: 0.5166\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9876 - accuracy: 0.5135 - val_loss: 0.9817 - val_accuracy: 0.5162\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9821 - accuracy: 0.5160 - val_loss: 0.9776 - val_accuracy: 0.5170\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9792 - accuracy: 0.5218 - val_loss: 0.9757 - val_accuracy: 0.5206\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9780 - accuracy: 0.5263 - val_loss: 0.9746 - val_accuracy: 0.5219\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9774 - accuracy: 0.5254 - val_loss: 0.9740 - val_accuracy: 0.5246\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9773 - accuracy: 0.5281 - val_loss: 0.9738 - val_accuracy: 0.5228\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5269 - val_loss: 0.9736 - val_accuracy: 0.5228\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9768 - accuracy: 0.5270 - val_loss: 0.9738 - val_accuracy: 0.5237\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9768 - accuracy: 0.5304 - val_loss: 0.9736 - val_accuracy: 0.5237\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9769 - accuracy: 0.5290 - val_loss: 0.9735 - val_accuracy: 0.5237\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9766 - accuracy: 0.5287 - val_loss: 0.9733 - val_accuracy: 0.5237\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9766 - accuracy: 0.5285 - val_loss: 0.9731 - val_accuracy: 0.5241\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9731 - val_accuracy: 0.5237\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9767 - accuracy: 0.5278 - val_loss: 0.9733 - val_accuracy: 0.5232\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9730 - val_accuracy: 0.5237\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9767 - accuracy: 0.5299 - val_loss: 0.9732 - val_accuracy: 0.5237\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9728 - val_accuracy: 0.5241\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9765 - accuracy: 0.5281 - val_loss: 0.9734 - val_accuracy: 0.5237\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9766 - accuracy: 0.5301 - val_loss: 0.9730 - val_accuracy: 0.5237\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9765 - accuracy: 0.5281 - val_loss: 0.9731 - val_accuracy: 0.5237\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9732 - val_accuracy: 0.5237\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 560us/step - loss: 0.9767 - accuracy: 0.5297 - val_loss: 0.9737 - val_accuracy: 0.5277\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 676us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9731 - val_accuracy: 0.5268\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9763 - accuracy: 0.5298 - val_loss: 0.9727 - val_accuracy: 0.5237\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9763 - accuracy: 0.5281 - val_loss: 0.9737 - val_accuracy: 0.5281\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9768 - accuracy: 0.5292 - val_loss: 0.9733 - val_accuracy: 0.5237\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9762 - accuracy: 0.5294 - val_loss: 0.9730 - val_accuracy: 0.5237\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9763 - accuracy: 0.5296 - val_loss: 0.9726 - val_accuracy: 0.5237\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9763 - accuracy: 0.5298 - val_loss: 0.9729 - val_accuracy: 0.5259\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9764 - accuracy: 0.5307 - val_loss: 0.9729 - val_accuracy: 0.5263\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9764 - accuracy: 0.5295 - val_loss: 0.9730 - val_accuracy: 0.5268\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9762 - accuracy: 0.5318 - val_loss: 0.9728 - val_accuracy: 0.5263\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9764 - accuracy: 0.5317 - val_loss: 0.9722 - val_accuracy: 0.5232\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9765 - accuracy: 0.5268 - val_loss: 0.9725 - val_accuracy: 0.5241\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9762 - accuracy: 0.5290 - val_loss: 0.9727 - val_accuracy: 0.5228\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9728 - val_accuracy: 0.5237\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9761 - accuracy: 0.5291 - val_loss: 0.9722 - val_accuracy: 0.5232\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9762 - accuracy: 0.5286 - val_loss: 0.9726 - val_accuracy: 0.5237\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9766 - accuracy: 0.5297 - val_loss: 0.9729 - val_accuracy: 0.5237\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9763 - accuracy: 0.5316 - val_loss: 0.9729 - val_accuracy: 0.5259\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9761 - accuracy: 0.5309 - val_loss: 0.9726 - val_accuracy: 0.5237\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9767 - accuracy: 0.5306 - val_loss: 0.9723 - val_accuracy: 0.5241\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9762 - accuracy: 0.5282 - val_loss: 0.9728 - val_accuracy: 0.5237\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9760 - accuracy: 0.5292 - val_loss: 0.9723 - val_accuracy: 0.5237\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9761 - accuracy: 0.5282 - val_loss: 0.9726 - val_accuracy: 0.5228\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9760 - accuracy: 0.5290 - val_loss: 0.9727 - val_accuracy: 0.5263\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9761 - accuracy: 0.5299 - val_loss: 0.9722 - val_accuracy: 0.5237\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9760 - accuracy: 0.5286 - val_loss: 0.9726 - val_accuracy: 0.5263\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9760 - accuracy: 0.5307 - val_loss: 0.9722 - val_accuracy: 0.5228\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9761 - accuracy: 0.5282 - val_loss: 0.9729 - val_accuracy: 0.5263\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9774 - accuracy: 0.5309 - val_loss: 0.9726 - val_accuracy: 0.5232\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9759 - accuracy: 0.5299 - val_loss: 0.9725 - val_accuracy: 0.5241\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9758 - accuracy: 0.5296 - val_loss: 0.9732 - val_accuracy: 0.5308\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9763 - accuracy: 0.5297 - val_loss: 0.9726 - val_accuracy: 0.5263\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9761 - accuracy: 0.5311 - val_loss: 0.9724 - val_accuracy: 0.5263\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9760 - accuracy: 0.5307 - val_loss: 0.9726 - val_accuracy: 0.5259\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9761 - accuracy: 0.5307 - val_loss: 0.9729 - val_accuracy: 0.5290\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9761 - accuracy: 0.5305 - val_loss: 0.9727 - val_accuracy: 0.5259\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9761 - accuracy: 0.5317 - val_loss: 0.9722 - val_accuracy: 0.5237\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9760 - accuracy: 0.5287 - val_loss: 0.9725 - val_accuracy: 0.5228\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9759 - accuracy: 0.5293 - val_loss: 0.9722 - val_accuracy: 0.5228\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9757 - accuracy: 0.5296 - val_loss: 0.9729 - val_accuracy: 0.5290\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9762 - accuracy: 0.5313 - val_loss: 0.9724 - val_accuracy: 0.5268\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 673us/step - loss: 0.9762 - accuracy: 0.5293 - val_loss: 0.9725 - val_accuracy: 0.5237\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9758 - accuracy: 0.5284 - val_loss: 0.9723 - val_accuracy: 0.5237\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9758 - accuracy: 0.5300 - val_loss: 0.9725 - val_accuracy: 0.5263\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 0.9725 - val_accuracy: 0.5259\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9758 - accuracy: 0.5307 - val_loss: 0.9726 - val_accuracy: 0.5263\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9759 - accuracy: 0.5305 - val_loss: 0.9722 - val_accuracy: 0.5241\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 562us/step - loss: 0.9760 - accuracy: 0.5293 - val_loss: 0.9721 - val_accuracy: 0.5228\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 781us/step - loss: 0.9761 - accuracy: 0.5300 - val_loss: 0.9727 - val_accuracy: 0.5277\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9762 - accuracy: 0.5301 - val_loss: 0.9723 - val_accuracy: 0.5237\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9760 - accuracy: 0.5286 - val_loss: 0.9724 - val_accuracy: 0.5241\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9759 - accuracy: 0.5316 - val_loss: 0.9729 - val_accuracy: 0.5290\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9757 - accuracy: 0.5327 - val_loss: 0.9718 - val_accuracy: 0.5237\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9758 - accuracy: 0.5309 - val_loss: 0.9721 - val_accuracy: 0.5263\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9756 - accuracy: 0.5303 - val_loss: 0.9727 - val_accuracy: 0.5308\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9724 - val_accuracy: 0.5259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9758 - accuracy: 0.5315 - val_loss: 0.9725 - val_accuracy: 0.5263\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9758 - accuracy: 0.5310 - val_loss: 0.9728 - val_accuracy: 0.5290\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9759 - accuracy: 0.5303 - val_loss: 0.9720 - val_accuracy: 0.5237\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 0.9722 - val_accuracy: 0.5241\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 0.9721 - val_accuracy: 0.5228\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9757 - accuracy: 0.5305 - val_loss: 0.9720 - val_accuracy: 0.5232\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9770 - accuracy: 0.5281 - val_loss: 0.9729 - val_accuracy: 0.5228\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9757 - accuracy: 0.5281 - val_loss: 0.9726 - val_accuracy: 0.5232\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9758 - accuracy: 0.5308 - val_loss: 0.9725 - val_accuracy: 0.5259\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9757 - accuracy: 0.5308 - val_loss: 0.9727 - val_accuracy: 0.5294\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9758 - accuracy: 0.5309 - val_loss: 0.9720 - val_accuracy: 0.5232\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9757 - accuracy: 0.5305 - val_loss: 0.9722 - val_accuracy: 0.5263\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9757 - accuracy: 0.5309 - val_loss: 0.9726 - val_accuracy: 0.5294\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9760 - accuracy: 0.5293 - val_loss: 0.9721 - val_accuracy: 0.5228\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9756 - accuracy: 0.5296 - val_loss: 0.9722 - val_accuracy: 0.5268\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9756 - accuracy: 0.5310 - val_loss: 0.9720 - val_accuracy: 0.5241\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9723 - val_accuracy: 0.5263\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9755 - accuracy: 0.5312 - val_loss: 0.9719 - val_accuracy: 0.5263\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9755 - accuracy: 0.5309 - val_loss: 0.9720 - val_accuracy: 0.5246\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9761 - accuracy: 0.5303 - val_loss: 0.9720 - val_accuracy: 0.5263\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9755 - accuracy: 0.5304 - val_loss: 0.9720 - val_accuracy: 0.5259\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9722 - val_accuracy: 0.5272\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9755 - accuracy: 0.5318 - val_loss: 0.9720 - val_accuracy: 0.5268\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9755 - accuracy: 0.5296 - val_loss: 0.9719 - val_accuracy: 0.5246\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9755 - accuracy: 0.5295 - val_loss: 0.9720 - val_accuracy: 0.5268\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9722 - val_accuracy: 0.5259\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9757 - accuracy: 0.5324 - val_loss: 0.9717 - val_accuracy: 0.5232\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9755 - accuracy: 0.5292 - val_loss: 0.9720 - val_accuracy: 0.5268\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9718 - val_accuracy: 0.5228\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9756 - accuracy: 0.5303 - val_loss: 0.9720 - val_accuracy: 0.5263\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9757 - accuracy: 0.5311 - val_loss: 0.9720 - val_accuracy: 0.5263\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9754 - accuracy: 0.5321 - val_loss: 0.9716 - val_accuracy: 0.5241\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9762 - accuracy: 0.5252 - val_loss: 0.9723 - val_accuracy: 0.5228\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9755 - accuracy: 0.5291 - val_loss: 0.9723 - val_accuracy: 0.5246\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9754 - accuracy: 0.5306 - val_loss: 0.9723 - val_accuracy: 0.5263\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9753 - accuracy: 0.5298 - val_loss: 0.9718 - val_accuracy: 0.5224\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9753 - accuracy: 0.5301 - val_loss: 0.9721 - val_accuracy: 0.5263\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9715 - val_accuracy: 0.5237\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9725 - val_accuracy: 0.5294\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9754 - accuracy: 0.5291 - val_loss: 0.9721 - val_accuracy: 0.5228\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9753 - accuracy: 0.5313 - val_loss: 0.9723 - val_accuracy: 0.5246\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9760 - accuracy: 0.5303 - val_loss: 0.9723 - val_accuracy: 0.5259\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9755 - accuracy: 0.5314 - val_loss: 0.9716 - val_accuracy: 0.5224\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9754 - accuracy: 0.5294 - val_loss: 0.9720 - val_accuracy: 0.5268\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9754 - accuracy: 0.5313 - val_loss: 0.9720 - val_accuracy: 0.5263\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9754 - accuracy: 0.5311 - val_loss: 0.9720 - val_accuracy: 0.5263\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9721 - val_accuracy: 0.5259\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9753 - accuracy: 0.5302 - val_loss: 0.9717 - val_accuracy: 0.5237\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9753 - accuracy: 0.5297 - val_loss: 0.9726 - val_accuracy: 0.5321\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9758 - accuracy: 0.5314 - val_loss: 0.9723 - val_accuracy: 0.5272\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9752 - accuracy: 0.5312 - val_loss: 0.9729 - val_accuracy: 0.5321\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9720 - val_accuracy: 0.5290\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9753 - accuracy: 0.5312 - val_loss: 0.9716 - val_accuracy: 0.5268\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9753 - accuracy: 0.5302 - val_loss: 0.9719 - val_accuracy: 0.5263\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9755 - accuracy: 0.5316 - val_loss: 0.9718 - val_accuracy: 0.5259\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9754 - accuracy: 0.5315 - val_loss: 0.9717 - val_accuracy: 0.5268\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 592us/step - loss: 0.9751 - accuracy: 0.5311 - val_loss: 0.9722 - val_accuracy: 0.5290\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9756 - accuracy: 0.5307 - val_loss: 0.9717 - val_accuracy: 0.5268\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9753 - accuracy: 0.5292 - val_loss: 0.9724 - val_accuracy: 0.5317\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9755 - accuracy: 0.5314 - val_loss: 0.9723 - val_accuracy: 0.5277\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9719 - val_accuracy: 0.5259\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9751 - accuracy: 0.5310 - val_loss: 0.9718 - val_accuracy: 0.5263\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9753 - accuracy: 0.5314 - val_loss: 0.9714 - val_accuracy: 0.5224\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9753 - accuracy: 0.5294 - val_loss: 0.9719 - val_accuracy: 0.5268\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9765 - accuracy: 0.5305 - val_loss: 0.9715 - val_accuracy: 0.5224\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9718 - val_accuracy: 0.5268\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9751 - accuracy: 0.5313 - val_loss: 0.9714 - val_accuracy: 0.5228\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9750 - accuracy: 0.5295 - val_loss: 0.9718 - val_accuracy: 0.5268\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9752 - accuracy: 0.5313 - val_loss: 0.9719 - val_accuracy: 0.5290\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9751 - accuracy: 0.5319 - val_loss: 0.9715 - val_accuracy: 0.5268\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9756 - accuracy: 0.5314 - val_loss: 0.9718 - val_accuracy: 0.5259\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9755 - accuracy: 0.5290 - val_loss: 0.9716 - val_accuracy: 0.5224\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9751 - accuracy: 0.5291 - val_loss: 0.9720 - val_accuracy: 0.5272\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9750 - accuracy: 0.5302 - val_loss: 0.9716 - val_accuracy: 0.5268\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9718 - val_accuracy: 0.5263\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9753 - accuracy: 0.5317 - val_loss: 0.9714 - val_accuracy: 0.5268\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9752 - accuracy: 0.5310 - val_loss: 0.9711 - val_accuracy: 0.5224\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9753 - accuracy: 0.5301 - val_loss: 0.9717 - val_accuracy: 0.5268\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9751 - accuracy: 0.5315 - val_loss: 0.9713 - val_accuracy: 0.5246\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9751 - accuracy: 0.5315 - val_loss: 0.9716 - val_accuracy: 0.5259\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9752 - accuracy: 0.5306 - val_loss: 0.9718 - val_accuracy: 0.5272\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9752 - accuracy: 0.5330 - val_loss: 0.9717 - val_accuracy: 0.5268\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9749 - accuracy: 0.5315 - val_loss: 0.9716 - val_accuracy: 0.5268\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 566us/step - loss: 0.9752 - accuracy: 0.5312 - val_loss: 0.9720 - val_accuracy: 0.5325\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9754 - accuracy: 0.5303 - val_loss: 0.9716 - val_accuracy: 0.5268\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9752 - accuracy: 0.5311 - val_loss: 0.9715 - val_accuracy: 0.5268\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 0.9711 - val_accuracy: 0.5224\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9750 - accuracy: 0.5293 - val_loss: 0.9716 - val_accuracy: 0.5259\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9748 - accuracy: 0.5307 - val_loss: 0.9714 - val_accuracy: 0.5268\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9749 - accuracy: 0.5308 - val_loss: 0.9716 - val_accuracy: 0.5272\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9752 - accuracy: 0.5304 - val_loss: 0.9714 - val_accuracy: 0.5268\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9752 - accuracy: 0.5310 - val_loss: 0.9721 - val_accuracy: 0.5325\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9752 - accuracy: 0.5306 - val_loss: 0.9712 - val_accuracy: 0.5224\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9752 - accuracy: 0.5315 - val_loss: 0.9710 - val_accuracy: 0.5224\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9750 - accuracy: 0.5293 - val_loss: 0.9714 - val_accuracy: 0.5268\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9750 - accuracy: 0.5315 - val_loss: 0.9714 - val_accuracy: 0.5259\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9752 - accuracy: 0.5320 - val_loss: 0.9710 - val_accuracy: 0.5224\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9752 - accuracy: 0.5291 - val_loss: 0.9713 - val_accuracy: 0.5268\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9749 - accuracy: 0.5316 - val_loss: 0.9714 - val_accuracy: 0.5272\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9749 - accuracy: 0.5319 - val_loss: 0.9712 - val_accuracy: 0.5237\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9749 - accuracy: 0.5317 - val_loss: 0.9711 - val_accuracy: 0.5268\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9749 - accuracy: 0.5316 - val_loss: 0.9712 - val_accuracy: 0.5268\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9749 - accuracy: 0.5306 - val_loss: 0.9710 - val_accuracy: 0.5224\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9748 - accuracy: 0.5316 - val_loss: 0.9712 - val_accuracy: 0.5224\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9751 - accuracy: 0.5314 - val_loss: 0.9712 - val_accuracy: 0.5268\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9749 - accuracy: 0.5306 - val_loss: 0.9711 - val_accuracy: 0.5237\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 0.9712 - val_accuracy: 0.5268\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9748 - accuracy: 0.5315 - val_loss: 0.9709 - val_accuracy: 0.5268\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9748 - accuracy: 0.5315 - val_loss: 0.9711 - val_accuracy: 0.5268\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9747 - accuracy: 0.5313 - val_loss: 0.9711 - val_accuracy: 0.5259\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9747 - accuracy: 0.5308 - val_loss: 0.9714 - val_accuracy: 0.5268\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9749 - accuracy: 0.5311 - val_loss: 0.9710 - val_accuracy: 0.5237\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 581us/step - loss: 0.9748 - accuracy: 0.5304 - val_loss: 0.9715 - val_accuracy: 0.5268\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9752 - accuracy: 0.5303 - val_loss: 0.9710 - val_accuracy: 0.5268\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9747 - accuracy: 0.5317 - val_loss: 0.9709 - val_accuracy: 0.5268\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 329us/step - loss: 0.9745 - accuracy: 0.5316\n",
      "Accuracy : 0.5315988659858704\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9709 - accuracy: 0.5268\n",
      "Accuracy : 0.5267817378044128\n",
      "\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 2.2136 - accuracy: 0.2103 - val_loss: 2.5108 - val_accuracy: 0.2143\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 778us/step - loss: 1.8291 - accuracy: 0.2196 - val_loss: 2.0668 - val_accuracy: 0.2138\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.5485 - accuracy: 0.2262 - val_loss: 1.7132 - val_accuracy: 0.2275\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.3506 - accuracy: 0.2546 - val_loss: 1.4574 - val_accuracy: 0.2545\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.2278 - accuracy: 0.2625 - val_loss: 1.2907 - val_accuracy: 0.2581\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 1.1600 - accuracy: 0.2892 - val_loss: 1.1926 - val_accuracy: 0.2829\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.1261 - accuracy: 0.3055 - val_loss: 1.1390 - val_accuracy: 0.3010\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 1.1070 - accuracy: 0.3341 - val_loss: 1.1083 - val_accuracy: 0.3218\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0923 - accuracy: 0.3729 - val_loss: 1.0846 - val_accuracy: 0.3736\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0723 - accuracy: 0.4394 - val_loss: 1.0366 - val_accuracy: 0.4591\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 1.0402 - accuracy: 0.4591 - val_loss: 1.0048 - val_accuracy: 0.4591\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0252 - accuracy: 0.4591 - val_loss: 0.9977 - val_accuracy: 0.4591\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 1.0176 - accuracy: 0.4591 - val_loss: 0.9947 - val_accuracy: 0.4591\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0139 - accuracy: 0.4591 - val_loss: 0.9930 - val_accuracy: 0.4591\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 1.0115 - accuracy: 0.4591 - val_loss: 0.9913 - val_accuracy: 0.4591\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0098 - accuracy: 0.4591 - val_loss: 0.9904 - val_accuracy: 0.4591\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 1.0085 - accuracy: 0.4591 - val_loss: 0.9899 - val_accuracy: 0.4591\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0076 - accuracy: 0.4591 - val_loss: 0.9897 - val_accuracy: 0.4591\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 1.0070 - accuracy: 0.4591 - val_loss: 0.9894 - val_accuracy: 0.4591\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 1.0065 - accuracy: 0.4591 - val_loss: 0.9891 - val_accuracy: 0.4591\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 1.0062 - accuracy: 0.4591 - val_loss: 0.9888 - val_accuracy: 0.4591\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0057 - accuracy: 0.4591 - val_loss: 0.9885 - val_accuracy: 0.4591\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0055 - accuracy: 0.4591 - val_loss: 0.9883 - val_accuracy: 0.4591\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0052 - accuracy: 0.4591 - val_loss: 0.9883 - val_accuracy: 0.4591\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.0050 - accuracy: 0.4591 - val_loss: 0.9887 - val_accuracy: 0.4591\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 1.0049 - accuracy: 0.4591 - val_loss: 0.9885 - val_accuracy: 0.4591\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0047 - accuracy: 0.4591 - val_loss: 0.9884 - val_accuracy: 0.4591\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 1.0047 - accuracy: 0.4591 - val_loss: 0.9884 - val_accuracy: 0.4591\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0045 - accuracy: 0.4591 - val_loss: 0.9881 - val_accuracy: 0.4591\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0049 - accuracy: 0.4591 - val_loss: 0.9880 - val_accuracy: 0.4591\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0045 - accuracy: 0.4591 - val_loss: 0.9881 - val_accuracy: 0.4591\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0044 - accuracy: 0.4591 - val_loss: 0.9881 - val_accuracy: 0.4591\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 672us/step - loss: 1.0043 - accuracy: 0.4591 - val_loss: 0.9883 - val_accuracy: 0.4591\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0043 - accuracy: 0.4591 - val_loss: 0.9882 - val_accuracy: 0.4591\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 1.0043 - accuracy: 0.4591 - val_loss: 0.9880 - val_accuracy: 0.4591\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0042 - accuracy: 0.4591 - val_loss: 0.9881 - val_accuracy: 0.4591\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 1.0042 - accuracy: 0.4591 - val_loss: 0.9881 - val_accuracy: 0.4591\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 1.0041 - accuracy: 0.4591 - val_loss: 0.9883 - val_accuracy: 0.4591\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0042 - accuracy: 0.4591 - val_loss: 0.9881 - val_accuracy: 0.4591\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0040 - accuracy: 0.4591 - val_loss: 0.9881 - val_accuracy: 0.4591\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0040 - accuracy: 0.4591 - val_loss: 0.9883 - val_accuracy: 0.4591\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 1.0040 - accuracy: 0.4591 - val_loss: 0.9879 - val_accuracy: 0.4591\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0041 - accuracy: 0.4591 - val_loss: 0.9880 - val_accuracy: 0.4591\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 1.0039 - accuracy: 0.4591 - val_loss: 0.9879 - val_accuracy: 0.4591\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0038 - accuracy: 0.4591 - val_loss: 0.9879 - val_accuracy: 0.4591\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 1.0038 - accuracy: 0.4591 - val_loss: 0.9878 - val_accuracy: 0.4591\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0038 - accuracy: 0.4591 - val_loss: 0.9878 - val_accuracy: 0.4591\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0038 - accuracy: 0.4591 - val_loss: 0.9880 - val_accuracy: 0.4591\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 1.0038 - accuracy: 0.4591 - val_loss: 0.9879 - val_accuracy: 0.4591\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0039 - accuracy: 0.4591 - val_loss: 0.9877 - val_accuracy: 0.4591\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 1.0037 - accuracy: 0.4591 - val_loss: 0.9877 - val_accuracy: 0.4591\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0036 - accuracy: 0.4591 - val_loss: 0.9876 - val_accuracy: 0.4591\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 617us/step - loss: 1.0038 - accuracy: 0.4591 - val_loss: 0.9875 - val_accuracy: 0.4591\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 1.0036 - accuracy: 0.4591 - val_loss: 0.9874 - val_accuracy: 0.4591\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0037 - accuracy: 0.4591 - val_loss: 0.9872 - val_accuracy: 0.4591\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0035 - accuracy: 0.4591 - val_loss: 0.9874 - val_accuracy: 0.4591\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0036 - accuracy: 0.4591 - val_loss: 0.9875 - val_accuracy: 0.4591\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0034 - accuracy: 0.4591 - val_loss: 0.9873 - val_accuracy: 0.4591\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0034 - accuracy: 0.4591 - val_loss: 0.9873 - val_accuracy: 0.4591\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 1.0035 - accuracy: 0.4591 - val_loss: 0.9874 - val_accuracy: 0.4591\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 1.0034 - accuracy: 0.4591 - val_loss: 0.9876 - val_accuracy: 0.4591\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 1.0034 - accuracy: 0.4591 - val_loss: 0.9874 - val_accuracy: 0.4591\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0032 - accuracy: 0.4591 - val_loss: 0.9874 - val_accuracy: 0.4591\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0033 - accuracy: 0.4591 - val_loss: 0.9872 - val_accuracy: 0.4591\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0038 - accuracy: 0.4591 - val_loss: 0.9869 - val_accuracy: 0.4591\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0033 - accuracy: 0.4591 - val_loss: 0.9868 - val_accuracy: 0.4591\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 1.0031 - accuracy: 0.4591 - val_loss: 0.9869 - val_accuracy: 0.4591\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 1.0031 - accuracy: 0.4591 - val_loss: 0.9869 - val_accuracy: 0.4591\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 1.0030 - accuracy: 0.4591 - val_loss: 0.9870 - val_accuracy: 0.4591\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0031 - accuracy: 0.4591 - val_loss: 0.9867 - val_accuracy: 0.4591\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0031 - accuracy: 0.4591 - val_loss: 0.9868 - val_accuracy: 0.4591\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.0030 - accuracy: 0.4591 - val_loss: 0.9866 - val_accuracy: 0.4591\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0031 - accuracy: 0.4591 - val_loss: 0.9866 - val_accuracy: 0.4591\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 1.0030 - accuracy: 0.4591 - val_loss: 0.9866 - val_accuracy: 0.4591\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0029 - accuracy: 0.4591 - val_loss: 0.9867 - val_accuracy: 0.4591\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 1.0028 - accuracy: 0.4591 - val_loss: 0.9867 - val_accuracy: 0.4591\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0028 - accuracy: 0.4591 - val_loss: 0.9866 - val_accuracy: 0.4591\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0029 - accuracy: 0.4591 - val_loss: 0.9866 - val_accuracy: 0.4591\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 1.0029 - accuracy: 0.4591 - val_loss: 0.9865 - val_accuracy: 0.4591\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0028 - accuracy: 0.4591 - val_loss: 0.9863 - val_accuracy: 0.4591\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 1.0027 - accuracy: 0.4591 - val_loss: 0.9863 - val_accuracy: 0.4591\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0028 - accuracy: 0.4591 - val_loss: 0.9862 - val_accuracy: 0.4591\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0027 - accuracy: 0.4591 - val_loss: 0.9864 - val_accuracy: 0.4591\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0026 - accuracy: 0.4591 - val_loss: 0.9864 - val_accuracy: 0.4591\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0026 - accuracy: 0.4591 - val_loss: 0.9863 - val_accuracy: 0.4591\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 671us/step - loss: 1.0026 - accuracy: 0.4591 - val_loss: 0.9862 - val_accuracy: 0.4591\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 1.0027 - accuracy: 0.4591 - val_loss: 0.9863 - val_accuracy: 0.4591\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 1.0025 - accuracy: 0.4591 - val_loss: 0.9864 - val_accuracy: 0.4591\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 1.0026 - accuracy: 0.4591 - val_loss: 0.9863 - val_accuracy: 0.4591\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 1.0028 - accuracy: 0.4591 - val_loss: 0.9859 - val_accuracy: 0.4591\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0025 - accuracy: 0.4591 - val_loss: 0.9863 - val_accuracy: 0.4591\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0025 - accuracy: 0.4591 - val_loss: 0.9862 - val_accuracy: 0.4591\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 1.0025 - accuracy: 0.4591 - val_loss: 0.9859 - val_accuracy: 0.4591\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0024 - accuracy: 0.4591 - val_loss: 0.9858 - val_accuracy: 0.4591\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 1.0024 - accuracy: 0.4591 - val_loss: 0.9859 - val_accuracy: 0.4591\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 1.0023 - accuracy: 0.4591 - val_loss: 0.9860 - val_accuracy: 0.4591\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0029 - accuracy: 0.4591 - val_loss: 0.9854 - val_accuracy: 0.4591\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.0024 - accuracy: 0.4591 - val_loss: 0.9855 - val_accuracy: 0.4591\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0023 - accuracy: 0.4591 - val_loss: 0.9857 - val_accuracy: 0.4591\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 1.0022 - accuracy: 0.4591 - val_loss: 0.9856 - val_accuracy: 0.4591\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 1.0022 - accuracy: 0.4591 - val_loss: 0.9856 - val_accuracy: 0.4591\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 1.0023 - accuracy: 0.4591 - val_loss: 0.9854 - val_accuracy: 0.4591\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.0023 - accuracy: 0.4591 - val_loss: 0.9854 - val_accuracy: 0.4591\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 1.0023 - accuracy: 0.4591 - val_loss: 0.9855 - val_accuracy: 0.4591\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0023 - accuracy: 0.4591 - val_loss: 0.9854 - val_accuracy: 0.4591\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 1.0021 - accuracy: 0.4591 - val_loss: 0.9856 - val_accuracy: 0.4591\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 1.0023 - accuracy: 0.4591 - val_loss: 0.9854 - val_accuracy: 0.4591\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 1.0022 - accuracy: 0.4591 - val_loss: 0.9858 - val_accuracy: 0.4591\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 1.0021 - accuracy: 0.4591 - val_loss: 0.9855 - val_accuracy: 0.4591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0021 - accuracy: 0.4591 - val_loss: 0.9853 - val_accuracy: 0.4591\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0020 - accuracy: 0.4591 - val_loss: 0.9854 - val_accuracy: 0.4591\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 1.0021 - accuracy: 0.4591 - val_loss: 0.9852 - val_accuracy: 0.4591\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0020 - accuracy: 0.4591 - val_loss: 0.9855 - val_accuracy: 0.4591\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 1.0020 - accuracy: 0.4591 - val_loss: 0.9853 - val_accuracy: 0.4591\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 1.0022 - accuracy: 0.4591 - val_loss: 0.9851 - val_accuracy: 0.4591\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0019 - accuracy: 0.4591 - val_loss: 0.9853 - val_accuracy: 0.4591\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.0020 - accuracy: 0.4591 - val_loss: 0.9852 - val_accuracy: 0.4591\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0019 - accuracy: 0.4591 - val_loss: 0.9851 - val_accuracy: 0.4591\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 1.0019 - accuracy: 0.4591 - val_loss: 0.9853 - val_accuracy: 0.4591\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 1.0019 - accuracy: 0.4591 - val_loss: 0.9855 - val_accuracy: 0.4591\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 1.0019 - accuracy: 0.4591 - val_loss: 0.9853 - val_accuracy: 0.4591\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 1.0019 - accuracy: 0.4591 - val_loss: 0.9851 - val_accuracy: 0.4591\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 1.0018 - accuracy: 0.4591 - val_loss: 0.9851 - val_accuracy: 0.4591\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0018 - accuracy: 0.4591 - val_loss: 0.9849 - val_accuracy: 0.4591\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 1.0019 - accuracy: 0.4591 - val_loss: 0.9850 - val_accuracy: 0.4591\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 1.0018 - accuracy: 0.4591 - val_loss: 0.9849 - val_accuracy: 0.4591\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0017 - accuracy: 0.4591 - val_loss: 0.9850 - val_accuracy: 0.4591\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 1.0017 - accuracy: 0.4591 - val_loss: 0.9848 - val_accuracy: 0.4591\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.0016 - accuracy: 0.4591 - val_loss: 0.9850 - val_accuracy: 0.4591\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0017 - accuracy: 0.4591 - val_loss: 0.9850 - val_accuracy: 0.4591\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0015 - accuracy: 0.4591 - val_loss: 0.9848 - val_accuracy: 0.4591\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 1.0014 - accuracy: 0.4591 - val_loss: 0.9850 - val_accuracy: 0.4591\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 1.0015 - accuracy: 0.4591 - val_loss: 0.9850 - val_accuracy: 0.4591\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0014 - accuracy: 0.4595 - val_loss: 0.9848 - val_accuracy: 0.4670\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 1.0013 - accuracy: 0.4645 - val_loss: 0.9844 - val_accuracy: 0.4856\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 1.0013 - accuracy: 0.4825 - val_loss: 0.9843 - val_accuracy: 0.5033\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 1.0011 - accuracy: 0.4919 - val_loss: 0.9842 - val_accuracy: 0.5131\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 696us/step - loss: 1.0008 - accuracy: 0.5034 - val_loss: 0.9841 - val_accuracy: 0.5188\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 1.0004 - accuracy: 0.5131 - val_loss: 0.9835 - val_accuracy: 0.5215\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.0000 - accuracy: 0.5140 - val_loss: 0.9828 - val_accuracy: 0.5286\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9990 - accuracy: 0.5240 - val_loss: 0.9820 - val_accuracy: 0.5378\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9979 - accuracy: 0.5308 - val_loss: 0.9807 - val_accuracy: 0.5356\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9960 - accuracy: 0.5310 - val_loss: 0.9781 - val_accuracy: 0.5330\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 0.9942 - accuracy: 0.5276 - val_loss: 0.9753 - val_accuracy: 0.5330\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 567us/step - loss: 0.9919 - accuracy: 0.5284 - val_loss: 0.9728 - val_accuracy: 0.5330\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 0.9899 - accuracy: 0.5278 - val_loss: 0.9699 - val_accuracy: 0.5330\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9887 - accuracy: 0.5280 - val_loss: 0.9690 - val_accuracy: 0.5330\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9879 - accuracy: 0.5276 - val_loss: 0.9684 - val_accuracy: 0.5330\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9868 - accuracy: 0.5276 - val_loss: 0.9682 - val_accuracy: 0.5330\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9862 - accuracy: 0.5275 - val_loss: 0.9679 - val_accuracy: 0.5325\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9858 - accuracy: 0.5298 - val_loss: 0.9676 - val_accuracy: 0.5325\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9853 - accuracy: 0.5307 - val_loss: 0.9675 - val_accuracy: 0.5325\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9849 - accuracy: 0.5291 - val_loss: 0.9672 - val_accuracy: 0.5325\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9845 - accuracy: 0.5287 - val_loss: 0.9673 - val_accuracy: 0.5325\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9839 - accuracy: 0.5313 - val_loss: 0.9670 - val_accuracy: 0.5325\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9837 - accuracy: 0.5304 - val_loss: 0.9665 - val_accuracy: 0.5325\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9835 - accuracy: 0.5309 - val_loss: 0.9660 - val_accuracy: 0.5339\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9831 - accuracy: 0.5290 - val_loss: 0.9656 - val_accuracy: 0.5339\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9827 - accuracy: 0.5316 - val_loss: 0.9652 - val_accuracy: 0.5339\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9820 - accuracy: 0.5303 - val_loss: 0.9646 - val_accuracy: 0.5325\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9818 - accuracy: 0.5311 - val_loss: 0.9640 - val_accuracy: 0.5325\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9812 - accuracy: 0.5289 - val_loss: 0.9631 - val_accuracy: 0.5330\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9807 - accuracy: 0.5315 - val_loss: 0.9626 - val_accuracy: 0.5339\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9801 - accuracy: 0.5317 - val_loss: 0.9624 - val_accuracy: 0.5339\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9797 - accuracy: 0.5318 - val_loss: 0.9614 - val_accuracy: 0.5339\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 597us/step - loss: 0.9792 - accuracy: 0.5322 - val_loss: 0.9607 - val_accuracy: 0.5339\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9788 - accuracy: 0.5317 - val_loss: 0.9596 - val_accuracy: 0.5343\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9785 - accuracy: 0.5304 - val_loss: 0.9589 - val_accuracy: 0.5339\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9779 - accuracy: 0.5310 - val_loss: 0.9589 - val_accuracy: 0.5339\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9775 - accuracy: 0.5317 - val_loss: 0.9580 - val_accuracy: 0.5339\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9773 - accuracy: 0.5318 - val_loss: 0.9573 - val_accuracy: 0.5339\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9768 - accuracy: 0.5316 - val_loss: 0.9569 - val_accuracy: 0.5339\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9772 - accuracy: 0.5316 - val_loss: 0.9564 - val_accuracy: 0.5339\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9764 - accuracy: 0.5315 - val_loss: 0.9564 - val_accuracy: 0.5339\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9762 - accuracy: 0.5318 - val_loss: 0.9564 - val_accuracy: 0.5339\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9761 - accuracy: 0.5310 - val_loss: 0.9558 - val_accuracy: 0.5325\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9760 - accuracy: 0.5315 - val_loss: 0.9557 - val_accuracy: 0.5339\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9760 - accuracy: 0.5307 - val_loss: 0.9556 - val_accuracy: 0.5339\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9757 - accuracy: 0.5317 - val_loss: 0.9557 - val_accuracy: 0.5339\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9755 - accuracy: 0.5322 - val_loss: 0.9554 - val_accuracy: 0.5343\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9754 - accuracy: 0.5326 - val_loss: 0.9555 - val_accuracy: 0.5339\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9755 - accuracy: 0.5324 - val_loss: 0.9555 - val_accuracy: 0.5356\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9753 - accuracy: 0.5317 - val_loss: 0.9555 - val_accuracy: 0.5356\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9752 - accuracy: 0.5322 - val_loss: 0.9553 - val_accuracy: 0.5356\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9753 - accuracy: 0.5326 - val_loss: 0.9552 - val_accuracy: 0.5356\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9751 - accuracy: 0.5323 - val_loss: 0.9553 - val_accuracy: 0.5356\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9754 - accuracy: 0.5313 - val_loss: 0.9549 - val_accuracy: 0.5343\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9752 - accuracy: 0.5322 - val_loss: 0.9557 - val_accuracy: 0.5356\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9753 - accuracy: 0.5316 - val_loss: 0.9554 - val_accuracy: 0.5356\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9751 - accuracy: 0.5328 - val_loss: 0.9554 - val_accuracy: 0.5356\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9753 - accuracy: 0.5314 - val_loss: 0.9550 - val_accuracy: 0.5356\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9753 - accuracy: 0.5319 - val_loss: 0.9551 - val_accuracy: 0.5365\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9753 - accuracy: 0.5311 - val_loss: 0.9552 - val_accuracy: 0.5352\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9751 - accuracy: 0.5323 - val_loss: 0.9550 - val_accuracy: 0.5343\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9752 - accuracy: 0.5331 - val_loss: 0.9555 - val_accuracy: 0.5356\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9751 - accuracy: 0.5316 - val_loss: 0.9550 - val_accuracy: 0.5365\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9752 - accuracy: 0.5324 - val_loss: 0.9549 - val_accuracy: 0.5356\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9751 - accuracy: 0.5311 - val_loss: 0.9557 - val_accuracy: 0.5365\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9751 - accuracy: 0.5323 - val_loss: 0.9560 - val_accuracy: 0.5356\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9751 - accuracy: 0.5317 - val_loss: 0.9555 - val_accuracy: 0.5365\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 334us/step - loss: 0.9749 - accuracy: 0.5319\n",
      "Accuracy : 0.5318939685821533\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9555 - accuracy: 0.5365\n",
      "Accuracy : 0.5365206003189087\n",
      "\n",
      "\n",
      "The final train accuracy is:0.5315746068954468 \n",
      "\n",
      "The final test accuracy is:0.5321797609329224 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"B365.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data = np.array(df.iloc[:,0:3])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "    \n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "    \n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (3,1)),\n",
    "        keras.layers.Dense(3,activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels,batch_size = 221, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\\n\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "running-toronto",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "north-complement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rapid-recruitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAssUlEQVR4nO3dd3xUVfrH8c8zSei9Q0ABwY6iq4gKihWssDbwp2tfLKiAHXV1UbHgygqrWBZRVlEEsVEUEAvguoAiFkClKQQivdeU5/fHXDBAyoRkmNzwffO6r8zccs65k/DMmeeec8fcHRERCY9IohsgIiKFo8AtIhIyCtwiIiGjwC0iEjIK3CIiIaPALSISMgrcUmRmVt7MRpnZOjMbUYRyrjCz8cXZtkQws4/M7OpEt0NKLwXu/YiZ/Z+ZfW1mG80sPQgwbYqh6EuAukBNd790bwtx96HufnYxtGcXZtbOzNzM3t1t/dHB+s9jLOfvZvZGQfu5+znuPmQvmytSIAXu/YSZ3QE8CzxONMgeAAwEOhZD8QcCv7h7ZjGUFS8rgJPMrGaOdVcDvxRXBRal/1MSd/oj2w+YWVXgEaCbu7/r7pvcPcPdR7n73cE+Zc3sWTNbGizPmlnZYFs7M0szszvNbHnQW7822NYbeAjoHPTkr9+9Z2pmjYOebXLw/BozW2BmG8xsoZldkWP9lBzHnWRm04MUzHQzOynHts/N7FEz+zIoZ7yZ1crnZdgOvA90CY5PAi4Dhu72WvU3s8Vmtt7MvjGztsH6DsD9Oc7zuxzt6GNmXwKbgabBuhuC7S+Y2Ts5yn/KzCaamcX6+xPZnQL3/uFEoBzwXj77PAC0BloCRwOtgAdzbK8HVAVSgeuB582surs/TLQX/7a7V3L3V/JriJlVBAYA57h7ZeAkYGYu+9UAxgT71gT6AWN26zH/H3AtUAcoA9yVX93Af4CrgsftgVnA0t32mU70NagBvAmMMLNy7v7xbud5dI5j/gJ0BSoDv+1W3p3AUcGbUluir93VrntNSBEocO8fagIrC0hlXAE84u7L3X0F0JtoQNohI9ie4e5jgY3AIXvZnmzgSDMr7+7p7j4rl33OA+a6++vununubwE/ARfk2OdVd//F3bcAw4kG3Dy5+3+BGmZ2CNEA/p9c9nnD3VcFdT4DlKXg83zN3WcFx2TsVt5m4EqibzxvALe5e1oB5YnkS4F7/7AKqLUjVZGHBuzaW/wtWLezjN0C/2agUmEb4u6bgM7ATUC6mY0xs0NjaM+ONqXmeP77XrTndeBW4DRy+QQSpIPmBOmZtUQ/ZeSXggFYnN9Gd58GLACM6BuMSJEocO8fvgK2Ap3y2Wcp0YuMOxzAnmmEWG0CKuR4Xi/nRncf5+5nAfWJ9qL/HUN7drRpyV62aYfXgVuAsUFveKcglXEv0dx3dXevBqwjGnAB8kpv5Jv2MLNuRHvuS4F79rrlIgEF7v2Au68jegHxeTPrZGYVzCzFzM4xs77Bbm8BD5pZ7eAi30NEP9rvjZnAKWZ2QHBhtNeODWZW18wuDHLd24imXLJyKWMscHAwhDHZzDoDhwOj97JNALj7QuBUojn93VUGMomOQEk2s4eAKjm2LwMaF2bkiJkdDDxGNF3yF+AeM2u5d60XiVLg3k+4ez/gDqIXHFcQ/Xh/K9GRFhANLl8D3wM/ADOCdXtT1wTg7aCsb9g12EaIXrBbCqwmGkRvyaWMVcD5wb6riPZUz3f3lXvTpt3KnuLuuX2aGAd8RHSI4G9EP6XkTIPsmFy0ysxmFFRPkJp6A3jK3b9z97lER6a8vmPEjsjeMF3cFhEJF/W4RURCRoFbRCRkFLhFREJGgVtEJGTym5CRUMllUnXVNM7GVm+b6CaUek+lrE50E/YLE9PGF/neLxkrF8Qcc1JqNU3ovWbU4xYRCZkS2+MWEdmnsnObB1YyKXCLiABkleTbye9KgVtEBHDPTnQTYqbALSICkK3ALSISLupxi4iEjC5OioiEjHrcIiLh4hpVIiISMro4KSISMkqViIiEjC5OioiEjHrcIiIho4uTIiIho4uTIiLh4q4ct4hIuCjHLSISMkqViIiEjHrcIiIhk5WR6BbETIFbRASUKhERCZ0QpUr0Le8iIhDtcce6FMDMeprZLDP70czeMrNyZlbDzCaY2dzgZ/Uc+/cys3lm9rOZtS+ofAVuEREotsBtZqnA7cBx7n4kkAR0Ae4DJrp7c2Bi8BwzOzzYfgTQARhoZkn51aHALSICeFZGzEsMkoHyZpYMVACWAh2BIcH2IUCn4HFHYJi7b3P3hcA8oFV+hStwi4hANMcd42JmXc3s6xxL153FuC8B/gEsAtKBde4+Hqjr7unBPulAneCQVGBxjpakBevypIuTIiJQqFEl7v4y8HJu24LcdUegCbAWGGFmV+ZTnOVWRX71K3CLiEBxjio5E1jo7isAzOxd4CRgmZnVd/d0M6sPLA/2TwMa5Ti+IdHUSp6UKhERgeIcVbIIaG1mFczMgDOAOcCHwNXBPlcDHwSPPwS6mFlZM2sCNAem5VeBetwiIlBsPW53n2pm7wAzgEzgW6JplUrAcDO7nmhwvzTYf5aZDQdmB/t38wJuVajALSICkFl8X6Tg7g8DD++2ehvR3ndu+/cB+sRavgJ3MWh/djv69XuEpEiEwa++Rd+nn090k0qWiNF6/ONs+30N317Zd5dNFZo14Mj+N1GlRRPmPvE2v70wusjVWZlkWjzXjSpHNSFjzUa+69qfrYtXUPmIAzms7/UkVyqPZ2ez4Nn3WfbBV0WuL9Hu+scdtD6zNWtXruWGM7vmus/RJx7FLX+/meTkJNatWc8dl9xVpDpTyqRw77N3c/BRzVm/ZgOP3tyHZWnLOOjwpvR44nYqVKpAdnY2Qwe8xeejvihSXfuMZk7uPyKRCAP69+H8C66kxdGn0blzJw47rHmim1WiHPjXc9g0N/drLZlrN/LTA6/x614E7HKNanPcuw/tsb7h/51GxtqNTGndg99eGsPBf/s/ALK2bOfHWwfy31PvZkaXJzn00atIrlKh0PWWNONGTKDXlffnub1ilYp073Mbf7v2Ia4/oyuP3PhYzGXXbViXZ0Y8vcf6c7p0YOO6jVzV5lpG/vtd/nr/9QBs27KNJ3v05fozunLflfdzy99vomKVioU/qUQoxpmT8abAXUStjj+G+fN/ZeHCRWRkZDB8+AdceEGBM1b3G2Xr16DWWceyZOinuW7fvnI962cuwDP2TOnVv7gNJ3z8GK0nPslhT98AkdxGTe2pdofjWDp8EgDLRk2lRpsjANi8IJ3NC38HYNuyNWxfuZ4yNavszWmVKD9M/YH1azfkuf2MTqcz+aMvWb50BQBrV63due3Mi87g+dEDeGncC/R8sjuRSGwh4aSzT2T8iAkAfDFmEse2OQaAtIVLWLIw+ia9atlq1q5aS7WaVffmtPa9QozjTrS4BW4zO9TM7jWzAWbWP3h8WLzqS5QGqfVYnPZHbzJtSToNGtRLYItKlkMfvZpfHhmKZ+c7LHUPFZs3oF6nE5l2/sP874z7ICub+he3ienYcvVrsHXJKgA8K5vMDVtIqVF5l32qHHMQlpLM5l+XFapdYdSwaSqVq1bimRFP88LY5znr4jMBOKBZI9pdcCq3d+rJje1vJisrmzP+fHpMZdaqV4vl6dE3guysbDat30SV6ru+CR7S8hCSU1JY+mt68Z5QvISoxx2XHLeZ3QtcDgzjj2EtDYG3zGyYuz8Zj3oTITraZ1fuhQtSpVWts45l+8p1bPh+IdVPOrxQx9Zo24LKRzXhhHHR6zVJ5cqwfeV6AI5+9Q7KH1CHSEoy5RrWovXE6J/Ton9/xNJheeRTc/xOytSpRovnuvHj7QN3WV9aJSUn0fyo5tzd+V7KlCvDvz7sz5wZczimzTE0b9GcgWOeA6BsuTI7e+O9Bz1MvUb1SElJpk5qHV4a9wIA777yHuOGjyeXP/tdXssadWrQq/89PNXz6fD8fygBPelYxevi5PXAEe6+y6R+M+sHzAJyDdzBtNGuAJZUlUik5OfGlqSl06hhg53PG6bWJz299PfiYlGt1cHUbv8nap1xDJFyKSRXKs+Rz3fjx24xXLw1WDp8EvP6DNtj03fX9gOiOe4j+9/M1xc9ssv2remrKZdak23pq7GkCMmVy5OxZiMASZXKc+zQe5n35Nus+2Ze0U8yBFakr2Td6vVs3bKVrVu28sPUH2h6eFPMjPHvTOCVJwfvcczDN/QGojnue/55F3deevceZdapX5uV6SuJJEWoWKXiznRNhUoVeHzIowzu+xpzZvwU/xMsLsU4qiTe4pUqyQYa5LK+frAtV+7+srsf5+7HhSFoA0z/eibNmjWhceNGpKSkcNllHRk1enyim1UizOszjEnHdGPy8bfx/Y0DWP3lrNiCNrB68o/UPf8EytSKfvxOrlaRcg1rxXTsinHf0OCyUwCoe8EJrJ4yCwBLSaLla3eydMQklo2auhdnFE7/HfdfWrQ6kkhShLLlynJoy0NZNG8x3075llPOa0u1mtUAqFytMnVS6+RfWOCrCV9x9qVnAXDqeafw7ZczAUhOSab3oIcZ/84nTBozOR6nEz/usS8JFq8edw9gopnN5Y+bpxwANANujVOdCZGVlUX3Hg8ydsybJEUivDbkbWbP/iXRzSrRGl4VzbGm/ecTytSuSuvxj5NcuTye7RzY9Ry+bHsXm35Zwrwnh3Ps2/djEcMzspjTazBb01YWWP6SNz/jyOe60eZ/z5KxdiPf3zgAgHoXnkj11oeSUr0SDTqfCsCs219gw6zf4ney+8ADz/Xi6BOPomqNqgybPpQhz7xOUnL0rqCj3xjDonmLmf751wya8BLZ2c7Ytz7i159/BeDVvq/x1JtPEIkYmRlZDHjwXyxfsjyf2qLGDvuYXv3v5T9TXmXD2g08dsvjALS74FSOOqEFVapXof1lZwPQt+fTzJ+9ID4nX5xKQO46Vhav/JOZRYjemjCV6E1U0oDpBc0I2iG5TGri39ZKubHV2ya6CaXeUymrE92E/cLEtPGxDTnKx5ahf4s55pS/4tEi11cUcZuA4+7ZwP/iVb6ISLHSxUkRkZDJiikZUCIocIuIQKhy3ArcIiKgwC0iEjrKcYuIhEthb8uQSArcIiKgVImISOhoVImISMioxy0iEjIK3CIiIVMCbh4VKwVuERFQj1tEJHQ0HFBEJGQ0qkREJFxcqRIRkZBRqkREJGR0rxIRkZBRj1tEJGQydXFSRCRclCoREQkZpUpERMJFwwFFRMJGPW4RkZBR4BYRCRlNeRcRCRd956SISNgocIuIhIxGlYiIhIx63CIiIROiwB1JdANEREoCz8qOeSmImVUzs3fM7Cczm2NmJ5pZDTObYGZzg5/Vc+zfy8zmmdnPZta+oPLV496PnTbr8UQ3odR78KhrE90EiVXx9rj7Ax+7+yVmVgaoANwPTHT3J83sPuA+4F4zOxzoAhwBNAA+MbOD3T3P8YnqcYuIEB0OGOuSHzOrApwCvALg7tvdfS3QERgS7DYE6BQ87ggMc/dt7r4QmAe0yq8OBW4REYj2uGNczKyrmX2dY+mao6SmwArgVTP71swGmVlFoK67pwMEP+sE+6cCi3Mcnxasy5NSJSIiAIUYDejuLwMv57E5GTgWuM3dp5pZf6JpkbxYblXkV7963CIigGdmx7wUIA1Ic/epwfN3iAbyZWZWHyD4uTzH/o1yHN8QWJpfBQrcIiIQ7XHHuuTD3X8HFpvZIcGqM4DZwIfA1cG6q4EPgscfAl3MrKyZNQGaA9Pyq0OpEhERiv1eJbcBQ4MRJQuAa4l2lIeb2fXAIuBSAHefZWbDiQb3TKBbfiNKQIFbRCSqGGe8u/tM4LhcNp2Rx/59gD6xlq/ALSKC7g4oIhI+4bnHlAK3iAiAZya6BbErcFSJmXU3syoW9YqZzTCzs/dF40RE9hXPjn1JtFiGA17n7uuBs4HaRK+OPhnXVomI7GvFNBxwX4glVbJjVs+5wKvu/p2Z5TbTR0QktEpCTzpWsQTub8xsPNAE6GVmlSkR7zkiIsWntAXu64GWwAJ332xmNYmmS0RESg3PCk8iIc/AbWbH7raqqTIkIlJalZYe9zP5bHPg9GJui4hIwnh2eDqmeQZudz9tXzZERCSRwtTjjmUcdwUze9DMXg6eNzez8+PfNBGRfcfdYl4SLZZx3K8C24GTgudpwGNxa5GISAKEaQJOLKNKDnL3zmZ2OYC7b9E4bhEpbbJLw6iSHLabWXmCr9Ixs4OAbXFtlYjIPlYqLk7m8DDwMdDIzIYCJwPXxLNRIiL7WqkK3O4+wcxmAK2JTn/v7u4r494yEZF9yMNzO+6Yb+t6KtCGaLokBXgvbi0SEUmAUtXjNrOBQDPgrWDVjWZ2prt3i2vLRET2oZIwzC9WsfS4TwWOdPcdFyeHAD/EtVUiIvtYVohGlcQyjvtn4IAczxsB38enOSIiiRGmCTj53WRqFNGcdlVgjplNC56fAPx33zRPRGTfKC057n/ss1aIiCRYqRhV4u5f7MuGiIgkUph63LHcZKq1mU03s41mtt3Mssxs/b5onIjIvpKVHYl5SbRYWvAccDkwFygP3BCsk0D7s9sx68dJ/DR7CvfcrVGSOb0+/H06XXkTHa+4kdff3nP4/4LfFnNF154c0+4CXn3znWKpc/v27dz5tyc457LruPyvPViSvgyAn36ZzxVde9Lxihv581U389EnpeND5YP97uXj79/nrU9fzXX7Ke1PZugng3ljwiCGfPQSR7dqUeQ6U8qk0OfFhxn55VAGj36B+g3rAdD8iGa88uFAhn32GkM/GcyZF4bn7tDusS+JFtNbh7vPA5LcPcvdXwXaxbVVIRKJRBjQvw/nX3AlLY4+jc6dO3HYYc0T3awSYe6CXxn54ce8NehZRg4ZyBf/ncZvi5fssk/VKpW5r+dNXHP5xYUuf0n6Mq659Z491r87ejxVKlfio+GD+UvnTvQbOBiAcuXK8vjf7uKDoS/x0jOP8dSAl1i/YePenVwJMubtj+h+xd15bp8+eQZXnHkdV551A4/e8RQP/CPvfXdXv2E9Xnjn2T3WX3j5eWxYu4GLT76Ct/49glsfvBGAbVu28vfufehy2jV0v+Ju7uh9G5WqVCr0OSVCtlvMS6LFErg3m1kZYKaZ9TWznkDFOLcrNFodfwzz5//KwoWLyMjIYPjwD7jwgvaJblaJsODXxRx1xKGUL1eO5OQkjmvZgomTdh2QVLN6NVocdgjJyXtebhk17lO63NCdi6/uRu++A8jKyoqp3k8nf0XHc88E4Ox2bZn6zUzcncYHNOTARqkA1KldkxrVq7Fm7boinmXifTv1e9av2ZDn9i2bt+x8XL5C+V16jB0uOotXx7zIGxMGcd9TdxKJxJYGOLX9yYwZMQ6AT0d/wfFtot90uGhBGosXRt+cVy5bxZqVa6hes2phTykhwjQcMJbf0l+C/W4FNhEdx33R3lZoZqXqi4YbpNZjcdrSnc/TlqTToEG9BLao5GjW9EC++e5H1q5bz5atW5n81XR+X7YipmPn/7qIjyd+wesvPsPIIc8TiUQYPf6zmI5dvmIV9erUAiA5OYlKFSuwdt2ul2V+mP0zGRmZNEqtX7iTCql2HdoyfNJ/6PefJ3nsjqcAaNzsQM7qeDo3dOzGlWfdQHZWNh0uOium8mrXq8WypcsByMrKYuP6TVStsWuAPrzloSSXSSHt16W5FVHihClVEstNpn4LHm4FegOY2dtA572sszfRL2fYg5l1BboCWFJVIpGS37HP7dbkXhJ+syXAQY0P4LorLuWvPe6nQvnyHNysKUlJSTEdO/Xrmcz+aR5dru8OwLZt26hRvRoAt/d6hCVLl5GRmUH6shVcfHX0usKVl3Xkz+ednevrn/P3tGLlano98jR9Hoy9hxl2n388mc8/nswxJxzFjfdcx62d7+T4tsdyaIuDGfLRSwCULVeWNavWAND3lcdocEA9klNSqJdahzcmDAJg2KCRjH77o1z/7nNGtJp1atD7Xw/Qu/sTofn/UBJSILGK9SZTuzsxv41mltfMSgPq5nWcu78MvAyQXCY1FL/tJWnpNGrYYOfzhqn1SQ8uhglcfEF7Lg5SR8+++NrOnnBB3J0LzzmTnjfv+QFtwBMPAdEc9wN9nuG15/rusr1unVr8vnwl9erUJjMzi42bNlO1SmUANm7axC13P8RtXa/m6CMPK8qphdK3U7+n4YGpVK1RFTNjzIiPGfjEv/fY757rHwSiOe6Hnr2Pmy/pscv25ekrqNugDsvTV5CUlESlKhVZtyb6qaZipQr88/WnePGpV/hxxuy4n1NxKQmjRWIVr5bWBa4CLshlWRWnOhNi+tczadasCY0bNyIlJYXLLuvIqNHjE92sEmPVmrUApP++nIlffMk5Z54a03Gtj2vJhM+n7Dx+3foNLP09tjfE09q05oOxnwAw/vPJnPCnozEzMjIy6N7rUS7scAbtT29b6HMJq4aNU3c+PqRFc5JTklm3eh3TJ3/D6ee1o3rNagBUqVaZeql59qt2MWn8l5x3afQN+fTzT+XrKd8CkJySTN9XHmPsiHFMHP15sZ5HvHkhlkTLb8r7sXltInpr1/yMBiq5+8xcyv081saFQVZWFt17PMjYMW+SFInw2pC3mT37l0Q3q8Toef9jrF2/nuTkZB648xaqVqnM2++NAaDzn89j5arVdL7+djZu2kwkEuGN4e/zwdCXOKjJgdz216vo2uMBsj2blORkHrjjFhrUKziwXHR+e3o9+jTnXHYdVatU5une9wHw8aeT+Wbmj6xdt4H3g8De54E7OPTgg+L3AuwDjw58iD+d2JJqNaoy6usR/PuZV3de7H339Q85/bxTOPeS9mRmZrJty3YeuLk3AAvn/saLfQfxr2H/wCxCZmYmT9//LL8vKfgN8sO3xtJ7wAOM/HIo69du2FnmmRecxjGtj6ZqjSqc37kDAL17PMncWfPidPbFJ0ypEssr/2Rm+V4Jcve4DtAMS6okzLYsnZzoJpR6Jx9Vqq7Fl1jTln5R5Kj7Zb1LYo45J//+TkKjfH5T3sMzcl5EpIhKwJe3x2xvL06KiJQqTnhSJQrcIiJAZohy3ArcIiKEq8cdy90BzcyuNLOHgucHmFmr+DdNRGTfyS7EkmixjOMeSHTCzeXB8w3A83FrkYhIAjgW8xILM0sys2/NbHTwvIaZTTCzucHP6jn27WVm88zsZzMr8GZHsQTuE4JvdN8K4O5rgDIxtVxEJCTi0OPuDszJ8fw+YKK7NwcmBs8xs8OBLsARQAdgoJnle2+IWAJ3RlDIjm95r124touIlHxZWMxLQcysIXAeMCjH6o7AkODxEKBTjvXD3H2buy8E5gH5pqNjCdwDgPeAOmbWB5gCPB7DcSIioZFtsS9m1tXMvs6xdN2tuGeBe9i1k1vX3dMBgp91gvWpwOIc+6UF6/IUy90Bh5rZN8AZRKe7d3L3OQUcJiISKtmFGFWS84Z4uzOz84Hl7v6NmbWLobjcKs53FmeBgdvMDgA2A6NyrnP3RTE0SEQkFIrxHhsnAxea2blAOaCKmb0BLDOz+u6ebmb1geXB/mlEv+dgh4ZAvjcxjyVVMoboTaPGEE2oLwA+KtRpiIiUcMV1cdLde7l7Q3dvTPSi46fufiXwIXB1sNvVwAfB4w+BLmZW1syaAM2BafnVEUuqZJdvFg3uGnhjQceJiIRJdm5fDlG8ngSGm9n1wCLgUgB3n2Vmw4HZQCbQzd3z/Z6+Qs+cdPcZZnZ84dssIlJyxfaNpoXj7p8DnwePVxG9Vpjbfn2APrGWG0uO+44cTyPAsUBsXxwoIhIS2eGZ8R5Tj7tyjseZRHPdI+PTHBGRxCjMqJJEyzdwBxNvKrn73fuoPSIiCRGmb27J76vLkt09M5+vMBMRKTVKS6pkGtF89kwz+xAYAWzasdHd341z20RE9pkw3ccjlhx3DaLfzH460U8TFvxU4BaRUiOrlPS46wQjSn7kj4C9Q5jSQSIiBSotPe4koBJ7MY9eRCRsSkvgTnf3R/ZZS0REEihEXzmZb+AO0WmIiBRNaelx5zo1U0SkNIrHlPd4yTNwu/vqfdkQEZFEKi3juEVE9hulJVUiIrLfUOAWEQmZMI1xVuAWEUE5bhGR0CkVo0qk9Bvc8qFEN6HU65jSMNFNkBhlhyhZosAtIoIuToqIhE54+tsK3CIigHrcIiKhk2nh6XMrcIuIoFSJiEjoKFUiIhIyGg4oIhIy4QnbCtwiIoBSJSIioZMVoj63AreICOpxi4iEjqvHLSISLupxi4iEjIYDioiETHjCtgK3iAgAmSEK3QrcIiLo4qSISOjo4qSISMioxy0iEjLqcYuIhEyWh6fHHUl0A0RESoJsPOYlP2bWyMw+M7M5ZjbLzLoH62uY2QQzmxv8rJ7jmF5mNs/Mfjaz9gW1VYFbRIRojjvWfwXIBO5098OA1kA3MzscuA+Y6O7NgYnBc4JtXYAjgA7AQDNLyq8CBW4REaI57liX/Lh7urvPCB5vAOYAqUBHYEiw2xCgU/C4IzDM3be5+0JgHtAqvzoUuEVEKFyqxMy6mtnXOZauuZVpZo2BY4CpQF13T4docAfqBLulAotzHJYWrMuTLk6KiFC44YDu/jLwcn77mFklYCTQw93Xm1meu+banHwocIuIULyjSswshWjQHuru7warl5lZfXdPN7P6wPJgfRrQKMfhDYGl+ZWvVImICMU6qsSAV4A57t4vx6YPgauDx1cDH+RY38XMyppZE6A5MC2/OtTjFhGhWCfgnAz8BfjBzGYG6+4HngSGm9n1wCLgUgB3n2Vmw4HZREekdHP3rPwqUOAWEaH4pry7+xRyz1sDnJHHMX2APrHWocAtIoK+SGG/0/7sdvTr9whJkQiDX32Lvk8/n+gmlQhJZVO4cOSDJJVJxpKSWDh2Gl8/8+4u+9Q/8TDav9KTDYtXALDwo+nMePb9ItUbKZPM6c/eRK2jmrB1zQY+ufk5NqatpObhB9D2iWtJqVQez87m2wEfMH/U1CLVVRIllU3hquF/I6lMMpHkJH4aO41J/xxZpDJbXNyWNrd1AmDKv97nh5GTAejY/xbqt2hCVmYW6d/NZ2yvwWRn5vspv8TyEE15V+AuokgkwoD+fehw7uWkpaXzv6/GMmr0eObMmZvopiVc1rYMRl32OJmbtxFJTuLC9/7Gos++Y/mM+bvs9/u0n/n4mmcKXX6lhrU47Z83MurSXT9hHtqlHdvWbWJYmzs56MLWtL6/C5/c8hyZW7bzaY8XWb9wGRXqVuOisY+x+Isf2L5+c5HOs6TJ2pbBG5f3ISN43a965yHmff4dS7+dV+CxVw57gFF3vcS6tJU715WrWpG2PS5i8PkPgjvXjenD3AnfsHX9Zn58/0s+6D4QgE4DutGySztmvDExbucWT1nqce8/Wh1/DPPn/8rChYsAGD78Ay68oL0CdyBz8zYAIslJRJKTC/X9UM0vOpkjrzubSEoyy7+dz5T7X8WzCy6g8dnH8k2/aM9+wZhpnPxY9EL+uoW/79xn87K1bF21jnI1K5e6wA2QkeN1T0pJAneqHVCHDo9eQ4WaVcjYso2x9w1i1fz0AstqeupRLJz8A1vXbQJg4eQfaNruaGZ/+BXzP/tu535Lv5tPlfo14nNC+0CYUiVxGw5oZoea2RnBIPSc6zvEq85EaJBaj8Vpfwy5TFuSToMG9RLYopLFIsbF4/pw1XcDWTL5B5Z/O3+Pfer+qRmXjO/DOa/fTfWDoxPGqjVrwEEXnMAHnR5hZPsH8Kxsmv355JjqrFivOhvTVwPgWdlsX7+ZctV3+TOkdsumRFKSWf/r8tyKCD2LGDeMfZyeM15gweQfWTpzPuc+eT3jHh7C4PMfZGKfN+nw2LUxlVW5XnXWB68nwIbfV1O5XvVd9okkJ9HiojbM//z7Yj2PfcndY14SLS49bjO7HehGdI7+K2bW3d13jFl8HPg4HvUmQm6zoUrCL7ak8GxnZPsHKFOlAmcP6kH1Qxqy5ue0ndtX/vArQ0/oQebmbTQ6/Wjav9KTYW3vIrXNEdRq0YQ/j3kEgORyZdiyaj0AZw/qQeVGtUlKSaZSak0uHhdNlfz4yjh+Hj4Jcv2d/PG4Qp1qnN7/Zj7r+eKuG0oRz3YGnXs/ZatU4JKXe1L74IY0/NPBXDyw+859kspG//sfdekptLo22p+q3rgunV+7h+ztmaxdvJx3bnw217/x3TunHR67lkVTf2Lx9J/jdk7xFqYed7xSJX8F/uTuG4O5+u+YWWN370/ew2QI5vt3BbCkqkQiFePUvOKzJC2dRg0b7HzeMLU+6enLEtiikmn7+s2kfzWHRu2O2iVwZ2zcsvPx4k+/I9Lnmmjv2OCXdyYz7cnhe5Q1/oZngbxz3JvSV1Opfg02pa/GkiKUqVKBbWs3ApBSqTwdhtzF9L4j9si1l0bb1m9m0VdzOKTD8Wxbv4lB596/xz7fj5jE9yMmAbnnuNenr+bA1oftfF65Xg1++9+cnc/bdr+ICjUq806vV+J4JvEXpm/AiVeqJMndNwK4+69AO+AcM+tHPoHb3V929+Pc/bgwBG2A6V/PpFmzJjRu3IiUlBQuu6wjo0aPT3SzSoRyNSpTpkoFAJLKpZDa5kjWztt1Jm/52lV3Pq7dsilEjK1rNrJkyiyanteKcjWrAFC2WkUqpdaMqd7fJszg4EvbAtD0vFYs/XI2AJGUJNoP6sHcdyazYEy+E9NCrUKNypQNXvfksik0bnMEv//4K2sXr+DQc/+46Vydww6IqbwFX3xP01NaUK5KBcpVqUDTU1qw4ItoSqRll3Y0PbUF79/2XOg/vWS5x7wkWrx63L+bWUt3nwkQ9LzPBwYDLeJUZ0JkZWXRvceDjB3zJkmRCK8NeZvZs39JdLNKhAp1q3HaP2/EkiKYGfNHT2XRxJkcduXpAMx541OanteKw/9yBp6VRebWDCbeEh1KuXbuUqb3HcF5b96LRYzsjCymPPgaG5esKrDen4Z9wWn9b6LLlGfYtnYjn9zyHAAHXdCaeiccQtnqlTj4slMA+LznS6yavShOr0BiVKpTjQv63YRFIljEmDN6KvM+/ZYVc9M457FraXNbJyIpycz+8CuWzyn43Leu28SUAe9z7ahHAZjc/72dFyrP6XMd65as5Jr3egPw08fTmTLgvfidXByFKVVi8cjHmllDINPdf89l28nu/mVBZSSXSQ3PqxhSz9c5LdFNKPVWJunPeF944LeheX6Sj9WJqafF/Mv6aslnRa6vKOLS43b3tHy2FRi0RUT2tTANKtA4bhERwpUqUeAWESFco0oUuEVEgCwvxhu7xpkCt4gIynGLiISOctwiIiGjHLeISMhkK1UiIhIu6nGLiISMRpWIiISMUiUiIiGjVImISMioxy0iEjLqcYuIhEyWZyW6CTFT4BYRQVPeRURCR1PeRURCRj1uEZGQ0agSEZGQ0agSEZGQ0ZR3EZGQUY5bRCRklOMWEQkZ9bhFREJG47hFREJGPW4RkZDRqBIRkZDRxUkRkZAJU6okkugGiIiUBF6IfwUxsw5m9rOZzTOz+4q7repxi4hQfD1uM0sCngfOAtKA6Wb2obvPLpYKUOAWEQGKNcfdCpjn7gsAzGwY0BEo/YE7c/sSS3QbCsvMurr7y4luR2mm1zj+9tfXuDAxx8y6Al1zrHo5x2uWCizOsS0NOKHoLfyDctzFq2vBu0gR6TWOP73GBXD3l939uBxLzje63N4AivXKpwK3iEjxSgMa5XjeEFhanBUocIuIFK/pQHMza2JmZYAuwIfFWUGJzXGH1H6XF0wAvcbxp9e4CNw908xuBcYBScBgd59VnHVYmAadi4iIUiUiIqGjwC0iEjIK3MUg3tNbBcxssJktN7MfE92W0srMGpnZZ2Y2x8xmmVn3RLdJcqccdxEF01t/Icf0VuDy4pzeKmBmpwAbgf+4+5GJbk9pZGb1gfruPsPMKgPfAJ30t1zyqMdddDunt7r7dmDH9FYpRu4+CVid6HaUZu6e7u4zgscbgDlEZwFKCaPAXXS5TW/VH7uEmpk1Bo4Bpia4KZILBe6ii/v0VpF9ycwqASOBHu6+PtHtkT0pcBdd3Ke3iuwrZpZCNGgPdfd3E90eyZ0Cd9HFfXqryL5gZga8Asxx936Jbo/kTYG7iNw9E9gxvXUOMLy4p7cKmNlbwFfAIWaWZmbXJ7pNpdDJwF+A081sZrCcm+hGyZ40HFBEJGTU4xYRCRkFbhGRkFHgFhEJGQVuEZGQUeAWEQkZBW7Jk5llBUPCfjSzEWZWoQhlvWZmlwSPB5nZ4fns287MTtqLOn41s1qxrs+jjGvM7LniqFckXhS4JT9b3L1lcDe+7cBNOTcGd0YsNHe/oYA7zrUDCh24RfYXCtwSq8lAs6A3/JmZvQn8YGZJZva0mU03s+/N7EaIzsIzs+fMbLaZjQHq7CjIzD43s+OCxx3MbIaZfWdmE4ObG90E9Ax6+23NrLaZjQzqmG5mJwfH1jSz8Wb2rZm9RO73jcmVmbUys/8Gx/7XzA7JsbmRmX0c3GP94RzHXGlm04J2vbS3b1wiRaUvC5YCmVkycA7wcbCqFXCkuy80s67AOnc/3szKAl+a2Xiid5Y7BGgB1AVmA4N3K7c28G/glKCsGu6+2sxeBDa6+z+C/d4E/unuU8zsAKKzVA8DHgamuPsjZnYe0LUQp/VTUG+mmZ0JPA5cnPP8gM3A9OCNZxPQGTjZ3TPMbCBwBfCfQtQpUiwUuCU/5c1sZvB4MtH7WJwETHP3hcH6s4GjduSvgapAc+AU4C13zwKWmtmnuZTfGpi0oyx3z+t+22cCh0dvpQFAleBG/6cAFwXHjjGzNYU4t6rAEDNrTvRujik5tk1w91UAZvYu0AbIBP5ENJADlAeWF6I+kWKjwC352eLuLXOuCILWppyrgNvcfdxu+51Lwbe3tRj2gWhK70R335JLW/b2ng2PAp+5+5+D9MznObbtXqYHbR3i7r32sj6RYqMctxTVOODm4HagmNnBZlYRmAR0CXLg9YHTcjn2K+BUM2sSHFsjWL8BqJxjv/FEb+RFsF/L4OEkoukKzOwcoHoh2l0VWBI8vma3bWeZWQ0zKw90Ar4EJgKXmFmdHW01swMLUZ9IsVHglqIaRDR/PcOiX+T7EtFPcu8Bc4EfgBeAL3Y/0N1XEM1Lv2tm3wFvB5tGAX/ecXESuB04Lrj4OZs/Rrf0Bk4xsxlEUzaL8mnn98FdBdPMrB/QF3jCzL4Edr/IOAV4HZgJjHT3r4NRMA8C483se2ACUD+2l0ikeOnugCIiIaMet4hIyChwi4iEjAK3iEjIKHCLiISMAreISMgocIuIhIwCt4hIyPw/8uuKn7ZGbOYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-huntington",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
