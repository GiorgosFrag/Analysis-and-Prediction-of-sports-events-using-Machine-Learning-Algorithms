{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "technological-hours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 2.3689 - accuracy: 0.2529 - val_loss: 1.9776 - val_accuracy: 0.2531\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 711us/step - loss: 1.7262 - accuracy: 0.2500 - val_loss: 1.4858 - val_accuracy: 0.2469\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 1.3398 - accuracy: 0.2590 - val_loss: 1.2129 - val_accuracy: 0.2743\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.1446 - accuracy: 0.3584 - val_loss: 1.0875 - val_accuracy: 0.4779\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 1.0623 - accuracy: 0.5087 - val_loss: 1.0405 - val_accuracy: 0.5159\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 1.0310 - accuracy: 0.5261 - val_loss: 1.0225 - val_accuracy: 0.5230\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 1.0158 - accuracy: 0.5309 - val_loss: 1.0117 - val_accuracy: 0.5261\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0053 - accuracy: 0.5306 - val_loss: 1.0037 - val_accuracy: 0.5274\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9975 - accuracy: 0.5299 - val_loss: 0.9978 - val_accuracy: 0.5270\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9917 - accuracy: 0.5297 - val_loss: 0.9936 - val_accuracy: 0.5274\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9875 - accuracy: 0.5300 - val_loss: 0.9906 - val_accuracy: 0.5274\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9845 - accuracy: 0.5300 - val_loss: 0.9886 - val_accuracy: 0.5279\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9825 - accuracy: 0.5298 - val_loss: 0.9872 - val_accuracy: 0.5252\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9812 - accuracy: 0.5304 - val_loss: 0.9863 - val_accuracy: 0.5279\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9802 - accuracy: 0.5300 - val_loss: 0.9858 - val_accuracy: 0.5270\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 571us/step - loss: 0.9796 - accuracy: 0.5300 - val_loss: 0.9855 - val_accuracy: 0.5252\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9792 - accuracy: 0.5293 - val_loss: 0.9852 - val_accuracy: 0.5252\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9789 - accuracy: 0.5297 - val_loss: 0.9850 - val_accuracy: 0.5252\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9787 - accuracy: 0.5297 - val_loss: 0.9849 - val_accuracy: 0.5274\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9786 - accuracy: 0.5290 - val_loss: 0.9848 - val_accuracy: 0.5279\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9784 - accuracy: 0.5301 - val_loss: 0.9847 - val_accuracy: 0.5265\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9781 - accuracy: 0.5302 - val_loss: 0.9847 - val_accuracy: 0.5252\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9780 - accuracy: 0.5303 - val_loss: 0.9846 - val_accuracy: 0.5274\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9778 - accuracy: 0.5287 - val_loss: 0.9845 - val_accuracy: 0.5274\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9778 - accuracy: 0.5299 - val_loss: 0.9844 - val_accuracy: 0.5274\n",
      "Epoch 26/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9776 - accuracy: 0.5300 - val_loss: 0.9845 - val_accuracy: 0.5274\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9775 - accuracy: 0.5307 - val_loss: 0.9842 - val_accuracy: 0.5274\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9773 - accuracy: 0.5307 - val_loss: 0.9842 - val_accuracy: 0.5274\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9773 - accuracy: 0.5299 - val_loss: 0.9843 - val_accuracy: 0.5283\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9771 - accuracy: 0.5302 - val_loss: 0.9840 - val_accuracy: 0.5265\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9769 - accuracy: 0.5312 - val_loss: 0.9841 - val_accuracy: 0.5283\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9769 - accuracy: 0.5307 - val_loss: 0.9840 - val_accuracy: 0.5270\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 584us/step - loss: 0.9768 - accuracy: 0.5303 - val_loss: 0.9841 - val_accuracy: 0.5265\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9766 - accuracy: 0.5304 - val_loss: 0.9838 - val_accuracy: 0.5270\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9766 - accuracy: 0.5306 - val_loss: 0.9838 - val_accuracy: 0.5265\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9765 - accuracy: 0.5303 - val_loss: 0.9838 - val_accuracy: 0.5226\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9838 - val_accuracy: 0.5261\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9764 - accuracy: 0.5307 - val_loss: 0.9836 - val_accuracy: 0.5270\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9763 - accuracy: 0.5308 - val_loss: 0.9838 - val_accuracy: 0.5261\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9763 - accuracy: 0.5306 - val_loss: 0.9836 - val_accuracy: 0.5270\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9762 - accuracy: 0.5309 - val_loss: 0.9839 - val_accuracy: 0.5274\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9762 - accuracy: 0.5300 - val_loss: 0.9836 - val_accuracy: 0.5274\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9760 - accuracy: 0.5307 - val_loss: 0.9840 - val_accuracy: 0.5292\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9764 - accuracy: 0.5310 - val_loss: 0.9835 - val_accuracy: 0.5283\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9762 - accuracy: 0.5303 - val_loss: 0.9836 - val_accuracy: 0.5288\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9762 - accuracy: 0.5297 - val_loss: 0.9836 - val_accuracy: 0.5230\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9762 - accuracy: 0.5301 - val_loss: 0.9837 - val_accuracy: 0.5239\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 582us/step - loss: 0.9761 - accuracy: 0.5309 - val_loss: 0.9835 - val_accuracy: 0.5274\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9760 - accuracy: 0.5313 - val_loss: 0.9837 - val_accuracy: 0.5243\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9760 - accuracy: 0.5311 - val_loss: 0.9836 - val_accuracy: 0.5261\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9759 - accuracy: 0.5309 - val_loss: 0.9840 - val_accuracy: 0.5230\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9762 - accuracy: 0.5296 - val_loss: 0.9842 - val_accuracy: 0.5274\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9835 - val_accuracy: 0.5243\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9760 - accuracy: 0.5304 - val_loss: 0.9840 - val_accuracy: 0.5243\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9759 - accuracy: 0.5304 - val_loss: 0.9836 - val_accuracy: 0.5279\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9835 - val_accuracy: 0.5230\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9759 - accuracy: 0.5306 - val_loss: 0.9835 - val_accuracy: 0.5243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9758 - accuracy: 0.5300 - val_loss: 0.9836 - val_accuracy: 0.5239\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 564us/step - loss: 0.9759 - accuracy: 0.5296 - val_loss: 0.9837 - val_accuracy: 0.5288\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9760 - accuracy: 0.5298 - val_loss: 0.9835 - val_accuracy: 0.5248\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9759 - accuracy: 0.5291 - val_loss: 0.9836 - val_accuracy: 0.5252\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9759 - accuracy: 0.5305 - val_loss: 0.9835 - val_accuracy: 0.5261\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9757 - accuracy: 0.5305 - val_loss: 0.9837 - val_accuracy: 0.5279\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9758 - accuracy: 0.5306 - val_loss: 0.9835 - val_accuracy: 0.5279\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9757 - accuracy: 0.5294 - val_loss: 0.9839 - val_accuracy: 0.5230\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9758 - accuracy: 0.5303 - val_loss: 0.9837 - val_accuracy: 0.5235\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9757 - accuracy: 0.5303 - val_loss: 0.9834 - val_accuracy: 0.5235\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9758 - accuracy: 0.5311 - val_loss: 0.9835 - val_accuracy: 0.5235\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 547us/step - loss: 0.9757 - accuracy: 0.5309 - val_loss: 0.9835 - val_accuracy: 0.5274\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5304 - val_loss: 0.9835 - val_accuracy: 0.5274\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9758 - accuracy: 0.5307 - val_loss: 0.9835 - val_accuracy: 0.5243\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9757 - accuracy: 0.5309 - val_loss: 0.9835 - val_accuracy: 0.5235\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 592us/step - loss: 0.9759 - accuracy: 0.5306 - val_loss: 0.9837 - val_accuracy: 0.5261\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 578us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9836 - val_accuracy: 0.5252\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9757 - accuracy: 0.5293 - val_loss: 0.9835 - val_accuracy: 0.5235\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 0.9757 - accuracy: 0.5308 - val_loss: 0.9837 - val_accuracy: 0.5265\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 593us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 601us/step - loss: 0.9757 - accuracy: 0.5305 - val_loss: 0.9838 - val_accuracy: 0.5221\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 581us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9836 - val_accuracy: 0.5265\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 586us/step - loss: 0.9757 - accuracy: 0.5310 - val_loss: 0.9835 - val_accuracy: 0.5226\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 634us/step - loss: 0.9756 - accuracy: 0.5309 - val_loss: 0.9835 - val_accuracy: 0.5221\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9755 - accuracy: 0.5302 - val_loss: 0.9839 - val_accuracy: 0.5252\n",
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9835 - val_accuracy: 0.5235\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9756 - accuracy: 0.5306 - val_loss: 0.9837 - val_accuracy: 0.5235\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9836 - val_accuracy: 0.5217\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9756 - accuracy: 0.5305 - val_loss: 0.9835 - val_accuracy: 0.5221\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9838 - val_accuracy: 0.5274\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5308 - val_loss: 0.9839 - val_accuracy: 0.5221\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 589us/step - loss: 0.9757 - accuracy: 0.5305 - val_loss: 0.9840 - val_accuracy: 0.5212\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 570us/step - loss: 0.9755 - accuracy: 0.5302 - val_loss: 0.9836 - val_accuracy: 0.5252\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9755 - accuracy: 0.5299 - val_loss: 0.9836 - val_accuracy: 0.5226\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5307 - val_loss: 0.9839 - val_accuracy: 0.5217\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9756 - accuracy: 0.5304 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9755 - accuracy: 0.5302 - val_loss: 0.9835 - val_accuracy: 0.5221\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9755 - accuracy: 0.5302 - val_loss: 0.9836 - val_accuracy: 0.5226\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9754 - accuracy: 0.5304 - val_loss: 0.9835 - val_accuracy: 0.5221\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9754 - accuracy: 0.5302 - val_loss: 0.9835 - val_accuracy: 0.5226\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9755 - accuracy: 0.5300 - val_loss: 0.9841 - val_accuracy: 0.5226\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9755 - accuracy: 0.5304 - val_loss: 0.9837 - val_accuracy: 0.5261\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9755 - accuracy: 0.5308 - val_loss: 0.9839 - val_accuracy: 0.5221\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5313 - val_loss: 0.9837 - val_accuracy: 0.5212\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9836 - val_accuracy: 0.5252\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9754 - accuracy: 0.5296 - val_loss: 0.9837 - val_accuracy: 0.5217\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9753 - accuracy: 0.5298 - val_loss: 0.9837 - val_accuracy: 0.5274\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9754 - accuracy: 0.5304 - val_loss: 0.9836 - val_accuracy: 0.5252\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9753 - accuracy: 0.5301 - val_loss: 0.9841 - val_accuracy: 0.5212\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9753 - accuracy: 0.5298 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5301 - val_loss: 0.9837 - val_accuracy: 0.5221\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 599us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9841 - val_accuracy: 0.5283\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9754 - accuracy: 0.5301 - val_loss: 0.9837 - val_accuracy: 0.5252\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5302 - val_loss: 0.9836 - val_accuracy: 0.5226\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9837 - val_accuracy: 0.5252\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 568us/step - loss: 0.9752 - accuracy: 0.5306 - val_loss: 0.9838 - val_accuracy: 0.5252\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 548us/step - loss: 0.9753 - accuracy: 0.5307 - val_loss: 0.9835 - val_accuracy: 0.5226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9836 - val_accuracy: 0.5235\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9753 - accuracy: 0.5310 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9837 - val_accuracy: 0.5221\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9836 - val_accuracy: 0.5226\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9752 - accuracy: 0.5306 - val_loss: 0.9839 - val_accuracy: 0.5226\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9752 - accuracy: 0.5305 - val_loss: 0.9837 - val_accuracy: 0.5226\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9752 - accuracy: 0.5310 - val_loss: 0.9836 - val_accuracy: 0.5217\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9838 - val_accuracy: 0.5274\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5305 - val_loss: 0.9836 - val_accuracy: 0.5217\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9835 - val_accuracy: 0.5221\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9752 - accuracy: 0.5310 - val_loss: 0.9835 - val_accuracy: 0.5221\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9753 - accuracy: 0.5307 - val_loss: 0.9836 - val_accuracy: 0.5217\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9752 - accuracy: 0.5302 - val_loss: 0.9836 - val_accuracy: 0.5226\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9752 - accuracy: 0.5302 - val_loss: 0.9837 - val_accuracy: 0.5221\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9751 - accuracy: 0.5304 - val_loss: 0.9840 - val_accuracy: 0.5226\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9752 - accuracy: 0.5313 - val_loss: 0.9842 - val_accuracy: 0.5217\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9840 - val_accuracy: 0.5226\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9753 - accuracy: 0.5308 - val_loss: 0.9837 - val_accuracy: 0.5226\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9752 - accuracy: 0.5305 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 575us/step - loss: 0.9752 - accuracy: 0.5307 - val_loss: 0.9837 - val_accuracy: 0.5226\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9751 - accuracy: 0.5298 - val_loss: 0.9836 - val_accuracy: 0.5226\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9752 - accuracy: 0.5303 - val_loss: 0.9838 - val_accuracy: 0.5212\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9751 - accuracy: 0.5297 - val_loss: 0.9836 - val_accuracy: 0.5265\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9751 - accuracy: 0.5309 - val_loss: 0.9839 - val_accuracy: 0.5217\n",
      "Epoch 139/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9752 - accuracy: 0.5305 - val_loss: 0.9837 - val_accuracy: 0.5226\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9750 - accuracy: 0.5306 - val_loss: 0.9835 - val_accuracy: 0.5230\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5301 - val_loss: 0.9844 - val_accuracy: 0.5212\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9751 - accuracy: 0.5287 - val_loss: 0.9836 - val_accuracy: 0.5252\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9753 - accuracy: 0.5305 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9751 - accuracy: 0.5303 - val_loss: 0.9835 - val_accuracy: 0.5221\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 571us/step - loss: 0.9752 - accuracy: 0.5307 - val_loss: 0.9837 - val_accuracy: 0.5221\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9750 - accuracy: 0.5313 - val_loss: 0.9835 - val_accuracy: 0.5221\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9751 - accuracy: 0.5301 - val_loss: 0.9838 - val_accuracy: 0.5226\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 564us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9837 - val_accuracy: 0.5217\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9751 - accuracy: 0.5308 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9750 - accuracy: 0.5305 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9749 - accuracy: 0.5298 - val_loss: 0.9838 - val_accuracy: 0.5279\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9837 - val_accuracy: 0.5265\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9750 - accuracy: 0.5311 - val_loss: 0.9839 - val_accuracy: 0.5212\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9751 - accuracy: 0.5298 - val_loss: 0.9839 - val_accuracy: 0.5217\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9751 - accuracy: 0.5304 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9751 - accuracy: 0.5296 - val_loss: 0.9836 - val_accuracy: 0.5252\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9835 - val_accuracy: 0.5221\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 0.9835 - val_accuracy: 0.5217\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9749 - accuracy: 0.5301 - val_loss: 0.9836 - val_accuracy: 0.5257\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9751 - accuracy: 0.5298 - val_loss: 0.9836 - val_accuracy: 0.5230\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 0.9835 - val_accuracy: 0.5226\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9749 - accuracy: 0.5308 - val_loss: 0.9837 - val_accuracy: 0.5217\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9750 - accuracy: 0.5305 - val_loss: 0.9840 - val_accuracy: 0.5221\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9749 - accuracy: 0.5308 - val_loss: 0.9838 - val_accuracy: 0.5217\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 0.9748 - accuracy: 0.5310 - val_loss: 0.9840 - val_accuracy: 0.5226\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9836 - val_accuracy: 0.5221\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9839 - val_accuracy: 0.5221\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9840 - val_accuracy: 0.5212\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 0.9840 - val_accuracy: 0.5265\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 555us/step - loss: 0.9750 - accuracy: 0.5305 - val_loss: 0.9841 - val_accuracy: 0.5265\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9748 - accuracy: 0.5312 - val_loss: 0.9836 - val_accuracy: 0.5217\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9748 - accuracy: 0.5299 - val_loss: 0.9835 - val_accuracy: 0.5226\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 603us/step - loss: 0.9750 - accuracy: 0.5305 - val_loss: 0.9836 - val_accuracy: 0.5217\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9749 - accuracy: 0.5309 - val_loss: 0.9836 - val_accuracy: 0.5217\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9750 - accuracy: 0.5303 - val_loss: 0.9836 - val_accuracy: 0.5226\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9748 - accuracy: 0.5307 - val_loss: 0.9841 - val_accuracy: 0.5248\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9750 - accuracy: 0.5308 - val_loss: 0.9836 - val_accuracy: 0.5226\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9749 - accuracy: 0.5299 - val_loss: 0.9839 - val_accuracy: 0.5212\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9747 - accuracy: 0.5305 - val_loss: 0.9838 - val_accuracy: 0.5252\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9748 - accuracy: 0.5311 - val_loss: 0.9840 - val_accuracy: 0.5212\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9839 - val_accuracy: 0.5217\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9836 - val_accuracy: 0.5217\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5303 - val_loss: 0.9837 - val_accuracy: 0.5226\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9748 - accuracy: 0.5307 - val_loss: 0.9838 - val_accuracy: 0.5248\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 571us/step - loss: 0.9748 - accuracy: 0.5308 - val_loss: 0.9836 - val_accuracy: 0.5226\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9750 - accuracy: 0.5309 - val_loss: 0.9839 - val_accuracy: 0.5226\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5304 - val_loss: 0.9838 - val_accuracy: 0.5221\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9749 - accuracy: 0.5301 - val_loss: 0.9837 - val_accuracy: 0.5221\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9748 - accuracy: 0.5307 - val_loss: 0.9837 - val_accuracy: 0.5274\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5313 - val_loss: 0.9839 - val_accuracy: 0.5230\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9748 - accuracy: 0.5309 - val_loss: 0.9839 - val_accuracy: 0.5221\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9748 - accuracy: 0.5293 - val_loss: 0.9836 - val_accuracy: 0.5252\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9749 - accuracy: 0.5303 - val_loss: 0.9835 - val_accuracy: 0.5230\n",
      "Epoch 195/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9748 - accuracy: 0.5305 - val_loss: 0.9838 - val_accuracy: 0.5252\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 0.9836 - val_accuracy: 0.5230\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9748 - accuracy: 0.5308 - val_loss: 0.9836 - val_accuracy: 0.5252\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9748 - accuracy: 0.5305 - val_loss: 0.9836 - val_accuracy: 0.5248\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9747 - accuracy: 0.5306 - val_loss: 0.9840 - val_accuracy: 0.5212\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9747 - accuracy: 0.5301 - val_loss: 0.9839 - val_accuracy: 0.5221\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 349us/step - loss: 0.9746 - accuracy: 0.5307\n",
      "Accuracy : 0.5306905508041382\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9839 - accuracy: 0.5221\n",
      "Accuracy : 0.5221238732337952\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 1.3278 - accuracy: 0.3030 - val_loss: 1.2297 - val_accuracy: 0.3022\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 639us/step - loss: 1.1617 - accuracy: 0.3047 - val_loss: 1.1015 - val_accuracy: 0.3093\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 1.0666 - accuracy: 0.3115 - val_loss: 1.0449 - val_accuracy: 0.3199\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 1.0283 - accuracy: 0.4488 - val_loss: 1.0238 - val_accuracy: 0.5283\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 1.0068 - accuracy: 0.5254 - val_loss: 1.0003 - val_accuracy: 0.5288\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9888 - accuracy: 0.5249 - val_loss: 0.9838 - val_accuracy: 0.5288\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9809 - accuracy: 0.5251 - val_loss: 0.9780 - val_accuracy: 0.5279\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 599us/step - loss: 0.9782 - accuracy: 0.5266 - val_loss: 0.9764 - val_accuracy: 0.5279\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 0.9774 - accuracy: 0.5265 - val_loss: 0.9756 - val_accuracy: 0.5292\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9770 - accuracy: 0.5266 - val_loss: 0.9754 - val_accuracy: 0.5296\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9768 - accuracy: 0.5267 - val_loss: 0.9755 - val_accuracy: 0.5296\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9768 - accuracy: 0.5266 - val_loss: 0.9753 - val_accuracy: 0.5336\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9767 - accuracy: 0.5272 - val_loss: 0.9753 - val_accuracy: 0.5345\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9768 - accuracy: 0.5279 - val_loss: 0.9758 - val_accuracy: 0.5296\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 575us/step - loss: 0.9767 - accuracy: 0.5275 - val_loss: 0.9755 - val_accuracy: 0.5305\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 573us/step - loss: 0.9767 - accuracy: 0.5269 - val_loss: 0.9754 - val_accuracy: 0.5336\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9767 - accuracy: 0.5279 - val_loss: 0.9754 - val_accuracy: 0.5345\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9766 - accuracy: 0.5277 - val_loss: 0.9755 - val_accuracy: 0.5336\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9766 - accuracy: 0.5277 - val_loss: 0.9753 - val_accuracy: 0.5305\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9766 - accuracy: 0.5278 - val_loss: 0.9753 - val_accuracy: 0.5336\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9765 - accuracy: 0.5286 - val_loss: 0.9753 - val_accuracy: 0.5345\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9765 - accuracy: 0.5278 - val_loss: 0.9756 - val_accuracy: 0.5305\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9765 - accuracy: 0.5276 - val_loss: 0.9753 - val_accuracy: 0.5305\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9765 - accuracy: 0.5277 - val_loss: 0.9752 - val_accuracy: 0.5336\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9765 - accuracy: 0.5281 - val_loss: 0.9754 - val_accuracy: 0.5345\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 554us/step - loss: 0.9765 - accuracy: 0.5283 - val_loss: 0.9755 - val_accuracy: 0.5305\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9764 - accuracy: 0.5273 - val_loss: 0.9749 - val_accuracy: 0.5354\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9765 - accuracy: 0.5275 - val_loss: 0.9751 - val_accuracy: 0.5336\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 572us/step - loss: 0.9764 - accuracy: 0.5278 - val_loss: 0.9750 - val_accuracy: 0.5336\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9763 - accuracy: 0.5283 - val_loss: 0.9752 - val_accuracy: 0.5305\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9764 - accuracy: 0.5280 - val_loss: 0.9757 - val_accuracy: 0.5292\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9765 - accuracy: 0.5282 - val_loss: 0.9755 - val_accuracy: 0.5305\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9765 - accuracy: 0.5271 - val_loss: 0.9754 - val_accuracy: 0.5296\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9763 - accuracy: 0.5274 - val_loss: 0.9749 - val_accuracy: 0.5336\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9765 - accuracy: 0.5288 - val_loss: 0.9751 - val_accuracy: 0.5305\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9763 - accuracy: 0.5281 - val_loss: 0.9750 - val_accuracy: 0.5345\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9764 - accuracy: 0.5280 - val_loss: 0.9750 - val_accuracy: 0.5305\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9762 - accuracy: 0.5283 - val_loss: 0.9748 - val_accuracy: 0.5336\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9762 - accuracy: 0.5283 - val_loss: 0.9751 - val_accuracy: 0.5305\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9762 - accuracy: 0.5277 - val_loss: 0.9748 - val_accuracy: 0.5341\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9762 - accuracy: 0.5280 - val_loss: 0.9748 - val_accuracy: 0.5336\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9763 - accuracy: 0.5280 - val_loss: 0.9748 - val_accuracy: 0.5345\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9763 - accuracy: 0.5283 - val_loss: 0.9750 - val_accuracy: 0.5345\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9762 - accuracy: 0.5279 - val_loss: 0.9747 - val_accuracy: 0.5336\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9761 - accuracy: 0.5278 - val_loss: 0.9747 - val_accuracy: 0.5341\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9762 - accuracy: 0.5280 - val_loss: 0.9753 - val_accuracy: 0.5305\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9761 - accuracy: 0.5276 - val_loss: 0.9748 - val_accuracy: 0.5345\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9761 - accuracy: 0.5286 - val_loss: 0.9748 - val_accuracy: 0.5345\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9761 - accuracy: 0.5287 - val_loss: 0.9750 - val_accuracy: 0.5296\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9761 - accuracy: 0.5287 - val_loss: 0.9747 - val_accuracy: 0.5336\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9762 - accuracy: 0.5282 - val_loss: 0.9747 - val_accuracy: 0.5336\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9761 - accuracy: 0.5282 - val_loss: 0.9746 - val_accuracy: 0.5354\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9763 - accuracy: 0.5276 - val_loss: 0.9747 - val_accuracy: 0.5336\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 586us/step - loss: 0.9761 - accuracy: 0.5285 - val_loss: 0.9748 - val_accuracy: 0.5305\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9760 - accuracy: 0.5279 - val_loss: 0.9747 - val_accuracy: 0.5336\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9760 - accuracy: 0.5280 - val_loss: 0.9745 - val_accuracy: 0.5336\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9760 - accuracy: 0.5281 - val_loss: 0.9746 - val_accuracy: 0.5336\n",
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9760 - accuracy: 0.5282 - val_loss: 0.9746 - val_accuracy: 0.5336\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9760 - accuracy: 0.5280 - val_loss: 0.9747 - val_accuracy: 0.5345\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9760 - accuracy: 0.5280 - val_loss: 0.9747 - val_accuracy: 0.5345\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9759 - accuracy: 0.5282 - val_loss: 0.9751 - val_accuracy: 0.5292\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9759 - accuracy: 0.5281 - val_loss: 0.9745 - val_accuracy: 0.5341\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 572us/step - loss: 0.9760 - accuracy: 0.5277 - val_loss: 0.9745 - val_accuracy: 0.5336\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9760 - accuracy: 0.5281 - val_loss: 0.9746 - val_accuracy: 0.5336\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9759 - accuracy: 0.5279 - val_loss: 0.9744 - val_accuracy: 0.5336\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9759 - accuracy: 0.5287 - val_loss: 0.9745 - val_accuracy: 0.5336\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9760 - accuracy: 0.5282 - val_loss: 0.9744 - val_accuracy: 0.5341\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9758 - accuracy: 0.5271 - val_loss: 0.9745 - val_accuracy: 0.5345\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9758 - accuracy: 0.5281 - val_loss: 0.9746 - val_accuracy: 0.5336\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9759 - accuracy: 0.5283 - val_loss: 0.9744 - val_accuracy: 0.5336\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9759 - accuracy: 0.5280 - val_loss: 0.9744 - val_accuracy: 0.5350\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9759 - accuracy: 0.5277 - val_loss: 0.9744 - val_accuracy: 0.5336\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9759 - accuracy: 0.5284 - val_loss: 0.9744 - val_accuracy: 0.5336\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9758 - accuracy: 0.5282 - val_loss: 0.9745 - val_accuracy: 0.5345\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9758 - accuracy: 0.5281 - val_loss: 0.9743 - val_accuracy: 0.5336\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9758 - accuracy: 0.5282 - val_loss: 0.9749 - val_accuracy: 0.5292\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5275 - val_loss: 0.9745 - val_accuracy: 0.5305\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9758 - accuracy: 0.5280 - val_loss: 0.9743 - val_accuracy: 0.5336\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9758 - accuracy: 0.5281 - val_loss: 0.9745 - val_accuracy: 0.5305\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9759 - accuracy: 0.5281 - val_loss: 0.9743 - val_accuracy: 0.5336\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9757 - accuracy: 0.5279 - val_loss: 0.9742 - val_accuracy: 0.5336\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9759 - accuracy: 0.5269 - val_loss: 0.9743 - val_accuracy: 0.5336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 568us/step - loss: 0.9757 - accuracy: 0.5284 - val_loss: 0.9742 - val_accuracy: 0.5354\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5285 - val_loss: 0.9743 - val_accuracy: 0.5305\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5276 - val_loss: 0.9742 - val_accuracy: 0.5354\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9757 - accuracy: 0.5279 - val_loss: 0.9744 - val_accuracy: 0.5354\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9758 - accuracy: 0.5281 - val_loss: 0.9742 - val_accuracy: 0.5341\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 553us/step - loss: 0.9756 - accuracy: 0.5282 - val_loss: 0.9742 - val_accuracy: 0.5354\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9757 - accuracy: 0.5279 - val_loss: 0.9741 - val_accuracy: 0.5354\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9757 - accuracy: 0.5282 - val_loss: 0.9742 - val_accuracy: 0.5345\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9758 - accuracy: 0.5286 - val_loss: 0.9742 - val_accuracy: 0.5354\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9756 - accuracy: 0.5288 - val_loss: 0.9745 - val_accuracy: 0.5345\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9757 - accuracy: 0.5275 - val_loss: 0.9742 - val_accuracy: 0.5345\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9756 - accuracy: 0.5279 - val_loss: 0.9741 - val_accuracy: 0.5354\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9755 - accuracy: 0.5290 - val_loss: 0.9745 - val_accuracy: 0.5305\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9757 - accuracy: 0.5272 - val_loss: 0.9741 - val_accuracy: 0.5354\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9755 - accuracy: 0.5286 - val_loss: 0.9740 - val_accuracy: 0.5336\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9756 - accuracy: 0.5280 - val_loss: 0.9743 - val_accuracy: 0.5345\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9755 - accuracy: 0.5280 - val_loss: 0.9739 - val_accuracy: 0.5341\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9755 - accuracy: 0.5278 - val_loss: 0.9739 - val_accuracy: 0.5354\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9755 - accuracy: 0.5282 - val_loss: 0.9740 - val_accuracy: 0.5354\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9757 - accuracy: 0.5277 - val_loss: 0.9740 - val_accuracy: 0.5336\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9755 - accuracy: 0.5281 - val_loss: 0.9740 - val_accuracy: 0.5341\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9756 - accuracy: 0.5281 - val_loss: 0.9740 - val_accuracy: 0.5341\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 581us/step - loss: 0.9755 - accuracy: 0.5282 - val_loss: 0.9741 - val_accuracy: 0.5336\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 578us/step - loss: 0.9756 - accuracy: 0.5283 - val_loss: 0.9740 - val_accuracy: 0.5336\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5283 - val_loss: 0.9740 - val_accuracy: 0.5336\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5284 - val_loss: 0.9742 - val_accuracy: 0.5345\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9755 - accuracy: 0.5278 - val_loss: 0.9739 - val_accuracy: 0.5354\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 557us/step - loss: 0.9756 - accuracy: 0.5288 - val_loss: 0.9742 - val_accuracy: 0.5341\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9755 - accuracy: 0.5278 - val_loss: 0.9739 - val_accuracy: 0.5336\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9755 - accuracy: 0.5277 - val_loss: 0.9740 - val_accuracy: 0.5336\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9754 - accuracy: 0.5281 - val_loss: 0.9738 - val_accuracy: 0.5354\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 571us/step - loss: 0.9754 - accuracy: 0.5286 - val_loss: 0.9740 - val_accuracy: 0.5341\n",
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9754 - accuracy: 0.5286 - val_loss: 0.9746 - val_accuracy: 0.5292\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5273 - val_loss: 0.9739 - val_accuracy: 0.5354\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9754 - accuracy: 0.5282 - val_loss: 0.9741 - val_accuracy: 0.5336\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5281 - val_loss: 0.9738 - val_accuracy: 0.5341\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9754 - accuracy: 0.5284 - val_loss: 0.9740 - val_accuracy: 0.5341\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9753 - accuracy: 0.5286 - val_loss: 0.9742 - val_accuracy: 0.5345\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9753 - accuracy: 0.5280 - val_loss: 0.9738 - val_accuracy: 0.5354\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9753 - accuracy: 0.5286 - val_loss: 0.9741 - val_accuracy: 0.5345\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 570us/step - loss: 0.9754 - accuracy: 0.5279 - val_loss: 0.9740 - val_accuracy: 0.5336\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 591us/step - loss: 0.9752 - accuracy: 0.5282 - val_loss: 0.9740 - val_accuracy: 0.5336\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9754 - accuracy: 0.5285 - val_loss: 0.9739 - val_accuracy: 0.5336\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9753 - accuracy: 0.5283 - val_loss: 0.9737 - val_accuracy: 0.5341\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9754 - accuracy: 0.5291 - val_loss: 0.9737 - val_accuracy: 0.5336\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9753 - accuracy: 0.5287 - val_loss: 0.9739 - val_accuracy: 0.5336\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9753 - accuracy: 0.5289 - val_loss: 0.9738 - val_accuracy: 0.5341\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9753 - accuracy: 0.5281 - val_loss: 0.9739 - val_accuracy: 0.5336\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9753 - accuracy: 0.5283 - val_loss: 0.9740 - val_accuracy: 0.5345\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9752 - accuracy: 0.5280 - val_loss: 0.9738 - val_accuracy: 0.5354\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9753 - accuracy: 0.5282 - val_loss: 0.9739 - val_accuracy: 0.5354\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9753 - accuracy: 0.5281 - val_loss: 0.9738 - val_accuracy: 0.5363\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9753 - accuracy: 0.5284 - val_loss: 0.9737 - val_accuracy: 0.5341\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9752 - accuracy: 0.5287 - val_loss: 0.9736 - val_accuracy: 0.5354\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9752 - accuracy: 0.5282 - val_loss: 0.9738 - val_accuracy: 0.5341\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 562us/step - loss: 0.9753 - accuracy: 0.5278 - val_loss: 0.9740 - val_accuracy: 0.5305\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 565us/step - loss: 0.9752 - accuracy: 0.5280 - val_loss: 0.9737 - val_accuracy: 0.5354\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9753 - accuracy: 0.5281 - val_loss: 0.9738 - val_accuracy: 0.5345\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9752 - accuracy: 0.5286 - val_loss: 0.9736 - val_accuracy: 0.5345\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 579us/step - loss: 0.9751 - accuracy: 0.5281 - val_loss: 0.9738 - val_accuracy: 0.5336\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 590us/step - loss: 0.9752 - accuracy: 0.5286 - val_loss: 0.9739 - val_accuracy: 0.5345\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 587us/step - loss: 0.9752 - accuracy: 0.5288 - val_loss: 0.9739 - val_accuracy: 0.5336\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9752 - accuracy: 0.5286 - val_loss: 0.9736 - val_accuracy: 0.5354\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9751 - accuracy: 0.5280 - val_loss: 0.9736 - val_accuracy: 0.5354\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9752 - accuracy: 0.5286 - val_loss: 0.9738 - val_accuracy: 0.5341\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9752 - accuracy: 0.5280 - val_loss: 0.9737 - val_accuracy: 0.5336\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 543us/step - loss: 0.9752 - accuracy: 0.5289 - val_loss: 0.9737 - val_accuracy: 0.5336\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9751 - accuracy: 0.5284 - val_loss: 0.9736 - val_accuracy: 0.5354\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9751 - accuracy: 0.5279 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9750 - accuracy: 0.5284 - val_loss: 0.9736 - val_accuracy: 0.5336\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9751 - accuracy: 0.5280 - val_loss: 0.9736 - val_accuracy: 0.5345\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9751 - accuracy: 0.5283 - val_loss: 0.9739 - val_accuracy: 0.5345\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9752 - accuracy: 0.5286 - val_loss: 0.9737 - val_accuracy: 0.5336\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9751 - accuracy: 0.5289 - val_loss: 0.9735 - val_accuracy: 0.5341\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 594us/step - loss: 0.9752 - accuracy: 0.5286 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 591us/step - loss: 0.9751 - accuracy: 0.5275 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 624us/step - loss: 0.9751 - accuracy: 0.5287 - val_loss: 0.9739 - val_accuracy: 0.5305\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 612us/step - loss: 0.9751 - accuracy: 0.5284 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 603us/step - loss: 0.9750 - accuracy: 0.5284 - val_loss: 0.9736 - val_accuracy: 0.5336\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 621us/step - loss: 0.9751 - accuracy: 0.5286 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 597us/step - loss: 0.9751 - accuracy: 0.5282 - val_loss: 0.9735 - val_accuracy: 0.5341\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 594us/step - loss: 0.9751 - accuracy: 0.5281 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9751 - accuracy: 0.5293 - val_loss: 0.9737 - val_accuracy: 0.5345\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9750 - accuracy: 0.5289 - val_loss: 0.9738 - val_accuracy: 0.5345\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9749 - accuracy: 0.5285 - val_loss: 0.9741 - val_accuracy: 0.5345\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9750 - accuracy: 0.5285 - val_loss: 0.9737 - val_accuracy: 0.5336\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 563us/step - loss: 0.9751 - accuracy: 0.5288 - val_loss: 0.9734 - val_accuracy: 0.5354\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 564us/step - loss: 0.9750 - accuracy: 0.5283 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 171/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9750 - accuracy: 0.5282 - val_loss: 0.9733 - val_accuracy: 0.5354\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 544us/step - loss: 0.9750 - accuracy: 0.5285 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9750 - accuracy: 0.5286 - val_loss: 0.9736 - val_accuracy: 0.5336\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 567us/step - loss: 0.9750 - accuracy: 0.5285 - val_loss: 0.9737 - val_accuracy: 0.5336\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 559us/step - loss: 0.9750 - accuracy: 0.5281 - val_loss: 0.9734 - val_accuracy: 0.5354\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9750 - accuracy: 0.5275 - val_loss: 0.9734 - val_accuracy: 0.5354\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9750 - accuracy: 0.5287 - val_loss: 0.9737 - val_accuracy: 0.5336\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9750 - accuracy: 0.5283 - val_loss: 0.9734 - val_accuracy: 0.5341\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9750 - accuracy: 0.5287 - val_loss: 0.9735 - val_accuracy: 0.5336\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 561us/step - loss: 0.9750 - accuracy: 0.5282 - val_loss: 0.9736 - val_accuracy: 0.5345\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9750 - accuracy: 0.5287 - val_loss: 0.9733 - val_accuracy: 0.5354\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9750 - accuracy: 0.5285 - val_loss: 0.9732 - val_accuracy: 0.5354\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 563us/step - loss: 0.9750 - accuracy: 0.5284 - val_loss: 0.9736 - val_accuracy: 0.5345\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 569us/step - loss: 0.9750 - accuracy: 0.5284 - val_loss: 0.9734 - val_accuracy: 0.5354\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9749 - accuracy: 0.5294 - val_loss: 0.9734 - val_accuracy: 0.5354\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9750 - accuracy: 0.5289 - val_loss: 0.9734 - val_accuracy: 0.5354\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9750 - accuracy: 0.5285 - val_loss: 0.9734 - val_accuracy: 0.5341\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 566us/step - loss: 0.9750 - accuracy: 0.5283 - val_loss: 0.9733 - val_accuracy: 0.5354\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 560us/step - loss: 0.9749 - accuracy: 0.5288 - val_loss: 0.9732 - val_accuracy: 0.5354\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9749 - accuracy: 0.5283 - val_loss: 0.9734 - val_accuracy: 0.5354\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 565us/step - loss: 0.9750 - accuracy: 0.5287 - val_loss: 0.9733 - val_accuracy: 0.5354\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5282 - val_loss: 0.9732 - val_accuracy: 0.5354\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 580us/step - loss: 0.9750 - accuracy: 0.5287 - val_loss: 0.9733 - val_accuracy: 0.5350\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 568us/step - loss: 0.9749 - accuracy: 0.5284 - val_loss: 0.9733 - val_accuracy: 0.5341\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 565us/step - loss: 0.9749 - accuracy: 0.5282 - val_loss: 0.9733 - val_accuracy: 0.5354\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9749 - accuracy: 0.5284 - val_loss: 0.9734 - val_accuracy: 0.5341\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9749 - accuracy: 0.5279 - val_loss: 0.9734 - val_accuracy: 0.5354\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9748 - accuracy: 0.5283 - val_loss: 0.9733 - val_accuracy: 0.5354\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 554us/step - loss: 0.9749 - accuracy: 0.5285 - val_loss: 0.9734 - val_accuracy: 0.5354\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9749 - accuracy: 0.5283 - val_loss: 0.9732 - val_accuracy: 0.5354\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 343us/step - loss: 0.9747 - accuracy: 0.5288\n",
      "Accuracy : 0.528821587562561\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9732 - accuracy: 0.5354\n",
      "Accuracy : 0.5353982448577881\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.1008 - accuracy: 0.4461 - val_loss: 1.0815 - val_accuracy: 0.4254\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 750us/step - loss: 1.0592 - accuracy: 0.4837 - val_loss: 1.0543 - val_accuracy: 0.4785\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0281 - accuracy: 0.5163 - val_loss: 1.0336 - val_accuracy: 0.5148\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0057 - accuracy: 0.5244 - val_loss: 1.0205 - val_accuracy: 0.5197\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9909 - accuracy: 0.5244 - val_loss: 1.0121 - val_accuracy: 0.5210\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9826 - accuracy: 0.5307 - val_loss: 1.0081 - val_accuracy: 0.5193\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9784 - accuracy: 0.5290 - val_loss: 1.0056 - val_accuracy: 0.5201\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5313 - val_loss: 1.0051 - val_accuracy: 0.5224\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9755 - accuracy: 0.5324 - val_loss: 1.0046 - val_accuracy: 0.5259\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9750 - accuracy: 0.5312 - val_loss: 1.0046 - val_accuracy: 0.5263\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9747 - accuracy: 0.5315 - val_loss: 1.0042 - val_accuracy: 0.5219\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9746 - accuracy: 0.5311 - val_loss: 1.0039 - val_accuracy: 0.5237\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9744 - accuracy: 0.5308 - val_loss: 1.0043 - val_accuracy: 0.5224\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9743 - accuracy: 0.5304 - val_loss: 1.0047 - val_accuracy: 0.5219\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9743 - accuracy: 0.5302 - val_loss: 1.0039 - val_accuracy: 0.5241\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9738 - accuracy: 0.5294 - val_loss: 1.0040 - val_accuracy: 0.5219\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 1.0042 - val_accuracy: 0.5241\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9737 - accuracy: 0.5302 - val_loss: 1.0041 - val_accuracy: 0.5219\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9737 - accuracy: 0.5298 - val_loss: 1.0036 - val_accuracy: 0.5224\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9736 - accuracy: 0.5295 - val_loss: 1.0037 - val_accuracy: 0.5228\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9737 - accuracy: 0.5302 - val_loss: 1.0038 - val_accuracy: 0.5224\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9734 - accuracy: 0.5304 - val_loss: 1.0041 - val_accuracy: 0.5241\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9733 - accuracy: 0.5296 - val_loss: 1.0034 - val_accuracy: 0.5259\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9732 - accuracy: 0.5293 - val_loss: 1.0035 - val_accuracy: 0.5224\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9730 - accuracy: 0.5304 - val_loss: 1.0040 - val_accuracy: 0.5228\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 1.0035 - val_accuracy: 0.5224\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9736 - accuracy: 0.5310 - val_loss: 1.0040 - val_accuracy: 0.5237\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9729 - accuracy: 0.5291 - val_loss: 1.0043 - val_accuracy: 0.5228\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9731 - accuracy: 0.5299 - val_loss: 1.0033 - val_accuracy: 0.5215\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9728 - accuracy: 0.5303 - val_loss: 1.0032 - val_accuracy: 0.5241\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9731 - accuracy: 0.5304 - val_loss: 1.0039 - val_accuracy: 0.5219\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9727 - accuracy: 0.5304 - val_loss: 1.0038 - val_accuracy: 0.5219\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 1.0031 - val_accuracy: 0.5237\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9727 - accuracy: 0.5310 - val_loss: 1.0037 - val_accuracy: 0.5219\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9727 - accuracy: 0.5308 - val_loss: 1.0033 - val_accuracy: 0.5237\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9727 - accuracy: 0.5302 - val_loss: 1.0030 - val_accuracy: 0.5232\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9726 - accuracy: 0.5300 - val_loss: 1.0031 - val_accuracy: 0.5232\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9726 - accuracy: 0.5305 - val_loss: 1.0040 - val_accuracy: 0.5219\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9734 - accuracy: 0.5305 - val_loss: 1.0031 - val_accuracy: 0.5232\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9725 - accuracy: 0.5302 - val_loss: 1.0034 - val_accuracy: 0.5210\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9725 - accuracy: 0.5299 - val_loss: 1.0031 - val_accuracy: 0.5232\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 426us/step - loss: 0.9725 - accuracy: 0.5298 - val_loss: 1.0032 - val_accuracy: 0.5232\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9725 - accuracy: 0.5297 - val_loss: 1.0033 - val_accuracy: 0.5215\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9725 - accuracy: 0.5301 - val_loss: 1.0035 - val_accuracy: 0.5228\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9725 - accuracy: 0.5287 - val_loss: 1.0039 - val_accuracy: 0.5228\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9726 - accuracy: 0.5293 - val_loss: 1.0033 - val_accuracy: 0.5232\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9725 - accuracy: 0.5296 - val_loss: 1.0035 - val_accuracy: 0.5228\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 562us/step - loss: 0.9723 - accuracy: 0.5293 - val_loss: 1.0038 - val_accuracy: 0.5210\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9724 - accuracy: 0.5301 - val_loss: 1.0034 - val_accuracy: 0.5232\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 613us/step - loss: 0.9722 - accuracy: 0.5298 - val_loss: 1.0034 - val_accuracy: 0.5237\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9723 - accuracy: 0.5286 - val_loss: 1.0035 - val_accuracy: 0.5228\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9722 - accuracy: 0.5299 - val_loss: 1.0031 - val_accuracy: 0.5232\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 513us/step - loss: 0.9723 - accuracy: 0.5290 - val_loss: 1.0028 - val_accuracy: 0.5232\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9725 - accuracy: 0.5302 - val_loss: 1.0032 - val_accuracy: 0.5232\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9722 - accuracy: 0.5295 - val_loss: 1.0034 - val_accuracy: 0.5232\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9722 - accuracy: 0.5297 - val_loss: 1.0035 - val_accuracy: 0.5224\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 531us/step - loss: 0.9722 - accuracy: 0.5303 - val_loss: 1.0028 - val_accuracy: 0.5228\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 548us/step - loss: 0.9723 - accuracy: 0.5309 - val_loss: 1.0030 - val_accuracy: 0.5228\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 758us/step - loss: 0.9726 - accuracy: 0.5295 - val_loss: 1.0038 - val_accuracy: 0.5237\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9724 - accuracy: 0.5297 - val_loss: 1.0035 - val_accuracy: 0.5232\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9722 - accuracy: 0.5282 - val_loss: 1.0033 - val_accuracy: 0.5232\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9721 - accuracy: 0.5302 - val_loss: 1.0029 - val_accuracy: 0.5246\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9723 - accuracy: 0.5298 - val_loss: 1.0032 - val_accuracy: 0.5246\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9723 - accuracy: 0.5287 - val_loss: 1.0034 - val_accuracy: 0.5210\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9723 - accuracy: 0.5281 - val_loss: 1.0029 - val_accuracy: 0.5237\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9722 - accuracy: 0.5301 - val_loss: 1.0026 - val_accuracy: 0.5228\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9723 - accuracy: 0.5313 - val_loss: 1.0031 - val_accuracy: 0.5237\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9721 - accuracy: 0.5288 - val_loss: 1.0035 - val_accuracy: 0.5246\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9722 - accuracy: 0.5292 - val_loss: 1.0037 - val_accuracy: 0.5237\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9728 - accuracy: 0.5295 - val_loss: 1.0037 - val_accuracy: 0.5237\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9727 - accuracy: 0.5295 - val_loss: 1.0032 - val_accuracy: 0.5237\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9721 - accuracy: 0.5291 - val_loss: 1.0031 - val_accuracy: 0.5277\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9722 - accuracy: 0.5299 - val_loss: 1.0029 - val_accuracy: 0.5237\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9725 - accuracy: 0.5291 - val_loss: 1.0034 - val_accuracy: 0.5210\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9721 - accuracy: 0.5290 - val_loss: 1.0030 - val_accuracy: 0.5232\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9721 - accuracy: 0.5288 - val_loss: 1.0030 - val_accuracy: 0.5237\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9723 - accuracy: 0.5301 - val_loss: 1.0034 - val_accuracy: 0.5237\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9721 - accuracy: 0.5299 - val_loss: 1.0033 - val_accuracy: 0.5237\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9720 - accuracy: 0.5298 - val_loss: 1.0025 - val_accuracy: 0.5228\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9723 - accuracy: 0.5291 - val_loss: 1.0027 - val_accuracy: 0.5237\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9721 - accuracy: 0.5302 - val_loss: 1.0026 - val_accuracy: 0.5250\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9722 - accuracy: 0.5298 - val_loss: 1.0029 - val_accuracy: 0.5241\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9722 - accuracy: 0.5297 - val_loss: 1.0027 - val_accuracy: 0.5246\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9721 - accuracy: 0.5290 - val_loss: 1.0030 - val_accuracy: 0.5277\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9726 - accuracy: 0.5313 - val_loss: 1.0036 - val_accuracy: 0.5237\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9723 - accuracy: 0.5300 - val_loss: 1.0033 - val_accuracy: 0.5237\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9721 - accuracy: 0.5296 - val_loss: 1.0033 - val_accuracy: 0.5241\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9720 - accuracy: 0.5299 - val_loss: 1.0029 - val_accuracy: 0.5237\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9725 - accuracy: 0.5324 - val_loss: 1.0030 - val_accuracy: 0.5219\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9721 - accuracy: 0.5289 - val_loss: 1.0034 - val_accuracy: 0.5232\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9721 - accuracy: 0.5294 - val_loss: 1.0028 - val_accuracy: 0.5224\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9720 - accuracy: 0.5294 - val_loss: 1.0028 - val_accuracy: 0.5228\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9719 - accuracy: 0.5300 - val_loss: 1.0032 - val_accuracy: 0.5237\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9728 - accuracy: 0.5301 - val_loss: 1.0023 - val_accuracy: 0.5241\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9722 - accuracy: 0.5305 - val_loss: 1.0028 - val_accuracy: 0.5241\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9720 - accuracy: 0.5296 - val_loss: 1.0024 - val_accuracy: 0.5241\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9719 - accuracy: 0.5298 - val_loss: 1.0030 - val_accuracy: 0.5215\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9722 - accuracy: 0.5284 - val_loss: 1.0034 - val_accuracy: 0.5237\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9722 - accuracy: 0.5297 - val_loss: 1.0032 - val_accuracy: 0.5241\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9720 - accuracy: 0.5302 - val_loss: 1.0036 - val_accuracy: 0.5219\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9721 - accuracy: 0.5293 - val_loss: 1.0029 - val_accuracy: 0.5219\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9720 - accuracy: 0.5286 - val_loss: 1.0031 - val_accuracy: 0.5241\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9719 - accuracy: 0.5286 - val_loss: 1.0030 - val_accuracy: 0.5241\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9718 - accuracy: 0.5299 - val_loss: 1.0029 - val_accuracy: 0.5219\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9720 - accuracy: 0.5302 - val_loss: 1.0030 - val_accuracy: 0.5237\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9719 - accuracy: 0.5290 - val_loss: 1.0030 - val_accuracy: 0.5241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9721 - accuracy: 0.5308 - val_loss: 1.0031 - val_accuracy: 0.5232\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9719 - accuracy: 0.5298 - val_loss: 1.0031 - val_accuracy: 0.5246\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9728 - accuracy: 0.5293 - val_loss: 1.0028 - val_accuracy: 0.5219\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9721 - accuracy: 0.5291 - val_loss: 1.0027 - val_accuracy: 0.5237\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9721 - accuracy: 0.5296 - val_loss: 1.0037 - val_accuracy: 0.5232\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9725 - accuracy: 0.5291 - val_loss: 1.0035 - val_accuracy: 0.5232\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9721 - accuracy: 0.5287 - val_loss: 1.0033 - val_accuracy: 0.5277\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9722 - accuracy: 0.5299 - val_loss: 1.0032 - val_accuracy: 0.5219\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9720 - accuracy: 0.5278 - val_loss: 1.0027 - val_accuracy: 0.5232\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9719 - accuracy: 0.5297 - val_loss: 1.0024 - val_accuracy: 0.5250\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9720 - accuracy: 0.5312 - val_loss: 1.0034 - val_accuracy: 0.5241\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9720 - accuracy: 0.5296 - val_loss: 1.0028 - val_accuracy: 0.5219\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9719 - accuracy: 0.5285 - val_loss: 1.0031 - val_accuracy: 0.5232\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9723 - accuracy: 0.5304 - val_loss: 1.0025 - val_accuracy: 0.5224\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9720 - accuracy: 0.5300 - val_loss: 1.0028 - val_accuracy: 0.5241\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9719 - accuracy: 0.5293 - val_loss: 1.0028 - val_accuracy: 0.5241\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9721 - accuracy: 0.5292 - val_loss: 1.0027 - val_accuracy: 0.5241\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9721 - accuracy: 0.5303 - val_loss: 1.0029 - val_accuracy: 0.5246\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9719 - accuracy: 0.5299 - val_loss: 1.0033 - val_accuracy: 0.5241\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9721 - accuracy: 0.5299 - val_loss: 1.0026 - val_accuracy: 0.5241\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9718 - accuracy: 0.5292 - val_loss: 1.0029 - val_accuracy: 0.5237\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9722 - accuracy: 0.5299 - val_loss: 1.0024 - val_accuracy: 0.5224\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9720 - accuracy: 0.5311 - val_loss: 1.0022 - val_accuracy: 0.5241\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9722 - accuracy: 0.5300 - val_loss: 1.0028 - val_accuracy: 0.5232\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9717 - accuracy: 0.5301 - val_loss: 1.0029 - val_accuracy: 0.5219\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9720 - accuracy: 0.5288 - val_loss: 1.0026 - val_accuracy: 0.5237\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9719 - accuracy: 0.5293 - val_loss: 1.0026 - val_accuracy: 0.5241\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9719 - accuracy: 0.5299 - val_loss: 1.0031 - val_accuracy: 0.5232\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9717 - accuracy: 0.5302 - val_loss: 1.0024 - val_accuracy: 0.5237\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9717 - accuracy: 0.5299 - val_loss: 1.0031 - val_accuracy: 0.5232\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9718 - accuracy: 0.5293 - val_loss: 1.0027 - val_accuracy: 0.5232\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9722 - accuracy: 0.5298 - val_loss: 1.0030 - val_accuracy: 0.5232\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9719 - accuracy: 0.5282 - val_loss: 1.0025 - val_accuracy: 0.5250\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9719 - accuracy: 0.5293 - val_loss: 1.0030 - val_accuracy: 0.5232\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9720 - accuracy: 0.5297 - val_loss: 1.0028 - val_accuracy: 0.5246\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9722 - accuracy: 0.5300 - val_loss: 1.0032 - val_accuracy: 0.5246\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9719 - accuracy: 0.5297 - val_loss: 1.0022 - val_accuracy: 0.5250\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9719 - accuracy: 0.5298 - val_loss: 1.0026 - val_accuracy: 0.5219\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9719 - accuracy: 0.5301 - val_loss: 1.0024 - val_accuracy: 0.5232\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9719 - accuracy: 0.5295 - val_loss: 1.0027 - val_accuracy: 0.5241\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9718 - accuracy: 0.5286 - val_loss: 1.0027 - val_accuracy: 0.5237\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9719 - accuracy: 0.5298 - val_loss: 1.0028 - val_accuracy: 0.5246\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9720 - accuracy: 0.5309 - val_loss: 1.0026 - val_accuracy: 0.5219\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9718 - accuracy: 0.5291 - val_loss: 1.0032 - val_accuracy: 0.5241\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9718 - accuracy: 0.5292 - val_loss: 1.0022 - val_accuracy: 0.5237\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9720 - accuracy: 0.5299 - val_loss: 1.0023 - val_accuracy: 0.5228\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9720 - accuracy: 0.5293 - val_loss: 1.0028 - val_accuracy: 0.5241\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9718 - accuracy: 0.5301 - val_loss: 1.0022 - val_accuracy: 0.5241\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9720 - accuracy: 0.5294 - val_loss: 1.0023 - val_accuracy: 0.5237\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9718 - accuracy: 0.5305 - val_loss: 1.0024 - val_accuracy: 0.5241\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9720 - accuracy: 0.5298 - val_loss: 1.0024 - val_accuracy: 0.5228\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9718 - accuracy: 0.5307 - val_loss: 1.0031 - val_accuracy: 0.5219\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9722 - accuracy: 0.5286 - val_loss: 1.0030 - val_accuracy: 0.5246\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9718 - accuracy: 0.5295 - val_loss: 1.0025 - val_accuracy: 0.5237\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 664us/step - loss: 0.9719 - accuracy: 0.5303 - val_loss: 1.0032 - val_accuracy: 0.5219\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9719 - accuracy: 0.5294 - val_loss: 1.0027 - val_accuracy: 0.5219\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 664us/step - loss: 0.9721 - accuracy: 0.5279 - val_loss: 1.0029 - val_accuracy: 0.5232\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9718 - accuracy: 0.5301 - val_loss: 1.0024 - val_accuracy: 0.5250\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9718 - accuracy: 0.5295 - val_loss: 1.0028 - val_accuracy: 0.5246\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9718 - accuracy: 0.5306 - val_loss: 1.0030 - val_accuracy: 0.5232\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9721 - accuracy: 0.5297 - val_loss: 1.0024 - val_accuracy: 0.5224\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9720 - accuracy: 0.5314 - val_loss: 1.0024 - val_accuracy: 0.5237\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9718 - accuracy: 0.5295 - val_loss: 1.0028 - val_accuracy: 0.5232\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9717 - accuracy: 0.5297 - val_loss: 1.0025 - val_accuracy: 0.5237\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9718 - accuracy: 0.5293 - val_loss: 1.0025 - val_accuracy: 0.5232\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9718 - accuracy: 0.5289 - val_loss: 1.0023 - val_accuracy: 0.5237\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9718 - accuracy: 0.5305 - val_loss: 1.0025 - val_accuracy: 0.5237\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9717 - accuracy: 0.5293 - val_loss: 1.0030 - val_accuracy: 0.5246\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9718 - accuracy: 0.5289 - val_loss: 1.0022 - val_accuracy: 0.5224\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9719 - accuracy: 0.5308 - val_loss: 1.0029 - val_accuracy: 0.5224\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9718 - accuracy: 0.5308 - val_loss: 1.0023 - val_accuracy: 0.5219\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9719 - accuracy: 0.5281 - val_loss: 1.0026 - val_accuracy: 0.5232\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9719 - accuracy: 0.5296 - val_loss: 1.0024 - val_accuracy: 0.5250\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 673us/step - loss: 0.9719 - accuracy: 0.5295 - val_loss: 1.0023 - val_accuracy: 0.5237\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9718 - accuracy: 0.5313 - val_loss: 1.0028 - val_accuracy: 0.5219\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9718 - accuracy: 0.5295 - val_loss: 1.0019 - val_accuracy: 0.5228\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9719 - accuracy: 0.5298 - val_loss: 1.0026 - val_accuracy: 0.5219\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9718 - accuracy: 0.5297 - val_loss: 1.0026 - val_accuracy: 0.5224\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9722 - accuracy: 0.5308 - val_loss: 1.0025 - val_accuracy: 0.5215\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9719 - accuracy: 0.5297 - val_loss: 1.0025 - val_accuracy: 0.5237\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9719 - accuracy: 0.5289 - val_loss: 1.0026 - val_accuracy: 0.5237\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9720 - accuracy: 0.5307 - val_loss: 1.0025 - val_accuracy: 0.5232\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9718 - accuracy: 0.5296 - val_loss: 1.0029 - val_accuracy: 0.5237\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9716 - accuracy: 0.5300 - val_loss: 1.0021 - val_accuracy: 0.5232\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9719 - accuracy: 0.5295 - val_loss: 1.0022 - val_accuracy: 0.5241\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9716 - accuracy: 0.5300 - val_loss: 1.0032 - val_accuracy: 0.5241\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9716 - accuracy: 0.5299 - val_loss: 1.0023 - val_accuracy: 0.5241\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9718 - accuracy: 0.5292 - val_loss: 1.0026 - val_accuracy: 0.5241\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 672us/step - loss: 0.9717 - accuracy: 0.5305 - val_loss: 1.0024 - val_accuracy: 0.5232\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 561us/step - loss: 0.9719 - accuracy: 0.5305 - val_loss: 1.0024 - val_accuracy: 0.5241\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9716 - accuracy: 0.5288 - val_loss: 1.0022 - val_accuracy: 0.5232\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9717 - accuracy: 0.5295 - val_loss: 1.0018 - val_accuracy: 0.5237\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9720 - accuracy: 0.5312 - val_loss: 1.0022 - val_accuracy: 0.5237\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9718 - accuracy: 0.5298 - val_loss: 1.0022 - val_accuracy: 0.5250\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 343us/step - loss: 0.9715 - accuracy: 0.5294\n",
      "Accuracy : 0.5294349193572998\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0022 - accuracy: 0.5250\n",
      "Accuracy : 0.5250110626220703\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.2412 - accuracy: 0.2534 - val_loss: 1.1681 - val_accuracy: 0.2815\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 759us/step - loss: 1.1552 - accuracy: 0.2805 - val_loss: 1.1317 - val_accuracy: 0.2873\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 1.1216 - accuracy: 0.2862 - val_loss: 1.1132 - val_accuracy: 0.2877\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 1.1030 - accuracy: 0.2884 - val_loss: 1.1025 - val_accuracy: 0.2877\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 1.0924 - accuracy: 0.2891 - val_loss: 1.0965 - val_accuracy: 0.2877\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 1.0858 - accuracy: 0.2901 - val_loss: 1.0925 - val_accuracy: 0.2877\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 1.0821 - accuracy: 0.2914 - val_loss: 1.0901 - val_accuracy: 0.2877\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 658us/step - loss: 1.0794 - accuracy: 0.2925 - val_loss: 1.0882 - val_accuracy: 0.2877\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 1.0778 - accuracy: 0.2926 - val_loss: 1.0871 - val_accuracy: 0.2877\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 1.0768 - accuracy: 0.2928 - val_loss: 1.0863 - val_accuracy: 0.2873\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 1.0760 - accuracy: 0.2951 - val_loss: 1.0856 - val_accuracy: 0.2886\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 1.0754 - accuracy: 0.3018 - val_loss: 1.0851 - val_accuracy: 0.3023\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 1.0749 - accuracy: 0.3110 - val_loss: 1.0846 - val_accuracy: 0.3077\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 738us/step - loss: 1.0744 - accuracy: 0.3353 - val_loss: 1.0840 - val_accuracy: 0.3121\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0748 - accuracy: 0.3809 - val_loss: 1.0836 - val_accuracy: 0.3603\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0742 - accuracy: 0.3807 - val_loss: 1.0835 - val_accuracy: 0.3506\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 1.0739 - accuracy: 0.3737 - val_loss: 1.0835 - val_accuracy: 0.3488\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 595us/step - loss: 1.0736 - accuracy: 0.3819 - val_loss: 1.0833 - val_accuracy: 0.3621\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 1.0735 - accuracy: 0.3847 - val_loss: 1.0831 - val_accuracy: 0.3763\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 1.0733 - accuracy: 0.3971 - val_loss: 1.0828 - val_accuracy: 0.3927\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 1.0731 - accuracy: 0.4089 - val_loss: 1.0825 - val_accuracy: 0.3935\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0728 - accuracy: 0.4190 - val_loss: 1.0821 - val_accuracy: 0.4019\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 1.0726 - accuracy: 0.4321 - val_loss: 1.0818 - val_accuracy: 0.4161\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 1.0724 - accuracy: 0.4362 - val_loss: 1.0815 - val_accuracy: 0.4228\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 1.0722 - accuracy: 0.4630 - val_loss: 1.0810 - val_accuracy: 0.4396\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 1.0719 - accuracy: 0.4656 - val_loss: 1.0807 - val_accuracy: 0.4467\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0716 - accuracy: 0.4796 - val_loss: 1.0803 - val_accuracy: 0.4617\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0712 - accuracy: 0.5017 - val_loss: 1.0796 - val_accuracy: 0.4790\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0707 - accuracy: 0.5045 - val_loss: 1.0790 - val_accuracy: 0.4830\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0702 - accuracy: 0.5052 - val_loss: 1.0784 - val_accuracy: 0.4878\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.0695 - accuracy: 0.5206 - val_loss: 1.0772 - val_accuracy: 0.4993\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 1.0682 - accuracy: 0.5267 - val_loss: 1.0754 - val_accuracy: 0.5122\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 1.0663 - accuracy: 0.5293 - val_loss: 1.0726 - val_accuracy: 0.5064\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 1.0614 - accuracy: 0.5294 - val_loss: 1.0653 - val_accuracy: 0.5077\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 1.0494 - accuracy: 0.5250 - val_loss: 1.0479 - val_accuracy: 0.4940\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 658us/step - loss: 1.0252 - accuracy: 0.5177 - val_loss: 1.0340 - val_accuracy: 0.4949\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 1.0132 - accuracy: 0.5231 - val_loss: 1.0274 - val_accuracy: 0.5033\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 1.0060 - accuracy: 0.5253 - val_loss: 1.0212 - val_accuracy: 0.5042\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9971 - accuracy: 0.5258 - val_loss: 1.0148 - val_accuracy: 0.5077\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 744us/step - loss: 0.9880 - accuracy: 0.5282 - val_loss: 1.0107 - val_accuracy: 0.5148\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9845 - accuracy: 0.5318 - val_loss: 1.0092 - val_accuracy: 0.5126\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9825 - accuracy: 0.5318 - val_loss: 1.0088 - val_accuracy: 0.5122\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9815 - accuracy: 0.5324 - val_loss: 1.0081 - val_accuracy: 0.5126\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9805 - accuracy: 0.5322 - val_loss: 1.0076 - val_accuracy: 0.5122\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9797 - accuracy: 0.5322 - val_loss: 1.0072 - val_accuracy: 0.5122\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9790 - accuracy: 0.5312 - val_loss: 1.0066 - val_accuracy: 0.5122\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9786 - accuracy: 0.5319 - val_loss: 1.0062 - val_accuracy: 0.5122\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9778 - accuracy: 0.5313 - val_loss: 1.0057 - val_accuracy: 0.5069\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9775 - accuracy: 0.5310 - val_loss: 1.0055 - val_accuracy: 0.5113\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9769 - accuracy: 0.5310 - val_loss: 1.0053 - val_accuracy: 0.5064\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9767 - accuracy: 0.5312 - val_loss: 1.0051 - val_accuracy: 0.5064\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9765 - accuracy: 0.5312 - val_loss: 1.0051 - val_accuracy: 0.5126\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9765 - accuracy: 0.5320 - val_loss: 1.0048 - val_accuracy: 0.5113\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9763 - accuracy: 0.5314 - val_loss: 1.0046 - val_accuracy: 0.5060\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9767 - accuracy: 0.5298 - val_loss: 1.0044 - val_accuracy: 0.5060\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9762 - accuracy: 0.5305 - val_loss: 1.0045 - val_accuracy: 0.5126\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9759 - accuracy: 0.5315 - val_loss: 1.0046 - val_accuracy: 0.5064\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9756 - accuracy: 0.5311 - val_loss: 1.0044 - val_accuracy: 0.5060\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9758 - accuracy: 0.5310 - val_loss: 1.0046 - val_accuracy: 0.5126\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9758 - accuracy: 0.5312 - val_loss: 1.0046 - val_accuracy: 0.5126\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9755 - accuracy: 0.5310 - val_loss: 1.0046 - val_accuracy: 0.5126\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9754 - accuracy: 0.5313 - val_loss: 1.0045 - val_accuracy: 0.5064\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9754 - accuracy: 0.5314 - val_loss: 1.0044 - val_accuracy: 0.5100\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9755 - accuracy: 0.5315 - val_loss: 1.0043 - val_accuracy: 0.5064\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9754 - accuracy: 0.5303 - val_loss: 1.0044 - val_accuracy: 0.5126\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9755 - accuracy: 0.5306 - val_loss: 1.0043 - val_accuracy: 0.5060\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9752 - accuracy: 0.5310 - val_loss: 1.0046 - val_accuracy: 0.5126\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9754 - accuracy: 0.5314 - val_loss: 1.0044 - val_accuracy: 0.5126\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9750 - accuracy: 0.5308 - val_loss: 1.0043 - val_accuracy: 0.5064\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9753 - accuracy: 0.5313 - val_loss: 1.0043 - val_accuracy: 0.5060\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9750 - accuracy: 0.5317 - val_loss: 1.0044 - val_accuracy: 0.5126\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9750 - accuracy: 0.5314 - val_loss: 1.0043 - val_accuracy: 0.5064\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9749 - accuracy: 0.5316 - val_loss: 1.0043 - val_accuracy: 0.5113\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9750 - accuracy: 0.5316 - val_loss: 1.0045 - val_accuracy: 0.5126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9753 - accuracy: 0.5313 - val_loss: 1.0041 - val_accuracy: 0.5064\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9749 - accuracy: 0.5315 - val_loss: 1.0041 - val_accuracy: 0.5060\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9750 - accuracy: 0.5306 - val_loss: 1.0042 - val_accuracy: 0.5126\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9748 - accuracy: 0.5313 - val_loss: 1.0042 - val_accuracy: 0.5069\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9748 - accuracy: 0.5305 - val_loss: 1.0042 - val_accuracy: 0.5126\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9748 - accuracy: 0.5310 - val_loss: 1.0043 - val_accuracy: 0.5126\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9748 - accuracy: 0.5313 - val_loss: 1.0042 - val_accuracy: 0.5122\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9749 - accuracy: 0.5310 - val_loss: 1.0041 - val_accuracy: 0.5126\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9747 - accuracy: 0.5313 - val_loss: 1.0043 - val_accuracy: 0.5060\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 1.0041 - val_accuracy: 0.5064\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9752 - accuracy: 0.5324 - val_loss: 1.0041 - val_accuracy: 0.5126\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9748 - accuracy: 0.5314 - val_loss: 1.0039 - val_accuracy: 0.5122\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9750 - accuracy: 0.5309 - val_loss: 1.0041 - val_accuracy: 0.5064\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9749 - accuracy: 0.5318 - val_loss: 1.0041 - val_accuracy: 0.5126\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9747 - accuracy: 0.5305 - val_loss: 1.0041 - val_accuracy: 0.5064\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9747 - accuracy: 0.5315 - val_loss: 1.0041 - val_accuracy: 0.5122\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9747 - accuracy: 0.5313 - val_loss: 1.0041 - val_accuracy: 0.5108\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9748 - accuracy: 0.5316 - val_loss: 1.0042 - val_accuracy: 0.5122\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9747 - accuracy: 0.5309 - val_loss: 1.0041 - val_accuracy: 0.5122\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9745 - accuracy: 0.5320 - val_loss: 1.0041 - val_accuracy: 0.5113\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9745 - accuracy: 0.5303 - val_loss: 1.0044 - val_accuracy: 0.5117\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9763 - accuracy: 0.5312 - val_loss: 1.0043 - val_accuracy: 0.5122\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9746 - accuracy: 0.5312 - val_loss: 1.0041 - val_accuracy: 0.5113\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9747 - accuracy: 0.5317 - val_loss: 1.0040 - val_accuracy: 0.5122\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9746 - accuracy: 0.5306 - val_loss: 1.0042 - val_accuracy: 0.5131\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9746 - accuracy: 0.5323 - val_loss: 1.0039 - val_accuracy: 0.5069\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9746 - accuracy: 0.5313 - val_loss: 1.0039 - val_accuracy: 0.5069\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 1.0039 - val_accuracy: 0.5069\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9747 - accuracy: 0.5305 - val_loss: 1.0042 - val_accuracy: 0.5117\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9752 - accuracy: 0.5317 - val_loss: 1.0041 - val_accuracy: 0.5122\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9747 - accuracy: 0.5305 - val_loss: 1.0040 - val_accuracy: 0.5122\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9745 - accuracy: 0.5318 - val_loss: 1.0041 - val_accuracy: 0.5131\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9745 - accuracy: 0.5320 - val_loss: 1.0039 - val_accuracy: 0.5122\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9744 - accuracy: 0.5316 - val_loss: 1.0040 - val_accuracy: 0.5117\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9744 - accuracy: 0.5318 - val_loss: 1.0039 - val_accuracy: 0.5108\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9743 - accuracy: 0.5308 - val_loss: 1.0039 - val_accuracy: 0.5108\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9745 - accuracy: 0.5309 - val_loss: 1.0038 - val_accuracy: 0.5113\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9748 - accuracy: 0.5315 - val_loss: 1.0039 - val_accuracy: 0.5108\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9744 - accuracy: 0.5321 - val_loss: 1.0038 - val_accuracy: 0.5122\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9743 - accuracy: 0.5317 - val_loss: 1.0039 - val_accuracy: 0.5122\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9743 - accuracy: 0.5315 - val_loss: 1.0039 - val_accuracy: 0.5108\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9743 - accuracy: 0.5312 - val_loss: 1.0039 - val_accuracy: 0.5122\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9742 - accuracy: 0.5316 - val_loss: 1.0043 - val_accuracy: 0.5122\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9744 - accuracy: 0.5324 - val_loss: 1.0041 - val_accuracy: 0.5122\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9744 - accuracy: 0.5317 - val_loss: 1.0039 - val_accuracy: 0.5122\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9744 - accuracy: 0.5315 - val_loss: 1.0040 - val_accuracy: 0.5131\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9747 - accuracy: 0.5314 - val_loss: 1.0039 - val_accuracy: 0.5131\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9742 - accuracy: 0.5315 - val_loss: 1.0038 - val_accuracy: 0.5126\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9744 - accuracy: 0.5317 - val_loss: 1.0038 - val_accuracy: 0.5122\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9742 - accuracy: 0.5313 - val_loss: 1.0037 - val_accuracy: 0.5064\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9743 - accuracy: 0.5314 - val_loss: 1.0039 - val_accuracy: 0.5131\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9744 - accuracy: 0.5309 - val_loss: 1.0038 - val_accuracy: 0.5126\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9751 - accuracy: 0.5278 - val_loss: 1.0038 - val_accuracy: 0.5131\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9742 - accuracy: 0.5318 - val_loss: 1.0038 - val_accuracy: 0.5131\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9745 - accuracy: 0.5307 - val_loss: 1.0037 - val_accuracy: 0.5126\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9742 - accuracy: 0.5321 - val_loss: 1.0037 - val_accuracy: 0.5108\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9742 - accuracy: 0.5310 - val_loss: 1.0037 - val_accuracy: 0.5108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9742 - accuracy: 0.5315 - val_loss: 1.0037 - val_accuracy: 0.5122\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9741 - accuracy: 0.5323 - val_loss: 1.0037 - val_accuracy: 0.5064\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9743 - accuracy: 0.5313 - val_loss: 1.0038 - val_accuracy: 0.5064\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9744 - accuracy: 0.5311 - val_loss: 1.0037 - val_accuracy: 0.5108\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9742 - accuracy: 0.5314 - val_loss: 1.0037 - val_accuracy: 0.5064\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9742 - accuracy: 0.5311 - val_loss: 1.0038 - val_accuracy: 0.5108\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9742 - accuracy: 0.5308 - val_loss: 1.0038 - val_accuracy: 0.5108\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9742 - accuracy: 0.5316 - val_loss: 1.0037 - val_accuracy: 0.5108\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9741 - accuracy: 0.5314 - val_loss: 1.0037 - val_accuracy: 0.5108\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9740 - accuracy: 0.5315 - val_loss: 1.0038 - val_accuracy: 0.5108\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9741 - accuracy: 0.5310 - val_loss: 1.0037 - val_accuracy: 0.5108\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 1.0040 - val_accuracy: 0.5108\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9742 - accuracy: 0.5323 - val_loss: 1.0037 - val_accuracy: 0.5064\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9743 - accuracy: 0.5313 - val_loss: 1.0038 - val_accuracy: 0.5108\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9742 - accuracy: 0.5315 - val_loss: 1.0038 - val_accuracy: 0.5126\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9740 - accuracy: 0.5323 - val_loss: 1.0039 - val_accuracy: 0.5122\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9743 - accuracy: 0.5307 - val_loss: 1.0036 - val_accuracy: 0.5113\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9741 - accuracy: 0.5318 - val_loss: 1.0039 - val_accuracy: 0.5108\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9740 - accuracy: 0.5320 - val_loss: 1.0037 - val_accuracy: 0.5108\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9739 - accuracy: 0.5314 - val_loss: 1.0037 - val_accuracy: 0.5108\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9741 - accuracy: 0.5314 - val_loss: 1.0039 - val_accuracy: 0.5131\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9743 - accuracy: 0.5317 - val_loss: 1.0039 - val_accuracy: 0.5108\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 1.0036 - val_accuracy: 0.5131\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 1.0038 - val_accuracy: 0.5126\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9742 - accuracy: 0.5315 - val_loss: 1.0036 - val_accuracy: 0.5108\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9739 - accuracy: 0.5317 - val_loss: 1.0038 - val_accuracy: 0.5108\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9741 - accuracy: 0.5329 - val_loss: 1.0036 - val_accuracy: 0.5108\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 1.0038 - val_accuracy: 0.5126\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9739 - accuracy: 0.5312 - val_loss: 1.0036 - val_accuracy: 0.5126\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9741 - accuracy: 0.5316 - val_loss: 1.0035 - val_accuracy: 0.5108\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9740 - accuracy: 0.5317 - val_loss: 1.0035 - val_accuracy: 0.5108\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9740 - accuracy: 0.5317 - val_loss: 1.0036 - val_accuracy: 0.5122\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9738 - accuracy: 0.5318 - val_loss: 1.0038 - val_accuracy: 0.5113\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9738 - accuracy: 0.5322 - val_loss: 1.0035 - val_accuracy: 0.5108\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9740 - accuracy: 0.5317 - val_loss: 1.0038 - val_accuracy: 0.5122\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9741 - accuracy: 0.5327 - val_loss: 1.0035 - val_accuracy: 0.5108\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9739 - accuracy: 0.5309 - val_loss: 1.0038 - val_accuracy: 0.5122\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9740 - accuracy: 0.5323 - val_loss: 1.0037 - val_accuracy: 0.5117\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 1.0036 - val_accuracy: 0.5122\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9739 - accuracy: 0.5320 - val_loss: 1.0036 - val_accuracy: 0.5131\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9739 - accuracy: 0.5310 - val_loss: 1.0035 - val_accuracy: 0.5069\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9740 - accuracy: 0.5324 - val_loss: 1.0037 - val_accuracy: 0.5122\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 1.0039 - val_accuracy: 0.5122\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9741 - accuracy: 0.5321 - val_loss: 1.0035 - val_accuracy: 0.5117\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9737 - accuracy: 0.5312 - val_loss: 1.0036 - val_accuracy: 0.5122\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9739 - accuracy: 0.5326 - val_loss: 1.0036 - val_accuracy: 0.5108\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9736 - accuracy: 0.5323 - val_loss: 1.0034 - val_accuracy: 0.5122\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 1.0036 - val_accuracy: 0.5117\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9739 - accuracy: 0.5317 - val_loss: 1.0036 - val_accuracy: 0.5122\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9738 - accuracy: 0.5317 - val_loss: 1.0035 - val_accuracy: 0.5113\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9741 - accuracy: 0.5325 - val_loss: 1.0036 - val_accuracy: 0.5117\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9738 - accuracy: 0.5313 - val_loss: 1.0034 - val_accuracy: 0.5108\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9741 - accuracy: 0.5310 - val_loss: 1.0035 - val_accuracy: 0.5117\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9738 - accuracy: 0.5320 - val_loss: 1.0037 - val_accuracy: 0.5104\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9737 - accuracy: 0.5321 - val_loss: 1.0036 - val_accuracy: 0.5117\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 1.0036 - val_accuracy: 0.5117\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 595us/step - loss: 0.9743 - accuracy: 0.5324 - val_loss: 1.0034 - val_accuracy: 0.5113\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9738 - accuracy: 0.5323 - val_loss: 1.0034 - val_accuracy: 0.5117\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9737 - accuracy: 0.5322 - val_loss: 1.0036 - val_accuracy: 0.5113\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 1.0036 - val_accuracy: 0.5117\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9741 - accuracy: 0.5314 - val_loss: 1.0036 - val_accuracy: 0.5117\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9736 - accuracy: 0.5322 - val_loss: 1.0034 - val_accuracy: 0.5117\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9737 - accuracy: 0.5318 - val_loss: 1.0033 - val_accuracy: 0.5117\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9739 - accuracy: 0.5326 - val_loss: 1.0035 - val_accuracy: 0.5117\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9737 - accuracy: 0.5321 - val_loss: 1.0037 - val_accuracy: 0.5117\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9739 - accuracy: 0.5321 - val_loss: 1.0035 - val_accuracy: 0.5117\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 1.0036 - val_accuracy: 0.5117\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9737 - accuracy: 0.5312 - val_loss: 1.0032 - val_accuracy: 0.5108\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9742 - accuracy: 0.5329 - val_loss: 1.0034 - val_accuracy: 0.5117\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 337us/step - loss: 0.9734 - accuracy: 0.5319\n",
      "Accuracy : 0.5318939685821533\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0034 - accuracy: 0.5117\n",
      "Accuracy : 0.5117308497428894\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.1821 - accuracy: 0.5279 - val_loss: 1.1128 - val_accuracy: 0.4914\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 714us/step - loss: 1.0828 - accuracy: 0.4321 - val_loss: 1.0615 - val_accuracy: 0.3931\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 1.0525 - accuracy: 0.3738 - val_loss: 1.0521 - val_accuracy: 0.3807\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0438 - accuracy: 0.4079 - val_loss: 1.0471 - val_accuracy: 0.4228\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 1.0383 - accuracy: 0.4775 - val_loss: 1.0425 - val_accuracy: 0.5162\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 1.0334 - accuracy: 0.5248 - val_loss: 1.0386 - val_accuracy: 0.5179\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 1.0286 - accuracy: 0.5238 - val_loss: 1.0342 - val_accuracy: 0.5175\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 1.0240 - accuracy: 0.5251 - val_loss: 1.0303 - val_accuracy: 0.5188\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0200 - accuracy: 0.5283 - val_loss: 1.0269 - val_accuracy: 0.5188\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 1.0160 - accuracy: 0.5283 - val_loss: 1.0232 - val_accuracy: 0.5201\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0122 - accuracy: 0.5270 - val_loss: 1.0195 - val_accuracy: 0.5193\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 1.0079 - accuracy: 0.5288 - val_loss: 1.0159 - val_accuracy: 0.5184\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0039 - accuracy: 0.5304 - val_loss: 1.0126 - val_accuracy: 0.5197\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0006 - accuracy: 0.5316 - val_loss: 1.0100 - val_accuracy: 0.5193\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9978 - accuracy: 0.5313 - val_loss: 1.0078 - val_accuracy: 0.5197\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9940 - accuracy: 0.5307 - val_loss: 1.0052 - val_accuracy: 0.5170\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9912 - accuracy: 0.5295 - val_loss: 1.0033 - val_accuracy: 0.5179\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9890 - accuracy: 0.5308 - val_loss: 1.0018 - val_accuracy: 0.5184\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9868 - accuracy: 0.5301 - val_loss: 1.0003 - val_accuracy: 0.5117\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9855 - accuracy: 0.5313 - val_loss: 0.9993 - val_accuracy: 0.5117\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9838 - accuracy: 0.5300 - val_loss: 0.9984 - val_accuracy: 0.5100\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9826 - accuracy: 0.5309 - val_loss: 0.9977 - val_accuracy: 0.5122\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9811 - accuracy: 0.5303 - val_loss: 0.9970 - val_accuracy: 0.5100\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9805 - accuracy: 0.5306 - val_loss: 0.9967 - val_accuracy: 0.5122\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9808 - accuracy: 0.5300 - val_loss: 0.9965 - val_accuracy: 0.5100\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9795 - accuracy: 0.5305 - val_loss: 0.9961 - val_accuracy: 0.5117\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9793 - accuracy: 0.5300 - val_loss: 0.9956 - val_accuracy: 0.5126\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9787 - accuracy: 0.5278 - val_loss: 0.9953 - val_accuracy: 0.5113\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9781 - accuracy: 0.5308 - val_loss: 0.9953 - val_accuracy: 0.5131\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9781 - accuracy: 0.5290 - val_loss: 0.9951 - val_accuracy: 0.5184\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9777 - accuracy: 0.5304 - val_loss: 0.9948 - val_accuracy: 0.5108\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9774 - accuracy: 0.5314 - val_loss: 0.9947 - val_accuracy: 0.5122\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9777 - accuracy: 0.5308 - val_loss: 0.9944 - val_accuracy: 0.5100\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9770 - accuracy: 0.5303 - val_loss: 0.9944 - val_accuracy: 0.5179\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9771 - accuracy: 0.5307 - val_loss: 0.9942 - val_accuracy: 0.5117\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9773 - accuracy: 0.5305 - val_loss: 0.9941 - val_accuracy: 0.5179\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9768 - accuracy: 0.5305 - val_loss: 0.9938 - val_accuracy: 0.5108\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9766 - accuracy: 0.5307 - val_loss: 0.9938 - val_accuracy: 0.5179\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9766 - accuracy: 0.5313 - val_loss: 0.9935 - val_accuracy: 0.5100\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9764 - accuracy: 0.5308 - val_loss: 0.9934 - val_accuracy: 0.5100\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9767 - accuracy: 0.5295 - val_loss: 0.9933 - val_accuracy: 0.5179\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9762 - accuracy: 0.5306 - val_loss: 0.9931 - val_accuracy: 0.5117\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 611us/step - loss: 0.9764 - accuracy: 0.5322 - val_loss: 0.9929 - val_accuracy: 0.5113\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9929 - val_accuracy: 0.5184\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9762 - accuracy: 0.5292 - val_loss: 0.9928 - val_accuracy: 0.5117\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9759 - accuracy: 0.5305 - val_loss: 0.9928 - val_accuracy: 0.5113\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9758 - accuracy: 0.5304 - val_loss: 0.9928 - val_accuracy: 0.5188\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9759 - accuracy: 0.5314 - val_loss: 0.9927 - val_accuracy: 0.5113\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9763 - accuracy: 0.5286 - val_loss: 0.9924 - val_accuracy: 0.5117\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9756 - accuracy: 0.5306 - val_loss: 0.9924 - val_accuracy: 0.5113\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9755 - accuracy: 0.5309 - val_loss: 0.9924 - val_accuracy: 0.5175\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9925 - val_accuracy: 0.5117\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9755 - accuracy: 0.5300 - val_loss: 0.9924 - val_accuracy: 0.5126\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9922 - val_accuracy: 0.5188\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9753 - accuracy: 0.5305 - val_loss: 0.9922 - val_accuracy: 0.5122\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9754 - accuracy: 0.5300 - val_loss: 0.9922 - val_accuracy: 0.5126\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9754 - accuracy: 0.5305 - val_loss: 0.9922 - val_accuracy: 0.5184\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9920 - val_accuracy: 0.5179\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9918 - val_accuracy: 0.5184\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9752 - accuracy: 0.5308 - val_loss: 0.9918 - val_accuracy: 0.5179\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9749 - accuracy: 0.5301 - val_loss: 0.9918 - val_accuracy: 0.5117\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9753 - accuracy: 0.5317 - val_loss: 0.9918 - val_accuracy: 0.5184\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9917 - val_accuracy: 0.5108\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9753 - accuracy: 0.5307 - val_loss: 0.9915 - val_accuracy: 0.5184\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9752 - accuracy: 0.5302 - val_loss: 0.9916 - val_accuracy: 0.5193\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9752 - accuracy: 0.5299 - val_loss: 0.9915 - val_accuracy: 0.5184\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9750 - accuracy: 0.5306 - val_loss: 0.9914 - val_accuracy: 0.5135\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9749 - accuracy: 0.5304 - val_loss: 0.9914 - val_accuracy: 0.5184\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9749 - accuracy: 0.5308 - val_loss: 0.9913 - val_accuracy: 0.5188\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9748 - accuracy: 0.5304 - val_loss: 0.9913 - val_accuracy: 0.5188\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9912 - val_accuracy: 0.5188\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 707us/step - loss: 0.9747 - accuracy: 0.5298 - val_loss: 0.9912 - val_accuracy: 0.5166\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9748 - accuracy: 0.5297 - val_loss: 0.9911 - val_accuracy: 0.5188\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9748 - accuracy: 0.5302 - val_loss: 0.9911 - val_accuracy: 0.5184\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 748us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9914 - val_accuracy: 0.5201\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9747 - accuracy: 0.5309 - val_loss: 0.9909 - val_accuracy: 0.5188\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9746 - accuracy: 0.5300 - val_loss: 0.9909 - val_accuracy: 0.5184\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 755us/step - loss: 0.9746 - accuracy: 0.5311 - val_loss: 0.9910 - val_accuracy: 0.5188\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9746 - accuracy: 0.5303 - val_loss: 0.9910 - val_accuracy: 0.5144\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9748 - accuracy: 0.5307 - val_loss: 0.9911 - val_accuracy: 0.5197\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 658us/step - loss: 0.9747 - accuracy: 0.5300 - val_loss: 0.9909 - val_accuracy: 0.5206\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9745 - accuracy: 0.5316 - val_loss: 0.9908 - val_accuracy: 0.5188\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9746 - accuracy: 0.5300 - val_loss: 0.9907 - val_accuracy: 0.5188\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9745 - accuracy: 0.5301 - val_loss: 0.9907 - val_accuracy: 0.5197\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9746 - accuracy: 0.5307 - val_loss: 0.9909 - val_accuracy: 0.5201\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9749 - accuracy: 0.5282 - val_loss: 0.9905 - val_accuracy: 0.5179\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9745 - accuracy: 0.5308 - val_loss: 0.9905 - val_accuracy: 0.5193\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 0.9905 - val_accuracy: 0.5188\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9746 - accuracy: 0.5318 - val_loss: 0.9906 - val_accuracy: 0.5188\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9745 - accuracy: 0.5307 - val_loss: 0.9904 - val_accuracy: 0.5184\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9749 - accuracy: 0.5290 - val_loss: 0.9903 - val_accuracy: 0.5197\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9746 - accuracy: 0.5315 - val_loss: 0.9902 - val_accuracy: 0.5193\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9746 - accuracy: 0.5307 - val_loss: 0.9904 - val_accuracy: 0.5197\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9756 - accuracy: 0.5305 - val_loss: 0.9906 - val_accuracy: 0.5188\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9746 - accuracy: 0.5309 - val_loss: 0.9906 - val_accuracy: 0.5197\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9746 - accuracy: 0.5308 - val_loss: 0.9904 - val_accuracy: 0.5175\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9751 - accuracy: 0.5310 - val_loss: 0.9900 - val_accuracy: 0.5179\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9753 - accuracy: 0.5298 - val_loss: 0.9899 - val_accuracy: 0.5179\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9749 - accuracy: 0.5309 - val_loss: 0.9899 - val_accuracy: 0.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9745 - accuracy: 0.5307 - val_loss: 0.9899 - val_accuracy: 0.5206\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9745 - accuracy: 0.5311 - val_loss: 0.9899 - val_accuracy: 0.5197\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9744 - accuracy: 0.5303 - val_loss: 0.9900 - val_accuracy: 0.5197\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9745 - accuracy: 0.5313 - val_loss: 0.9901 - val_accuracy: 0.5193\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9743 - accuracy: 0.5317 - val_loss: 0.9901 - val_accuracy: 0.5197\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9746 - accuracy: 0.5310 - val_loss: 0.9900 - val_accuracy: 0.5197\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9745 - accuracy: 0.5305 - val_loss: 0.9900 - val_accuracy: 0.5188\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9741 - accuracy: 0.5309 - val_loss: 0.9901 - val_accuracy: 0.5197\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9745 - accuracy: 0.5307 - val_loss: 0.9900 - val_accuracy: 0.5188\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 0.9742 - accuracy: 0.5315 - val_loss: 0.9900 - val_accuracy: 0.5193\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9744 - accuracy: 0.5309 - val_loss: 0.9900 - val_accuracy: 0.5201\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9744 - accuracy: 0.5306 - val_loss: 0.9900 - val_accuracy: 0.5193\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9742 - accuracy: 0.5307 - val_loss: 0.9902 - val_accuracy: 0.5188\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9745 - accuracy: 0.5307 - val_loss: 0.9901 - val_accuracy: 0.5197\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9746 - accuracy: 0.5314 - val_loss: 0.9900 - val_accuracy: 0.5184\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9746 - accuracy: 0.5308 - val_loss: 0.9898 - val_accuracy: 0.5193\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9745 - accuracy: 0.5308 - val_loss: 0.9899 - val_accuracy: 0.5193\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9744 - accuracy: 0.5300 - val_loss: 0.9900 - val_accuracy: 0.5201\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9741 - accuracy: 0.5308 - val_loss: 0.9900 - val_accuracy: 0.5206\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9744 - accuracy: 0.5312 - val_loss: 0.9900 - val_accuracy: 0.5188\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9741 - accuracy: 0.5316 - val_loss: 0.9903 - val_accuracy: 0.5197\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9742 - accuracy: 0.5312 - val_loss: 0.9899 - val_accuracy: 0.5193\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9741 - accuracy: 0.5310 - val_loss: 0.9899 - val_accuracy: 0.5206\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9741 - accuracy: 0.5315 - val_loss: 0.9901 - val_accuracy: 0.5210\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9747 - accuracy: 0.5313 - val_loss: 0.9899 - val_accuracy: 0.5197\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9741 - accuracy: 0.5320 - val_loss: 0.9900 - val_accuracy: 0.5206\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9744 - accuracy: 0.5314 - val_loss: 0.9901 - val_accuracy: 0.5184\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9744 - accuracy: 0.5310 - val_loss: 0.9899 - val_accuracy: 0.5210\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9740 - accuracy: 0.5314 - val_loss: 0.9898 - val_accuracy: 0.5210\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9746 - accuracy: 0.5314 - val_loss: 0.9899 - val_accuracy: 0.5193\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 0.9898 - val_accuracy: 0.5193\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9743 - accuracy: 0.5314 - val_loss: 0.9898 - val_accuracy: 0.5184\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9741 - accuracy: 0.5311 - val_loss: 0.9897 - val_accuracy: 0.5210\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9741 - accuracy: 0.5311 - val_loss: 0.9897 - val_accuracy: 0.5206\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9740 - accuracy: 0.5302 - val_loss: 0.9897 - val_accuracy: 0.5210\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9742 - accuracy: 0.5306 - val_loss: 0.9899 - val_accuracy: 0.5184\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9742 - accuracy: 0.5309 - val_loss: 0.9898 - val_accuracy: 0.5201\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 658us/step - loss: 0.9743 - accuracy: 0.5304 - val_loss: 0.9898 - val_accuracy: 0.5201\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9744 - accuracy: 0.5306 - val_loss: 0.9897 - val_accuracy: 0.5193\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 0.9741 - accuracy: 0.5312 - val_loss: 0.9897 - val_accuracy: 0.5184\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9740 - accuracy: 0.5306 - val_loss: 0.9899 - val_accuracy: 0.5184\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9741 - accuracy: 0.5317 - val_loss: 0.9897 - val_accuracy: 0.5201\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9742 - accuracy: 0.5306 - val_loss: 0.9898 - val_accuracy: 0.5206\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9741 - accuracy: 0.5311 - val_loss: 0.9897 - val_accuracy: 0.5193\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 0.9898 - val_accuracy: 0.5184\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9742 - accuracy: 0.5309 - val_loss: 0.9897 - val_accuracy: 0.5210\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9741 - accuracy: 0.5310 - val_loss: 0.9898 - val_accuracy: 0.5184\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9740 - accuracy: 0.5303 - val_loss: 0.9898 - val_accuracy: 0.5184\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9739 - accuracy: 0.5309 - val_loss: 0.9897 - val_accuracy: 0.5210\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9742 - accuracy: 0.5309 - val_loss: 0.9899 - val_accuracy: 0.5179\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9739 - accuracy: 0.5306 - val_loss: 0.9900 - val_accuracy: 0.5184\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9744 - accuracy: 0.5303 - val_loss: 0.9901 - val_accuracy: 0.5184\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9745 - accuracy: 0.5316 - val_loss: 0.9898 - val_accuracy: 0.5188\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9741 - accuracy: 0.5310 - val_loss: 0.9898 - val_accuracy: 0.5201\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9745 - accuracy: 0.5310 - val_loss: 0.9896 - val_accuracy: 0.5184\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9741 - accuracy: 0.5308 - val_loss: 0.9896 - val_accuracy: 0.5184\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 594us/step - loss: 0.9740 - accuracy: 0.5304 - val_loss: 0.9896 - val_accuracy: 0.5197\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9742 - accuracy: 0.5311 - val_loss: 0.9897 - val_accuracy: 0.5179\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9748 - accuracy: 0.5292 - val_loss: 0.9895 - val_accuracy: 0.5179\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9741 - accuracy: 0.5309 - val_loss: 0.9896 - val_accuracy: 0.5184\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9740 - accuracy: 0.5315 - val_loss: 0.9896 - val_accuracy: 0.5201\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9743 - accuracy: 0.5314 - val_loss: 0.9896 - val_accuracy: 0.5188\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9742 - accuracy: 0.5305 - val_loss: 0.9895 - val_accuracy: 0.5179\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9739 - accuracy: 0.5314 - val_loss: 0.9895 - val_accuracy: 0.5210\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9738 - accuracy: 0.5306 - val_loss: 0.9896 - val_accuracy: 0.5219\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9741 - accuracy: 0.5307 - val_loss: 0.9896 - val_accuracy: 0.5201\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9740 - accuracy: 0.5311 - val_loss: 0.9896 - val_accuracy: 0.5219\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9739 - accuracy: 0.5309 - val_loss: 0.9897 - val_accuracy: 0.5193\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9743 - accuracy: 0.5316 - val_loss: 0.9895 - val_accuracy: 0.5210\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9744 - accuracy: 0.5315 - val_loss: 0.9896 - val_accuracy: 0.5219\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9741 - accuracy: 0.5301 - val_loss: 0.9897 - val_accuracy: 0.5188\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 0.9739 - accuracy: 0.5314 - val_loss: 0.9896 - val_accuracy: 0.5201\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 566us/step - loss: 0.9739 - accuracy: 0.5310 - val_loss: 0.9896 - val_accuracy: 0.5193\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 0.9897 - val_accuracy: 0.5228\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9741 - accuracy: 0.5302 - val_loss: 0.9896 - val_accuracy: 0.5193\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9741 - accuracy: 0.5312 - val_loss: 0.9897 - val_accuracy: 0.5210\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 0.9896 - val_accuracy: 0.5188\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9741 - accuracy: 0.5299 - val_loss: 0.9895 - val_accuracy: 0.5210\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9740 - accuracy: 0.5316 - val_loss: 0.9895 - val_accuracy: 0.5201\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9739 - accuracy: 0.5310 - val_loss: 0.9896 - val_accuracy: 0.5179\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9741 - accuracy: 0.5304 - val_loss: 0.9895 - val_accuracy: 0.5201\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9740 - accuracy: 0.5311 - val_loss: 0.9896 - val_accuracy: 0.5215\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9742 - accuracy: 0.5316 - val_loss: 0.9895 - val_accuracy: 0.5210\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9740 - accuracy: 0.5315 - val_loss: 0.9896 - val_accuracy: 0.5210\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9741 - accuracy: 0.5311 - val_loss: 0.9896 - val_accuracy: 0.5179\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9738 - accuracy: 0.5309 - val_loss: 0.9896 - val_accuracy: 0.5210\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9745 - accuracy: 0.5304 - val_loss: 0.9895 - val_accuracy: 0.5179\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9741 - accuracy: 0.5310 - val_loss: 0.9898 - val_accuracy: 0.5179\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9740 - accuracy: 0.5295 - val_loss: 0.9894 - val_accuracy: 0.5184\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9740 - accuracy: 0.5306 - val_loss: 0.9895 - val_accuracy: 0.5184\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9740 - accuracy: 0.5310 - val_loss: 0.9896 - val_accuracy: 0.5228\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9746 - accuracy: 0.5321 - val_loss: 0.9894 - val_accuracy: 0.5193\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9739 - accuracy: 0.5310 - val_loss: 0.9896 - val_accuracy: 0.5197\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9738 - accuracy: 0.5311 - val_loss: 0.9896 - val_accuracy: 0.5193\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9740 - accuracy: 0.5306 - val_loss: 0.9895 - val_accuracy: 0.5184\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9742 - accuracy: 0.5307 - val_loss: 0.9895 - val_accuracy: 0.5179\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9740 - accuracy: 0.5308 - val_loss: 0.9895 - val_accuracy: 0.5197\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 0.9897 - val_accuracy: 0.5197\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9738 - accuracy: 0.5313 - val_loss: 0.9897 - val_accuracy: 0.5184\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9741 - accuracy: 0.5315 - val_loss: 0.9895 - val_accuracy: 0.5228\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9739 - accuracy: 0.5309 - val_loss: 0.9898 - val_accuracy: 0.5188\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 344us/step - loss: 0.9739 - accuracy: 0.5318\n",
      "Accuracy : 0.5317956209182739\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9898 - accuracy: 0.5188\n",
      "Accuracy : 0.5188136100769043\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 2.7643 - accuracy: 0.3050 - val_loss: 2.4056 - val_accuracy: 0.3152\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 763us/step - loss: 2.2363 - accuracy: 0.3088 - val_loss: 1.9094 - val_accuracy: 0.3236\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 1.7753 - accuracy: 0.3140 - val_loss: 1.4966 - val_accuracy: 0.3245\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 1.4069 - accuracy: 0.3141 - val_loss: 1.1815 - val_accuracy: 0.3227\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 1.1409 - accuracy: 0.4302 - val_loss: 1.0396 - val_accuracy: 0.5286\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 1.0496 - accuracy: 0.5271 - val_loss: 1.0052 - val_accuracy: 0.5409\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.0187 - accuracy: 0.5292 - val_loss: 0.9906 - val_accuracy: 0.5405\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 1.0015 - accuracy: 0.5289 - val_loss: 0.9824 - val_accuracy: 0.5409\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9914 - accuracy: 0.5287 - val_loss: 0.9779 - val_accuracy: 0.5414\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9861 - accuracy: 0.5296 - val_loss: 0.9761 - val_accuracy: 0.5423\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 613us/step - loss: 0.9828 - accuracy: 0.5294 - val_loss: 0.9754 - val_accuracy: 0.5370\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9809 - accuracy: 0.5287 - val_loss: 0.9753 - val_accuracy: 0.5365\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9799 - accuracy: 0.5290 - val_loss: 0.9751 - val_accuracy: 0.5378\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5290 - val_loss: 0.9751 - val_accuracy: 0.5392\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9789 - accuracy: 0.5286 - val_loss: 0.9750 - val_accuracy: 0.5414\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9787 - accuracy: 0.5290 - val_loss: 0.9751 - val_accuracy: 0.5423\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9786 - accuracy: 0.5287 - val_loss: 0.9752 - val_accuracy: 0.5418\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9787 - accuracy: 0.5299 - val_loss: 0.9752 - val_accuracy: 0.5378\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9782 - accuracy: 0.5283 - val_loss: 0.9751 - val_accuracy: 0.5383\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9784 - accuracy: 0.5288 - val_loss: 0.9753 - val_accuracy: 0.5378\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9780 - accuracy: 0.5298 - val_loss: 0.9748 - val_accuracy: 0.5378\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9779 - accuracy: 0.5288 - val_loss: 0.9746 - val_accuracy: 0.5414\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9779 - accuracy: 0.5281 - val_loss: 0.9747 - val_accuracy: 0.5383\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9778 - accuracy: 0.5292 - val_loss: 0.9747 - val_accuracy: 0.5383\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9777 - accuracy: 0.5292 - val_loss: 0.9745 - val_accuracy: 0.5387\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9777 - accuracy: 0.5293 - val_loss: 0.9743 - val_accuracy: 0.5383\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9774 - accuracy: 0.5292 - val_loss: 0.9744 - val_accuracy: 0.5383\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9774 - accuracy: 0.5291 - val_loss: 0.9742 - val_accuracy: 0.5418\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9774 - accuracy: 0.5287 - val_loss: 0.9747 - val_accuracy: 0.5378\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9778 - accuracy: 0.5284 - val_loss: 0.9742 - val_accuracy: 0.5396\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9772 - accuracy: 0.5282 - val_loss: 0.9741 - val_accuracy: 0.5396\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9739 - val_accuracy: 0.5414\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9773 - accuracy: 0.5274 - val_loss: 0.9738 - val_accuracy: 0.5414\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9737 - val_accuracy: 0.5401\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9770 - accuracy: 0.5281 - val_loss: 0.9739 - val_accuracy: 0.5396\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9739 - val_accuracy: 0.5396\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9770 - accuracy: 0.5271 - val_loss: 0.9742 - val_accuracy: 0.5405\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9773 - accuracy: 0.5287 - val_loss: 0.9743 - val_accuracy: 0.5401\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9769 - accuracy: 0.5284 - val_loss: 0.9738 - val_accuracy: 0.5401\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9768 - accuracy: 0.5284 - val_loss: 0.9738 - val_accuracy: 0.5405\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9738 - val_accuracy: 0.5396\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9768 - accuracy: 0.5285 - val_loss: 0.9739 - val_accuracy: 0.5409\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9769 - accuracy: 0.5283 - val_loss: 0.9736 - val_accuracy: 0.5414\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9768 - accuracy: 0.5279 - val_loss: 0.9737 - val_accuracy: 0.5401\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9735 - val_accuracy: 0.5401\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9766 - accuracy: 0.5279 - val_loss: 0.9735 - val_accuracy: 0.5405\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9732 - val_accuracy: 0.5396\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9766 - accuracy: 0.5283 - val_loss: 0.9732 - val_accuracy: 0.5396\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9766 - accuracy: 0.5284 - val_loss: 0.9735 - val_accuracy: 0.5409\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9766 - accuracy: 0.5293 - val_loss: 0.9732 - val_accuracy: 0.5401\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9766 - accuracy: 0.5284 - val_loss: 0.9733 - val_accuracy: 0.5409\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9765 - accuracy: 0.5281 - val_loss: 0.9732 - val_accuracy: 0.5396\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9764 - accuracy: 0.5272 - val_loss: 0.9732 - val_accuracy: 0.5409\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9765 - accuracy: 0.5277 - val_loss: 0.9733 - val_accuracy: 0.5401\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9732 - val_accuracy: 0.5409\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9768 - accuracy: 0.5278 - val_loss: 0.9734 - val_accuracy: 0.5409\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9772 - accuracy: 0.5293 - val_loss: 0.9728 - val_accuracy: 0.5401\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9762 - accuracy: 0.5273 - val_loss: 0.9734 - val_accuracy: 0.5378\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9763 - accuracy: 0.5286 - val_loss: 0.9731 - val_accuracy: 0.5401\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9762 - accuracy: 0.5290 - val_loss: 0.9728 - val_accuracy: 0.5409\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9764 - accuracy: 0.5287 - val_loss: 0.9729 - val_accuracy: 0.5396\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9764 - accuracy: 0.5275 - val_loss: 0.9727 - val_accuracy: 0.5396\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9763 - accuracy: 0.5274 - val_loss: 0.9726 - val_accuracy: 0.5396\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9761 - accuracy: 0.5277 - val_loss: 0.9727 - val_accuracy: 0.5392\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9762 - accuracy: 0.5285 - val_loss: 0.9727 - val_accuracy: 0.5396\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9762 - accuracy: 0.5277 - val_loss: 0.9727 - val_accuracy: 0.5396\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9761 - accuracy: 0.5275 - val_loss: 0.9727 - val_accuracy: 0.5392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9761 - accuracy: 0.5280 - val_loss: 0.9730 - val_accuracy: 0.5392\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9767 - accuracy: 0.5286 - val_loss: 0.9731 - val_accuracy: 0.5378\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9763 - accuracy: 0.5273 - val_loss: 0.9731 - val_accuracy: 0.5396\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9759 - accuracy: 0.5276 - val_loss: 0.9728 - val_accuracy: 0.5370\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9761 - accuracy: 0.5267 - val_loss: 0.9727 - val_accuracy: 0.5370\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9760 - accuracy: 0.5275 - val_loss: 0.9726 - val_accuracy: 0.5374\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9758 - accuracy: 0.5282 - val_loss: 0.9723 - val_accuracy: 0.5370\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9761 - accuracy: 0.5269 - val_loss: 0.9724 - val_accuracy: 0.5387\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9760 - accuracy: 0.5274 - val_loss: 0.9725 - val_accuracy: 0.5378\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9761 - accuracy: 0.5274 - val_loss: 0.9727 - val_accuracy: 0.5387\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9758 - accuracy: 0.5262 - val_loss: 0.9728 - val_accuracy: 0.5418\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9762 - accuracy: 0.5286 - val_loss: 0.9724 - val_accuracy: 0.5392\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9762 - accuracy: 0.5275 - val_loss: 0.9726 - val_accuracy: 0.5387\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9759 - accuracy: 0.5279 - val_loss: 0.9725 - val_accuracy: 0.5387\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9760 - accuracy: 0.5285 - val_loss: 0.9726 - val_accuracy: 0.5392\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9759 - accuracy: 0.5282 - val_loss: 0.9723 - val_accuracy: 0.5378\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9758 - accuracy: 0.5285 - val_loss: 0.9722 - val_accuracy: 0.5396\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9759 - accuracy: 0.5283 - val_loss: 0.9721 - val_accuracy: 0.5405\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9761 - accuracy: 0.5282 - val_loss: 0.9724 - val_accuracy: 0.5414\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9760 - accuracy: 0.5284 - val_loss: 0.9723 - val_accuracy: 0.5414\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9759 - accuracy: 0.5280 - val_loss: 0.9725 - val_accuracy: 0.5405\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9758 - accuracy: 0.5285 - val_loss: 0.9722 - val_accuracy: 0.5392\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9724 - val_accuracy: 0.5405\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9758 - accuracy: 0.5285 - val_loss: 0.9722 - val_accuracy: 0.5378\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9759 - accuracy: 0.5274 - val_loss: 0.9722 - val_accuracy: 0.5370\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9760 - accuracy: 0.5277 - val_loss: 0.9723 - val_accuracy: 0.5374\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9758 - accuracy: 0.5285 - val_loss: 0.9724 - val_accuracy: 0.5418\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9758 - accuracy: 0.5285 - val_loss: 0.9720 - val_accuracy: 0.5405\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9756 - accuracy: 0.5275 - val_loss: 0.9721 - val_accuracy: 0.5392\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9760 - accuracy: 0.5288 - val_loss: 0.9720 - val_accuracy: 0.5374\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9758 - accuracy: 0.5271 - val_loss: 0.9721 - val_accuracy: 0.5378\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9764 - accuracy: 0.5282 - val_loss: 0.9721 - val_accuracy: 0.5378\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9764 - accuracy: 0.5258 - val_loss: 0.9727 - val_accuracy: 0.5370\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9759 - accuracy: 0.5278 - val_loss: 0.9722 - val_accuracy: 0.5374\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9756 - accuracy: 0.5284 - val_loss: 0.9720 - val_accuracy: 0.5378\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9758 - accuracy: 0.5269 - val_loss: 0.9720 - val_accuracy: 0.5374\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9757 - accuracy: 0.5272 - val_loss: 0.9720 - val_accuracy: 0.5370\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9757 - accuracy: 0.5270 - val_loss: 0.9721 - val_accuracy: 0.5374\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9759 - accuracy: 0.5265 - val_loss: 0.9725 - val_accuracy: 0.5370\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9757 - accuracy: 0.5260 - val_loss: 0.9726 - val_accuracy: 0.5396\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9759 - accuracy: 0.5287 - val_loss: 0.9725 - val_accuracy: 0.5378\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9758 - accuracy: 0.5269 - val_loss: 0.9725 - val_accuracy: 0.5378\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9758 - accuracy: 0.5275 - val_loss: 0.9725 - val_accuracy: 0.5374\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9757 - accuracy: 0.5280 - val_loss: 0.9725 - val_accuracy: 0.5378\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9755 - accuracy: 0.5281 - val_loss: 0.9725 - val_accuracy: 0.5396\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9755 - accuracy: 0.5278 - val_loss: 0.9726 - val_accuracy: 0.5378\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9756 - accuracy: 0.5281 - val_loss: 0.9723 - val_accuracy: 0.5378\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9755 - accuracy: 0.5269 - val_loss: 0.9724 - val_accuracy: 0.5396\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9761 - accuracy: 0.5284 - val_loss: 0.9727 - val_accuracy: 0.5378\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9765 - accuracy: 0.5276 - val_loss: 0.9722 - val_accuracy: 0.5378\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9754 - accuracy: 0.5278 - val_loss: 0.9722 - val_accuracy: 0.5401\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9757 - accuracy: 0.5279 - val_loss: 0.9722 - val_accuracy: 0.5401\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9755 - accuracy: 0.5278 - val_loss: 0.9722 - val_accuracy: 0.5396\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9758 - accuracy: 0.5276 - val_loss: 0.9721 - val_accuracy: 0.5378\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9755 - accuracy: 0.5280 - val_loss: 0.9725 - val_accuracy: 0.5401\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9763 - accuracy: 0.5290 - val_loss: 0.9728 - val_accuracy: 0.5370\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9754 - accuracy: 0.5269 - val_loss: 0.9728 - val_accuracy: 0.5374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9757 - accuracy: 0.5268 - val_loss: 0.9726 - val_accuracy: 0.5374\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9756 - accuracy: 0.5271 - val_loss: 0.9725 - val_accuracy: 0.5374\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9755 - accuracy: 0.5276 - val_loss: 0.9729 - val_accuracy: 0.5383\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9755 - accuracy: 0.5275 - val_loss: 0.9727 - val_accuracy: 0.5401\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9756 - accuracy: 0.5284 - val_loss: 0.9723 - val_accuracy: 0.5383\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9755 - accuracy: 0.5277 - val_loss: 0.9723 - val_accuracy: 0.5401\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9754 - accuracy: 0.5276 - val_loss: 0.9722 - val_accuracy: 0.5405\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9755 - accuracy: 0.5288 - val_loss: 0.9719 - val_accuracy: 0.5401\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9754 - accuracy: 0.5284 - val_loss: 0.9721 - val_accuracy: 0.5405\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9756 - accuracy: 0.5285 - val_loss: 0.9722 - val_accuracy: 0.5405\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9754 - accuracy: 0.5282 - val_loss: 0.9723 - val_accuracy: 0.5401\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9761 - accuracy: 0.5277 - val_loss: 0.9728 - val_accuracy: 0.5401\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9757 - accuracy: 0.5282 - val_loss: 0.9726 - val_accuracy: 0.5383\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 738us/step - loss: 0.9753 - accuracy: 0.5270 - val_loss: 0.9723 - val_accuracy: 0.5374\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9754 - accuracy: 0.5269 - val_loss: 0.9722 - val_accuracy: 0.5378\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9755 - accuracy: 0.5275 - val_loss: 0.9723 - val_accuracy: 0.5378\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9753 - accuracy: 0.5275 - val_loss: 0.9721 - val_accuracy: 0.5392\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9753 - accuracy: 0.5279 - val_loss: 0.9721 - val_accuracy: 0.5401\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9763 - accuracy: 0.5288 - val_loss: 0.9717 - val_accuracy: 0.5383\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9753 - accuracy: 0.5277 - val_loss: 0.9718 - val_accuracy: 0.5383\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9753 - accuracy: 0.5280 - val_loss: 0.9716 - val_accuracy: 0.5378\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9754 - accuracy: 0.5286 - val_loss: 0.9720 - val_accuracy: 0.5405\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9753 - accuracy: 0.5274 - val_loss: 0.9722 - val_accuracy: 0.5383\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9754 - accuracy: 0.5269 - val_loss: 0.9722 - val_accuracy: 0.5401\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9763 - accuracy: 0.5284 - val_loss: 0.9718 - val_accuracy: 0.5401\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9754 - accuracy: 0.5271 - val_loss: 0.9717 - val_accuracy: 0.5383\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9715 - val_accuracy: 0.5374\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9753 - accuracy: 0.5276 - val_loss: 0.9715 - val_accuracy: 0.5378\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9753 - accuracy: 0.5275 - val_loss: 0.9717 - val_accuracy: 0.5378\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9755 - accuracy: 0.5267 - val_loss: 0.9719 - val_accuracy: 0.5378\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9753 - accuracy: 0.5268 - val_loss: 0.9720 - val_accuracy: 0.5401\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9754 - accuracy: 0.5280 - val_loss: 0.9719 - val_accuracy: 0.5374\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9754 - accuracy: 0.5264 - val_loss: 0.9720 - val_accuracy: 0.5383\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 676us/step - loss: 0.9753 - accuracy: 0.5276 - val_loss: 0.9720 - val_accuracy: 0.5383\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9752 - accuracy: 0.5276 - val_loss: 0.9721 - val_accuracy: 0.5401\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9752 - accuracy: 0.5285 - val_loss: 0.9717 - val_accuracy: 0.5383\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9754 - accuracy: 0.5277 - val_loss: 0.9717 - val_accuracy: 0.5383\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 720us/step - loss: 0.9754 - accuracy: 0.5269 - val_loss: 0.9718 - val_accuracy: 0.5383\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9755 - accuracy: 0.5275 - val_loss: 0.9724 - val_accuracy: 0.5401\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9754 - accuracy: 0.5282 - val_loss: 0.9721 - val_accuracy: 0.5374\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9754 - accuracy: 0.5269 - val_loss: 0.9726 - val_accuracy: 0.5374\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9754 - accuracy: 0.5262 - val_loss: 0.9721 - val_accuracy: 0.5383\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9753 - accuracy: 0.5273 - val_loss: 0.9722 - val_accuracy: 0.5405\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9754 - accuracy: 0.5290 - val_loss: 0.9720 - val_accuracy: 0.5401\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9760 - accuracy: 0.5285 - val_loss: 0.9725 - val_accuracy: 0.5401\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9752 - accuracy: 0.5289 - val_loss: 0.9720 - val_accuracy: 0.5405\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9753 - accuracy: 0.5276 - val_loss: 0.9718 - val_accuracy: 0.5383\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9752 - accuracy: 0.5280 - val_loss: 0.9720 - val_accuracy: 0.5405\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9751 - accuracy: 0.5287 - val_loss: 0.9720 - val_accuracy: 0.5401\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9759 - accuracy: 0.5282 - val_loss: 0.9717 - val_accuracy: 0.5383\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9752 - accuracy: 0.5278 - val_loss: 0.9720 - val_accuracy: 0.5405\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9752 - accuracy: 0.5280 - val_loss: 0.9722 - val_accuracy: 0.5405\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9752 - accuracy: 0.5278 - val_loss: 0.9721 - val_accuracy: 0.5401\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9721 - val_accuracy: 0.5374\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9754 - accuracy: 0.5275 - val_loss: 0.9722 - val_accuracy: 0.5405\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9753 - accuracy: 0.5277 - val_loss: 0.9720 - val_accuracy: 0.5387\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 579us/step - loss: 0.9754 - accuracy: 0.5277 - val_loss: 0.9718 - val_accuracy: 0.5383\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9715 - val_accuracy: 0.5387\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9755 - accuracy: 0.5285 - val_loss: 0.9719 - val_accuracy: 0.5401\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9752 - accuracy: 0.5280 - val_loss: 0.9718 - val_accuracy: 0.5405\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9754 - accuracy: 0.5281 - val_loss: 0.9718 - val_accuracy: 0.5405\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9719 - val_accuracy: 0.5401\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9751 - accuracy: 0.5290 - val_loss: 0.9714 - val_accuracy: 0.5396\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9754 - accuracy: 0.5279 - val_loss: 0.9716 - val_accuracy: 0.5387\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9752 - accuracy: 0.5267 - val_loss: 0.9722 - val_accuracy: 0.5392\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5277 - val_loss: 0.9729 - val_accuracy: 0.5378\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9753 - accuracy: 0.5264 - val_loss: 0.9727 - val_accuracy: 0.5378\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9752 - accuracy: 0.5276 - val_loss: 0.9725 - val_accuracy: 0.5383\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9750 - accuracy: 0.5276 - val_loss: 0.9722 - val_accuracy: 0.5370\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9753 - accuracy: 0.5276 - val_loss: 0.9723 - val_accuracy: 0.5387\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9753 - accuracy: 0.5279 - val_loss: 0.9725 - val_accuracy: 0.5387\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9751 - accuracy: 0.5285 - val_loss: 0.9723 - val_accuracy: 0.5387\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9751 - accuracy: 0.5276 - val_loss: 0.9721 - val_accuracy: 0.5383\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9751 - accuracy: 0.5271 - val_loss: 0.9721 - val_accuracy: 0.5387\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9751 - accuracy: 0.5274 - val_loss: 0.9720 - val_accuracy: 0.5378\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9751 - accuracy: 0.5263 - val_loss: 0.9719 - val_accuracy: 0.5387\n",
      "\n",
      "Train split:\n",
      "  1/636 [..............................] - ETA: 0s - loss: 1.1697 - accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "636/636 [==============================] - 0s 348us/step - loss: 0.9749 - accuracy: 0.5279\n",
      "Accuracy : 0.5278611183166504\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9719 - accuracy: 0.5387\n",
      "Accuracy : 0.538733959197998\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 1.3258 - accuracy: 0.2895 - val_loss: 1.2164 - val_accuracy: 0.2891\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 1.1785 - accuracy: 0.2839 - val_loss: 1.1038 - val_accuracy: 0.2900\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 1.0729 - accuracy: 0.3713 - val_loss: 1.0093 - val_accuracy: 0.5436\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 1.0016 - accuracy: 0.5277 - val_loss: 0.9757 - val_accuracy: 0.5365\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9892 - accuracy: 0.5259 - val_loss: 0.9740 - val_accuracy: 0.5343\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9877 - accuracy: 0.5255 - val_loss: 0.9730 - val_accuracy: 0.5356\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9871 - accuracy: 0.5265 - val_loss: 0.9724 - val_accuracy: 0.5356\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9866 - accuracy: 0.5288 - val_loss: 0.9719 - val_accuracy: 0.5365\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9860 - accuracy: 0.5288 - val_loss: 0.9715 - val_accuracy: 0.5365\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9854 - accuracy: 0.5281 - val_loss: 0.9714 - val_accuracy: 0.5347\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9850 - accuracy: 0.5268 - val_loss: 0.9710 - val_accuracy: 0.5365\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9846 - accuracy: 0.5284 - val_loss: 0.9703 - val_accuracy: 0.5356\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9842 - accuracy: 0.5280 - val_loss: 0.9706 - val_accuracy: 0.5370\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9838 - accuracy: 0.5280 - val_loss: 0.9699 - val_accuracy: 0.5365\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9836 - accuracy: 0.5283 - val_loss: 0.9694 - val_accuracy: 0.5365\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9833 - accuracy: 0.5269 - val_loss: 0.9692 - val_accuracy: 0.5365\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9828 - accuracy: 0.5283 - val_loss: 0.9691 - val_accuracy: 0.5356\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9824 - accuracy: 0.5276 - val_loss: 0.9688 - val_accuracy: 0.5361\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9830 - accuracy: 0.5286 - val_loss: 0.9685 - val_accuracy: 0.5365\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9819 - accuracy: 0.5269 - val_loss: 0.9682 - val_accuracy: 0.5370\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9819 - accuracy: 0.5290 - val_loss: 0.9681 - val_accuracy: 0.5370\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9814 - accuracy: 0.5275 - val_loss: 0.9676 - val_accuracy: 0.5356\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9812 - accuracy: 0.5272 - val_loss: 0.9676 - val_accuracy: 0.5365\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9809 - accuracy: 0.5269 - val_loss: 0.9671 - val_accuracy: 0.5365\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9810 - accuracy: 0.5280 - val_loss: 0.9668 - val_accuracy: 0.5356\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9805 - accuracy: 0.5271 - val_loss: 0.9670 - val_accuracy: 0.5365\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9804 - accuracy: 0.5285 - val_loss: 0.9667 - val_accuracy: 0.5370\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9801 - accuracy: 0.5273 - val_loss: 0.9668 - val_accuracy: 0.5365\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9800 - accuracy: 0.5272 - val_loss: 0.9671 - val_accuracy: 0.5361\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9800 - accuracy: 0.5285 - val_loss: 0.9665 - val_accuracy: 0.5370\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9796 - accuracy: 0.5274 - val_loss: 0.9662 - val_accuracy: 0.5365\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9798 - accuracy: 0.5277 - val_loss: 0.9659 - val_accuracy: 0.5361\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9799 - accuracy: 0.5290 - val_loss: 0.9660 - val_accuracy: 0.5361\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 619us/step - loss: 0.9793 - accuracy: 0.5267 - val_loss: 0.9659 - val_accuracy: 0.5356\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9791 - accuracy: 0.5276 - val_loss: 0.9657 - val_accuracy: 0.5370\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9792 - accuracy: 0.5293 - val_loss: 0.9658 - val_accuracy: 0.5361\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9790 - accuracy: 0.5286 - val_loss: 0.9657 - val_accuracy: 0.5352\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9789 - accuracy: 0.5281 - val_loss: 0.9662 - val_accuracy: 0.5339\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9789 - accuracy: 0.5265 - val_loss: 0.9658 - val_accuracy: 0.5361\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9787 - accuracy: 0.5275 - val_loss: 0.9657 - val_accuracy: 0.5361\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9788 - accuracy: 0.5272 - val_loss: 0.9655 - val_accuracy: 0.5352\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9786 - accuracy: 0.5279 - val_loss: 0.9654 - val_accuracy: 0.5361\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9784 - accuracy: 0.5276 - val_loss: 0.9653 - val_accuracy: 0.5361\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9783 - accuracy: 0.5289 - val_loss: 0.9654 - val_accuracy: 0.5352\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9785 - accuracy: 0.5280 - val_loss: 0.9656 - val_accuracy: 0.5343\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9784 - accuracy: 0.5266 - val_loss: 0.9653 - val_accuracy: 0.5361\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9783 - accuracy: 0.5270 - val_loss: 0.9658 - val_accuracy: 0.5343\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9783 - accuracy: 0.5275 - val_loss: 0.9654 - val_accuracy: 0.5352\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9783 - accuracy: 0.5264 - val_loss: 0.9655 - val_accuracy: 0.5352\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9781 - accuracy: 0.5280 - val_loss: 0.9651 - val_accuracy: 0.5339\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9786 - accuracy: 0.5282 - val_loss: 0.9649 - val_accuracy: 0.5352\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9782 - accuracy: 0.5280 - val_loss: 0.9647 - val_accuracy: 0.5361\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9782 - accuracy: 0.5285 - val_loss: 0.9657 - val_accuracy: 0.5352\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9778 - accuracy: 0.5262 - val_loss: 0.9647 - val_accuracy: 0.5361\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9781 - accuracy: 0.5287 - val_loss: 0.9653 - val_accuracy: 0.5361\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9779 - accuracy: 0.5266 - val_loss: 0.9644 - val_accuracy: 0.5361\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9779 - accuracy: 0.5275 - val_loss: 0.9649 - val_accuracy: 0.5365\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9778 - accuracy: 0.5271 - val_loss: 0.9649 - val_accuracy: 0.5361\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9778 - accuracy: 0.5269 - val_loss: 0.9650 - val_accuracy: 0.5339\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9777 - accuracy: 0.5256 - val_loss: 0.9647 - val_accuracy: 0.5370\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9782 - accuracy: 0.5296 - val_loss: 0.9648 - val_accuracy: 0.5352\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9776 - accuracy: 0.5262 - val_loss: 0.9652 - val_accuracy: 0.5356\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9778 - accuracy: 0.5275 - val_loss: 0.9648 - val_accuracy: 0.5343\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9777 - accuracy: 0.5276 - val_loss: 0.9653 - val_accuracy: 0.5352\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9776 - accuracy: 0.5278 - val_loss: 0.9646 - val_accuracy: 0.5352\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9777 - accuracy: 0.5274 - val_loss: 0.9651 - val_accuracy: 0.5352\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9647 - val_accuracy: 0.5347\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9779 - accuracy: 0.5274 - val_loss: 0.9642 - val_accuracy: 0.5365\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9778 - accuracy: 0.5276 - val_loss: 0.9643 - val_accuracy: 0.5352\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9776 - accuracy: 0.5281 - val_loss: 0.9646 - val_accuracy: 0.5356\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9775 - accuracy: 0.5277 - val_loss: 0.9648 - val_accuracy: 0.5365\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9776 - accuracy: 0.5285 - val_loss: 0.9648 - val_accuracy: 0.5352\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9775 - accuracy: 0.5280 - val_loss: 0.9648 - val_accuracy: 0.5352\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9775 - accuracy: 0.5261 - val_loss: 0.9646 - val_accuracy: 0.5352\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9774 - accuracy: 0.5271 - val_loss: 0.9650 - val_accuracy: 0.5365\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9774 - accuracy: 0.5271 - val_loss: 0.9642 - val_accuracy: 0.5343\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9779 - accuracy: 0.5247 - val_loss: 0.9646 - val_accuracy: 0.5339\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9775 - accuracy: 0.5284 - val_loss: 0.9648 - val_accuracy: 0.5352\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9774 - accuracy: 0.5260 - val_loss: 0.9644 - val_accuracy: 0.5356\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9773 - accuracy: 0.5262 - val_loss: 0.9647 - val_accuracy: 0.5339\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9775 - accuracy: 0.5270 - val_loss: 0.9647 - val_accuracy: 0.5352\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9774 - accuracy: 0.5262 - val_loss: 0.9646 - val_accuracy: 0.5343\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9773 - accuracy: 0.5257 - val_loss: 0.9644 - val_accuracy: 0.5365\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9773 - accuracy: 0.5277 - val_loss: 0.9646 - val_accuracy: 0.5365\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9774 - accuracy: 0.5282 - val_loss: 0.9643 - val_accuracy: 0.5361\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9776 - accuracy: 0.5283 - val_loss: 0.9643 - val_accuracy: 0.5352\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9772 - accuracy: 0.5276 - val_loss: 0.9641 - val_accuracy: 0.5352\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9777 - accuracy: 0.5296 - val_loss: 0.9647 - val_accuracy: 0.5365\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9774 - accuracy: 0.5282 - val_loss: 0.9649 - val_accuracy: 0.5339\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9644 - val_accuracy: 0.5361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9775 - accuracy: 0.5302 - val_loss: 0.9649 - val_accuracy: 0.5352\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9772 - accuracy: 0.5281 - val_loss: 0.9642 - val_accuracy: 0.5352\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9773 - accuracy: 0.5267 - val_loss: 0.9643 - val_accuracy: 0.5352\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9773 - accuracy: 0.5283 - val_loss: 0.9641 - val_accuracy: 0.5361\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9774 - accuracy: 0.5278 - val_loss: 0.9640 - val_accuracy: 0.5365\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9639 - val_accuracy: 0.5365\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5290 - val_loss: 0.9643 - val_accuracy: 0.5365\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9774 - accuracy: 0.5266 - val_loss: 0.9639 - val_accuracy: 0.5365\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9772 - accuracy: 0.5294 - val_loss: 0.9637 - val_accuracy: 0.5365\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9776 - accuracy: 0.5282 - val_loss: 0.9640 - val_accuracy: 0.5352\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9772 - accuracy: 0.5263 - val_loss: 0.9642 - val_accuracy: 0.5352\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9775 - accuracy: 0.5259 - val_loss: 0.9643 - val_accuracy: 0.5352\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9774 - accuracy: 0.5269 - val_loss: 0.9640 - val_accuracy: 0.5339\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9774 - accuracy: 0.5263 - val_loss: 0.9641 - val_accuracy: 0.5352\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9771 - accuracy: 0.5259 - val_loss: 0.9638 - val_accuracy: 0.5352\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9776 - accuracy: 0.5278 - val_loss: 0.9638 - val_accuracy: 0.5352\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9771 - accuracy: 0.5272 - val_loss: 0.9641 - val_accuracy: 0.5352\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9773 - accuracy: 0.5293 - val_loss: 0.9639 - val_accuracy: 0.5352\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9772 - accuracy: 0.5279 - val_loss: 0.9645 - val_accuracy: 0.5352\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9772 - accuracy: 0.5275 - val_loss: 0.9639 - val_accuracy: 0.5365\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9772 - accuracy: 0.5299 - val_loss: 0.9643 - val_accuracy: 0.5339\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9772 - accuracy: 0.5260 - val_loss: 0.9637 - val_accuracy: 0.5352\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9775 - accuracy: 0.5265 - val_loss: 0.9645 - val_accuracy: 0.5352\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5272 - val_loss: 0.9641 - val_accuracy: 0.5356\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9773 - accuracy: 0.5269 - val_loss: 0.9639 - val_accuracy: 0.5352\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9770 - accuracy: 0.5279 - val_loss: 0.9640 - val_accuracy: 0.5352\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9771 - accuracy: 0.5286 - val_loss: 0.9640 - val_accuracy: 0.5352\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9771 - accuracy: 0.5283 - val_loss: 0.9643 - val_accuracy: 0.5339\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9637 - val_accuracy: 0.5365\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9772 - accuracy: 0.5278 - val_loss: 0.9641 - val_accuracy: 0.5365\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9771 - accuracy: 0.5267 - val_loss: 0.9642 - val_accuracy: 0.5365\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9770 - accuracy: 0.5275 - val_loss: 0.9639 - val_accuracy: 0.5361\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9640 - val_accuracy: 0.5361\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9769 - accuracy: 0.5290 - val_loss: 0.9635 - val_accuracy: 0.5365\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 0.9769 - accuracy: 0.5282 - val_loss: 0.9638 - val_accuracy: 0.5365\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 566us/step - loss: 0.9770 - accuracy: 0.5282 - val_loss: 0.9642 - val_accuracy: 0.5352\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9771 - accuracy: 0.5279 - val_loss: 0.9637 - val_accuracy: 0.5352\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9772 - accuracy: 0.5284 - val_loss: 0.9640 - val_accuracy: 0.5365\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9770 - accuracy: 0.5282 - val_loss: 0.9636 - val_accuracy: 0.5352\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9772 - accuracy: 0.5288 - val_loss: 0.9642 - val_accuracy: 0.5339\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9771 - accuracy: 0.5270 - val_loss: 0.9636 - val_accuracy: 0.5339\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9770 - accuracy: 0.5271 - val_loss: 0.9636 - val_accuracy: 0.5352\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9771 - accuracy: 0.5281 - val_loss: 0.9640 - val_accuracy: 0.5339\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9768 - accuracy: 0.5275 - val_loss: 0.9640 - val_accuracy: 0.5356\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9769 - accuracy: 0.5270 - val_loss: 0.9637 - val_accuracy: 0.5365\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9769 - accuracy: 0.5283 - val_loss: 0.9637 - val_accuracy: 0.5339\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5276 - val_loss: 0.9638 - val_accuracy: 0.5339\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9767 - accuracy: 0.5275 - val_loss: 0.9642 - val_accuracy: 0.5356\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5262 - val_loss: 0.9637 - val_accuracy: 0.5347\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9773 - accuracy: 0.5281 - val_loss: 0.9635 - val_accuracy: 0.5352\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 672us/step - loss: 0.9769 - accuracy: 0.5265 - val_loss: 0.9639 - val_accuracy: 0.5352\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9769 - accuracy: 0.5264 - val_loss: 0.9636 - val_accuracy: 0.5352\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9771 - accuracy: 0.5284 - val_loss: 0.9634 - val_accuracy: 0.5361\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9639 - val_accuracy: 0.5365\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9768 - accuracy: 0.5278 - val_loss: 0.9636 - val_accuracy: 0.5365\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9769 - accuracy: 0.5268 - val_loss: 0.9633 - val_accuracy: 0.5365\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 592us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9635 - val_accuracy: 0.5352\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9768 - accuracy: 0.5262 - val_loss: 0.9637 - val_accuracy: 0.5365\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9769 - accuracy: 0.5293 - val_loss: 0.9641 - val_accuracy: 0.5339\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9640 - val_accuracy: 0.5352\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9769 - accuracy: 0.5263 - val_loss: 0.9632 - val_accuracy: 0.5365\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9781 - accuracy: 0.5274 - val_loss: 0.9628 - val_accuracy: 0.5365\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5284 - val_loss: 0.9633 - val_accuracy: 0.5352\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9771 - accuracy: 0.5284 - val_loss: 0.9630 - val_accuracy: 0.5352\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9769 - accuracy: 0.5255 - val_loss: 0.9630 - val_accuracy: 0.5352\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 658us/step - loss: 0.9769 - accuracy: 0.5281 - val_loss: 0.9632 - val_accuracy: 0.5365\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9768 - accuracy: 0.5264 - val_loss: 0.9636 - val_accuracy: 0.5352\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9768 - accuracy: 0.5261 - val_loss: 0.9633 - val_accuracy: 0.5352\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9767 - accuracy: 0.5282 - val_loss: 0.9634 - val_accuracy: 0.5356\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 664us/step - loss: 0.9768 - accuracy: 0.5263 - val_loss: 0.9633 - val_accuracy: 0.5339\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9767 - accuracy: 0.5264 - val_loss: 0.9630 - val_accuracy: 0.5365\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9633 - val_accuracy: 0.5352\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9768 - accuracy: 0.5283 - val_loss: 0.9635 - val_accuracy: 0.5352\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9767 - accuracy: 0.5287 - val_loss: 0.9635 - val_accuracy: 0.5347\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9766 - accuracy: 0.5279 - val_loss: 0.9634 - val_accuracy: 0.5356\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9766 - accuracy: 0.5271 - val_loss: 0.9631 - val_accuracy: 0.5365\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9767 - accuracy: 0.5271 - val_loss: 0.9634 - val_accuracy: 0.5352\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9633 - val_accuracy: 0.5365\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9766 - accuracy: 0.5268 - val_loss: 0.9632 - val_accuracy: 0.5365\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9767 - accuracy: 0.5268 - val_loss: 0.9634 - val_accuracy: 0.5352\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9766 - accuracy: 0.5279 - val_loss: 0.9631 - val_accuracy: 0.5365\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9767 - accuracy: 0.5291 - val_loss: 0.9633 - val_accuracy: 0.5352\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9767 - accuracy: 0.5261 - val_loss: 0.9633 - val_accuracy: 0.5365\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9766 - accuracy: 0.5280 - val_loss: 0.9635 - val_accuracy: 0.5365\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9766 - accuracy: 0.5284 - val_loss: 0.9632 - val_accuracy: 0.5365\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9768 - accuracy: 0.5286 - val_loss: 0.9636 - val_accuracy: 0.5352\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9768 - accuracy: 0.5279 - val_loss: 0.9638 - val_accuracy: 0.5356\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9766 - accuracy: 0.5267 - val_loss: 0.9633 - val_accuracy: 0.5361\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9766 - accuracy: 0.5292 - val_loss: 0.9636 - val_accuracy: 0.5352\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9766 - accuracy: 0.5263 - val_loss: 0.9633 - val_accuracy: 0.5352\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9772 - accuracy: 0.5290 - val_loss: 0.9630 - val_accuracy: 0.5361\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9767 - accuracy: 0.5280 - val_loss: 0.9631 - val_accuracy: 0.5365\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9766 - accuracy: 0.5281 - val_loss: 0.9634 - val_accuracy: 0.5352\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9766 - accuracy: 0.5280 - val_loss: 0.9634 - val_accuracy: 0.5352\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9766 - accuracy: 0.5278 - val_loss: 0.9637 - val_accuracy: 0.5365\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9767 - accuracy: 0.5290 - val_loss: 0.9631 - val_accuracy: 0.5352\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9765 - accuracy: 0.5282 - val_loss: 0.9632 - val_accuracy: 0.5365\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 665us/step - loss: 0.9765 - accuracy: 0.5276 - val_loss: 0.9634 - val_accuracy: 0.5352\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 567us/step - loss: 0.9765 - accuracy: 0.5277 - val_loss: 0.9633 - val_accuracy: 0.5339\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9766 - accuracy: 0.5257 - val_loss: 0.9627 - val_accuracy: 0.5365\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9766 - accuracy: 0.5288 - val_loss: 0.9630 - val_accuracy: 0.5365\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9767 - accuracy: 0.5281 - val_loss: 0.9630 - val_accuracy: 0.5365\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9765 - accuracy: 0.5274 - val_loss: 0.9633 - val_accuracy: 0.5352\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9764 - accuracy: 0.5275 - val_loss: 0.9633 - val_accuracy: 0.5365\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9764 - accuracy: 0.5289 - val_loss: 0.9638 - val_accuracy: 0.5339\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9766 - accuracy: 0.5259 - val_loss: 0.9632 - val_accuracy: 0.5365\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9769 - accuracy: 0.5249 - val_loss: 0.9633 - val_accuracy: 0.5352\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 709us/step - loss: 0.9766 - accuracy: 0.5269 - val_loss: 0.9632 - val_accuracy: 0.5339\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9765 - accuracy: 0.5269 - val_loss: 0.9634 - val_accuracy: 0.5352\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9764 - accuracy: 0.5276 - val_loss: 0.9631 - val_accuracy: 0.5352\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 355us/step - loss: 0.9763 - accuracy: 0.5281\n",
      "Accuracy : 0.5280578136444092\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9631 - accuracy: 0.5352\n",
      "Accuracy : 0.5351925492286682\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0645 - accuracy: 0.4522 - val_loss: 0.9798 - val_accuracy: 0.5215\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 673us/step - loss: 1.0034 - accuracy: 0.4992 - val_loss: 0.9673 - val_accuracy: 0.5436\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9940 - accuracy: 0.5198 - val_loss: 0.9590 - val_accuracy: 0.5423\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9901 - accuracy: 0.5214 - val_loss: 0.9543 - val_accuracy: 0.5436\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9873 - accuracy: 0.5232 - val_loss: 0.9516 - val_accuracy: 0.5423\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9854 - accuracy: 0.5249 - val_loss: 0.9509 - val_accuracy: 0.5454\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9843 - accuracy: 0.5259 - val_loss: 0.9490 - val_accuracy: 0.5432\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9836 - accuracy: 0.5266 - val_loss: 0.9486 - val_accuracy: 0.5440\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9826 - accuracy: 0.5279 - val_loss: 0.9468 - val_accuracy: 0.5449\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9823 - accuracy: 0.5267 - val_loss: 0.9469 - val_accuracy: 0.5440\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9820 - accuracy: 0.5270 - val_loss: 0.9460 - val_accuracy: 0.5440\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9819 - accuracy: 0.5275 - val_loss: 0.9463 - val_accuracy: 0.5423\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9814 - accuracy: 0.5285 - val_loss: 0.9460 - val_accuracy: 0.5423\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9813 - accuracy: 0.5274 - val_loss: 0.9459 - val_accuracy: 0.5436\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9813 - accuracy: 0.5280 - val_loss: 0.9458 - val_accuracy: 0.5440\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9811 - accuracy: 0.5283 - val_loss: 0.9464 - val_accuracy: 0.5432\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9810 - accuracy: 0.5285 - val_loss: 0.9450 - val_accuracy: 0.5440\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9812 - accuracy: 0.5278 - val_loss: 0.9453 - val_accuracy: 0.5418\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9811 - accuracy: 0.5276 - val_loss: 0.9453 - val_accuracy: 0.5436\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9809 - accuracy: 0.5280 - val_loss: 0.9454 - val_accuracy: 0.5436\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9809 - accuracy: 0.5289 - val_loss: 0.9456 - val_accuracy: 0.5414\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9808 - accuracy: 0.5281 - val_loss: 0.9451 - val_accuracy: 0.5414\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9809 - accuracy: 0.5275 - val_loss: 0.9452 - val_accuracy: 0.5436\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9807 - accuracy: 0.5284 - val_loss: 0.9458 - val_accuracy: 0.5432\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9809 - accuracy: 0.5288 - val_loss: 0.9457 - val_accuracy: 0.5427\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9806 - accuracy: 0.5285 - val_loss: 0.9448 - val_accuracy: 0.5436\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9805 - accuracy: 0.5288 - val_loss: 0.9448 - val_accuracy: 0.5427\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9806 - accuracy: 0.5285 - val_loss: 0.9447 - val_accuracy: 0.5432\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9805 - accuracy: 0.5289 - val_loss: 0.9448 - val_accuracy: 0.5427\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9808 - accuracy: 0.5285 - val_loss: 0.9453 - val_accuracy: 0.5432\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9807 - accuracy: 0.5282 - val_loss: 0.9453 - val_accuracy: 0.5432\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9807 - accuracy: 0.5287 - val_loss: 0.9448 - val_accuracy: 0.5432\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9804 - accuracy: 0.5289 - val_loss: 0.9441 - val_accuracy: 0.5436\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9805 - accuracy: 0.5282 - val_loss: 0.9442 - val_accuracy: 0.5436\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9804 - accuracy: 0.5288 - val_loss: 0.9444 - val_accuracy: 0.5432\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9805 - accuracy: 0.5284 - val_loss: 0.9449 - val_accuracy: 0.5436\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9804 - accuracy: 0.5286 - val_loss: 0.9453 - val_accuracy: 0.5432\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9804 - accuracy: 0.5287 - val_loss: 0.9443 - val_accuracy: 0.5427\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9807 - accuracy: 0.5287 - val_loss: 0.9450 - val_accuracy: 0.5436\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9804 - accuracy: 0.5285 - val_loss: 0.9451 - val_accuracy: 0.5436\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9803 - accuracy: 0.5294 - val_loss: 0.9445 - val_accuracy: 0.5427\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 660us/step - loss: 0.9804 - accuracy: 0.5277 - val_loss: 0.9449 - val_accuracy: 0.5440\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9803 - accuracy: 0.5274 - val_loss: 0.9447 - val_accuracy: 0.5427\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9806 - accuracy: 0.5285 - val_loss: 0.9461 - val_accuracy: 0.5432\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9803 - accuracy: 0.5290 - val_loss: 0.9447 - val_accuracy: 0.5427\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9803 - accuracy: 0.5291 - val_loss: 0.9452 - val_accuracy: 0.5414\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9804 - accuracy: 0.5285 - val_loss: 0.9446 - val_accuracy: 0.5414\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9803 - accuracy: 0.5280 - val_loss: 0.9447 - val_accuracy: 0.5427\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9803 - accuracy: 0.5296 - val_loss: 0.9442 - val_accuracy: 0.5414\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9802 - accuracy: 0.5286 - val_loss: 0.9440 - val_accuracy: 0.5432\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9802 - accuracy: 0.5291 - val_loss: 0.9440 - val_accuracy: 0.5432\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9804 - accuracy: 0.5281 - val_loss: 0.9442 - val_accuracy: 0.5436\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9803 - accuracy: 0.5303 - val_loss: 0.9444 - val_accuracy: 0.5427\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9804 - accuracy: 0.5279 - val_loss: 0.9446 - val_accuracy: 0.5436\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9804 - accuracy: 0.5277 - val_loss: 0.9444 - val_accuracy: 0.5436\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9802 - accuracy: 0.5286 - val_loss: 0.9443 - val_accuracy: 0.5436\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9802 - accuracy: 0.5280 - val_loss: 0.9444 - val_accuracy: 0.5436\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9802 - accuracy: 0.5295 - val_loss: 0.9444 - val_accuracy: 0.5427\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 632us/step - loss: 0.9802 - accuracy: 0.5295 - val_loss: 0.9440 - val_accuracy: 0.5432\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9805 - accuracy: 0.5296 - val_loss: 0.9440 - val_accuracy: 0.5427\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9802 - accuracy: 0.5290 - val_loss: 0.9438 - val_accuracy: 0.5427\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9803 - accuracy: 0.5294 - val_loss: 0.9436 - val_accuracy: 0.5436\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9802 - accuracy: 0.5284 - val_loss: 0.9443 - val_accuracy: 0.5436\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9803 - accuracy: 0.5283 - val_loss: 0.9443 - val_accuracy: 0.5436\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9801 - accuracy: 0.5299 - val_loss: 0.9442 - val_accuracy: 0.5427\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9802 - accuracy: 0.5285 - val_loss: 0.9443 - val_accuracy: 0.5432\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9803 - accuracy: 0.5291 - val_loss: 0.9439 - val_accuracy: 0.5427\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9802 - accuracy: 0.5288 - val_loss: 0.9446 - val_accuracy: 0.5432\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9803 - accuracy: 0.5282 - val_loss: 0.9439 - val_accuracy: 0.5414\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 708us/step - loss: 0.9806 - accuracy: 0.5288 - val_loss: 0.9450 - val_accuracy: 0.5414\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9801 - accuracy: 0.5288 - val_loss: 0.9442 - val_accuracy: 0.5427\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9803 - accuracy: 0.5293 - val_loss: 0.9444 - val_accuracy: 0.5414\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9801 - accuracy: 0.5297 - val_loss: 0.9438 - val_accuracy: 0.5427\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9802 - accuracy: 0.5283 - val_loss: 0.9439 - val_accuracy: 0.5436\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9800 - accuracy: 0.5286 - val_loss: 0.9442 - val_accuracy: 0.5414\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9800 - accuracy: 0.5285 - val_loss: 0.9438 - val_accuracy: 0.5427\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9801 - accuracy: 0.5291 - val_loss: 0.9437 - val_accuracy: 0.5427\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9801 - accuracy: 0.5294 - val_loss: 0.9444 - val_accuracy: 0.5436\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9805 - accuracy: 0.5280 - val_loss: 0.9445 - val_accuracy: 0.5427\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9801 - accuracy: 0.5292 - val_loss: 0.9442 - val_accuracy: 0.5418\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9801 - accuracy: 0.5289 - val_loss: 0.9438 - val_accuracy: 0.5432\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9799 - accuracy: 0.5290 - val_loss: 0.9438 - val_accuracy: 0.5427\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9801 - accuracy: 0.5284 - val_loss: 0.9438 - val_accuracy: 0.5440\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9799 - accuracy: 0.5283 - val_loss: 0.9442 - val_accuracy: 0.5418\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9801 - accuracy: 0.5280 - val_loss: 0.9440 - val_accuracy: 0.5427\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9799 - accuracy: 0.5292 - val_loss: 0.9436 - val_accuracy: 0.5432\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9802 - accuracy: 0.5289 - val_loss: 0.9444 - val_accuracy: 0.5414\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9800 - accuracy: 0.5293 - val_loss: 0.9438 - val_accuracy: 0.5432\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9799 - accuracy: 0.5295 - val_loss: 0.9436 - val_accuracy: 0.5427\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9799 - accuracy: 0.5288 - val_loss: 0.9435 - val_accuracy: 0.5440\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9799 - accuracy: 0.5285 - val_loss: 0.9438 - val_accuracy: 0.5440\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9799 - accuracy: 0.5286 - val_loss: 0.9441 - val_accuracy: 0.5414\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9799 - accuracy: 0.5285 - val_loss: 0.9438 - val_accuracy: 0.5414\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9799 - accuracy: 0.5292 - val_loss: 0.9436 - val_accuracy: 0.5427\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9800 - accuracy: 0.5283 - val_loss: 0.9443 - val_accuracy: 0.5414\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9799 - accuracy: 0.5295 - val_loss: 0.9436 - val_accuracy: 0.5414\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9799 - accuracy: 0.5295 - val_loss: 0.9435 - val_accuracy: 0.5427\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9799 - accuracy: 0.5287 - val_loss: 0.9435 - val_accuracy: 0.5427\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9800 - accuracy: 0.5291 - val_loss: 0.9435 - val_accuracy: 0.5427\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9804 - accuracy: 0.5286 - val_loss: 0.9448 - val_accuracy: 0.5440\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9801 - accuracy: 0.5284 - val_loss: 0.9444 - val_accuracy: 0.5414\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9800 - accuracy: 0.5290 - val_loss: 0.9441 - val_accuracy: 0.5432\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9798 - accuracy: 0.5278 - val_loss: 0.9444 - val_accuracy: 0.5427\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9799 - accuracy: 0.5285 - val_loss: 0.9445 - val_accuracy: 0.5414\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9800 - accuracy: 0.5284 - val_loss: 0.9438 - val_accuracy: 0.5427\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9798 - accuracy: 0.5285 - val_loss: 0.9437 - val_accuracy: 0.5427\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9798 - accuracy: 0.5280 - val_loss: 0.9442 - val_accuracy: 0.5414\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9798 - accuracy: 0.5281 - val_loss: 0.9439 - val_accuracy: 0.5440\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9800 - accuracy: 0.5278 - val_loss: 0.9448 - val_accuracy: 0.5440\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9799 - accuracy: 0.5289 - val_loss: 0.9443 - val_accuracy: 0.5432\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9798 - accuracy: 0.5287 - val_loss: 0.9443 - val_accuracy: 0.5436\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9799 - accuracy: 0.5279 - val_loss: 0.9438 - val_accuracy: 0.5432\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9798 - accuracy: 0.5288 - val_loss: 0.9442 - val_accuracy: 0.5427\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9798 - accuracy: 0.5291 - val_loss: 0.9438 - val_accuracy: 0.5418\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9798 - accuracy: 0.5286 - val_loss: 0.9434 - val_accuracy: 0.5427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9800 - accuracy: 0.5292 - val_loss: 0.9437 - val_accuracy: 0.5414\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9800 - accuracy: 0.5287 - val_loss: 0.9437 - val_accuracy: 0.5414\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9799 - accuracy: 0.5291 - val_loss: 0.9436 - val_accuracy: 0.5427\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9796 - accuracy: 0.5294 - val_loss: 0.9434 - val_accuracy: 0.5427\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9799 - accuracy: 0.5293 - val_loss: 0.9436 - val_accuracy: 0.5440\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9799 - accuracy: 0.5280 - val_loss: 0.9440 - val_accuracy: 0.5440\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9798 - accuracy: 0.5280 - val_loss: 0.9437 - val_accuracy: 0.5427\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9797 - accuracy: 0.5285 - val_loss: 0.9435 - val_accuracy: 0.5440\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9797 - accuracy: 0.5282 - val_loss: 0.9432 - val_accuracy: 0.5427\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9797 - accuracy: 0.5287 - val_loss: 0.9436 - val_accuracy: 0.5427\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9796 - accuracy: 0.5284 - val_loss: 0.9434 - val_accuracy: 0.5432\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9796 - accuracy: 0.5288 - val_loss: 0.9437 - val_accuracy: 0.5436\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9797 - accuracy: 0.5285 - val_loss: 0.9435 - val_accuracy: 0.5432\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9796 - accuracy: 0.5296 - val_loss: 0.9433 - val_accuracy: 0.5427\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9800 - accuracy: 0.5294 - val_loss: 0.9434 - val_accuracy: 0.5440\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9799 - accuracy: 0.5282 - val_loss: 0.9445 - val_accuracy: 0.5445\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9798 - accuracy: 0.5277 - val_loss: 0.9440 - val_accuracy: 0.5432\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9798 - accuracy: 0.5280 - val_loss: 0.9437 - val_accuracy: 0.5409\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9798 - accuracy: 0.5280 - val_loss: 0.9436 - val_accuracy: 0.5440\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9800 - accuracy: 0.5270 - val_loss: 0.9443 - val_accuracy: 0.5440\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9796 - accuracy: 0.5286 - val_loss: 0.9438 - val_accuracy: 0.5440\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9796 - accuracy: 0.5290 - val_loss: 0.9440 - val_accuracy: 0.5414\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9797 - accuracy: 0.5293 - val_loss: 0.9435 - val_accuracy: 0.5440\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9797 - accuracy: 0.5285 - val_loss: 0.9441 - val_accuracy: 0.5418\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9796 - accuracy: 0.5291 - val_loss: 0.9434 - val_accuracy: 0.5432\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 665us/step - loss: 0.9795 - accuracy: 0.5291 - val_loss: 0.9432 - val_accuracy: 0.5414\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 568us/step - loss: 0.9795 - accuracy: 0.5288 - val_loss: 0.9435 - val_accuracy: 0.5432\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9798 - accuracy: 0.5286 - val_loss: 0.9432 - val_accuracy: 0.5414\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9796 - accuracy: 0.5293 - val_loss: 0.9431 - val_accuracy: 0.5432\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 642us/step - loss: 0.9796 - accuracy: 0.5291 - val_loss: 0.9441 - val_accuracy: 0.5432\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9796 - accuracy: 0.5286 - val_loss: 0.9435 - val_accuracy: 0.5414\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9796 - accuracy: 0.5292 - val_loss: 0.9435 - val_accuracy: 0.5427\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9795 - accuracy: 0.5291 - val_loss: 0.9431 - val_accuracy: 0.5414\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9797 - accuracy: 0.5292 - val_loss: 0.9432 - val_accuracy: 0.5414\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9796 - accuracy: 0.5285 - val_loss: 0.9432 - val_accuracy: 0.5440\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9796 - accuracy: 0.5281 - val_loss: 0.9435 - val_accuracy: 0.5427\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9794 - accuracy: 0.5295 - val_loss: 0.9433 - val_accuracy: 0.5432\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9796 - accuracy: 0.5281 - val_loss: 0.9443 - val_accuracy: 0.5427\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9801 - accuracy: 0.5268 - val_loss: 0.9447 - val_accuracy: 0.5440\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9797 - accuracy: 0.5292 - val_loss: 0.9441 - val_accuracy: 0.5436\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9795 - accuracy: 0.5285 - val_loss: 0.9432 - val_accuracy: 0.5440\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9796 - accuracy: 0.5281 - val_loss: 0.9442 - val_accuracy: 0.5414\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9795 - accuracy: 0.5291 - val_loss: 0.9433 - val_accuracy: 0.5427\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9794 - accuracy: 0.5285 - val_loss: 0.9435 - val_accuracy: 0.5432\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9795 - accuracy: 0.5293 - val_loss: 0.9430 - val_accuracy: 0.5427\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9796 - accuracy: 0.5290 - val_loss: 0.9430 - val_accuracy: 0.5440\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9796 - accuracy: 0.5280 - val_loss: 0.9432 - val_accuracy: 0.5440\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9796 - accuracy: 0.5283 - val_loss: 0.9440 - val_accuracy: 0.5418\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9794 - accuracy: 0.5285 - val_loss: 0.9435 - val_accuracy: 0.5436\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9796 - accuracy: 0.5275 - val_loss: 0.9436 - val_accuracy: 0.5436\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9794 - accuracy: 0.5290 - val_loss: 0.9440 - val_accuracy: 0.5436\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9795 - accuracy: 0.5277 - val_loss: 0.9440 - val_accuracy: 0.5414\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9795 - accuracy: 0.5286 - val_loss: 0.9432 - val_accuracy: 0.5449\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9796 - accuracy: 0.5276 - val_loss: 0.9439 - val_accuracy: 0.5427\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9431 - val_accuracy: 0.5414\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9796 - accuracy: 0.5293 - val_loss: 0.9431 - val_accuracy: 0.5427\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 600us/step - loss: 0.9795 - accuracy: 0.5289 - val_loss: 0.9435 - val_accuracy: 0.5432\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9794 - accuracy: 0.5293 - val_loss: 0.9430 - val_accuracy: 0.5414\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9793 - accuracy: 0.5299 - val_loss: 0.9434 - val_accuracy: 0.5414\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9795 - accuracy: 0.5285 - val_loss: 0.9431 - val_accuracy: 0.5414\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5283 - val_loss: 0.9434 - val_accuracy: 0.5432\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9795 - accuracy: 0.5288 - val_loss: 0.9433 - val_accuracy: 0.5414\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9795 - accuracy: 0.5286 - val_loss: 0.9430 - val_accuracy: 0.5432\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9794 - accuracy: 0.5279 - val_loss: 0.9431 - val_accuracy: 0.5436\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9793 - accuracy: 0.5284 - val_loss: 0.9432 - val_accuracy: 0.5440\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5285 - val_loss: 0.9432 - val_accuracy: 0.5418\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9795 - accuracy: 0.5288 - val_loss: 0.9431 - val_accuracy: 0.5414\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9793 - accuracy: 0.5288 - val_loss: 0.9433 - val_accuracy: 0.5418\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9794 - accuracy: 0.5295 - val_loss: 0.9432 - val_accuracy: 0.5427\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9795 - accuracy: 0.5287 - val_loss: 0.9431 - val_accuracy: 0.5440\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9794 - accuracy: 0.5279 - val_loss: 0.9432 - val_accuracy: 0.5436\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9793 - accuracy: 0.5284 - val_loss: 0.9440 - val_accuracy: 0.5436\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9795 - accuracy: 0.5295 - val_loss: 0.9434 - val_accuracy: 0.5414\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9793 - accuracy: 0.5281 - val_loss: 0.9431 - val_accuracy: 0.5440\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9793 - accuracy: 0.5280 - val_loss: 0.9433 - val_accuracy: 0.5449\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9794 - accuracy: 0.5278 - val_loss: 0.9438 - val_accuracy: 0.5436\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9793 - accuracy: 0.5289 - val_loss: 0.9435 - val_accuracy: 0.5414\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9793 - accuracy: 0.5288 - val_loss: 0.9430 - val_accuracy: 0.5427\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9800 - accuracy: 0.5291 - val_loss: 0.9445 - val_accuracy: 0.5414\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9794 - accuracy: 0.5288 - val_loss: 0.9437 - val_accuracy: 0.5427\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9794 - accuracy: 0.5291 - val_loss: 0.9443 - val_accuracy: 0.5418\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9792 - accuracy: 0.5293 - val_loss: 0.9435 - val_accuracy: 0.5414\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 565us/step - loss: 0.9792 - accuracy: 0.5295 - val_loss: 0.9437 - val_accuracy: 0.5414\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 665us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9431 - val_accuracy: 0.5414\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 563us/step - loss: 0.9793 - accuracy: 0.5279 - val_loss: 0.9435 - val_accuracy: 0.5427\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 346us/step - loss: 0.9791 - accuracy: 0.5290\n",
      "Accuracy : 0.5290414690971375\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9435 - accuracy: 0.5427\n",
      "Accuracy : 0.5427179932594299\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.2644 - accuracy: 0.3208 - val_loss: 1.1586 - val_accuracy: 0.3617\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 1.1467 - accuracy: 0.3677 - val_loss: 1.0918 - val_accuracy: 0.3962\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 1.0894 - accuracy: 0.4098 - val_loss: 1.0579 - val_accuracy: 0.4316\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 1.0552 - accuracy: 0.4503 - val_loss: 1.0325 - val_accuracy: 0.4591\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0289 - accuracy: 0.4590 - val_loss: 1.0173 - val_accuracy: 0.4595\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0167 - accuracy: 0.4590 - val_loss: 1.0110 - val_accuracy: 0.4595\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0115 - accuracy: 0.4590 - val_loss: 1.0084 - val_accuracy: 0.4595\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0089 - accuracy: 0.4590 - val_loss: 1.0072 - val_accuracy: 0.4595\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 1.0074 - accuracy: 0.4590 - val_loss: 1.0067 - val_accuracy: 0.4595\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 1.0065 - accuracy: 0.4590 - val_loss: 1.0060 - val_accuracy: 0.4595\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 1.0059 - accuracy: 0.4590 - val_loss: 1.0054 - val_accuracy: 0.4595\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 728us/step - loss: 1.0055 - accuracy: 0.4590 - val_loss: 1.0051 - val_accuracy: 0.4595\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0051 - accuracy: 0.4590 - val_loss: 1.0048 - val_accuracy: 0.4595\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0048 - accuracy: 0.4590 - val_loss: 1.0048 - val_accuracy: 0.4595\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0046 - accuracy: 0.4590 - val_loss: 1.0045 - val_accuracy: 0.4595\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0044 - accuracy: 0.4590 - val_loss: 1.0043 - val_accuracy: 0.4595\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 1.0041 - accuracy: 0.4590 - val_loss: 1.0041 - val_accuracy: 0.4595\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 1.0039 - accuracy: 0.4590 - val_loss: 1.0040 - val_accuracy: 0.4595\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 1.0037 - accuracy: 0.4588 - val_loss: 1.0037 - val_accuracy: 0.4591\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0036 - accuracy: 0.4591 - val_loss: 1.0036 - val_accuracy: 0.4591\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 1.0034 - accuracy: 0.4591 - val_loss: 1.0033 - val_accuracy: 0.4591\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0034 - accuracy: 0.4590 - val_loss: 1.0031 - val_accuracy: 0.4591\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0030 - accuracy: 0.4590 - val_loss: 1.0030 - val_accuracy: 0.4591\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 1.0029 - accuracy: 0.4590 - val_loss: 1.0028 - val_accuracy: 0.4591\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 1.0027 - accuracy: 0.4590 - val_loss: 1.0026 - val_accuracy: 0.4591\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 1.0026 - accuracy: 0.4590 - val_loss: 1.0024 - val_accuracy: 0.4591\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 583us/step - loss: 1.0023 - accuracy: 0.4590 - val_loss: 1.0023 - val_accuracy: 0.4591\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 1.0021 - accuracy: 0.4590 - val_loss: 1.0021 - val_accuracy: 0.4591\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 1.0020 - accuracy: 0.4590 - val_loss: 1.0018 - val_accuracy: 0.4591\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 1.0019 - accuracy: 0.4590 - val_loss: 1.0016 - val_accuracy: 0.4591\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 1.0016 - accuracy: 0.4590 - val_loss: 1.0015 - val_accuracy: 0.4591\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 1.0020 - accuracy: 0.4590 - val_loss: 1.0015 - val_accuracy: 0.4591\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0015 - accuracy: 0.4590 - val_loss: 1.0013 - val_accuracy: 0.4591\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 1.0016 - accuracy: 0.4590 - val_loss: 1.0012 - val_accuracy: 0.4591\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 1.0014 - accuracy: 0.4590 - val_loss: 1.0010 - val_accuracy: 0.4591\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 1.0013 - accuracy: 0.4590 - val_loss: 1.0009 - val_accuracy: 0.4591\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 1.0012 - accuracy: 0.4590 - val_loss: 1.0009 - val_accuracy: 0.4591\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 1.0011 - accuracy: 0.4590 - val_loss: 1.0009 - val_accuracy: 0.4591\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 1.0010 - accuracy: 0.4590 - val_loss: 1.0008 - val_accuracy: 0.4591\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0009 - accuracy: 0.4590 - val_loss: 1.0007 - val_accuracy: 0.4591\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 1.0009 - accuracy: 0.4590 - val_loss: 1.0009 - val_accuracy: 0.4591\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 1.0009 - accuracy: 0.4590 - val_loss: 1.0006 - val_accuracy: 0.4591\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 1.0009 - accuracy: 0.4590 - val_loss: 1.0008 - val_accuracy: 0.4591\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0012 - accuracy: 0.4590 - val_loss: 1.0008 - val_accuracy: 0.4591\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 1.0009 - accuracy: 0.4590 - val_loss: 1.0005 - val_accuracy: 0.4591\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0007 - accuracy: 0.4590 - val_loss: 1.0005 - val_accuracy: 0.4591\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 703us/step - loss: 1.0006 - accuracy: 0.4590 - val_loss: 1.0003 - val_accuracy: 0.4591\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 1.0007 - accuracy: 0.4590 - val_loss: 1.0004 - val_accuracy: 0.4591\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 1.0005 - accuracy: 0.4590 - val_loss: 1.0003 - val_accuracy: 0.4591\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 1.0005 - accuracy: 0.4590 - val_loss: 1.0001 - val_accuracy: 0.4591\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 660us/step - loss: 1.0006 - accuracy: 0.4590 - val_loss: 1.0000 - val_accuracy: 0.4591\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 1.0005 - accuracy: 0.4590 - val_loss: 1.0003 - val_accuracy: 0.4591\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 1.0005 - accuracy: 0.4590 - val_loss: 1.0002 - val_accuracy: 0.4591\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 1.0003 - accuracy: 0.4590 - val_loss: 0.9999 - val_accuracy: 0.4591\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 1.0004 - accuracy: 0.4590 - val_loss: 0.9999 - val_accuracy: 0.4591\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 1.0002 - accuracy: 0.4590 - val_loss: 1.0001 - val_accuracy: 0.4591\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 1.0002 - accuracy: 0.4590 - val_loss: 0.9999 - val_accuracy: 0.4591\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 1.0002 - accuracy: 0.4590 - val_loss: 1.0000 - val_accuracy: 0.4591\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 1.0002 - accuracy: 0.4590 - val_loss: 0.9997 - val_accuracy: 0.4591\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 1.0001 - accuracy: 0.4590 - val_loss: 0.9996 - val_accuracy: 0.4591\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 1.0000 - accuracy: 0.4590 - val_loss: 0.9996 - val_accuracy: 0.4591\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9999 - accuracy: 0.4592 - val_loss: 0.9996 - val_accuracy: 0.4591\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9999 - accuracy: 0.4596 - val_loss: 0.9997 - val_accuracy: 0.4591\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9999 - accuracy: 0.4615 - val_loss: 0.9993 - val_accuracy: 0.4613\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9997 - accuracy: 0.4632 - val_loss: 0.9992 - val_accuracy: 0.4613\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9998 - accuracy: 0.4637 - val_loss: 0.9993 - val_accuracy: 0.4644\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9997 - accuracy: 0.4645 - val_loss: 0.9993 - val_accuracy: 0.4688\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9997 - accuracy: 0.4677 - val_loss: 0.9991 - val_accuracy: 0.4692\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9996 - accuracy: 0.4735 - val_loss: 0.9988 - val_accuracy: 0.4745\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9997 - accuracy: 0.4736 - val_loss: 0.9990 - val_accuracy: 0.4816\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9995 - accuracy: 0.4775 - val_loss: 0.9989 - val_accuracy: 0.4905\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9994 - accuracy: 0.4791 - val_loss: 0.9989 - val_accuracy: 0.4954\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9992 - accuracy: 0.4832 - val_loss: 0.9989 - val_accuracy: 0.4971\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9992 - accuracy: 0.4853 - val_loss: 0.9988 - val_accuracy: 0.5007\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9988 - accuracy: 0.4889 - val_loss: 0.9981 - val_accuracy: 0.5007\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9990 - accuracy: 0.4914 - val_loss: 0.9983 - val_accuracy: 0.5020\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9985 - accuracy: 0.4975 - val_loss: 0.9979 - val_accuracy: 0.5086\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9983 - accuracy: 0.4981 - val_loss: 0.9982 - val_accuracy: 0.5144\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9984 - accuracy: 0.5024 - val_loss: 0.9976 - val_accuracy: 0.5148\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9979 - accuracy: 0.5061 - val_loss: 0.9976 - val_accuracy: 0.5148\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9979 - accuracy: 0.5062 - val_loss: 0.9972 - val_accuracy: 0.5148\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9975 - accuracy: 0.5114 - val_loss: 0.9969 - val_accuracy: 0.5166\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9987 - accuracy: 0.5175 - val_loss: 0.9961 - val_accuracy: 0.5166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9967 - accuracy: 0.5195 - val_loss: 0.9957 - val_accuracy: 0.5179\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9961 - accuracy: 0.5192 - val_loss: 0.9952 - val_accuracy: 0.5237\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9958 - accuracy: 0.5227 - val_loss: 0.9949 - val_accuracy: 0.5224\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9964 - accuracy: 0.5270 - val_loss: 0.9950 - val_accuracy: 0.5246\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9942 - accuracy: 0.5231 - val_loss: 0.9931 - val_accuracy: 0.5224\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9933 - accuracy: 0.5247 - val_loss: 0.9917 - val_accuracy: 0.5246\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9920 - accuracy: 0.5264 - val_loss: 0.9901 - val_accuracy: 0.5232\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9899 - accuracy: 0.5279 - val_loss: 0.9877 - val_accuracy: 0.5228\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9875 - accuracy: 0.5284 - val_loss: 0.9843 - val_accuracy: 0.5272\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9849 - accuracy: 0.5288 - val_loss: 0.9811 - val_accuracy: 0.5308\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9827 - accuracy: 0.5292 - val_loss: 0.9781 - val_accuracy: 0.5286\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9808 - accuracy: 0.5290 - val_loss: 0.9758 - val_accuracy: 0.5286\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9797 - accuracy: 0.5289 - val_loss: 0.9744 - val_accuracy: 0.5290\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9790 - accuracy: 0.5281 - val_loss: 0.9733 - val_accuracy: 0.5290\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9791 - accuracy: 0.5286 - val_loss: 0.9722 - val_accuracy: 0.5308\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9781 - accuracy: 0.5295 - val_loss: 0.9724 - val_accuracy: 0.5286\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9780 - accuracy: 0.5291 - val_loss: 0.9720 - val_accuracy: 0.5290\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9776 - accuracy: 0.5284 - val_loss: 0.9705 - val_accuracy: 0.5272\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9775 - accuracy: 0.5291 - val_loss: 0.9702 - val_accuracy: 0.5272\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9771 - accuracy: 0.5289 - val_loss: 0.9710 - val_accuracy: 0.5308\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9776 - accuracy: 0.5289 - val_loss: 0.9699 - val_accuracy: 0.5272\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9770 - accuracy: 0.5297 - val_loss: 0.9696 - val_accuracy: 0.5263\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9772 - accuracy: 0.5294 - val_loss: 0.9693 - val_accuracy: 0.5268\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9768 - accuracy: 0.5287 - val_loss: 0.9695 - val_accuracy: 0.5263\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9767 - accuracy: 0.5294 - val_loss: 0.9688 - val_accuracy: 0.5241\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9768 - accuracy: 0.5290 - val_loss: 0.9697 - val_accuracy: 0.5272\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9766 - accuracy: 0.5289 - val_loss: 0.9689 - val_accuracy: 0.5263\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9766 - accuracy: 0.5287 - val_loss: 0.9691 - val_accuracy: 0.5259\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9766 - accuracy: 0.5285 - val_loss: 0.9700 - val_accuracy: 0.5268\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9780 - accuracy: 0.5295 - val_loss: 0.9690 - val_accuracy: 0.5263\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9766 - accuracy: 0.5285 - val_loss: 0.9692 - val_accuracy: 0.5272\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9766 - accuracy: 0.5287 - val_loss: 0.9688 - val_accuracy: 0.5263\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 586us/step - loss: 0.9765 - accuracy: 0.5283 - val_loss: 0.9691 - val_accuracy: 0.5272\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9764 - accuracy: 0.5292 - val_loss: 0.9683 - val_accuracy: 0.5241\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9766 - accuracy: 0.5283 - val_loss: 0.9687 - val_accuracy: 0.5263\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9765 - accuracy: 0.5289 - val_loss: 0.9687 - val_accuracy: 0.5263\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9766 - accuracy: 0.5287 - val_loss: 0.9684 - val_accuracy: 0.5263\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5281 - val_loss: 0.9688 - val_accuracy: 0.5259\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9767 - accuracy: 0.5287 - val_loss: 0.9683 - val_accuracy: 0.5268\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9763 - accuracy: 0.5295 - val_loss: 0.9683 - val_accuracy: 0.5241\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9764 - accuracy: 0.5288 - val_loss: 0.9683 - val_accuracy: 0.5241\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9764 - accuracy: 0.5285 - val_loss: 0.9682 - val_accuracy: 0.5241\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9763 - accuracy: 0.5276 - val_loss: 0.9688 - val_accuracy: 0.5263\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9762 - accuracy: 0.5296 - val_loss: 0.9687 - val_accuracy: 0.5263\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9766 - accuracy: 0.5291 - val_loss: 0.9688 - val_accuracy: 0.5263\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9766 - accuracy: 0.5294 - val_loss: 0.9682 - val_accuracy: 0.5268\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9762 - accuracy: 0.5281 - val_loss: 0.9687 - val_accuracy: 0.5263\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9762 - accuracy: 0.5288 - val_loss: 0.9687 - val_accuracy: 0.5263\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9763 - accuracy: 0.5286 - val_loss: 0.9681 - val_accuracy: 0.5237\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9764 - accuracy: 0.5288 - val_loss: 0.9681 - val_accuracy: 0.5241\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9761 - accuracy: 0.5278 - val_loss: 0.9695 - val_accuracy: 0.5272\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9780 - accuracy: 0.5285 - val_loss: 0.9685 - val_accuracy: 0.5268\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9766 - accuracy: 0.5292 - val_loss: 0.9682 - val_accuracy: 0.5241\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9762 - accuracy: 0.5283 - val_loss: 0.9683 - val_accuracy: 0.5241\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9762 - accuracy: 0.5287 - val_loss: 0.9685 - val_accuracy: 0.5263\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9682 - val_accuracy: 0.5263\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 613us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9681 - val_accuracy: 0.5241\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9763 - accuracy: 0.5284 - val_loss: 0.9684 - val_accuracy: 0.5268\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9762 - accuracy: 0.5297 - val_loss: 0.9680 - val_accuracy: 0.5241\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9762 - accuracy: 0.5280 - val_loss: 0.9681 - val_accuracy: 0.5241\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9762 - accuracy: 0.5293 - val_loss: 0.9685 - val_accuracy: 0.5263\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9763 - accuracy: 0.5293 - val_loss: 0.9681 - val_accuracy: 0.5268\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9762 - accuracy: 0.5290 - val_loss: 0.9682 - val_accuracy: 0.5268\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9761 - accuracy: 0.5289 - val_loss: 0.9685 - val_accuracy: 0.5263\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9762 - accuracy: 0.5297 - val_loss: 0.9680 - val_accuracy: 0.5237\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9761 - accuracy: 0.5295 - val_loss: 0.9682 - val_accuracy: 0.5268\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9760 - accuracy: 0.5292 - val_loss: 0.9680 - val_accuracy: 0.5263\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9761 - accuracy: 0.5297 - val_loss: 0.9684 - val_accuracy: 0.5259\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9763 - accuracy: 0.5291 - val_loss: 0.9681 - val_accuracy: 0.5241\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9762 - accuracy: 0.5293 - val_loss: 0.9683 - val_accuracy: 0.5263\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9761 - accuracy: 0.5287 - val_loss: 0.9685 - val_accuracy: 0.5263\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9763 - accuracy: 0.5296 - val_loss: 0.9686 - val_accuracy: 0.5259\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9762 - accuracy: 0.5296 - val_loss: 0.9683 - val_accuracy: 0.5263\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9761 - accuracy: 0.5289 - val_loss: 0.9681 - val_accuracy: 0.5263\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9762 - accuracy: 0.5290 - val_loss: 0.9686 - val_accuracy: 0.5259\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9761 - accuracy: 0.5303 - val_loss: 0.9686 - val_accuracy: 0.5272\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9761 - accuracy: 0.5291 - val_loss: 0.9682 - val_accuracy: 0.5263\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9761 - accuracy: 0.5294 - val_loss: 0.9680 - val_accuracy: 0.5263\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9761 - accuracy: 0.5293 - val_loss: 0.9682 - val_accuracy: 0.5263\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9762 - accuracy: 0.5290 - val_loss: 0.9683 - val_accuracy: 0.5263\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9761 - accuracy: 0.5294 - val_loss: 0.9683 - val_accuracy: 0.5263\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9761 - accuracy: 0.5284 - val_loss: 0.9687 - val_accuracy: 0.5259\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9761 - accuracy: 0.5305 - val_loss: 0.9686 - val_accuracy: 0.5272\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9763 - accuracy: 0.5290 - val_loss: 0.9681 - val_accuracy: 0.5263\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9760 - accuracy: 0.5302 - val_loss: 0.9681 - val_accuracy: 0.5263\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9761 - accuracy: 0.5295 - val_loss: 0.9679 - val_accuracy: 0.5237\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 622us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9683 - val_accuracy: 0.5259\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9761 - accuracy: 0.5295 - val_loss: 0.9681 - val_accuracy: 0.5263\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9763 - accuracy: 0.5289 - val_loss: 0.9683 - val_accuracy: 0.5263\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9760 - accuracy: 0.5292 - val_loss: 0.9688 - val_accuracy: 0.5272\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9786 - accuracy: 0.5282 - val_loss: 0.9695 - val_accuracy: 0.5268\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9762 - accuracy: 0.5285 - val_loss: 0.9686 - val_accuracy: 0.5241\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9761 - accuracy: 0.5282 - val_loss: 0.9688 - val_accuracy: 0.5237\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9759 - accuracy: 0.5281 - val_loss: 0.9685 - val_accuracy: 0.5241\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9760 - accuracy: 0.5292 - val_loss: 0.9681 - val_accuracy: 0.5232\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9760 - accuracy: 0.5280 - val_loss: 0.9683 - val_accuracy: 0.5241\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9760 - accuracy: 0.5294 - val_loss: 0.9680 - val_accuracy: 0.5241\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9759 - accuracy: 0.5280 - val_loss: 0.9681 - val_accuracy: 0.5263\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9759 - accuracy: 0.5283 - val_loss: 0.9681 - val_accuracy: 0.5268\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 641us/step - loss: 0.9759 - accuracy: 0.5287 - val_loss: 0.9680 - val_accuracy: 0.5237\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9680 - val_accuracy: 0.5263\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9758 - accuracy: 0.5293 - val_loss: 0.9677 - val_accuracy: 0.5237\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9760 - accuracy: 0.5289 - val_loss: 0.9682 - val_accuracy: 0.5263\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9760 - accuracy: 0.5293 - val_loss: 0.9680 - val_accuracy: 0.5263\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9760 - accuracy: 0.5296 - val_loss: 0.9683 - val_accuracy: 0.5259\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9760 - accuracy: 0.5290 - val_loss: 0.9678 - val_accuracy: 0.5237\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9759 - accuracy: 0.5295 - val_loss: 0.9679 - val_accuracy: 0.5263\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9681 - val_accuracy: 0.5263\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9761 - accuracy: 0.5291 - val_loss: 0.9681 - val_accuracy: 0.5263\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9759 - accuracy: 0.5300 - val_loss: 0.9690 - val_accuracy: 0.5259\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 679us/step - loss: 0.9783 - accuracy: 0.5287 - val_loss: 0.9687 - val_accuracy: 0.5263\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9683 - val_accuracy: 0.5263\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 591us/step - loss: 0.9759 - accuracy: 0.5295 - val_loss: 0.9681 - val_accuracy: 0.5263\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9759 - accuracy: 0.5299 - val_loss: 0.9679 - val_accuracy: 0.5263\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9680 - val_accuracy: 0.5263\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 575us/step - loss: 0.9758 - accuracy: 0.5294 - val_loss: 0.9681 - val_accuracy: 0.5263\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9758 - accuracy: 0.5294 - val_loss: 0.9677 - val_accuracy: 0.5237\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 339us/step - loss: 0.9757 - accuracy: 0.5297\n",
      "Accuracy : 0.5297300219535828\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9677 - accuracy: 0.5237\n",
      "Accuracy : 0.5236830711364746\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.6027 - accuracy: 0.4614 - val_loss: 1.4899 - val_accuracy: 0.4688\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 1.2833 - accuracy: 0.4558 - val_loss: 1.2595 - val_accuracy: 0.4683\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 1.1627 - accuracy: 0.4532 - val_loss: 1.1690 - val_accuracy: 0.4626\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 1.1053 - accuracy: 0.4541 - val_loss: 1.1051 - val_accuracy: 0.4653\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 1.0636 - accuracy: 0.4614 - val_loss: 1.0553 - val_accuracy: 0.4768\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0310 - accuracy: 0.4823 - val_loss: 1.0161 - val_accuracy: 0.4896\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 1.0081 - accuracy: 0.5076 - val_loss: 0.9899 - val_accuracy: 0.5166\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9937 - accuracy: 0.5268 - val_loss: 0.9747 - val_accuracy: 0.5286\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9861 - accuracy: 0.5275 - val_loss: 0.9666 - val_accuracy: 0.5339\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9829 - accuracy: 0.5292 - val_loss: 0.9650 - val_accuracy: 0.5347\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9812 - accuracy: 0.5300 - val_loss: 0.9632 - val_accuracy: 0.5352\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9806 - accuracy: 0.5302 - val_loss: 0.9626 - val_accuracy: 0.5343\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9806 - accuracy: 0.5288 - val_loss: 0.9617 - val_accuracy: 0.5356\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9795 - accuracy: 0.5300 - val_loss: 0.9615 - val_accuracy: 0.5343\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9796 - accuracy: 0.5287 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9793 - accuracy: 0.5301 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9790 - accuracy: 0.5300 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9791 - accuracy: 0.5295 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9789 - accuracy: 0.5294 - val_loss: 0.9622 - val_accuracy: 0.5347\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9790 - accuracy: 0.5306 - val_loss: 0.9629 - val_accuracy: 0.5347\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9789 - accuracy: 0.5296 - val_loss: 0.9626 - val_accuracy: 0.5356\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9790 - accuracy: 0.5300 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9792 - accuracy: 0.5292 - val_loss: 0.9616 - val_accuracy: 0.5374\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9785 - accuracy: 0.5307 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9787 - accuracy: 0.5302 - val_loss: 0.9628 - val_accuracy: 0.5343\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9785 - accuracy: 0.5299 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9786 - accuracy: 0.5295 - val_loss: 0.9615 - val_accuracy: 0.5374\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9785 - accuracy: 0.5298 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9785 - accuracy: 0.5306 - val_loss: 0.9617 - val_accuracy: 0.5374\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9782 - accuracy: 0.5297 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9782 - accuracy: 0.5298 - val_loss: 0.9627 - val_accuracy: 0.5317\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9782 - accuracy: 0.5307 - val_loss: 0.9619 - val_accuracy: 0.5378\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9782 - accuracy: 0.5296 - val_loss: 0.9626 - val_accuracy: 0.5374\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9786 - accuracy: 0.5291 - val_loss: 0.9615 - val_accuracy: 0.5356\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9780 - accuracy: 0.5303 - val_loss: 0.9621 - val_accuracy: 0.5343\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9779 - accuracy: 0.5302 - val_loss: 0.9615 - val_accuracy: 0.5343\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9786 - accuracy: 0.5305 - val_loss: 0.9619 - val_accuracy: 0.5378\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9778 - accuracy: 0.5290 - val_loss: 0.9613 - val_accuracy: 0.5374\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9783 - accuracy: 0.5299 - val_loss: 0.9618 - val_accuracy: 0.5356\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9777 - accuracy: 0.5303 - val_loss: 0.9611 - val_accuracy: 0.5339\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9781 - accuracy: 0.5308 - val_loss: 0.9622 - val_accuracy: 0.5325\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9777 - accuracy: 0.5297 - val_loss: 0.9619 - val_accuracy: 0.5339\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9776 - accuracy: 0.5299 - val_loss: 0.9615 - val_accuracy: 0.5356\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9778 - accuracy: 0.5297 - val_loss: 0.9618 - val_accuracy: 0.5325\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9776 - accuracy: 0.5296 - val_loss: 0.9612 - val_accuracy: 0.5339\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9778 - accuracy: 0.5315 - val_loss: 0.9614 - val_accuracy: 0.5339\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9775 - accuracy: 0.5304 - val_loss: 0.9629 - val_accuracy: 0.5339\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9776 - accuracy: 0.5313 - val_loss: 0.9620 - val_accuracy: 0.5339\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9775 - accuracy: 0.5306 - val_loss: 0.9621 - val_accuracy: 0.5339\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9774 - accuracy: 0.5303 - val_loss: 0.9614 - val_accuracy: 0.5334\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 635us/step - loss: 0.9777 - accuracy: 0.5301 - val_loss: 0.9615 - val_accuracy: 0.5325\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9777 - accuracy: 0.5301 - val_loss: 0.9612 - val_accuracy: 0.5317\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9778 - accuracy: 0.5298 - val_loss: 0.9615 - val_accuracy: 0.5321\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9775 - accuracy: 0.5304 - val_loss: 0.9614 - val_accuracy: 0.5321\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5297 - val_loss: 0.9618 - val_accuracy: 0.5378\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9775 - accuracy: 0.5304 - val_loss: 0.9619 - val_accuracy: 0.5339\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5297 - val_loss: 0.9618 - val_accuracy: 0.5325\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9774 - accuracy: 0.5308 - val_loss: 0.9623 - val_accuracy: 0.5356\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9774 - accuracy: 0.5289 - val_loss: 0.9616 - val_accuracy: 0.5317\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9773 - accuracy: 0.5307 - val_loss: 0.9629 - val_accuracy: 0.5321\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9775 - accuracy: 0.5292 - val_loss: 0.9626 - val_accuracy: 0.5317\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9772 - accuracy: 0.5294 - val_loss: 0.9611 - val_accuracy: 0.5339\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9774 - accuracy: 0.5296 - val_loss: 0.9622 - val_accuracy: 0.5321\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9773 - accuracy: 0.5299 - val_loss: 0.9625 - val_accuracy: 0.5339\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9773 - accuracy: 0.5306 - val_loss: 0.9618 - val_accuracy: 0.5325\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9619 - val_accuracy: 0.5321\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9771 - accuracy: 0.5301 - val_loss: 0.9623 - val_accuracy: 0.5321\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5292 - val_loss: 0.9618 - val_accuracy: 0.5339\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9775 - accuracy: 0.5303 - val_loss: 0.9632 - val_accuracy: 0.5325\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9773 - accuracy: 0.5279 - val_loss: 0.9628 - val_accuracy: 0.5339\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9772 - accuracy: 0.5299 - val_loss: 0.9616 - val_accuracy: 0.5325\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9625 - val_accuracy: 0.5325\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9770 - accuracy: 0.5295 - val_loss: 0.9614 - val_accuracy: 0.5330\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 606us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9611 - val_accuracy: 0.5325\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5296 - val_loss: 0.9621 - val_accuracy: 0.5325\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9772 - accuracy: 0.5284 - val_loss: 0.9611 - val_accuracy: 0.5321\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9770 - accuracy: 0.5294 - val_loss: 0.9621 - val_accuracy: 0.5321\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9774 - accuracy: 0.5282 - val_loss: 0.9625 - val_accuracy: 0.5312\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5281 - val_loss: 0.9620 - val_accuracy: 0.5321\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9773 - accuracy: 0.5286 - val_loss: 0.9618 - val_accuracy: 0.5325\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9778 - accuracy: 0.5283 - val_loss: 0.9610 - val_accuracy: 0.5286\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9771 - accuracy: 0.5277 - val_loss: 0.9609 - val_accuracy: 0.5325\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9774 - accuracy: 0.5261 - val_loss: 0.9620 - val_accuracy: 0.5277\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9771 - accuracy: 0.5294 - val_loss: 0.9614 - val_accuracy: 0.5325\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9767 - accuracy: 0.5287 - val_loss: 0.9612 - val_accuracy: 0.5339\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9773 - accuracy: 0.5304 - val_loss: 0.9619 - val_accuracy: 0.5321\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5296 - val_loss: 0.9616 - val_accuracy: 0.5325\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9623 - val_accuracy: 0.5312\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9772 - accuracy: 0.5269 - val_loss: 0.9628 - val_accuracy: 0.5325\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5286 - val_loss: 0.9620 - val_accuracy: 0.5325\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9630 - val_accuracy: 0.5325\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9771 - accuracy: 0.5295 - val_loss: 0.9631 - val_accuracy: 0.5325\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9625 - val_accuracy: 0.5334\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9633 - val_accuracy: 0.5325\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5285 - val_loss: 0.9619 - val_accuracy: 0.5325\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 566us/step - loss: 0.9770 - accuracy: 0.5293 - val_loss: 0.9617 - val_accuracy: 0.5321\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 664us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9628 - val_accuracy: 0.5321\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9631 - val_accuracy: 0.5325\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5288 - val_loss: 0.9624 - val_accuracy: 0.5321\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9626 - val_accuracy: 0.5321\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9771 - accuracy: 0.5278 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5291 - val_loss: 0.9620 - val_accuracy: 0.5321\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9776 - accuracy: 0.5289 - val_loss: 0.9626 - val_accuracy: 0.5339\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9772 - accuracy: 0.5306 - val_loss: 0.9627 - val_accuracy: 0.5321\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9770 - accuracy: 0.5287 - val_loss: 0.9621 - val_accuracy: 0.5321\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9774 - accuracy: 0.5290 - val_loss: 0.9631 - val_accuracy: 0.5321\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9629 - val_accuracy: 0.5321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9770 - accuracy: 0.5274 - val_loss: 0.9618 - val_accuracy: 0.5321\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9771 - accuracy: 0.5283 - val_loss: 0.9631 - val_accuracy: 0.5321\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9770 - accuracy: 0.5277 - val_loss: 0.9625 - val_accuracy: 0.5321\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 688us/step - loss: 0.9769 - accuracy: 0.5287 - val_loss: 0.9629 - val_accuracy: 0.5330\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9773 - accuracy: 0.5291 - val_loss: 0.9630 - val_accuracy: 0.5325\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 632us/step - loss: 0.9767 - accuracy: 0.5282 - val_loss: 0.9631 - val_accuracy: 0.5321\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9768 - accuracy: 0.5286 - val_loss: 0.9626 - val_accuracy: 0.5330\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9775 - accuracy: 0.5291 - val_loss: 0.9633 - val_accuracy: 0.5321\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9625 - val_accuracy: 0.5321\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9771 - accuracy: 0.5293 - val_loss: 0.9626 - val_accuracy: 0.5321\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9771 - accuracy: 0.5294 - val_loss: 0.9638 - val_accuracy: 0.5339\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9775 - accuracy: 0.5296 - val_loss: 0.9622 - val_accuracy: 0.5325\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9768 - accuracy: 0.5297 - val_loss: 0.9623 - val_accuracy: 0.5321\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9768 - accuracy: 0.5283 - val_loss: 0.9639 - val_accuracy: 0.5321\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9767 - accuracy: 0.5289 - val_loss: 0.9636 - val_accuracy: 0.5321\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9768 - accuracy: 0.5288 - val_loss: 0.9636 - val_accuracy: 0.5321\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9768 - accuracy: 0.5287 - val_loss: 0.9631 - val_accuracy: 0.5325\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9773 - accuracy: 0.5295 - val_loss: 0.9622 - val_accuracy: 0.5321\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9776 - accuracy: 0.5303 - val_loss: 0.9612 - val_accuracy: 0.5321\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9620 - val_accuracy: 0.5299\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9770 - accuracy: 0.5276 - val_loss: 0.9622 - val_accuracy: 0.5277\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9768 - accuracy: 0.5284 - val_loss: 0.9617 - val_accuracy: 0.5321\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9773 - accuracy: 0.5287 - val_loss: 0.9623 - val_accuracy: 0.5321\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9769 - accuracy: 0.5275 - val_loss: 0.9612 - val_accuracy: 0.5321\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9772 - accuracy: 0.5288 - val_loss: 0.9629 - val_accuracy: 0.5321\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9768 - accuracy: 0.5282 - val_loss: 0.9625 - val_accuracy: 0.5321\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9773 - accuracy: 0.5254 - val_loss: 0.9618 - val_accuracy: 0.5277\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5271 - val_loss: 0.9618 - val_accuracy: 0.5321\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5285 - val_loss: 0.9617 - val_accuracy: 0.5321\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9613 - val_accuracy: 0.5321\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9778 - accuracy: 0.5284 - val_loss: 0.9606 - val_accuracy: 0.5321\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9771 - accuracy: 0.5270 - val_loss: 0.9616 - val_accuracy: 0.5321\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9611 - val_accuracy: 0.5321\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9770 - accuracy: 0.5273 - val_loss: 0.9619 - val_accuracy: 0.5321\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5301 - val_loss: 0.9624 - val_accuracy: 0.5321\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9768 - accuracy: 0.5282 - val_loss: 0.9626 - val_accuracy: 0.5321\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9627 - val_accuracy: 0.5321\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9767 - accuracy: 0.5276 - val_loss: 0.9638 - val_accuracy: 0.5325\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9767 - accuracy: 0.5280 - val_loss: 0.9630 - val_accuracy: 0.5325\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9633 - val_accuracy: 0.5321\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9767 - accuracy: 0.5291 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9771 - accuracy: 0.5287 - val_loss: 0.9628 - val_accuracy: 0.5321\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9768 - accuracy: 0.5284 - val_loss: 0.9628 - val_accuracy: 0.5299\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9768 - accuracy: 0.5285 - val_loss: 0.9626 - val_accuracy: 0.5321\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9631 - val_accuracy: 0.5321\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9767 - accuracy: 0.5289 - val_loss: 0.9638 - val_accuracy: 0.5321\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9769 - accuracy: 0.5283 - val_loss: 0.9625 - val_accuracy: 0.5321\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9625 - val_accuracy: 0.5321\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9770 - accuracy: 0.5289 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9767 - accuracy: 0.5294 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9772 - accuracy: 0.5295 - val_loss: 0.9629 - val_accuracy: 0.5321\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5298 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9771 - accuracy: 0.5294 - val_loss: 0.9630 - val_accuracy: 0.5321\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9767 - accuracy: 0.5269 - val_loss: 0.9637 - val_accuracy: 0.5334\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9773 - accuracy: 0.5293 - val_loss: 0.9629 - val_accuracy: 0.5299\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9770 - accuracy: 0.5279 - val_loss: 0.9636 - val_accuracy: 0.5321\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 598us/step - loss: 0.9767 - accuracy: 0.5297 - val_loss: 0.9644 - val_accuracy: 0.5277\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9770 - accuracy: 0.5277 - val_loss: 0.9629 - val_accuracy: 0.5317\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9772 - accuracy: 0.5295 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9767 - accuracy: 0.5284 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 651us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9629 - val_accuracy: 0.5321\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9768 - accuracy: 0.5284 - val_loss: 0.9630 - val_accuracy: 0.5321\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9784 - accuracy: 0.5283 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9768 - accuracy: 0.5287 - val_loss: 0.9635 - val_accuracy: 0.5321\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9769 - accuracy: 0.5279 - val_loss: 0.9635 - val_accuracy: 0.5321\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9768 - accuracy: 0.5290 - val_loss: 0.9641 - val_accuracy: 0.5321\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9769 - accuracy: 0.5286 - val_loss: 0.9639 - val_accuracy: 0.5277\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9769 - accuracy: 0.5277 - val_loss: 0.9634 - val_accuracy: 0.5277\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9771 - accuracy: 0.5285 - val_loss: 0.9630 - val_accuracy: 0.5321\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9768 - accuracy: 0.5307 - val_loss: 0.9623 - val_accuracy: 0.5321\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9778 - accuracy: 0.5294 - val_loss: 0.9637 - val_accuracy: 0.5299\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9769 - accuracy: 0.5284 - val_loss: 0.9629 - val_accuracy: 0.5321\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9769 - accuracy: 0.5286 - val_loss: 0.9633 - val_accuracy: 0.5321\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 610us/step - loss: 0.9769 - accuracy: 0.5294 - val_loss: 0.9647 - val_accuracy: 0.5321\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9769 - accuracy: 0.5285 - val_loss: 0.9639 - val_accuracy: 0.5321\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9768 - accuracy: 0.5285 - val_loss: 0.9634 - val_accuracy: 0.5321\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9767 - accuracy: 0.5290 - val_loss: 0.9639 - val_accuracy: 0.5321\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9770 - accuracy: 0.5289 - val_loss: 0.9640 - val_accuracy: 0.5321\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9770 - accuracy: 0.5295 - val_loss: 0.9633 - val_accuracy: 0.5290\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9632 - val_accuracy: 0.5321\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9771 - accuracy: 0.5286 - val_loss: 0.9640 - val_accuracy: 0.5277\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9768 - accuracy: 0.5289 - val_loss: 0.9629 - val_accuracy: 0.5299\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9768 - accuracy: 0.5279 - val_loss: 0.9629 - val_accuracy: 0.5321\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9626 - val_accuracy: 0.5321\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9772 - accuracy: 0.5291 - val_loss: 0.9642 - val_accuracy: 0.5321\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9768 - accuracy: 0.5299 - val_loss: 0.9655 - val_accuracy: 0.5277\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9771 - accuracy: 0.5271 - val_loss: 0.9646 - val_accuracy: 0.5321\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9770 - accuracy: 0.5291 - val_loss: 0.9637 - val_accuracy: 0.5321\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9769 - accuracy: 0.5277 - val_loss: 0.9644 - val_accuracy: 0.5321\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9767 - accuracy: 0.5278 - val_loss: 0.9634 - val_accuracy: 0.5321\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9766 - accuracy: 0.5288 - val_loss: 0.9630 - val_accuracy: 0.5317\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 645us/step - loss: 0.9771 - accuracy: 0.5286 - val_loss: 0.9635 - val_accuracy: 0.5321\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 351us/step - loss: 0.9765 - accuracy: 0.5292\n",
      "Accuracy : 0.5291889905929565\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9635 - accuracy: 0.5321\n",
      "Accuracy : 0.5320938229560852\n",
      "\n",
      "The final train accuracy is:0.5296516060829163 \n",
      "\n",
      "The final test accuracy is:0.5285499036312103 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "#importing the dataframe\n",
    "df = pd.read_csv(\"IW.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10) #defining how many folds we will use  \n",
    "\n",
    "#Spliting the array into the inputs we want to have in the neural network and the result we would like to get\n",
    "data = np.array(df.iloc[:,0:3])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    " \n",
    "#impementing the 10 fold cross validation\n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    #spliting the data and the labels into train sets and test sets \n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "\n",
    "    #implementing one-hot encoding for the 0,1,2 classes\n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    #Building our neural network model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (3,1)), #Adding the input layer\n",
    "        keras.layers.Dense(3,activation='sigmoid') #Adding the output layer with three neurals and a sigmoid activation function\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    #Configuring the model for training\n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    #Using the cpu to train the model\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels,batch_size = 221, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    #Printing the train and test accuracy per epoch\n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "#Printing the final train and the test accuracy by taking the average sum of every epoch\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advised-colon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "resident-station",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demonstrated-admission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsEklEQVR4nO3deZxWc//H8ddnltZpqmnThpCQJQktEgpR1G0tbrLcsstyu8l6i+z6iYQsaUGKkCQloixRSSpSkpqa9n1vZj6/P65T91SzXNPMdM2Z3k+P85jrOud7ne/nXKbPfK/P+Z5zmbsjIiLhERfrAEREJH+UuEVEQkaJW0QkZJS4RURCRolbRCRklLhFREJGiVsKzMzKmtknZrbWzIYVYD+Xm9mYwowtFszsMzPrEus4pORS4t6PmNllZjbZzDaYWVqQYE4phF1fBNQAqrj7xXu7E3d/293PKoR4dmFmp5mZm9nw3dYfF6wfH+V+/mtmg/Nq5+7nuPuAvQxXJE9K3PsJM7sTeB54nEiSPRDoC3QohN0fBPzh7umFsK+ishxobmZVsqzrAvxRWB1YhP5NSZHTL9l+wMwqAj2Am919uLtvdPft7v6Ju98dtCltZs+b2eJged7MSgfbTjOzVDO7y8yWBaP1q4NtjwAPAZcGI/lrdx+ZmtnBwcg2IXh+lZnNM7P1ZvaXmV2eZf3ELK9rbmY/BSWYn8yseZZt483sUTP7NtjPGDOrmsvbsA34COgUvD4euAR4e7f3qreZLTSzdWY2xcxaBuvbAvdlOc5fssTR08y+BTYBhwTr/hVsf9nM3s+y/6fMbJyZWbT//0R2p8S9f2gGlAE+zKXN/UBToBFwHHAS8ECW7QcAFYHawLXAS2ZW2d0fJjKKf8/dk9z9jdwCMbPywAvAOe5eAWgOTMumXQrwadC2CtAL+HS3EfNlwNVAdaAU8O/c+gYGAlcGj88GZgKLd2vzE5H3IAV4BxhmZmXcffRux3lcltdcAXQFKgB/77a/u4Bjgz9KLYm8d11c95qQAlDi3j9UAVbkUcq4HOjh7svcfTnwCJGEtMP2YPt2dx8FbAAa7GU8mcDRZlbW3dPcfWY2bdoBc9x9kLunu/u7wO/AeVna9Hf3P9x9MzCUSMLNkbt/B6SYWQMiCXxgNm0Gu/vKoM/ngNLkfZxvufvM4DXbd9vfJuCfRP7wDAZudffUPPYnkisl7v3DSqDqjlJFDmqx62jx72Ddzn3slvg3AUn5DcTdNwKXAjcAaWb2qZkdEUU8O2KqneX5kr2IZxBwC3A62XwCCcpBvwXlmTVEPmXkVoIBWJjbRnf/EZgHGJE/MCIFosS9f/ge2AJ0zKXNYiInGXc4kD3LCNHaCJTL8vyArBvd/XN3PxOoSWQU/VoU8eyIadFexrTDIOAmYFQwGt4pKGXcQ6T2XdndKwFriSRcgJzKG7mWPczsZiIj98XAf/Y6cpGAEvd+wN3XEjmB+JKZdTSzcmaWaGbnmNnTQbN3gQfMrFpwku8hIh/t98Y04FQzOzA4Mdp9xwYzq2Fm5we17q1ESi4Z2exjFHB4MIUxwcwuBY4CRu5lTAC4+19AKyI1/d1VANKJzEBJMLOHgOQs25cCB+dn5oiZHQ48RqRccgXwHzNrtHfRi0Qoce8n3L0XcCeRE47LiXy8v4XITAuIJJfJwHTgV2BqsG5v+hoLvBfsawq7Jts4IifsFgOriCTRm7LZx0qgfdB2JZGRant3X7E3Me2274nunt2nic+Bz4hMEfybyKeUrGWQHRcXrTSzqXn1E5SmBgNPufsv7j6HyMyUQTtm7IjsDdPJbRGRcNGIW0QkZJS4RURCRolbRCRklLhFREImtwsyYiqhVG2dNS1iX6c0i3UIJV43WxrrEPYLk9MmFPjeL9tXzIs65yRWPSSm95rRiFtEJGSK7YhbRGSfyszuOrDiSYlbRAQgozjfTn5XStwiIoB7ZqxDiJoSt4gIQKYSt4hIuGjELSISMjo5KSISMhpxi4iEi2tWiYhIyOjkpIhIyKhUIiISMjo5KSISMhpxi4iEjE5OioiEjE5OioiEi7tq3CIi4aIat4hIyKhUIiISMhpxi4iETMb2WEcQNSVuERFQqUREJHRUKhERCRmNuEVEQkaJW0QkXFwnJ0VEQiZENe64WAcgIlIsZGZGv+TBzO4ws5lmNsPM3jWzMmaWYmZjzWxO8LNylvbdzWyumc02s7Pz2r8St4gIREbc0S65MLPawG1AE3c/GogHOgH3AuPcvT4wLniOmR0VbG8ItAX6mll8bn0ocYuIQKGOuImUocuaWQJQDlgMdAAGBNsHAB2Dxx2AIe6+1d3/AuYCJ+W2cyVuERHI14jbzLqa2eQsS9edu3FfBDwLLADSgLXuPgao4e5pQZs0oHrwktrAwiyRpAbrcqSTkyIiAOnRf5GCu/cD+mW3LahddwDqAWuAYWb2z1x2Z9l1kVv/StyF4LV+z9Hu3DYsW76CRse3jnU4xU9cHMd9/hTblqzityue2GVTcvOGHPnWf9iyYBkAq0ZNYmGv9wvUnZVK4PAXb6X8sYeQvnoDs6/vxdaFyynf8GAOeeo6EiqUwzMySe39ASs+/q5AfRUHD/W6l1PObM7qFau59PQue2xve8GZdLn5cgA2bdzEk/c+x5xZfxaoz8RSiTzywv0ceWwD1q5eR/frHyYtdQmHNzyMe5+8i/IVypOZkcmbvQcydsSXBeprnym8WSVtgL/cfTmAmQ0HmgNLzaymu6eZWU1gWdA+Faib5fV1iJRWcqRSSSEYOHAo7dpfHuswiq1a153L5jmpOW5fN+l3fmlzN7+0uTtfSbt03WocPfyRPdbXuKw16Ws2MrXZrSx+dSQHPxAZ7GRs3sqcW1/k51Z3MKvzY9TrcTXxyeXyf0DFzCdDP+PWy/6d4/bFC9LoesEtdG59FW88P4D7n/lP1PuuWecAXv3ghT3Wd+jcjvVr1/OP5p15p99Qbn3gBgC2bN7Kw7f15NLTruTWy+7irh63kZSclP+DioXCq3EvAJqaWTkzM6A18BswAtjxl7UL8HHweATQycxKm1k9oD7wY24dKHEXggkTJ7Fq9ZpYh1EslaqZQuU2J7D07XH5fm21C1ty7GdPcNwXz3Do010hLrpf15SzT2TZ0PEArBj5PRVPOQaALfPS2PLXEgC2LV3N9hVrSaySnO+4ipuff/iFdavX5bh9+uQZrF+7AYBfp8ykes1qO7edc+FZDBj1Km+PfZP7nv43cVG+x63atmTk0NEAjBs5npNangDAgnkLWfhX5I/0iqUrWbViNZWrVNqbw9r3CmlWibtPAt4HpgK/Esmz/YAngTPNbA5wZvAcd58JDAVmAaOBmz2Pr+MpssRtZkeY2T1m9oKZ9Q4eH1lU/UnxVO/Rq5n/6CDccy7ZVTjhcBqNe5aj3rmfsg3qAFC2fm2qdmjBr+c9wC9t7sYzM6l2Ycuo+ixVM4Wti1dEnmRkkr5+EwkpFXZpk3T8YVhiAlvmL927AwupDp3b892XkwA4uP5BnHn+GVxz/k1cfuY1ZGRkcs6FZ0a1n+oHVGXp4sgn/YyMDDas20jFlIq7tGnY6EgSSyWQOn9R4R5EUSnEWSXu/rC7H+HuR7v7FcGMkZXu3trd6wc/V2Vp39PdD3X3Bu7+WV77L5Iat5ndA3QGhvC/IX8d4F0zG+LuTxZFv1K8VD7zBLavWMvG6fNIbt4w2zYbp89jcpMbydy0hcqtj+fI/vcwtfmtVGx5DEnHHsKxoyO/KvFlSrF9RWRUecSbd1P6wOrElUqgdO2qHPfFMwCkvT6KZUO+IvLpdDdZ/nAkVq/E4S/eyh+39dllfUl3QvPj6XBZO/7V4WYATjrlBI48tgEDP3sNgDJlSrN6xWoAnnmzJ7Xq1iSxVCIH1K7O22PfBGDI6+/zyXujII/3uEr1KvR48QEe7tYz1z/axUqIrpwsqpOT1wIN3X2Xi//NrBcwk+Ajwu6CKTVdASy+InFx5YsoPNkXkk9sQMpZJ1K5dWPiSicSn1SO+n1uY84t/6uZZmzYvPPx6nE/c8iT8SSkVMDMWDZ0PH8//s4e+/39mkiiLl23GvV738KMCx7eZfvWxSspXasq29JWQXwcCRXKkb46UiqITyrLUYPv4++nhrBh6pyiOOxi6bAjD+XB5+7htsvvZm1QVjEzRg4bzUuPv7pH+7uvuR+I1Lj/2/s+rr/wtl22L0tbTo1a1VmWtpz4+HiSksvv3G/5pHL0Hvw0fZ96jRlTZxXxkRWifMwqibWiKpVkArWyWV8z2JYtd+/n7k3cvYmSdvj9/fg7TG58PVNOvInZNzzP2m9n7JK0ARKrVdr5OOn4wzAz0letZ82EX6nSvhmJVSM16IRKSZSuUzWqfleNmUz1S04DoGr7Zqz9dgYAlpjAEf3/w7JhX7Pyk+8LfoAhUaN2dZ554zEeuvUxFsz733ThHydOoXW7Vjtr0MmVKnBAnRpR7fObzyfS/pK2ALRufxo/TZwKQEJiAs+8+TifDhvNuJHjC/U4ipx79EuMFdWI+3ZgXFCE3/GbciBwGHBLEfUZM4MHvUSrU5tRtWoK8+dN5pEez9L/rSGxDqvYOuDKswBYMnAMVc5rSs0uZ+PpGWRu2cbsG54HYPMfqSx46l2OGvIgFheHb0/nz+6vszV1RZ77X/rOOA7vcxuNv3+R9DUbmH39/wFQ9fxmJDc9koTKSVS/9DQA5nZ7iY0z5xfFYe4zPfs+zAnNj6dSSkU+nfIB/Z59k4TEyD/tDwZ+zHV3XE3FyhW554k7gUhN+sq21/HXH/N5+anX6TOkF3FxcaSnp/NU914sSc277v/xu5/S48UH+PC7d1m3Zh333fBfAM48/wwaNz2OipWTaX/JOQA8cvvj/DFzbtEcfGEK0W1drajqT2YWR+SyzdpEJpinAj/ldbZ0h4RStWP/Z62E+zqlWaxDKPG62f518jNWJqdNyO4ilnzZ/PaDUeecspc/WuD+CqLILsBx90zgh6Lav4hIodLJSRGRkMmIqhhQLChxi4hAqGrcStwiIqDELSISOqpxi4iEi2eGZyKbEreICKhUIiISOppVIiISMhpxi4iEjBK3iEjIFIObR0VLiVtEBDTiFhEJHU0HFBEJGc0qEREJF1epREQkZFQqEREJGd2rREQkZDTiFhEJmXSdnBQRCReVSkREQkalEhGRcNF0QBGRsNGIW0QkZJS4RURCRpe8i4iEi75zUkQkbJS4RURCRrNKRERCRiNuEZGQUeIWEQkXz1CpRELgpBlPxzqEEm9Lw8tiHYJESyNuEZFwCdN0wLhYByAiUixkevRLHsyskpm9b2a/m9lvZtbMzFLMbKyZzQl+Vs7SvruZzTWz2WZ2dl77V+IWEQHIzMeSt97AaHc/AjgO+A24Fxjn7vWBccFzzOwooBPQEGgL9DWz+Nx2rsQtIgJ4embUS27MLBk4FXgDwN23ufsaoAMwIGg2AOgYPO4ADHH3re7+FzAXOCm3PpS4RUQgXyNuM+tqZpOzLF2z7OkQYDnQ38x+NrPXzaw8UMPd0wCCn9WD9rWBhVlenxqsy5FOToqIkL+Tk+7eD+iXw+YEoDFwq7tPMrPeBGWRHFh2XeTWv0bcIiJQmDXuVCDV3ScFz98nksiXmllNgODnsizt62Z5fR1gcW4dKHGLiBAZcUe75Lof9yXAQjNrEKxqDcwCRgBdgnVdgI+DxyOATmZW2szqAfWBH3PrQ6USERGIdrZItG4F3jazUsA84GoiA+WhZnYtsAC4GMDdZ5rZUCLJPR242d1zvTm4EreICODphbgv92lAk2w2tc6hfU+gZ7T7z7NUYmbdzCzZIt4ws6lmdla0HYiIhIFnRr/EWjQ17mvcfR1wFlCNyJD/ySKNSkRkXyvcC3CKVDSlkh1TVc4F+rv7L2aW3fQVEZHQKg4j6WhFk7inmNkYoB7Q3cwqUCz+5oiIFJ6SlrivBRoB89x9k5lVIVIuEREpMTwjPIWEHBO3mTXebdUhqpCISElVUkbcz+WyzYEzCjkWEZGY8czwDExzTNzufvq+DEREJJbCNOKOZh53OTN7wMz6Bc/rm1n7og9NRGTfcbeol1iLZh53f2Ab0Dx4ngo8VmQRiYjEQJguwIlmVsmh7n6pmXUGcPfNmsctIiVNZkmYVZLFNjMrS3B/WDM7FNhapFGJiOxjJeLkZBYPA6OBumb2NtACuKoogxIR2ddKVOJ297FmNhVoSuTy927uvqLIIxMR2Yc8+i/Aiblob+vaCjiFSLkkEfiwyCISEYmBEjXiNrO+wGHAu8Gq682sjbvfXKSRiYjsQ8Vhml+0ohlxtwKOdvcdJycHAL8WaVQiIvtYRohmlUQzj3s2cGCW53WB6UUTjohIbITpApzcbjL1CZGadkXgNzP7MXh+MvDdvglPRGTfKCk17mf3WRQiIjFWImaVuPvX+zIQEZFYCtOIO5qbTDU1s5/MbIOZbTOzDDNbty+CExHZVzIy46JeYi2aCPoAnYE5QFngX8E6CbzW7zkWp/7CtJ/HxTqUYmfQ0I/o+M8b6HD59Qx6b8/p/19O+J5/XHkjF3a5mUuuuY2pv8wocJ/btm3jrgef4JxLrqHzdbezKG0pAL//8SeXd72DDpdfzz+uvJHPvigZHyofff5+vp45ig+/fjvb7fUOO4jBn77G1AXfcNWNlxVKn4mlEnm232OM+mEY73z2BrXq1gSgQcP6DP70NT76+h2GfzWYth3aFEp/+4J79EusRfWnw93nAvHunuHu/YHTijSqkBk4cCjt2l8e6zCKnTnz5vPBiNG8+/rzfDCgL19/9yN/L1y0S5umJzRi+IC+fDDgJR697w4efrJ31PtflLaUq275zx7rh48cQ3KFJD4b+iZXXNqRXn3fBKBMmdI8/uC/+fjtV3n1ucd46oVXWbd+Q8EOshj4aMin3NDpjhy3r12zjifv78VbL7+T733XqluT/sP77rH+gsvOZ92adZzb9GIGvfoudz4Yuaxjy+Yt3HdLDzq2uozrO93OPY/eToXkpHz3GwuZblEvsRZN4t5kZqWAaWb2tJndAZQv4rhCZcLESaxavSbWYRQ78+Yv5NiGR1C2TBkSEuJp0ugYxn2z64SkcuXKsuNmk5u3bIEsN5785PMv6fSvblzY5WYeefoFMjIyour3ywnf0+HcyEjvrNNaMmnKNNydgw+sw0F1awNQvVoVUipXYvWatYVxqDE15YdprF2Tc/Vy1YrVzJj2G+nb0/fY1v7Ctrw7+g3eHzeQh565h7i46MoAZ7RtycdDRwEw5pOvOPmUJgD8PW8hC/5aCMDypStYtWI1latUzu8hxUSYpgNG83/piqDdLcBGIvO4L9jbDs1MXzS8nzjskIOY8ssM1qxdx+YtW5jw/U8sWbp8j3ZffP0t53W+jpv+/RCP3hcZOf45fwGjx33NoFee44MBLxEXF8fIMV9F1e+y5Ss5oHpVABIS4kkqX441a3dNbL/Oms327enUrV2zgEcZXofUP5i2HdtwRfuuXNT6SjIzMml/4dlRvbZ6zWosWRQpQWVkZLBh/QYqpVTcpc3Rxx9FYmIiC+enFnrsRSFMpZJobjL1d/BwC/AIgJm9B1y6l30+QuTLGfZgZl2BrgAWX5G4OA3sw+zQgw/kmssv5rrb76Nc2bIcftghxMfH79GuTasWtGnVgsnTfqXPawN5vfcTTJo8jVm/z6XTtd0A2Lp1KymVKwFwW/ceLFq8lO3p20lbupwLu0Q+pv/zkg78o91ZeDb/srLeQn75ilV07/EMPR+4K+oRZkl0cssmHHVsA4Z8HvnnWLpMaVatWA1A7/5PUvvAWiQmJlKzTg3eHzcQgMGvvcdHQz7F2HPUmfV9r1q9Ck/0eZj7b+uR7f+P4qg4lECiFe1NpnbXLLeNZpbTlZUG1Mjpde7eD+gHkFCqdjj+b0uuLjzvbC48LzKKe/6Vt3aOhLPTpNExLFyUxuo1a3F3zj+nDXfcuOcHtBeeeAiI1Ljv7/kcb/V5epftNapXZcmyFRxQvRrp6Rls2LiJiskVANiwcSM33f0Qt3btwnFHH1lYhxlKZsaIoaN4vufLe2zrdvW9QKTG3bP3g1x9wU27bF+atowDatdgadpy4uPjSaqQxNrVkU815ZPK0fftXrz45KtMnzKz6A+kkBSH2SLRKqpIawBXAudls6wsoj6lGFoZ1P7Tlixj3Nffck6bVrtsX5C6eOeIbNbsuWzfnk6lisk0bdKIseMn7nz92nXrWbxkaVR9nn5KUz4e9QUAY8ZP4OQTjsPM2L59O926P8r5bVtz9hktC+cAQ+yHCT9xZvszSKkaqUEnV0qmZp0DonrtV59PoMMl5wJw1nmnM2niZAASEhPo/dZTjBg2ijGffFk0gRcRz8cSa7ld8t44p01Ebu2am5FAkrtPy2a/46MNLiwGD3qJVqc2o2rVFObPm8wjPZ6l/1tDYh1WsXDHfY+xZt06EhISuP+um6iYXIH3PvwUgEv/0Y6x4ycy4rNxJCQkUKZ0KZ7tcS9mxqH1DuLW666k6+33k+mZJCYkcP+dN1HrgBw/sO10Qfuz6f7oM5xzyTVUTK7AM49ERo+jv5zAlGkzWLN2PR8Fib3n/XdyxOGHFt0bsA88/UoPTmzemEoplfji5xH0feY1EhIi/7SHDvyQKtVSeG/MWyRVKE9mZib/7NqJDi07Me+P+bz45Kv0e683cXFxbN+eTs/uz5CWuiTPPoe/8wlP9HmYUT8MY+2addx9/YMAtD2/DSc0PZ5KlSvS8dJ2ANx/26PMnjmn6N6AQhKmUonlVH8ys1zPBLn76UUSUUClkqK3efGEWIdQ4h3fsHDmTUvuZiz9ocBZ99sDLoo657RY8n5Ms3xul7wXaWIWESlOisGXt0dtb09OioiUKJ7NTJniSolbRARID1GNW4lbRIRwjbijuTugmdk/zeyh4PmBZnZS0YcmIrLvZOZjibVo5nH3JXLBTefg+XrgpSKLSEQkBhyLeom1aEolJ7t7YzP7GcDdVwc3nRIRKTGKw0g6WtGMuLebWTzBBUNmVo1wHaOISJ4ysKiXaJhZvJn9bGYjg+cpZjbWzOYEPytnadvdzOaa2Wwzy/NOX9Ek7heAD4HqZtYTmAg8HlXkIiIhkWnRL1HqBvyW5fm9wDh3rw+MC55jZkcBnYCGQFugbzBYzlGeidvd3wb+AzwBpAEd3X1Y1KGLiIRAJhb1khczqwO0A17PsroDMCB4PADomGX9EHff6u5/AXOBXCeARDOr5EBgE/AJMALYGKwTESkx8nOTKTPramaTsyxdd9vd80QGvFnLyjXcPQ0g+Fk9WF8bWJilXWqwLkfRnJz8dEesQBmgHjCbyLBeRKREyM+Ju6y3oN6dmbUHlrn7FDM7LYrdZTeEz/W+KdF8kcIxuwXVGLg+imBEREIj0wptml8L4HwzO5fIYDfZzAYDS82sprunmVlNYFnQPpXIN4vtUAdYnFsH+b4ft7tPBU7M7+tERIqzjHwsuXH37u5ex90PJnLS8Ut3/yeRUnOXoFkX4OPg8Qigk5mVNrN6QH3gx9z6yHPEbWZ3ZnkaBzQG9vziQBGREMvHbJG99SQw1MyuBRYAFwO4+0wzGwrMAtKBm909178P0dS4K2R5nE6k5v3B3kQtIlJcRTNbJL/cfTwwPni8EmidQ7ueQM9o95tr4g7mEia5+93R7lBEJIzC9M0tuX11WYK7p+fyFWYiIiXGPiiVFJrcRtw/EqlnTzOzEcAwYOOOje4+vIhjExHZZ8J0H49oatwpRL6Z/Qz+N5/bASVuESkxMkrIiLt6MKNkBv9L2DuEqRwkIpKnkjLijgeS2IurekREwqakJO40d++xzyIREYmhEH3lZK6JO0SHISJSMCVlxJ3tRHERkZIor0vZi5McE7e7r9qXgYiIxFJJmcctIrLfKCmlEhGR/YYSt4hIyIRpjrMSt4gIqnGLiIROiZhVIiXfe8c+FOsQSry2ZevFOgSJUmaIiiVK3CIi6OSkiEjohGe8rcQtIgJoxC0iEjrpFp4xtxK3iAgqlYiIhI5KJSIiIaPpgCIiIROetK3ELSICqFQiIhI6GSEacytxi4igEbeISOi4RtwiIuGiEbeISMhoOqCISMiEJ20rcYuIAJAeotStxC0igk5OioiEjk5OioiEjEbcIiIhoxG3iEjIZLhG3CIioRKmedxxsQ5ARKQ48Hz8lxszq2tmX5nZb2Y208y6BetTzGysmc0JflbO8pruZjbXzGab2dl5xarELSJCpMYd7ZKHdOAudz8SaArcbGZHAfcC49y9PjAueE6wrRPQEGgL9DWz+Nw6UOIWESFSKol2yY27p7n71ODxeuA3oDbQARgQNBsAdAwedwCGuPtWd/8LmAuclFsfStwiIuSvVGJmXc1scpala3b7NLODgeOBSUANd0+DSHIHqgfNagMLs7wsNViXI52cFBEhf7NK3L0f0C+3NmaWBHwA3O7u68wsx6bZdZHbvpW4RUQo3FklZpZIJGm/7e7Dg9VLzaymu6eZWU1gWbA+Faib5eV1gMW57V+lEhERCu/kpEWG1m8Av7l7ryybRgBdgsddgI+zrO9kZqXNrB5QH/gxtz404hYRoVAveW8BXAH8ambTgnX3AU8CQ83sWmABcDGAu880s6HALCIzUm5294zcOlDiFhGh8Eol7j6R7OvWAK1zeE1PoGe0fShxF4LX+j1Hu3PbsGz5Chodn+3/l/1SXOlEzhr+APGlErCEeBZ8+iPTnx2+S5vECmVp0edGyteqgiXEM+uVUcx775uC9VsqgeYv3ECVY+qxdfV6JtzQh42pK6jc8EBOeuJqEiuUxTMymfHCx/w9YlKB+ioOKtZMoXOvm6hQrRKe6fzw7jgm9h+9S5vTurbn+I4tAIiPj6f6YbV5uHFXNq/duNf9xpdKoHOvm6hzdD02rdnAoFt6szp1BbWOOogLHruGMknlyMzIZNxLH/LLyB8KdIz7guuS9/3LwIFD6du3P/379451KMVK5tbtfHHx46Rv2oolxHP2Rw+y+MtfWDH1z51tDr/qTNb+sYjxXXpROqUC5094hvnDvyVze66fFAEoX6cqzZ+/nrEX7TpQOazzaWxbs5GPW9zFQR2acvwDnZh4Qx/SN2/ju26vsP6vpZStUYlzRz/G4vG/sn3dpkI/9n0pMz2TTx4bzKKZ8yldvgy3f/I4cyb8ytK5i3a2Gd9vJOP7jQTgqNaNOfXac6NO2pXrVKXTszfycqdHd1l/8iWns3ntRp487Q4andeMdvdexuBbXmDb5q0MufNlVsxfQnL1ytw+siezv5nOlmL+PmeE6JJ3Je5CMGHiJA46qE6swyiW0jdtBSAuMZ64xAT2GNS4k1C+LAAJ5cuwbc1GMtMjp3/qXdCCBteeRVypBFZO/ZMfu/fHM/P+x1Xn7MZMfy4ysl8w8kdO7Bk5H7R+3pKdbTYvXcOWFWspU6VC6BP3+uVrWL98DQBbN25h6Z+LSD4gZZfEnVWj85vz84jvdj5v3PEUTrnqbOJLJbBg2lyGP/BmVO9zw7NOYMzzHwAwfdQk/vHI1QCs+Ot/7/O6ZavZsHIdSSnJxT5x614lgJkdYWatg7mMWde3Lao+pfixOOPcsT25aHpf0r75lZU//7nL9tn9x1Kxfi0u/LkP7b98gskPDQJ3kg+rxUEdTubzDj0Ydeb9ZGZkcvAFLaLqs9wBldm0eBUAnpHJ9nWbKJ2yy68hVRodQlypBNbPX5bdLkKrcp2q1D7qYBZMm5vt9sQypTii1XFM/yxSIqp+aC0atW9Kn4v+y/+d2x3PcBp3PCWqvirWSGHN4pUAZGZksnn9JspVrrBLm7rHHUp8YgIr/15agKPaN9w96iXWimTEbWa3ATcTudTzDTPr5u47pr48DozO8cVSonimM+rM+0lMLkerN26nYoM6rJ2dunN7rdOOYfXMv/ni4sdJOrgGbYbcw7JJszmgZUNSjqnHOZ/1ACChTCm2rlwHwKlv3E7SgdWIS0ygfO0qnDs2Uir5/fXPI/XxbC50yPpvrWz1SrR48Ua+6/YKe34ECK9S5UrT5eU7+LjHQLZu2Jxtm6PaNGb+5Nk7yyT1WxxN7WMOoduIxwBILF2KDSvXAtDl1TtJqVuNhMQEKtWqyh2jngBgYv/R/DTs62zf56zvZ4Vqlejc6yaG/PvlYpHs8hKmEXdRlUquA05w9w3BJZ/vm9nB7t6bnM+2Elw22hXA4isSF1e+iMKTfW37uk0s/f43ap1+7C6J+9BLWzGjzycAbJi/lA0LlpN8WE3MYN6wCUx7Yuge+/rm2ueBnGvcm9JWUa5WCpvSVmHxcSQml2Pb6g0AJCaV5fRB/2baU8N2qbWHXVxCPF1euYOpH33LjM9/yrFdo/N2LZNgxuQPvuGzp4fs0XbA9ZEpyDnVuNcuWUmlWlVYu2QVcfFxlK1Qjk1rIu9z6aSyXNv/P4x+bigLfs5+9F/chOkbcIqqVBLv7hsA3H0+cBpwjpn1IpfE7e793L2JuzdR0g6/0ikVSEwuB0B8mURqtjyadXN3vSBs46IV1GzZEIAyVZNJPrQmGxYsY8mEmRzY7iRKV0kGoFSl8pSvXSWqflPHTOWQi1sCcGD7k1g6cRYQqbOf+sbtzBs2gQUjc72+IXQueaorS+cu5ps3RuXYpkyFshx68pHMHDtl57q5387g2HNOIil4n8tWLE/l2lWj6nPm2Ck0ufBUAI4992TmfjcTgPjEeK569U6mDJ/A9FHhmbWT4R71EmtFNeJeYmaN3H0aQDDybg+8CRxTRH3GzOBBL9Hq1GZUrZrC/HmTeaTHs/R/a88RzP6mbI1KNO99PRYXh8UZf38yiUVfTKP+FWcAMGfQl/z6/Ec0e/562o17AjP4ued7bF21ga2rNvDL08NoPeQezIzM9Ax+uu8tNi5amWe/c9/9mhYv3ECHb59j65oNTLyxDwAHndeUGk0bUDoliUMujSSc729/ldUzFxTdm7APHNykAU0uPJXFvy3YWc747On3dibg79/+AoCjzz6R2ROms23z1p2vXTp3EaOfG8p1g7pjFkdmejrDH+rP6kUr8uz3x6Hj6dzrJu4d/39sWrOBwbe+CMBx7ZpxyElHUK5yEk0uirzP7/37FRbP+rtQj7uwhalUYkVRezKzOkC6uy/JZlsLd/82r30klKodnncxpN6qenqsQyjxppXKe1qjFNyz89/N8ZN8tJrVPj3qnPP9oq8K3F9BFMmI291Tc9mWZ9IWEdnXwnACdQfN4xYRIVylEiVuERHCNatEiVtEBMjwKL5NsphQ4hYRQTVuEZHQUY1bRCRkVOMWEQmZTJVKRETCRSNuEZGQ0awSEZGQUalERCRkVCoREQkZjbhFREJGI24RkZDJ8PDcgleJW0QEXfIuIhI6uuRdRCRkNOIWEQkZzSoREQkZzSoREQkZXfIuIhIyqnGLiISMatwiIiGjEbeISMhoHreISMhoxC0iEjKaVSIiEjI6OSkiEjIqlYiIhIyunBQRCRmNuEVEQiZMNW4L01+Z4s7Murp7v1jHUZLpPS56eo+Lv7hYB1DCdI11APsBvcdFT+9xMafELSISMkrcIiIho8RduFQXLHp6j4ue3uNiTicnRURCRiNuEZGQUeIWEQkZJe5CYGZtzWy2mc01s3tjHU9JZGZvmtkyM5sR61hKKjOra2ZfmdlvZjbTzLrFOibJnmrcBWRm8cAfwJlAKvAT0NndZ8U0sBLGzE4FNgAD3f3oWMdTEplZTaCmu081swrAFKCjfpeLH424C+4kYK67z3P3bcAQoEOMYypx3P0bYFWs4yjJ3D3N3acGj9cDvwG1YxuVZEeJu+BqAwuzPE9Fv+wScmZ2MHA8MCnGoUg2lLgLzrJZp/qThJaZJQEfALe7+7pYxyN7UuIuuFSgbpbndYDFMYpFpEDMLJFI0n7b3YfHOh7JnhJ3wf0E1DezemZWCugEjIhxTCL5ZmYGvAH85u69Yh2P5EyJu4DcPR24BficyMmcoe4+M7ZRlTxm9i7wPdDAzFLN7NpYx1QCtQCuAM4ws2nBcm6sg5I9aTqgiEjIaMQtIhIyStwiIiGjxC0iEjJK3CIiIaPELSISMkrckiMzywimhM0ws2FmVq4A+3rLzC4KHr9uZkfl0vY0M2u+F33MN7Oq0a7PYR9XmVmfwuhXpKgocUtuNrt7o+BufNuAG7JuDO6MmG/u/q887jh3GpDvxC2yv1DilmhNAA4LRsNfmdk7wK9mFm9mz5jZT2Y23cyuh8hVeGbWx8xmmdmnQPUdOzKz8WbWJHjc1symmtkvZjYuuLnRDcAdwWi/pZlVM7MPgj5+MrMWwWurmNkYM/vZzF4l+/vGZMvMTjKz74LXfmdmDbJsrmtmo4N7rD+c5TX/NLMfg7he3ds/XCIFlRDrAKT4M7ME4BxgdLDqJOBod//LzLoCa939RDMrDXxrZmOI3FmuAXAMUAOYBby5236rAa8Bpwb7SnH3VWb2CrDB3Z8N2r0D/J+7TzSzA4lcpXok8DAw0d17mFk7oGs+Duv3oN90M2sDPA5cmPX4gE3AT8Efno3ApUALd99uZn2By4GB+ehTpFAocUtuyprZtODxBCL3sWgO/OjufwXrzwKO3VG/BioC9YFTgXfdPQNYbGZfZrP/psA3O/bl7jndb7sNcFTkVhoAJAc3+j8VuCB47admtjofx1YRGGBm9YnczTExy7ax7r4SwMyGA6cA6cAJRBI5QFlgWT76Eyk0StySm83u3ijriiBpbcy6CrjV3T/frd255H17W4uiDURKes3cfXM2seztPRseBb5y938E5ZnxWbbtvk8PYh3g7t33sj+RQqMatxTU58CNwe1AMbPDzaw88A3QKaiB1wROz+a13wOtzKxe8NqUYP16oEKWdmOI3MiLoF2j4OE3RMoVmNk5QOV8xF0RWBQ8vmq3bWeaWYqZlQU6At8C44CLzKz6jljN7KB89CdSaJS4paBeJ1K/nmqRL/J9lcgnuQ+BOcCvwMvA17u/0N2XE6lLDzezX4D3gk2fAP/YcXISuA1oEpz8nMX/Zrc8ApxqZlOJlGwW5BLn9OCugqlm1gt4GnjCzL4Fdj/JOBEYBEwDPnD3ycEsmAeAMWY2HRgL1IzuLRIpXLo7oIhIyGjELSISMkrcIiIho8QtIhIyStwiIiGjxC0iEjJK3CIiIaPELSISMv8PC6I3YS2HDj4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ploting the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-appendix",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-leonard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
