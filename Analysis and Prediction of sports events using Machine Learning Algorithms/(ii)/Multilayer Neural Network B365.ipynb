{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mathematical-regular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 655us/step - loss: 1.0680 - accuracy: 0.4236 - val_loss: 1.0270 - val_accuracy: 0.5102\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 1.0076 - accuracy: 0.5244 - val_loss: 1.0018 - val_accuracy: 0.5212\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9895 - accuracy: 0.5299 - val_loss: 0.9939 - val_accuracy: 0.5190\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9839 - accuracy: 0.5291 - val_loss: 0.9910 - val_accuracy: 0.5190\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9810 - accuracy: 0.5288 - val_loss: 0.9888 - val_accuracy: 0.5248\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9793 - accuracy: 0.5302 - val_loss: 0.9871 - val_accuracy: 0.5199\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9777 - accuracy: 0.5302 - val_loss: 0.9860 - val_accuracy: 0.5243\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9768 - accuracy: 0.5303 - val_loss: 0.9855 - val_accuracy: 0.5252\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9761 - accuracy: 0.5310 - val_loss: 0.9852 - val_accuracy: 0.5261\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9755 - accuracy: 0.5313 - val_loss: 0.9847 - val_accuracy: 0.5235\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 565us/step - loss: 0.9748 - accuracy: 0.5308 - val_loss: 0.9841 - val_accuracy: 0.5248\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9746 - accuracy: 0.5318 - val_loss: 0.9838 - val_accuracy: 0.5265\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9744 - accuracy: 0.5335 - val_loss: 0.9836 - val_accuracy: 0.5248\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9739 - accuracy: 0.5320 - val_loss: 0.9833 - val_accuracy: 0.5270\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9738 - accuracy: 0.5312 - val_loss: 0.9834 - val_accuracy: 0.5230\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9735 - accuracy: 0.5319 - val_loss: 0.9838 - val_accuracy: 0.5235\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9735 - accuracy: 0.5314 - val_loss: 0.9830 - val_accuracy: 0.5226\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9731 - accuracy: 0.5319 - val_loss: 0.9834 - val_accuracy: 0.5212\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9731 - accuracy: 0.5331 - val_loss: 0.9827 - val_accuracy: 0.5257\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9728 - accuracy: 0.5324 - val_loss: 0.9837 - val_accuracy: 0.5230\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9727 - accuracy: 0.5317 - val_loss: 0.9833 - val_accuracy: 0.5252\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9728 - accuracy: 0.5327 - val_loss: 0.9830 - val_accuracy: 0.5221\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9725 - accuracy: 0.5329 - val_loss: 0.9833 - val_accuracy: 0.5252\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9724 - accuracy: 0.5333 - val_loss: 0.9827 - val_accuracy: 0.5257\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9725 - accuracy: 0.5323 - val_loss: 0.9832 - val_accuracy: 0.5261\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9724 - accuracy: 0.5324 - val_loss: 0.9829 - val_accuracy: 0.5248\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9723 - accuracy: 0.5324 - val_loss: 0.9827 - val_accuracy: 0.5265\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9721 - accuracy: 0.5317 - val_loss: 0.9848 - val_accuracy: 0.5212\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9723 - accuracy: 0.5324 - val_loss: 0.9830 - val_accuracy: 0.5230\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9721 - accuracy: 0.5319 - val_loss: 0.9824 - val_accuracy: 0.5257\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9722 - accuracy: 0.5328 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9720 - accuracy: 0.5321 - val_loss: 0.9829 - val_accuracy: 0.5217\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9720 - accuracy: 0.5318 - val_loss: 0.9824 - val_accuracy: 0.5261\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9719 - accuracy: 0.5322 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9719 - accuracy: 0.5336 - val_loss: 0.9825 - val_accuracy: 0.5265\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9718 - accuracy: 0.5325 - val_loss: 0.9830 - val_accuracy: 0.5226\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9721 - accuracy: 0.5320 - val_loss: 0.9823 - val_accuracy: 0.5257\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9717 - accuracy: 0.5337 - val_loss: 0.9824 - val_accuracy: 0.5257\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9719 - accuracy: 0.5332 - val_loss: 0.9824 - val_accuracy: 0.5252\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9718 - accuracy: 0.5331 - val_loss: 0.9826 - val_accuracy: 0.5257\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9717 - accuracy: 0.5332 - val_loss: 0.9827 - val_accuracy: 0.5257\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9718 - accuracy: 0.5328 - val_loss: 0.9823 - val_accuracy: 0.5257\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9717 - accuracy: 0.5323 - val_loss: 0.9822 - val_accuracy: 0.5212\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9715 - accuracy: 0.5313 - val_loss: 0.9821 - val_accuracy: 0.5239\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9715 - accuracy: 0.5330 - val_loss: 0.9824 - val_accuracy: 0.5212\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9715 - accuracy: 0.5334 - val_loss: 0.9822 - val_accuracy: 0.5265\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9716 - accuracy: 0.5319 - val_loss: 0.9832 - val_accuracy: 0.5257\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9717 - accuracy: 0.5331 - val_loss: 0.9823 - val_accuracy: 0.5239\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9714 - accuracy: 0.5324 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 566us/step - loss: 0.9714 - accuracy: 0.5314 - val_loss: 0.9821 - val_accuracy: 0.5265\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9717 - accuracy: 0.5319 - val_loss: 0.9821 - val_accuracy: 0.5265\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9714 - accuracy: 0.5320 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9715 - accuracy: 0.5334 - val_loss: 0.9827 - val_accuracy: 0.5257\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9713 - accuracy: 0.5321 - val_loss: 0.9822 - val_accuracy: 0.5261\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9714 - accuracy: 0.5327 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9714 - accuracy: 0.5325 - val_loss: 0.9822 - val_accuracy: 0.5230\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 510us/step - loss: 0.9714 - accuracy: 0.5322 - val_loss: 0.9829 - val_accuracy: 0.5217\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9714 - accuracy: 0.5311 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9712 - accuracy: 0.5325 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9713 - accuracy: 0.5324 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9713 - accuracy: 0.5330 - val_loss: 0.9821 - val_accuracy: 0.5235\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9713 - accuracy: 0.5325 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9715 - accuracy: 0.5322 - val_loss: 0.9826 - val_accuracy: 0.5226\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9713 - accuracy: 0.5319 - val_loss: 0.9831 - val_accuracy: 0.5212\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9712 - accuracy: 0.5331 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9713 - accuracy: 0.5312 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9713 - accuracy: 0.5318 - val_loss: 0.9820 - val_accuracy: 0.5265\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9712 - accuracy: 0.5323 - val_loss: 0.9821 - val_accuracy: 0.5265\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9712 - accuracy: 0.5329 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9709 - accuracy: 0.5326 - val_loss: 0.9825 - val_accuracy: 0.5226\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9714 - accuracy: 0.5331 - val_loss: 0.9828 - val_accuracy: 0.5199\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9711 - accuracy: 0.5331 - val_loss: 0.9824 - val_accuracy: 0.5261\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 564us/step - loss: 0.9713 - accuracy: 0.5319 - val_loss: 0.9822 - val_accuracy: 0.5261\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 592us/step - loss: 0.9712 - accuracy: 0.5330 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9712 - accuracy: 0.5319 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9711 - accuracy: 0.5324 - val_loss: 0.9828 - val_accuracy: 0.5217\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9712 - accuracy: 0.5323 - val_loss: 0.9828 - val_accuracy: 0.5204\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9710 - accuracy: 0.5331 - val_loss: 0.9830 - val_accuracy: 0.5212\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9712 - accuracy: 0.5323 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9712 - accuracy: 0.5333 - val_loss: 0.9822 - val_accuracy: 0.5230\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9711 - accuracy: 0.5327 - val_loss: 0.9827 - val_accuracy: 0.5257\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9711 - accuracy: 0.5334 - val_loss: 0.9819 - val_accuracy: 0.5230\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9709 - accuracy: 0.5312 - val_loss: 0.9822 - val_accuracy: 0.5257\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9710 - accuracy: 0.5326 - val_loss: 0.9832 - val_accuracy: 0.5204\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9710 - accuracy: 0.5320 - val_loss: 0.9831 - val_accuracy: 0.5204\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9712 - accuracy: 0.5329 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9713 - accuracy: 0.5327 - val_loss: 0.9819 - val_accuracy: 0.5230\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9712 - accuracy: 0.5324 - val_loss: 0.9818 - val_accuracy: 0.5226\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9711 - accuracy: 0.5336 - val_loss: 0.9818 - val_accuracy: 0.5230\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9711 - accuracy: 0.5324 - val_loss: 0.9818 - val_accuracy: 0.5257\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9710 - accuracy: 0.5324 - val_loss: 0.9818 - val_accuracy: 0.5226\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9710 - accuracy: 0.5327 - val_loss: 0.9822 - val_accuracy: 0.5257\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9710 - accuracy: 0.5331 - val_loss: 0.9821 - val_accuracy: 0.5230\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9710 - accuracy: 0.5329 - val_loss: 0.9822 - val_accuracy: 0.5252\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9713 - accuracy: 0.5342 - val_loss: 0.9818 - val_accuracy: 0.5257\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9711 - accuracy: 0.5320 - val_loss: 0.9819 - val_accuracy: 0.5257\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9710 - accuracy: 0.5331 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9711 - accuracy: 0.5319 - val_loss: 0.9819 - val_accuracy: 0.5226\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9708 - accuracy: 0.5329 - val_loss: 0.9821 - val_accuracy: 0.5230\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9710 - accuracy: 0.5330 - val_loss: 0.9819 - val_accuracy: 0.5230\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9710 - accuracy: 0.5332 - val_loss: 0.9826 - val_accuracy: 0.5257\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9710 - accuracy: 0.5323 - val_loss: 0.9819 - val_accuracy: 0.5265\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9712 - accuracy: 0.5329 - val_loss: 0.9819 - val_accuracy: 0.5252\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9709 - accuracy: 0.5329 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9711 - accuracy: 0.5325 - val_loss: 0.9818 - val_accuracy: 0.5252\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9712 - accuracy: 0.5334 - val_loss: 0.9822 - val_accuracy: 0.5257\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9711 - accuracy: 0.5321 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9710 - accuracy: 0.5329 - val_loss: 0.9817 - val_accuracy: 0.5212\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9710 - accuracy: 0.5335 - val_loss: 0.9822 - val_accuracy: 0.5257\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9711 - accuracy: 0.5326 - val_loss: 0.9817 - val_accuracy: 0.5252\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9710 - accuracy: 0.5321 - val_loss: 0.9822 - val_accuracy: 0.5257\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9710 - accuracy: 0.5337 - val_loss: 0.9818 - val_accuracy: 0.5235\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 524us/step - loss: 0.9710 - accuracy: 0.5334 - val_loss: 0.9825 - val_accuracy: 0.5204\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9710 - accuracy: 0.5329 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9712 - accuracy: 0.5328 - val_loss: 0.9816 - val_accuracy: 0.5265\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9710 - accuracy: 0.5330 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9710 - accuracy: 0.5325 - val_loss: 0.9819 - val_accuracy: 0.5226\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9712 - accuracy: 0.5327 - val_loss: 0.9817 - val_accuracy: 0.5257\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9710 - accuracy: 0.5322 - val_loss: 0.9818 - val_accuracy: 0.5212\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9709 - accuracy: 0.5324 - val_loss: 0.9826 - val_accuracy: 0.5212\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9711 - accuracy: 0.5323 - val_loss: 0.9818 - val_accuracy: 0.5261\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5333 - val_loss: 0.9819 - val_accuracy: 0.5230\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9710 - accuracy: 0.5331 - val_loss: 0.9822 - val_accuracy: 0.5217\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9710 - accuracy: 0.5327 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9709 - accuracy: 0.5321 - val_loss: 0.9819 - val_accuracy: 0.5212\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9708 - accuracy: 0.5325 - val_loss: 0.9819 - val_accuracy: 0.5252\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9709 - accuracy: 0.5321 - val_loss: 0.9817 - val_accuracy: 0.5239\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9711 - accuracy: 0.5325 - val_loss: 0.9819 - val_accuracy: 0.5265\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9709 - accuracy: 0.5338 - val_loss: 0.9839 - val_accuracy: 0.5190\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9709 - accuracy: 0.5328 - val_loss: 0.9824 - val_accuracy: 0.5257\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9710 - accuracy: 0.5326 - val_loss: 0.9822 - val_accuracy: 0.5239\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9710 - accuracy: 0.5328 - val_loss: 0.9817 - val_accuracy: 0.5261\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9708 - accuracy: 0.5327 - val_loss: 0.9835 - val_accuracy: 0.5168\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9711 - accuracy: 0.5323 - val_loss: 0.9818 - val_accuracy: 0.5226\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9709 - accuracy: 0.5325 - val_loss: 0.9818 - val_accuracy: 0.5230\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9710 - accuracy: 0.5317 - val_loss: 0.9819 - val_accuracy: 0.5235\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9708 - accuracy: 0.5341 - val_loss: 0.9817 - val_accuracy: 0.5257\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9710 - accuracy: 0.5329 - val_loss: 0.9829 - val_accuracy: 0.5252\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9710 - accuracy: 0.5332 - val_loss: 0.9819 - val_accuracy: 0.5265\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9708 - accuracy: 0.5331 - val_loss: 0.9817 - val_accuracy: 0.5230\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9710 - accuracy: 0.5331 - val_loss: 0.9825 - val_accuracy: 0.5204\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9709 - accuracy: 0.5324 - val_loss: 0.9817 - val_accuracy: 0.5221\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9710 - accuracy: 0.5320 - val_loss: 0.9817 - val_accuracy: 0.5261\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9710 - accuracy: 0.5327 - val_loss: 0.9818 - val_accuracy: 0.5265\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9709 - accuracy: 0.5314 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9710 - accuracy: 0.5323 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9709 - accuracy: 0.5333 - val_loss: 0.9818 - val_accuracy: 0.5252\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9709 - accuracy: 0.5323 - val_loss: 0.9820 - val_accuracy: 0.5257\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9710 - accuracy: 0.5325 - val_loss: 0.9820 - val_accuracy: 0.5257\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9709 - accuracy: 0.5326 - val_loss: 0.9825 - val_accuracy: 0.5212\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9709 - accuracy: 0.5338 - val_loss: 0.9818 - val_accuracy: 0.5239\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9709 - accuracy: 0.5324 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9708 - accuracy: 0.5328 - val_loss: 0.9817 - val_accuracy: 0.5252\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9709 - accuracy: 0.5327 - val_loss: 0.9817 - val_accuracy: 0.5226\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9710 - accuracy: 0.5317 - val_loss: 0.9820 - val_accuracy: 0.5257\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9709 - accuracy: 0.5328 - val_loss: 0.9822 - val_accuracy: 0.5257\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9709 - accuracy: 0.5325 - val_loss: 0.9816 - val_accuracy: 0.5226\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 547us/step - loss: 0.9706 - accuracy: 0.5334 - val_loss: 0.9835 - val_accuracy: 0.5177\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9710 - accuracy: 0.5332 - val_loss: 0.9819 - val_accuracy: 0.5257\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9711 - accuracy: 0.5333 - val_loss: 0.9818 - val_accuracy: 0.5257\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9709 - accuracy: 0.5331 - val_loss: 0.9818 - val_accuracy: 0.5226\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9710 - accuracy: 0.5315 - val_loss: 0.9816 - val_accuracy: 0.5226\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9709 - accuracy: 0.5329 - val_loss: 0.9820 - val_accuracy: 0.5257\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9708 - accuracy: 0.5333 - val_loss: 0.9815 - val_accuracy: 0.5265\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9709 - accuracy: 0.5334 - val_loss: 0.9823 - val_accuracy: 0.5257\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9708 - accuracy: 0.5313 - val_loss: 0.9834 - val_accuracy: 0.5252\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9707 - accuracy: 0.5331 - val_loss: 0.9816 - val_accuracy: 0.5265\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9708 - accuracy: 0.5316 - val_loss: 0.9825 - val_accuracy: 0.5217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9709 - accuracy: 0.5326 - val_loss: 0.9817 - val_accuracy: 0.5230\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9708 - accuracy: 0.5329 - val_loss: 0.9817 - val_accuracy: 0.5230\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9709 - accuracy: 0.5330 - val_loss: 0.9818 - val_accuracy: 0.5230\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9708 - accuracy: 0.5332 - val_loss: 0.9817 - val_accuracy: 0.5265\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9710 - accuracy: 0.5324 - val_loss: 0.9820 - val_accuracy: 0.5265\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9710 - accuracy: 0.5326 - val_loss: 0.9816 - val_accuracy: 0.5257\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9708 - accuracy: 0.5333 - val_loss: 0.9824 - val_accuracy: 0.5217\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9709 - accuracy: 0.5318 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9709 - accuracy: 0.5325 - val_loss: 0.9827 - val_accuracy: 0.5195\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9709 - accuracy: 0.5321 - val_loss: 0.9821 - val_accuracy: 0.5230\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9709 - accuracy: 0.5327 - val_loss: 0.9818 - val_accuracy: 0.5230\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9710 - accuracy: 0.5320 - val_loss: 0.9819 - val_accuracy: 0.5230\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9708 - accuracy: 0.5337 - val_loss: 0.9820 - val_accuracy: 0.5230\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9707 - accuracy: 0.5327 - val_loss: 0.9828 - val_accuracy: 0.5204\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9709 - accuracy: 0.5335 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9708 - accuracy: 0.5333 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9708 - accuracy: 0.5331 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9706 - accuracy: 0.5330 - val_loss: 0.9816 - val_accuracy: 0.5252\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9708 - accuracy: 0.5324 - val_loss: 0.9816 - val_accuracy: 0.5257\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9707 - accuracy: 0.5333 - val_loss: 0.9819 - val_accuracy: 0.5252\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9706 - accuracy: 0.5329 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9708 - accuracy: 0.5324 - val_loss: 0.9817 - val_accuracy: 0.5265\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9708 - accuracy: 0.5337 - val_loss: 0.9817 - val_accuracy: 0.5257\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9709 - accuracy: 0.5330 - val_loss: 0.9818 - val_accuracy: 0.5230\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9707 - accuracy: 0.5312 - val_loss: 0.9817 - val_accuracy: 0.5230\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9706 - accuracy: 0.5333 - val_loss: 0.9815 - val_accuracy: 0.5252\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9706 - accuracy: 0.5325 - val_loss: 0.9815 - val_accuracy: 0.5265\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9709 - accuracy: 0.5331 - val_loss: 0.9818 - val_accuracy: 0.5226\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9708 - accuracy: 0.5331 - val_loss: 0.9814 - val_accuracy: 0.5226\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9708 - accuracy: 0.5341 - val_loss: 0.9818 - val_accuracy: 0.5226\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9707 - accuracy: 0.5338 - val_loss: 0.9815 - val_accuracy: 0.5257\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9707 - accuracy: 0.5331 - val_loss: 0.9820 - val_accuracy: 0.5257\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 340us/step - loss: 0.9709 - accuracy: 0.5317\n",
      "Accuracy : 0.5317233800888062\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9820 - accuracy: 0.5257\n",
      "Accuracy : 0.5256637334823608\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 653us/step - loss: 1.0544 - accuracy: 0.4565 - val_loss: 1.0362 - val_accuracy: 0.4593\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 1.0258 - accuracy: 0.4659 - val_loss: 1.0079 - val_accuracy: 0.5181\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 1.0029 - accuracy: 0.5252 - val_loss: 0.9895 - val_accuracy: 0.5358\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9919 - accuracy: 0.5272 - val_loss: 0.9830 - val_accuracy: 0.5358\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9869 - accuracy: 0.5272 - val_loss: 0.9787 - val_accuracy: 0.5358\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9837 - accuracy: 0.5271 - val_loss: 0.9765 - val_accuracy: 0.5358\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9810 - accuracy: 0.5271 - val_loss: 0.9750 - val_accuracy: 0.5358\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9796 - accuracy: 0.5272 - val_loss: 0.9740 - val_accuracy: 0.5358\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9784 - accuracy: 0.5273 - val_loss: 0.9732 - val_accuracy: 0.5358\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9777 - accuracy: 0.5270 - val_loss: 0.9730 - val_accuracy: 0.5358\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9770 - accuracy: 0.5278 - val_loss: 0.9723 - val_accuracy: 0.5358\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9765 - accuracy: 0.5278 - val_loss: 0.9722 - val_accuracy: 0.5358\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9758 - accuracy: 0.5280 - val_loss: 0.9723 - val_accuracy: 0.5367\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 470us/step - loss: 0.9757 - accuracy: 0.5287 - val_loss: 0.9722 - val_accuracy: 0.5358\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9754 - accuracy: 0.5273 - val_loss: 0.9718 - val_accuracy: 0.5358\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9753 - accuracy: 0.5278 - val_loss: 0.9718 - val_accuracy: 0.5367\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9750 - accuracy: 0.5286 - val_loss: 0.9717 - val_accuracy: 0.5376\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9750 - accuracy: 0.5292 - val_loss: 0.9721 - val_accuracy: 0.5363\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9750 - accuracy: 0.5296 - val_loss: 0.9722 - val_accuracy: 0.5358\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9747 - accuracy: 0.5290 - val_loss: 0.9722 - val_accuracy: 0.5363\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9723 - val_accuracy: 0.5358\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9745 - accuracy: 0.5289 - val_loss: 0.9722 - val_accuracy: 0.5358\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 490us/step - loss: 0.9744 - accuracy: 0.5288 - val_loss: 0.9721 - val_accuracy: 0.5358\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9742 - accuracy: 0.5284 - val_loss: 0.9728 - val_accuracy: 0.5358\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9739 - accuracy: 0.5305 - val_loss: 0.9726 - val_accuracy: 0.5358\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9741 - accuracy: 0.5303 - val_loss: 0.9724 - val_accuracy: 0.5376\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9740 - accuracy: 0.5303 - val_loss: 0.9718 - val_accuracy: 0.5389\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9740 - accuracy: 0.5288 - val_loss: 0.9716 - val_accuracy: 0.5363\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9739 - accuracy: 0.5303 - val_loss: 0.9733 - val_accuracy: 0.5358\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9719 - val_accuracy: 0.5358\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9737 - accuracy: 0.5287 - val_loss: 0.9722 - val_accuracy: 0.5345\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9738 - accuracy: 0.5294 - val_loss: 0.9720 - val_accuracy: 0.5358\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9722 - val_accuracy: 0.5363\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9735 - accuracy: 0.5294 - val_loss: 0.9719 - val_accuracy: 0.5363\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9734 - accuracy: 0.5306 - val_loss: 0.9725 - val_accuracy: 0.5381\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5314 - val_loss: 0.9720 - val_accuracy: 0.5358\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9735 - accuracy: 0.5277 - val_loss: 0.9716 - val_accuracy: 0.5367\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9731 - accuracy: 0.5284 - val_loss: 0.9734 - val_accuracy: 0.5376\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9733 - accuracy: 0.5295 - val_loss: 0.9729 - val_accuracy: 0.5385\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 0.9720 - val_accuracy: 0.5358\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9731 - accuracy: 0.5300 - val_loss: 0.9721 - val_accuracy: 0.5358\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9730 - accuracy: 0.5291 - val_loss: 0.9721 - val_accuracy: 0.5376\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9730 - accuracy: 0.5299 - val_loss: 0.9722 - val_accuracy: 0.5381\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9728 - accuracy: 0.5294 - val_loss: 0.9719 - val_accuracy: 0.5381\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9729 - accuracy: 0.5304 - val_loss: 0.9722 - val_accuracy: 0.5376\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9727 - accuracy: 0.5304 - val_loss: 0.9720 - val_accuracy: 0.5381\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9727 - accuracy: 0.5299 - val_loss: 0.9731 - val_accuracy: 0.5358\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9727 - accuracy: 0.5293 - val_loss: 0.9727 - val_accuracy: 0.5367\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9726 - accuracy: 0.5308 - val_loss: 0.9725 - val_accuracy: 0.5376\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9727 - accuracy: 0.5312 - val_loss: 0.9719 - val_accuracy: 0.5367\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9726 - accuracy: 0.5310 - val_loss: 0.9730 - val_accuracy: 0.5376\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9727 - accuracy: 0.5315 - val_loss: 0.9721 - val_accuracy: 0.5381\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9726 - accuracy: 0.5310 - val_loss: 0.9720 - val_accuracy: 0.5363\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - ETA: 0s - loss: 0.9721 - accuracy: 0.53 - 0s 476us/step - loss: 0.9725 - accuracy: 0.5300 - val_loss: 0.9718 - val_accuracy: 0.5367\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9724 - accuracy: 0.5302 - val_loss: 0.9733 - val_accuracy: 0.5358\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9726 - accuracy: 0.5304 - val_loss: 0.9718 - val_accuracy: 0.5394\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 548us/step - loss: 0.9725 - accuracy: 0.5301 - val_loss: 0.9722 - val_accuracy: 0.5358\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9724 - accuracy: 0.5312 - val_loss: 0.9724 - val_accuracy: 0.5376\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9720 - accuracy: 0.5322 - val_loss: 0.9723 - val_accuracy: 0.5363\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9723 - accuracy: 0.5311 - val_loss: 0.9719 - val_accuracy: 0.5367\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9725 - accuracy: 0.5320 - val_loss: 0.9718 - val_accuracy: 0.5394\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9722 - accuracy: 0.5297 - val_loss: 0.9726 - val_accuracy: 0.5358\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9725 - accuracy: 0.5309 - val_loss: 0.9722 - val_accuracy: 0.5358\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9723 - accuracy: 0.5316 - val_loss: 0.9719 - val_accuracy: 0.5381\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9724 - accuracy: 0.5299 - val_loss: 0.9717 - val_accuracy: 0.5389\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9722 - accuracy: 0.5309 - val_loss: 0.9724 - val_accuracy: 0.5358\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9724 - accuracy: 0.5328 - val_loss: 0.9732 - val_accuracy: 0.5363\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9722 - accuracy: 0.5312 - val_loss: 0.9721 - val_accuracy: 0.5363\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9722 - accuracy: 0.5313 - val_loss: 0.9719 - val_accuracy: 0.5376\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9722 - accuracy: 0.5306 - val_loss: 0.9724 - val_accuracy: 0.5376\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9721 - accuracy: 0.5317 - val_loss: 0.9720 - val_accuracy: 0.5367\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9723 - accuracy: 0.5310 - val_loss: 0.9722 - val_accuracy: 0.5367\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9720 - accuracy: 0.5316 - val_loss: 0.9730 - val_accuracy: 0.5363\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9721 - accuracy: 0.5305 - val_loss: 0.9715 - val_accuracy: 0.5394\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9721 - accuracy: 0.5311 - val_loss: 0.9727 - val_accuracy: 0.5394\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9720 - accuracy: 0.5327 - val_loss: 0.9724 - val_accuracy: 0.5385\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9721 - accuracy: 0.5317 - val_loss: 0.9726 - val_accuracy: 0.5350\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9723 - accuracy: 0.5316 - val_loss: 0.9719 - val_accuracy: 0.5376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9721 - accuracy: 0.5305 - val_loss: 0.9720 - val_accuracy: 0.5363\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 466us/step - loss: 0.9723 - accuracy: 0.5316 - val_loss: 0.9720 - val_accuracy: 0.5394\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9718 - accuracy: 0.5313 - val_loss: 0.9727 - val_accuracy: 0.5354\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9721 - accuracy: 0.5303 - val_loss: 0.9718 - val_accuracy: 0.5363\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9719 - accuracy: 0.5305 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9718 - accuracy: 0.5317 - val_loss: 0.9721 - val_accuracy: 0.5363\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9718 - accuracy: 0.5299 - val_loss: 0.9723 - val_accuracy: 0.5385\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9720 - accuracy: 0.5315 - val_loss: 0.9717 - val_accuracy: 0.5394\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9720 - accuracy: 0.5297 - val_loss: 0.9728 - val_accuracy: 0.5376\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9721 - accuracy: 0.5322 - val_loss: 0.9724 - val_accuracy: 0.5394\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9720 - accuracy: 0.5308 - val_loss: 0.9724 - val_accuracy: 0.5354\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9718 - accuracy: 0.5321 - val_loss: 0.9728 - val_accuracy: 0.5354\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9719 - accuracy: 0.5318 - val_loss: 0.9726 - val_accuracy: 0.5363\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5323 - val_loss: 0.9720 - val_accuracy: 0.5363\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9717 - accuracy: 0.5303 - val_loss: 0.9720 - val_accuracy: 0.5363\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9718 - accuracy: 0.5310 - val_loss: 0.9717 - val_accuracy: 0.5363\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9721 - accuracy: 0.5304 - val_loss: 0.9730 - val_accuracy: 0.5354\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9719 - accuracy: 0.5311 - val_loss: 0.9722 - val_accuracy: 0.5376\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9717 - accuracy: 0.5310 - val_loss: 0.9731 - val_accuracy: 0.5350\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9719 - accuracy: 0.5314 - val_loss: 0.9727 - val_accuracy: 0.5376\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9722 - val_accuracy: 0.5358\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9719 - accuracy: 0.5310 - val_loss: 0.9719 - val_accuracy: 0.5363\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9718 - accuracy: 0.5308 - val_loss: 0.9725 - val_accuracy: 0.5376\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9719 - accuracy: 0.5311 - val_loss: 0.9725 - val_accuracy: 0.5354\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9718 - accuracy: 0.5317 - val_loss: 0.9729 - val_accuracy: 0.5376\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9718 - accuracy: 0.5321 - val_loss: 0.9727 - val_accuracy: 0.5372\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9719 - val_accuracy: 0.5394\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9716 - accuracy: 0.5299 - val_loss: 0.9724 - val_accuracy: 0.5394\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9717 - accuracy: 0.5312 - val_loss: 0.9728 - val_accuracy: 0.5385\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9715 - accuracy: 0.5322 - val_loss: 0.9725 - val_accuracy: 0.5381\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 470us/step - loss: 0.9718 - accuracy: 0.5296 - val_loss: 0.9718 - val_accuracy: 0.5363\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9717 - accuracy: 0.5310 - val_loss: 0.9728 - val_accuracy: 0.5363\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9718 - accuracy: 0.5313 - val_loss: 0.9722 - val_accuracy: 0.5354\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9717 - accuracy: 0.5331 - val_loss: 0.9723 - val_accuracy: 0.5363\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9719 - val_accuracy: 0.5376\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9719 - accuracy: 0.5306 - val_loss: 0.9724 - val_accuracy: 0.5363\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9718 - accuracy: 0.5317 - val_loss: 0.9726 - val_accuracy: 0.5376\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9717 - accuracy: 0.5307 - val_loss: 0.9726 - val_accuracy: 0.5327\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9716 - accuracy: 0.5320 - val_loss: 0.9730 - val_accuracy: 0.5367\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9718 - accuracy: 0.5312 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9718 - accuracy: 0.5321 - val_loss: 0.9732 - val_accuracy: 0.5376\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9720 - accuracy: 0.5307 - val_loss: 0.9731 - val_accuracy: 0.5372\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9719 - val_accuracy: 0.5394\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9715 - accuracy: 0.5314 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9717 - accuracy: 0.5330 - val_loss: 0.9719 - val_accuracy: 0.5336\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9717 - accuracy: 0.5311 - val_loss: 0.9720 - val_accuracy: 0.5363\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9716 - accuracy: 0.5314 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9717 - accuracy: 0.5302 - val_loss: 0.9718 - val_accuracy: 0.5372\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9718 - accuracy: 0.5306 - val_loss: 0.9718 - val_accuracy: 0.5363\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9719 - accuracy: 0.5317 - val_loss: 0.9721 - val_accuracy: 0.5385\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9718 - accuracy: 0.5313 - val_loss: 0.9720 - val_accuracy: 0.5363\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9715 - accuracy: 0.5318 - val_loss: 0.9731 - val_accuracy: 0.5354\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9715 - accuracy: 0.5325 - val_loss: 0.9722 - val_accuracy: 0.5376\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9716 - accuracy: 0.5314 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9716 - accuracy: 0.5292 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9715 - accuracy: 0.5314 - val_loss: 0.9716 - val_accuracy: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9717 - accuracy: 0.5308 - val_loss: 0.9729 - val_accuracy: 0.5394\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9714 - accuracy: 0.5326 - val_loss: 0.9729 - val_accuracy: 0.5376\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9718 - accuracy: 0.5310 - val_loss: 0.9720 - val_accuracy: 0.5363\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9717 - accuracy: 0.5320 - val_loss: 0.9719 - val_accuracy: 0.5358\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9716 - accuracy: 0.5311 - val_loss: 0.9726 - val_accuracy: 0.5372\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9715 - accuracy: 0.5306 - val_loss: 0.9727 - val_accuracy: 0.5394\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9723 - val_accuracy: 0.5394\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9717 - accuracy: 0.5303 - val_loss: 0.9727 - val_accuracy: 0.5358\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9718 - accuracy: 0.5321 - val_loss: 0.9724 - val_accuracy: 0.5381\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9717 - accuracy: 0.5310 - val_loss: 0.9734 - val_accuracy: 0.5358\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9715 - accuracy: 0.5304 - val_loss: 0.9729 - val_accuracy: 0.5376\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9715 - accuracy: 0.5311 - val_loss: 0.9734 - val_accuracy: 0.5358\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9716 - accuracy: 0.5318 - val_loss: 0.9719 - val_accuracy: 0.5363\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9716 - accuracy: 0.5322 - val_loss: 0.9723 - val_accuracy: 0.5376\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - ETA: 0s - loss: 0.9726 - accuracy: 0.53 - 0s 468us/step - loss: 0.9716 - accuracy: 0.5317 - val_loss: 0.9729 - val_accuracy: 0.5376\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 468us/step - loss: 0.9714 - accuracy: 0.5310 - val_loss: 0.9735 - val_accuracy: 0.5372\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9718 - accuracy: 0.5307 - val_loss: 0.9723 - val_accuracy: 0.5367\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9714 - accuracy: 0.5301 - val_loss: 0.9720 - val_accuracy: 0.5394\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9716 - accuracy: 0.5326 - val_loss: 0.9727 - val_accuracy: 0.5358\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9724 - val_accuracy: 0.5394\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9716 - accuracy: 0.5312 - val_loss: 0.9731 - val_accuracy: 0.5363\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9716 - accuracy: 0.5317 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9715 - accuracy: 0.5309 - val_loss: 0.9723 - val_accuracy: 0.5394\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9715 - accuracy: 0.5320 - val_loss: 0.9718 - val_accuracy: 0.5394\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9715 - accuracy: 0.5324 - val_loss: 0.9725 - val_accuracy: 0.5389\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9714 - accuracy: 0.5316 - val_loss: 0.9735 - val_accuracy: 0.5381\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9717 - accuracy: 0.5316 - val_loss: 0.9719 - val_accuracy: 0.5394\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9715 - accuracy: 0.5322 - val_loss: 0.9724 - val_accuracy: 0.5363\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9717 - accuracy: 0.5314 - val_loss: 0.9725 - val_accuracy: 0.5354\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9713 - accuracy: 0.5321 - val_loss: 0.9717 - val_accuracy: 0.5363\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9716 - accuracy: 0.5313 - val_loss: 0.9715 - val_accuracy: 0.5363\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9715 - accuracy: 0.5321 - val_loss: 0.9729 - val_accuracy: 0.5372\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9714 - accuracy: 0.5321 - val_loss: 0.9723 - val_accuracy: 0.5332\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9715 - accuracy: 0.5330 - val_loss: 0.9725 - val_accuracy: 0.5367\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9715 - accuracy: 0.5316 - val_loss: 0.9714 - val_accuracy: 0.5372\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9714 - accuracy: 0.5309 - val_loss: 0.9729 - val_accuracy: 0.5358\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9716 - accuracy: 0.5316 - val_loss: 0.9718 - val_accuracy: 0.5372\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9717 - accuracy: 0.5311 - val_loss: 0.9726 - val_accuracy: 0.5372\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9718 - accuracy: 0.5313 - val_loss: 0.9720 - val_accuracy: 0.5372\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9715 - accuracy: 0.5312 - val_loss: 0.9715 - val_accuracy: 0.5394\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9715 - accuracy: 0.5309 - val_loss: 0.9714 - val_accuracy: 0.5363\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9715 - accuracy: 0.5311 - val_loss: 0.9721 - val_accuracy: 0.5358\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9715 - accuracy: 0.5318 - val_loss: 0.9719 - val_accuracy: 0.5363\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5306 - val_loss: 0.9724 - val_accuracy: 0.5341\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9715 - accuracy: 0.5311 - val_loss: 0.9728 - val_accuracy: 0.5381\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9714 - accuracy: 0.5317 - val_loss: 0.9722 - val_accuracy: 0.5358\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9716 - accuracy: 0.5321 - val_loss: 0.9721 - val_accuracy: 0.5394\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9715 - accuracy: 0.5318 - val_loss: 0.9726 - val_accuracy: 0.5358\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9715 - accuracy: 0.5313 - val_loss: 0.9733 - val_accuracy: 0.5358\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 481us/step - loss: 0.9715 - accuracy: 0.5321 - val_loss: 0.9717 - val_accuracy: 0.5394\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9713 - accuracy: 0.5310 - val_loss: 0.9730 - val_accuracy: 0.5394\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9714 - accuracy: 0.5327 - val_loss: 0.9739 - val_accuracy: 0.5381\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9715 - accuracy: 0.5320 - val_loss: 0.9721 - val_accuracy: 0.5363\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9715 - accuracy: 0.5315 - val_loss: 0.9723 - val_accuracy: 0.5363\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9714 - accuracy: 0.5309 - val_loss: 0.9726 - val_accuracy: 0.5372\n",
      "Epoch 190/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 490us/step - loss: 0.9714 - accuracy: 0.5314 - val_loss: 0.9737 - val_accuracy: 0.5394\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9713 - accuracy: 0.5326 - val_loss: 0.9724 - val_accuracy: 0.5358\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9714 - accuracy: 0.5313 - val_loss: 0.9719 - val_accuracy: 0.5363\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9715 - accuracy: 0.5322 - val_loss: 0.9725 - val_accuracy: 0.5358\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9715 - accuracy: 0.5319 - val_loss: 0.9721 - val_accuracy: 0.5363\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9716 - accuracy: 0.5311 - val_loss: 0.9719 - val_accuracy: 0.5358\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9714 - accuracy: 0.5321 - val_loss: 0.9717 - val_accuracy: 0.5358\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9713 - accuracy: 0.5327 - val_loss: 0.9747 - val_accuracy: 0.5363\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9715 - accuracy: 0.5317 - val_loss: 0.9717 - val_accuracy: 0.5363\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9716 - accuracy: 0.5318 - val_loss: 0.9731 - val_accuracy: 0.5372\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9715 - accuracy: 0.5309 - val_loss: 0.9716 - val_accuracy: 0.5376\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 337us/step - loss: 0.9708 - accuracy: 0.5323\n",
      "Accuracy : 0.5322644114494324\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9716 - accuracy: 0.5376\n",
      "Accuracy : 0.5376105904579163\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 648us/step - loss: 1.0646 - accuracy: 0.4343 - val_loss: 1.0423 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 1.0134 - accuracy: 0.5099 - val_loss: 1.0147 - val_accuracy: 0.5219\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9901 - accuracy: 0.5305 - val_loss: 1.0075 - val_accuracy: 0.5237\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9834 - accuracy: 0.5292 - val_loss: 1.0055 - val_accuracy: 0.5232\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9808 - accuracy: 0.5297 - val_loss: 1.0040 - val_accuracy: 0.5232\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 556us/step - loss: 0.9787 - accuracy: 0.5306 - val_loss: 1.0030 - val_accuracy: 0.5237\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9773 - accuracy: 0.5312 - val_loss: 1.0020 - val_accuracy: 0.5241\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9760 - accuracy: 0.5311 - val_loss: 1.0020 - val_accuracy: 0.5241\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9750 - accuracy: 0.5332 - val_loss: 1.0020 - val_accuracy: 0.5290\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9741 - accuracy: 0.5325 - val_loss: 1.0013 - val_accuracy: 0.5237\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9733 - accuracy: 0.5320 - val_loss: 1.0008 - val_accuracy: 0.5281\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9729 - accuracy: 0.5316 - val_loss: 1.0008 - val_accuracy: 0.5281\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9724 - accuracy: 0.5313 - val_loss: 1.0003 - val_accuracy: 0.5281\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9722 - accuracy: 0.5321 - val_loss: 1.0004 - val_accuracy: 0.5241\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9719 - accuracy: 0.5325 - val_loss: 1.0001 - val_accuracy: 0.5290\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9717 - accuracy: 0.5327 - val_loss: 1.0008 - val_accuracy: 0.5286\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9716 - accuracy: 0.5319 - val_loss: 1.0007 - val_accuracy: 0.5277\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9715 - accuracy: 0.5331 - val_loss: 1.0004 - val_accuracy: 0.5281\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9713 - accuracy: 0.5323 - val_loss: 1.0015 - val_accuracy: 0.5232\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9710 - accuracy: 0.5323 - val_loss: 1.0008 - val_accuracy: 0.5286\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9711 - accuracy: 0.5317 - val_loss: 1.0011 - val_accuracy: 0.5241\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9711 - accuracy: 0.5314 - val_loss: 1.0009 - val_accuracy: 0.5232\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9709 - accuracy: 0.5313 - val_loss: 0.9998 - val_accuracy: 0.5237\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9708 - accuracy: 0.5328 - val_loss: 1.0021 - val_accuracy: 0.5232\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9707 - accuracy: 0.5323 - val_loss: 1.0038 - val_accuracy: 0.5215\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9707 - accuracy: 0.5313 - val_loss: 1.0004 - val_accuracy: 0.5286\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9706 - accuracy: 0.5316 - val_loss: 0.9997 - val_accuracy: 0.5277\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9707 - accuracy: 0.5322 - val_loss: 0.9993 - val_accuracy: 0.5281\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9706 - accuracy: 0.5317 - val_loss: 0.9995 - val_accuracy: 0.5281\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9706 - accuracy: 0.5326 - val_loss: 1.0011 - val_accuracy: 0.5228\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9707 - accuracy: 0.5316 - val_loss: 1.0000 - val_accuracy: 0.5255\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9704 - accuracy: 0.5319 - val_loss: 0.9995 - val_accuracy: 0.5281\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9705 - accuracy: 0.5324 - val_loss: 0.9997 - val_accuracy: 0.5286\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9704 - accuracy: 0.5320 - val_loss: 0.9998 - val_accuracy: 0.5259\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9702 - accuracy: 0.5321 - val_loss: 0.9996 - val_accuracy: 0.5241\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9704 - accuracy: 0.5320 - val_loss: 1.0005 - val_accuracy: 0.5286\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9703 - accuracy: 0.5321 - val_loss: 1.0009 - val_accuracy: 0.5232\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9704 - accuracy: 0.5325 - val_loss: 1.0001 - val_accuracy: 0.5263\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9704 - accuracy: 0.5325 - val_loss: 0.9991 - val_accuracy: 0.5281\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9703 - accuracy: 0.5322 - val_loss: 1.0031 - val_accuracy: 0.5206\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 481us/step - loss: 0.9702 - accuracy: 0.5318 - val_loss: 1.0004 - val_accuracy: 0.5224\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9703 - accuracy: 0.5324 - val_loss: 0.9994 - val_accuracy: 0.5277\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9702 - accuracy: 0.5330 - val_loss: 0.9991 - val_accuracy: 0.5255\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 497us/step - loss: 0.9703 - accuracy: 0.5315 - val_loss: 0.9988 - val_accuracy: 0.5281\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9700 - accuracy: 0.5312 - val_loss: 1.0003 - val_accuracy: 0.5232\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9701 - accuracy: 0.5316 - val_loss: 0.9996 - val_accuracy: 0.5237\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9701 - accuracy: 0.5324 - val_loss: 0.9990 - val_accuracy: 0.5290\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9699 - accuracy: 0.5318 - val_loss: 0.9989 - val_accuracy: 0.5286\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 557us/step - loss: 0.9700 - accuracy: 0.5324 - val_loss: 0.9991 - val_accuracy: 0.5281\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9701 - accuracy: 0.5326 - val_loss: 0.9992 - val_accuracy: 0.5286\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9701 - accuracy: 0.5320 - val_loss: 0.9990 - val_accuracy: 0.5286\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9700 - accuracy: 0.5321 - val_loss: 0.9991 - val_accuracy: 0.5286\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9697 - accuracy: 0.5332 - val_loss: 0.9987 - val_accuracy: 0.5246\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9700 - accuracy: 0.5313 - val_loss: 0.9988 - val_accuracy: 0.5281\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 553us/step - loss: 0.9698 - accuracy: 0.5326 - val_loss: 0.9987 - val_accuracy: 0.5281\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 575us/step - loss: 0.9699 - accuracy: 0.5327 - val_loss: 0.9994 - val_accuracy: 0.5286\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9698 - accuracy: 0.5318 - val_loss: 1.0018 - val_accuracy: 0.5215\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9699 - accuracy: 0.5317 - val_loss: 0.9993 - val_accuracy: 0.5259\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9699 - accuracy: 0.5326 - val_loss: 0.9986 - val_accuracy: 0.5281\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9697 - accuracy: 0.5325 - val_loss: 1.0005 - val_accuracy: 0.5215\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9699 - accuracy: 0.5316 - val_loss: 0.9998 - val_accuracy: 0.5224\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9697 - accuracy: 0.5314 - val_loss: 1.0003 - val_accuracy: 0.5263\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9699 - accuracy: 0.5319 - val_loss: 0.9991 - val_accuracy: 0.5259\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9698 - accuracy: 0.5325 - val_loss: 0.9993 - val_accuracy: 0.5281\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9698 - accuracy: 0.5321 - val_loss: 0.9990 - val_accuracy: 0.5281\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9698 - accuracy: 0.5316 - val_loss: 0.9991 - val_accuracy: 0.5263\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9698 - accuracy: 0.5315 - val_loss: 0.9987 - val_accuracy: 0.5281\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9699 - accuracy: 0.5319 - val_loss: 0.9990 - val_accuracy: 0.5286\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9696 - accuracy: 0.5319 - val_loss: 0.9987 - val_accuracy: 0.5272\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9700 - accuracy: 0.5326 - val_loss: 0.9988 - val_accuracy: 0.5286\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9698 - accuracy: 0.5333 - val_loss: 0.9983 - val_accuracy: 0.5281\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9699 - accuracy: 0.5313 - val_loss: 0.9992 - val_accuracy: 0.5259\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9698 - accuracy: 0.5313 - val_loss: 0.9992 - val_accuracy: 0.5281\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9699 - accuracy: 0.5320 - val_loss: 0.9995 - val_accuracy: 0.5228\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9698 - accuracy: 0.5318 - val_loss: 0.9991 - val_accuracy: 0.5286\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9698 - accuracy: 0.5320 - val_loss: 0.9993 - val_accuracy: 0.5281\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9698 - accuracy: 0.5329 - val_loss: 0.9986 - val_accuracy: 0.5286\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9698 - accuracy: 0.5319 - val_loss: 0.9996 - val_accuracy: 0.5232\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9696 - accuracy: 0.5333 - val_loss: 0.9992 - val_accuracy: 0.5277\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9696 - accuracy: 0.5314 - val_loss: 0.9991 - val_accuracy: 0.5286\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9694 - accuracy: 0.5321 - val_loss: 0.9992 - val_accuracy: 0.5250\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9692 - accuracy: 0.5329 - val_loss: 0.9992 - val_accuracy: 0.5286\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9695 - accuracy: 0.5316 - val_loss: 1.0000 - val_accuracy: 0.5259\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9697 - accuracy: 0.5327 - val_loss: 0.9987 - val_accuracy: 0.5286\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9696 - accuracy: 0.5327 - val_loss: 0.9986 - val_accuracy: 0.5290\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9695 - accuracy: 0.5315 - val_loss: 0.9988 - val_accuracy: 0.5281\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9696 - accuracy: 0.5318 - val_loss: 0.9992 - val_accuracy: 0.5237\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9694 - accuracy: 0.5325 - val_loss: 0.9996 - val_accuracy: 0.5228\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9694 - accuracy: 0.5308 - val_loss: 0.9982 - val_accuracy: 0.5286\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9694 - accuracy: 0.5339 - val_loss: 0.9986 - val_accuracy: 0.5281\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9695 - accuracy: 0.5315 - val_loss: 0.9988 - val_accuracy: 0.5237\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5324 - val_loss: 0.9985 - val_accuracy: 0.5250\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9694 - accuracy: 0.5323 - val_loss: 0.9992 - val_accuracy: 0.5263\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9696 - accuracy: 0.5328 - val_loss: 0.9991 - val_accuracy: 0.5281\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5324 - val_loss: 0.9981 - val_accuracy: 0.5286\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9693 - accuracy: 0.5321 - val_loss: 1.0008 - val_accuracy: 0.5224\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9693 - accuracy: 0.5326 - val_loss: 0.9988 - val_accuracy: 0.5263\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9694 - accuracy: 0.5317 - val_loss: 0.9988 - val_accuracy: 0.5286\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9694 - accuracy: 0.5315 - val_loss: 0.9990 - val_accuracy: 0.5246\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 521us/step - loss: 0.9693 - accuracy: 0.5327 - val_loss: 0.9981 - val_accuracy: 0.5272\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5317 - val_loss: 0.9987 - val_accuracy: 0.5277\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9693 - accuracy: 0.5319 - val_loss: 0.9993 - val_accuracy: 0.5241\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9696 - accuracy: 0.5324 - val_loss: 0.9982 - val_accuracy: 0.5286\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 552us/step - loss: 0.9693 - accuracy: 0.5324 - val_loss: 0.9988 - val_accuracy: 0.5290\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9694 - accuracy: 0.5308 - val_loss: 0.9985 - val_accuracy: 0.5272\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9692 - accuracy: 0.5316 - val_loss: 0.9991 - val_accuracy: 0.5241\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9694 - accuracy: 0.5320 - val_loss: 0.9996 - val_accuracy: 0.5286\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9692 - accuracy: 0.5338 - val_loss: 0.9981 - val_accuracy: 0.5272\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9694 - accuracy: 0.5319 - val_loss: 0.9984 - val_accuracy: 0.5246\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9693 - accuracy: 0.5332 - val_loss: 0.9988 - val_accuracy: 0.5246\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9693 - accuracy: 0.5323 - val_loss: 0.9984 - val_accuracy: 0.5286\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9693 - accuracy: 0.5316 - val_loss: 0.9980 - val_accuracy: 0.5272\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9694 - accuracy: 0.5318 - val_loss: 0.9980 - val_accuracy: 0.5281\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9693 - accuracy: 0.5325 - val_loss: 0.9982 - val_accuracy: 0.5268\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9692 - accuracy: 0.5331 - val_loss: 0.9984 - val_accuracy: 0.5286\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9694 - accuracy: 0.5331 - val_loss: 0.9989 - val_accuracy: 0.5228\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9692 - accuracy: 0.5336 - val_loss: 0.9984 - val_accuracy: 0.5277\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9691 - accuracy: 0.5328 - val_loss: 0.9989 - val_accuracy: 0.5246\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9692 - accuracy: 0.5327 - val_loss: 0.9984 - val_accuracy: 0.5290\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9692 - accuracy: 0.5320 - val_loss: 0.9981 - val_accuracy: 0.5290\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9693 - accuracy: 0.5322 - val_loss: 0.9982 - val_accuracy: 0.5268\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5325 - val_loss: 0.9994 - val_accuracy: 0.5286\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9692 - accuracy: 0.5321 - val_loss: 1.0000 - val_accuracy: 0.5228\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9692 - accuracy: 0.5318 - val_loss: 0.9982 - val_accuracy: 0.5290\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9693 - accuracy: 0.5323 - val_loss: 0.9983 - val_accuracy: 0.5263\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9692 - accuracy: 0.5324 - val_loss: 0.9986 - val_accuracy: 0.5290\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9691 - accuracy: 0.5324 - val_loss: 0.9996 - val_accuracy: 0.5224\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9692 - accuracy: 0.5320 - val_loss: 0.9985 - val_accuracy: 0.5286\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9692 - accuracy: 0.5318 - val_loss: 0.9982 - val_accuracy: 0.5268\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9693 - accuracy: 0.5329 - val_loss: 0.9985 - val_accuracy: 0.5286\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9693 - accuracy: 0.5318 - val_loss: 0.9989 - val_accuracy: 0.5250\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9693 - accuracy: 0.5325 - val_loss: 0.9978 - val_accuracy: 0.5281\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9692 - accuracy: 0.5325 - val_loss: 0.9991 - val_accuracy: 0.5290\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9693 - accuracy: 0.5329 - val_loss: 0.9987 - val_accuracy: 0.5286\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9692 - accuracy: 0.5341 - val_loss: 0.9984 - val_accuracy: 0.5246\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9692 - accuracy: 0.5316 - val_loss: 0.9980 - val_accuracy: 0.5286\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9691 - accuracy: 0.5328 - val_loss: 0.9985 - val_accuracy: 0.5286\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9691 - accuracy: 0.5316 - val_loss: 0.9978 - val_accuracy: 0.5286\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9693 - accuracy: 0.5330 - val_loss: 0.9985 - val_accuracy: 0.5263\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9690 - accuracy: 0.5334 - val_loss: 0.9985 - val_accuracy: 0.5272\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9692 - accuracy: 0.5331 - val_loss: 0.9987 - val_accuracy: 0.5232\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9693 - accuracy: 0.5321 - val_loss: 0.9981 - val_accuracy: 0.5237\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9694 - accuracy: 0.5326 - val_loss: 0.9992 - val_accuracy: 0.5246\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9691 - accuracy: 0.5324 - val_loss: 0.9986 - val_accuracy: 0.5241\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5325 - val_loss: 0.9986 - val_accuracy: 0.5250\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9692 - accuracy: 0.5326 - val_loss: 0.9981 - val_accuracy: 0.5259\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9691 - accuracy: 0.5326 - val_loss: 0.9979 - val_accuracy: 0.5286\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9690 - accuracy: 0.5327 - val_loss: 0.9981 - val_accuracy: 0.5268\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9690 - accuracy: 0.5317 - val_loss: 0.9991 - val_accuracy: 0.5294\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9691 - accuracy: 0.5322 - val_loss: 0.9979 - val_accuracy: 0.5268\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9694 - accuracy: 0.5322 - val_loss: 0.9985 - val_accuracy: 0.5232\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9690 - accuracy: 0.5328 - val_loss: 0.9982 - val_accuracy: 0.5268\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 578us/step - loss: 0.9693 - accuracy: 0.5324 - val_loss: 0.9982 - val_accuracy: 0.5268\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9691 - accuracy: 0.5333 - val_loss: 0.9982 - val_accuracy: 0.5286\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9690 - accuracy: 0.5321 - val_loss: 0.9987 - val_accuracy: 0.5272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9691 - accuracy: 0.5334 - val_loss: 0.9981 - val_accuracy: 0.5263\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9691 - accuracy: 0.5323 - val_loss: 0.9981 - val_accuracy: 0.5268\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9691 - accuracy: 0.5332 - val_loss: 0.9980 - val_accuracy: 0.5263\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9692 - accuracy: 0.5321 - val_loss: 0.9980 - val_accuracy: 0.5263\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5328 - val_loss: 0.9987 - val_accuracy: 0.5294\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9689 - accuracy: 0.5336 - val_loss: 0.9986 - val_accuracy: 0.5268\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9691 - accuracy: 0.5323 - val_loss: 1.0013 - val_accuracy: 0.5241\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5319 - val_loss: 0.9983 - val_accuracy: 0.5241\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9690 - accuracy: 0.5308 - val_loss: 0.9993 - val_accuracy: 0.5246\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9692 - accuracy: 0.5320 - val_loss: 0.9980 - val_accuracy: 0.5281\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9691 - accuracy: 0.5322 - val_loss: 0.9977 - val_accuracy: 0.5268\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9692 - accuracy: 0.5330 - val_loss: 0.9979 - val_accuracy: 0.5290\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9691 - accuracy: 0.5331 - val_loss: 0.9996 - val_accuracy: 0.5224\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9689 - accuracy: 0.5323 - val_loss: 0.9981 - val_accuracy: 0.5241\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9692 - accuracy: 0.5325 - val_loss: 0.9981 - val_accuracy: 0.5268\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9692 - accuracy: 0.5316 - val_loss: 0.9983 - val_accuracy: 0.5241\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9691 - accuracy: 0.5337 - val_loss: 1.0005 - val_accuracy: 0.5219\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9693 - accuracy: 0.5323 - val_loss: 0.9981 - val_accuracy: 0.5290\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9691 - accuracy: 0.5329 - val_loss: 0.9991 - val_accuracy: 0.5237\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9691 - accuracy: 0.5323 - val_loss: 0.9980 - val_accuracy: 0.5268\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9691 - accuracy: 0.5319 - val_loss: 1.0001 - val_accuracy: 0.5241\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9691 - accuracy: 0.5328 - val_loss: 0.9993 - val_accuracy: 0.5241\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9692 - accuracy: 0.5332 - val_loss: 0.9980 - val_accuracy: 0.5250\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9691 - accuracy: 0.5322 - val_loss: 0.9978 - val_accuracy: 0.5281\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9689 - accuracy: 0.5329 - val_loss: 1.0001 - val_accuracy: 0.5219\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9693 - accuracy: 0.5318 - val_loss: 0.9980 - val_accuracy: 0.5286\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9690 - accuracy: 0.5328 - val_loss: 0.9979 - val_accuracy: 0.5286\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9690 - accuracy: 0.5322 - val_loss: 0.9987 - val_accuracy: 0.5263\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9690 - accuracy: 0.5338 - val_loss: 0.9980 - val_accuracy: 0.5268\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9691 - accuracy: 0.5334 - val_loss: 0.9980 - val_accuracy: 0.5268\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9690 - accuracy: 0.5327 - val_loss: 0.9989 - val_accuracy: 0.5241\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9692 - accuracy: 0.5323 - val_loss: 0.9995 - val_accuracy: 0.5241\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9691 - accuracy: 0.5310 - val_loss: 1.0000 - val_accuracy: 0.5250\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9690 - accuracy: 0.5322 - val_loss: 0.9987 - val_accuracy: 0.5268\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9691 - accuracy: 0.5327 - val_loss: 0.9988 - val_accuracy: 0.5228\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9689 - accuracy: 0.5333 - val_loss: 0.9985 - val_accuracy: 0.5268\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9689 - accuracy: 0.5319 - val_loss: 0.9980 - val_accuracy: 0.5286\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9689 - accuracy: 0.5327 - val_loss: 0.9980 - val_accuracy: 0.5268\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9688 - accuracy: 0.5313 - val_loss: 0.9987 - val_accuracy: 0.5299\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9690 - accuracy: 0.5321 - val_loss: 0.9987 - val_accuracy: 0.5255\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9690 - accuracy: 0.5327 - val_loss: 0.9991 - val_accuracy: 0.5294\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9690 - accuracy: 0.5328 - val_loss: 0.9989 - val_accuracy: 0.5268\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9690 - accuracy: 0.5320 - val_loss: 0.9993 - val_accuracy: 0.5290\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9691 - accuracy: 0.5326 - val_loss: 0.9982 - val_accuracy: 0.5255\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9690 - accuracy: 0.5325 - val_loss: 0.9978 - val_accuracy: 0.5290\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 366us/step - loss: 0.9685 - accuracy: 0.5328\n",
      "Accuracy : 0.5327792167663574\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9978 - accuracy: 0.5290\n",
      "Accuracy : 0.528995156288147\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 659us/step - loss: 1.0668 - accuracy: 0.4194 - val_loss: 1.0361 - val_accuracy: 0.4626\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 1.0041 - accuracy: 0.5225 - val_loss: 1.0136 - val_accuracy: 0.4998\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9873 - accuracy: 0.5319 - val_loss: 1.0125 - val_accuracy: 0.4989\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9834 - accuracy: 0.5317 - val_loss: 1.0101 - val_accuracy: 0.4998\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9807 - accuracy: 0.5315 - val_loss: 1.0084 - val_accuracy: 0.4998\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9783 - accuracy: 0.5318 - val_loss: 1.0078 - val_accuracy: 0.5082\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9770 - accuracy: 0.5340 - val_loss: 1.0068 - val_accuracy: 0.5064\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9759 - accuracy: 0.5324 - val_loss: 1.0058 - val_accuracy: 0.5020\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9747 - accuracy: 0.5349 - val_loss: 1.0057 - val_accuracy: 0.5064\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 500us/step - loss: 0.9740 - accuracy: 0.5324 - val_loss: 1.0055 - val_accuracy: 0.5082\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9736 - accuracy: 0.5334 - val_loss: 1.0058 - val_accuracy: 0.5091\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9728 - accuracy: 0.5342 - val_loss: 1.0060 - val_accuracy: 0.5069\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9725 - accuracy: 0.5342 - val_loss: 1.0048 - val_accuracy: 0.5091\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9723 - accuracy: 0.5338 - val_loss: 1.0045 - val_accuracy: 0.5073\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9720 - accuracy: 0.5339 - val_loss: 1.0056 - val_accuracy: 0.5091\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9717 - accuracy: 0.5340 - val_loss: 1.0048 - val_accuracy: 0.5069\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9715 - accuracy: 0.5334 - val_loss: 1.0044 - val_accuracy: 0.5069\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9712 - accuracy: 0.5343 - val_loss: 1.0043 - val_accuracy: 0.5073\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9712 - accuracy: 0.5348 - val_loss: 1.0047 - val_accuracy: 0.5073\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9711 - accuracy: 0.5340 - val_loss: 1.0042 - val_accuracy: 0.5086\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9708 - accuracy: 0.5341 - val_loss: 1.0043 - val_accuracy: 0.5091\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9709 - accuracy: 0.5344 - val_loss: 1.0047 - val_accuracy: 0.5064\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9708 - accuracy: 0.5343 - val_loss: 1.0045 - val_accuracy: 0.5100\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9708 - accuracy: 0.5338 - val_loss: 1.0040 - val_accuracy: 0.5082\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9706 - accuracy: 0.5326 - val_loss: 1.0043 - val_accuracy: 0.5082\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9704 - accuracy: 0.5348 - val_loss: 1.0040 - val_accuracy: 0.5091\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9704 - accuracy: 0.5338 - val_loss: 1.0041 - val_accuracy: 0.5091\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9704 - accuracy: 0.5339 - val_loss: 1.0039 - val_accuracy: 0.5091\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9704 - accuracy: 0.5345 - val_loss: 1.0044 - val_accuracy: 0.5069\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9703 - accuracy: 0.5329 - val_loss: 1.0044 - val_accuracy: 0.5069\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9703 - accuracy: 0.5334 - val_loss: 1.0046 - val_accuracy: 0.5077\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9702 - accuracy: 0.5334 - val_loss: 1.0035 - val_accuracy: 0.5082\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9702 - accuracy: 0.5335 - val_loss: 1.0039 - val_accuracy: 0.5069\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9701 - accuracy: 0.5338 - val_loss: 1.0038 - val_accuracy: 0.5060\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9698 - accuracy: 0.5343 - val_loss: 1.0042 - val_accuracy: 0.5091\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9701 - accuracy: 0.5327 - val_loss: 1.0037 - val_accuracy: 0.5086\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9700 - accuracy: 0.5343 - val_loss: 1.0036 - val_accuracy: 0.5086\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9698 - accuracy: 0.5335 - val_loss: 1.0038 - val_accuracy: 0.5091\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9699 - accuracy: 0.5340 - val_loss: 1.0035 - val_accuracy: 0.5091\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9698 - accuracy: 0.5326 - val_loss: 1.0045 - val_accuracy: 0.5100\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9700 - accuracy: 0.5336 - val_loss: 1.0035 - val_accuracy: 0.5100\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9698 - accuracy: 0.5331 - val_loss: 1.0039 - val_accuracy: 0.5069\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9698 - accuracy: 0.5333 - val_loss: 1.0049 - val_accuracy: 0.5091\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9696 - accuracy: 0.5341 - val_loss: 1.0064 - val_accuracy: 0.5086\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9697 - accuracy: 0.5347 - val_loss: 1.0030 - val_accuracy: 0.5086\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9697 - accuracy: 0.5348 - val_loss: 1.0032 - val_accuracy: 0.5091\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9698 - accuracy: 0.5344 - val_loss: 1.0037 - val_accuracy: 0.5082\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 555us/step - loss: 0.9697 - accuracy: 0.5340 - val_loss: 1.0035 - val_accuracy: 0.5082\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9698 - accuracy: 0.5341 - val_loss: 1.0037 - val_accuracy: 0.5060\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9695 - accuracy: 0.5336 - val_loss: 1.0049 - val_accuracy: 0.5069\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9697 - accuracy: 0.5336 - val_loss: 1.0052 - val_accuracy: 0.5100\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9696 - accuracy: 0.5329 - val_loss: 1.0036 - val_accuracy: 0.5086\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9696 - accuracy: 0.5335 - val_loss: 1.0034 - val_accuracy: 0.5100\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9696 - accuracy: 0.5340 - val_loss: 1.0032 - val_accuracy: 0.5086\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9697 - accuracy: 0.5327 - val_loss: 1.0031 - val_accuracy: 0.5086\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9695 - accuracy: 0.5345 - val_loss: 1.0046 - val_accuracy: 0.5100\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5359 - val_loss: 1.0034 - val_accuracy: 0.5060\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9695 - accuracy: 0.5340 - val_loss: 1.0034 - val_accuracy: 0.5086\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9694 - accuracy: 0.5333 - val_loss: 1.0035 - val_accuracy: 0.5100\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9695 - accuracy: 0.5343 - val_loss: 1.0034 - val_accuracy: 0.5060\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9695 - accuracy: 0.5344 - val_loss: 1.0034 - val_accuracy: 0.5100\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9694 - accuracy: 0.5338 - val_loss: 1.0042 - val_accuracy: 0.5060\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9693 - accuracy: 0.5347 - val_loss: 1.0043 - val_accuracy: 0.5077\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9695 - accuracy: 0.5336 - val_loss: 1.0045 - val_accuracy: 0.5077\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9693 - accuracy: 0.5341 - val_loss: 1.0035 - val_accuracy: 0.5086\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 485us/step - loss: 0.9693 - accuracy: 0.5343 - val_loss: 1.0042 - val_accuracy: 0.5091\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5341 - val_loss: 1.0043 - val_accuracy: 0.5091\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9695 - accuracy: 0.5353 - val_loss: 1.0031 - val_accuracy: 0.5082\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9694 - accuracy: 0.5339 - val_loss: 1.0034 - val_accuracy: 0.5082\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9694 - accuracy: 0.5342 - val_loss: 1.0035 - val_accuracy: 0.5091\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9694 - accuracy: 0.5336 - val_loss: 1.0043 - val_accuracy: 0.5100\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9692 - accuracy: 0.5342 - val_loss: 1.0031 - val_accuracy: 0.5086\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9694 - accuracy: 0.5334 - val_loss: 1.0031 - val_accuracy: 0.5082\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9693 - accuracy: 0.5344 - val_loss: 1.0034 - val_accuracy: 0.5091\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9693 - accuracy: 0.5347 - val_loss: 1.0039 - val_accuracy: 0.5086\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9693 - accuracy: 0.5341 - val_loss: 1.0042 - val_accuracy: 0.5100\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9694 - accuracy: 0.5333 - val_loss: 1.0036 - val_accuracy: 0.5086\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9689 - accuracy: 0.5355 - val_loss: 1.0035 - val_accuracy: 0.5091\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9692 - accuracy: 0.5332 - val_loss: 1.0031 - val_accuracy: 0.5077\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9695 - accuracy: 0.5337 - val_loss: 1.0040 - val_accuracy: 0.5082\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9694 - accuracy: 0.5340 - val_loss: 1.0039 - val_accuracy: 0.5082\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9691 - accuracy: 0.5344 - val_loss: 1.0054 - val_accuracy: 0.5086\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9693 - accuracy: 0.5330 - val_loss: 1.0032 - val_accuracy: 0.5086\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9693 - accuracy: 0.5353 - val_loss: 1.0037 - val_accuracy: 0.5077\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9693 - accuracy: 0.5323 - val_loss: 1.0036 - val_accuracy: 0.5082\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9692 - accuracy: 0.5341 - val_loss: 1.0038 - val_accuracy: 0.5060\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9692 - accuracy: 0.5355 - val_loss: 1.0034 - val_accuracy: 0.5100\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9692 - accuracy: 0.5340 - val_loss: 1.0027 - val_accuracy: 0.5091\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9691 - accuracy: 0.5333 - val_loss: 1.0038 - val_accuracy: 0.5091\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9694 - accuracy: 0.5336 - val_loss: 1.0034 - val_accuracy: 0.5100\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9692 - accuracy: 0.5342 - val_loss: 1.0037 - val_accuracy: 0.5100\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9692 - accuracy: 0.5350 - val_loss: 1.0036 - val_accuracy: 0.5091\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9692 - accuracy: 0.5346 - val_loss: 1.0037 - val_accuracy: 0.5086\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9693 - accuracy: 0.5326 - val_loss: 1.0039 - val_accuracy: 0.5073\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9693 - accuracy: 0.5330 - val_loss: 1.0038 - val_accuracy: 0.5086\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9691 - accuracy: 0.5343 - val_loss: 1.0033 - val_accuracy: 0.5100\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 576us/step - loss: 0.9692 - accuracy: 0.5322 - val_loss: 1.0033 - val_accuracy: 0.5091\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 557us/step - loss: 0.9693 - accuracy: 0.5345 - val_loss: 1.0030 - val_accuracy: 0.5082\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9690 - accuracy: 0.5333 - val_loss: 1.0036 - val_accuracy: 0.5069\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9692 - accuracy: 0.5338 - val_loss: 1.0036 - val_accuracy: 0.5086\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9692 - accuracy: 0.5341 - val_loss: 1.0032 - val_accuracy: 0.5086\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9692 - accuracy: 0.5336 - val_loss: 1.0042 - val_accuracy: 0.5095\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9691 - accuracy: 0.5343 - val_loss: 1.0032 - val_accuracy: 0.5082\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9694 - accuracy: 0.5334 - val_loss: 1.0029 - val_accuracy: 0.5086\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9691 - accuracy: 0.5331 - val_loss: 1.0033 - val_accuracy: 0.5069\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9690 - accuracy: 0.5349 - val_loss: 1.0066 - val_accuracy: 0.5122\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9693 - accuracy: 0.5336 - val_loss: 1.0033 - val_accuracy: 0.5091\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9691 - accuracy: 0.5350 - val_loss: 1.0037 - val_accuracy: 0.5100\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9692 - accuracy: 0.5337 - val_loss: 1.0031 - val_accuracy: 0.5091\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9691 - accuracy: 0.5347 - val_loss: 1.0039 - val_accuracy: 0.5082\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9691 - accuracy: 0.5340 - val_loss: 1.0035 - val_accuracy: 0.5091\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9693 - accuracy: 0.5332 - val_loss: 1.0041 - val_accuracy: 0.5091\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9692 - accuracy: 0.5340 - val_loss: 1.0041 - val_accuracy: 0.5069\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9691 - accuracy: 0.5338 - val_loss: 1.0039 - val_accuracy: 0.5095\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9690 - accuracy: 0.5343 - val_loss: 1.0029 - val_accuracy: 0.5082\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9690 - accuracy: 0.5347 - val_loss: 1.0031 - val_accuracy: 0.5086\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9691 - accuracy: 0.5350 - val_loss: 1.0032 - val_accuracy: 0.5082\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9692 - accuracy: 0.5336 - val_loss: 1.0033 - val_accuracy: 0.5100\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9693 - accuracy: 0.5335 - val_loss: 1.0042 - val_accuracy: 0.5082\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9692 - accuracy: 0.5332 - val_loss: 1.0034 - val_accuracy: 0.5082\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9691 - accuracy: 0.5337 - val_loss: 1.0032 - val_accuracy: 0.5077\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 518us/step - loss: 0.9692 - accuracy: 0.5346 - val_loss: 1.0030 - val_accuracy: 0.5082\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9690 - accuracy: 0.5350 - val_loss: 1.0040 - val_accuracy: 0.5077\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9691 - accuracy: 0.5339 - val_loss: 1.0037 - val_accuracy: 0.5100\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9692 - accuracy: 0.5351 - val_loss: 1.0036 - val_accuracy: 0.5086\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9693 - accuracy: 0.5338 - val_loss: 1.0036 - val_accuracy: 0.5060\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9691 - accuracy: 0.5340 - val_loss: 1.0036 - val_accuracy: 0.5082\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9690 - accuracy: 0.5337 - val_loss: 1.0037 - val_accuracy: 0.5091\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9691 - accuracy: 0.5336 - val_loss: 1.0028 - val_accuracy: 0.5082\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9691 - accuracy: 0.5325 - val_loss: 1.0033 - val_accuracy: 0.5091\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9690 - accuracy: 0.5342 - val_loss: 1.0037 - val_accuracy: 0.5091\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9692 - accuracy: 0.5331 - val_loss: 1.0034 - val_accuracy: 0.5091\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9691 - accuracy: 0.5333 - val_loss: 1.0055 - val_accuracy: 0.5104\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9691 - accuracy: 0.5339 - val_loss: 1.0039 - val_accuracy: 0.5077\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9691 - accuracy: 0.5340 - val_loss: 1.0039 - val_accuracy: 0.5095\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9694 - accuracy: 0.5342 - val_loss: 1.0032 - val_accuracy: 0.5082\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9691 - accuracy: 0.5346 - val_loss: 1.0027 - val_accuracy: 0.5091\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9693 - accuracy: 0.5335 - val_loss: 1.0035 - val_accuracy: 0.5082\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9689 - accuracy: 0.5348 - val_loss: 1.0036 - val_accuracy: 0.5082\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9690 - accuracy: 0.5337 - val_loss: 1.0041 - val_accuracy: 0.5086\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9693 - accuracy: 0.5332 - val_loss: 1.0040 - val_accuracy: 0.5091\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9689 - accuracy: 0.5355 - val_loss: 1.0037 - val_accuracy: 0.5069\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9691 - accuracy: 0.5341 - val_loss: 1.0035 - val_accuracy: 0.5091\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9692 - accuracy: 0.5332 - val_loss: 1.0030 - val_accuracy: 0.5100\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 581us/step - loss: 0.9690 - accuracy: 0.5348 - val_loss: 1.0031 - val_accuracy: 0.5095\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 559us/step - loss: 0.9690 - accuracy: 0.5339 - val_loss: 1.0036 - val_accuracy: 0.5086\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9693 - accuracy: 0.5336 - val_loss: 1.0028 - val_accuracy: 0.5091\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9691 - accuracy: 0.5336 - val_loss: 1.0035 - val_accuracy: 0.5095\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9691 - accuracy: 0.5340 - val_loss: 1.0039 - val_accuracy: 0.5077\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9690 - accuracy: 0.5350 - val_loss: 1.0028 - val_accuracy: 0.5082\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9692 - accuracy: 0.5343 - val_loss: 1.0031 - val_accuracy: 0.5091\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9690 - accuracy: 0.5346 - val_loss: 1.0030 - val_accuracy: 0.5100\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9689 - accuracy: 0.5340 - val_loss: 1.0031 - val_accuracy: 0.5100\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9690 - accuracy: 0.5342 - val_loss: 1.0027 - val_accuracy: 0.5091\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9691 - accuracy: 0.5335 - val_loss: 1.0035 - val_accuracy: 0.5100\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9692 - accuracy: 0.5339 - val_loss: 1.0044 - val_accuracy: 0.5095\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9690 - accuracy: 0.5344 - val_loss: 1.0032 - val_accuracy: 0.5082\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9689 - accuracy: 0.5347 - val_loss: 1.0034 - val_accuracy: 0.5100\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9689 - accuracy: 0.5345 - val_loss: 1.0037 - val_accuracy: 0.5073\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 550us/step - loss: 0.9692 - accuracy: 0.5337 - val_loss: 1.0025 - val_accuracy: 0.5082\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9693 - accuracy: 0.5339 - val_loss: 1.0027 - val_accuracy: 0.5082\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9688 - accuracy: 0.5342 - val_loss: 1.0027 - val_accuracy: 0.5091\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9688 - accuracy: 0.5338 - val_loss: 1.0046 - val_accuracy: 0.5069\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9691 - accuracy: 0.5346 - val_loss: 1.0038 - val_accuracy: 0.5095\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9692 - accuracy: 0.5334 - val_loss: 1.0031 - val_accuracy: 0.5100\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9692 - accuracy: 0.5334 - val_loss: 1.0032 - val_accuracy: 0.5091\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9689 - accuracy: 0.5344 - val_loss: 1.0038 - val_accuracy: 0.5091\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9691 - accuracy: 0.5336 - val_loss: 1.0040 - val_accuracy: 0.5095\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9690 - accuracy: 0.5341 - val_loss: 1.0037 - val_accuracy: 0.5100\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9692 - accuracy: 0.5346 - val_loss: 1.0028 - val_accuracy: 0.5091\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9689 - accuracy: 0.5340 - val_loss: 1.0034 - val_accuracy: 0.5091\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9690 - accuracy: 0.5345 - val_loss: 1.0043 - val_accuracy: 0.5095\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9691 - accuracy: 0.5333 - val_loss: 1.0040 - val_accuracy: 0.5082\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9691 - accuracy: 0.5351 - val_loss: 1.0031 - val_accuracy: 0.5086\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9691 - accuracy: 0.5357 - val_loss: 1.0049 - val_accuracy: 0.5073\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9693 - accuracy: 0.5340 - val_loss: 1.0036 - val_accuracy: 0.5100\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9691 - accuracy: 0.5341 - val_loss: 1.0030 - val_accuracy: 0.5100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9688 - accuracy: 0.5341 - val_loss: 1.0040 - val_accuracy: 0.5069\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9692 - accuracy: 0.5346 - val_loss: 1.0029 - val_accuracy: 0.5086\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9690 - accuracy: 0.5343 - val_loss: 1.0031 - val_accuracy: 0.5091\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9689 - accuracy: 0.5338 - val_loss: 1.0036 - val_accuracy: 0.5069\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9690 - accuracy: 0.5341 - val_loss: 1.0031 - val_accuracy: 0.5100\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9689 - accuracy: 0.5336 - val_loss: 1.0035 - val_accuracy: 0.5100\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9692 - accuracy: 0.5335 - val_loss: 1.0036 - val_accuracy: 0.5104\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9691 - accuracy: 0.5338 - val_loss: 1.0030 - val_accuracy: 0.5086\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9690 - accuracy: 0.5334 - val_loss: 1.0035 - val_accuracy: 0.5091\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9691 - accuracy: 0.5336 - val_loss: 1.0026 - val_accuracy: 0.5091\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9692 - accuracy: 0.5339 - val_loss: 1.0031 - val_accuracy: 0.5082\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9689 - accuracy: 0.5341 - val_loss: 1.0028 - val_accuracy: 0.5086\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9692 - accuracy: 0.5344 - val_loss: 1.0040 - val_accuracy: 0.5069\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9692 - accuracy: 0.5350 - val_loss: 1.0033 - val_accuracy: 0.5095\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9689 - accuracy: 0.5340 - val_loss: 1.0037 - val_accuracy: 0.5095\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 562us/step - loss: 0.9690 - accuracy: 0.5338 - val_loss: 1.0039 - val_accuracy: 0.5082\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 611us/step - loss: 0.9688 - accuracy: 0.5342 - val_loss: 1.0048 - val_accuracy: 0.5011\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 564us/step - loss: 0.9691 - accuracy: 0.5338 - val_loss: 1.0046 - val_accuracy: 0.5064\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 547us/step - loss: 0.9691 - accuracy: 0.5335 - val_loss: 1.0030 - val_accuracy: 0.5100\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9688 - accuracy: 0.5346 - val_loss: 1.0035 - val_accuracy: 0.5082\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9691 - accuracy: 0.5348 - val_loss: 1.0029 - val_accuracy: 0.5091\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9689 - accuracy: 0.5335 - val_loss: 1.0041 - val_accuracy: 0.5060\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9689 - accuracy: 0.5341 - val_loss: 1.0024 - val_accuracy: 0.5082\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 334us/step - loss: 0.9686 - accuracy: 0.5340\n",
      "Accuracy : 0.5339595675468445\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0024 - accuracy: 0.5082\n",
      "Accuracy : 0.5081894397735596\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 649us/step - loss: 1.0507 - accuracy: 0.4591 - val_loss: 1.0351 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 1.0133 - accuracy: 0.4859 - val_loss: 1.0069 - val_accuracy: 0.5148\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9905 - accuracy: 0.5299 - val_loss: 0.9985 - val_accuracy: 0.5166\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9843 - accuracy: 0.5294 - val_loss: 0.9949 - val_accuracy: 0.5166\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9809 - accuracy: 0.5292 - val_loss: 0.9922 - val_accuracy: 0.5166\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9784 - accuracy: 0.5306 - val_loss: 0.9913 - val_accuracy: 0.5166\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9769 - accuracy: 0.5304 - val_loss: 0.9894 - val_accuracy: 0.5179\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9757 - accuracy: 0.5313 - val_loss: 0.9898 - val_accuracy: 0.5166\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9749 - accuracy: 0.5316 - val_loss: 0.9885 - val_accuracy: 0.5193\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 547us/step - loss: 0.9747 - accuracy: 0.5321 - val_loss: 0.9885 - val_accuracy: 0.5166\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9740 - accuracy: 0.5308 - val_loss: 0.9879 - val_accuracy: 0.5237\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9738 - accuracy: 0.5320 - val_loss: 0.9878 - val_accuracy: 0.5224\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9738 - accuracy: 0.5310 - val_loss: 0.9877 - val_accuracy: 0.5312\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9735 - accuracy: 0.5325 - val_loss: 0.9879 - val_accuracy: 0.5197\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9876 - val_accuracy: 0.5246\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9732 - accuracy: 0.5316 - val_loss: 0.9876 - val_accuracy: 0.5228\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9730 - accuracy: 0.5316 - val_loss: 0.9873 - val_accuracy: 0.5303\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9727 - accuracy: 0.5331 - val_loss: 0.9879 - val_accuracy: 0.5281\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9729 - accuracy: 0.5321 - val_loss: 0.9878 - val_accuracy: 0.5228\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9728 - accuracy: 0.5325 - val_loss: 0.9874 - val_accuracy: 0.5232\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9727 - accuracy: 0.5325 - val_loss: 0.9870 - val_accuracy: 0.5290\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9726 - accuracy: 0.5328 - val_loss: 0.9871 - val_accuracy: 0.5281\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9725 - accuracy: 0.5338 - val_loss: 0.9870 - val_accuracy: 0.5268\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9723 - accuracy: 0.5317 - val_loss: 0.9870 - val_accuracy: 0.5268\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9723 - accuracy: 0.5319 - val_loss: 0.9871 - val_accuracy: 0.5268\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9722 - accuracy: 0.5315 - val_loss: 0.9868 - val_accuracy: 0.5317\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9722 - accuracy: 0.5331 - val_loss: 0.9868 - val_accuracy: 0.5268\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9719 - accuracy: 0.5327 - val_loss: 0.9870 - val_accuracy: 0.5290\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9721 - accuracy: 0.5328 - val_loss: 0.9868 - val_accuracy: 0.5224\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9722 - accuracy: 0.5317 - val_loss: 0.9865 - val_accuracy: 0.5268\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9720 - accuracy: 0.5317 - val_loss: 0.9866 - val_accuracy: 0.5268\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 485us/step - loss: 0.9719 - accuracy: 0.5325 - val_loss: 0.9865 - val_accuracy: 0.5250\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9718 - accuracy: 0.5321 - val_loss: 0.9865 - val_accuracy: 0.5268\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9715 - accuracy: 0.5324 - val_loss: 0.9872 - val_accuracy: 0.5228\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9719 - accuracy: 0.5310 - val_loss: 0.9863 - val_accuracy: 0.5255\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9718 - accuracy: 0.5323 - val_loss: 0.9864 - val_accuracy: 0.5272\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9715 - accuracy: 0.5324 - val_loss: 0.9860 - val_accuracy: 0.5281\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9716 - accuracy: 0.5319 - val_loss: 0.9864 - val_accuracy: 0.5259\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9714 - accuracy: 0.5331 - val_loss: 0.9868 - val_accuracy: 0.5286\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9715 - accuracy: 0.5323 - val_loss: 0.9871 - val_accuracy: 0.5277\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9714 - accuracy: 0.5333 - val_loss: 0.9867 - val_accuracy: 0.5237\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9714 - accuracy: 0.5336 - val_loss: 0.9872 - val_accuracy: 0.5237\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9712 - accuracy: 0.5320 - val_loss: 0.9862 - val_accuracy: 0.5277\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9715 - accuracy: 0.5317 - val_loss: 0.9860 - val_accuracy: 0.5268\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9712 - accuracy: 0.5332 - val_loss: 0.9861 - val_accuracy: 0.5294\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9713 - accuracy: 0.5316 - val_loss: 0.9859 - val_accuracy: 0.5259\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9710 - accuracy: 0.5334 - val_loss: 0.9864 - val_accuracy: 0.5290\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9708 - accuracy: 0.5328 - val_loss: 0.9875 - val_accuracy: 0.5259\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9713 - accuracy: 0.5326 - val_loss: 0.9862 - val_accuracy: 0.5259\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9711 - accuracy: 0.5330 - val_loss: 0.9861 - val_accuracy: 0.5268\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9712 - accuracy: 0.5333 - val_loss: 0.9861 - val_accuracy: 0.5259\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9712 - accuracy: 0.5315 - val_loss: 0.9860 - val_accuracy: 0.5259\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9710 - accuracy: 0.5326 - val_loss: 0.9873 - val_accuracy: 0.5219\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9713 - accuracy: 0.5313 - val_loss: 0.9866 - val_accuracy: 0.5294\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9711 - accuracy: 0.5318 - val_loss: 0.9864 - val_accuracy: 0.5259\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5329 - val_loss: 0.9859 - val_accuracy: 0.5263\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5318 - val_loss: 0.9867 - val_accuracy: 0.5312\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9713 - accuracy: 0.5323 - val_loss: 0.9867 - val_accuracy: 0.5241\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5326 - val_loss: 0.9858 - val_accuracy: 0.5263\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5325 - val_loss: 0.9860 - val_accuracy: 0.5272\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9710 - accuracy: 0.5324 - val_loss: 0.9863 - val_accuracy: 0.5241\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9710 - accuracy: 0.5318 - val_loss: 0.9863 - val_accuracy: 0.5246\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9710 - accuracy: 0.5327 - val_loss: 0.9865 - val_accuracy: 0.5224\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9709 - accuracy: 0.5321 - val_loss: 0.9861 - val_accuracy: 0.5294\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9711 - accuracy: 0.5338 - val_loss: 0.9857 - val_accuracy: 0.5272\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9709 - accuracy: 0.5313 - val_loss: 0.9860 - val_accuracy: 0.5272\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9711 - accuracy: 0.5325 - val_loss: 0.9856 - val_accuracy: 0.5272\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9709 - accuracy: 0.5322 - val_loss: 0.9861 - val_accuracy: 0.5268\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5333 - val_loss: 0.9872 - val_accuracy: 0.5228\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9707 - accuracy: 0.5317 - val_loss: 0.9857 - val_accuracy: 0.5259\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9708 - accuracy: 0.5325 - val_loss: 0.9858 - val_accuracy: 0.5259\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5318 - val_loss: 0.9857 - val_accuracy: 0.5299\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9708 - accuracy: 0.5325 - val_loss: 0.9865 - val_accuracy: 0.5286\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9707 - accuracy: 0.5319 - val_loss: 0.9866 - val_accuracy: 0.5268\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9708 - accuracy: 0.5330 - val_loss: 0.9860 - val_accuracy: 0.5250\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9707 - accuracy: 0.5319 - val_loss: 0.9858 - val_accuracy: 0.5272\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9711 - accuracy: 0.5317 - val_loss: 0.9864 - val_accuracy: 0.5312\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9706 - accuracy: 0.5330 - val_loss: 0.9859 - val_accuracy: 0.5259\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9707 - accuracy: 0.5322 - val_loss: 0.9857 - val_accuracy: 0.5259\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9706 - accuracy: 0.5323 - val_loss: 0.9880 - val_accuracy: 0.5299\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9708 - accuracy: 0.5317 - val_loss: 0.9857 - val_accuracy: 0.5268\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9706 - accuracy: 0.5319 - val_loss: 0.9861 - val_accuracy: 0.5259\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9704 - accuracy: 0.5324 - val_loss: 0.9870 - val_accuracy: 0.5232\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9708 - accuracy: 0.5333 - val_loss: 0.9860 - val_accuracy: 0.5277\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9707 - accuracy: 0.5325 - val_loss: 0.9856 - val_accuracy: 0.5268\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9707 - accuracy: 0.5329 - val_loss: 0.9860 - val_accuracy: 0.5268\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9707 - accuracy: 0.5325 - val_loss: 0.9861 - val_accuracy: 0.5272\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 528us/step - loss: 0.9706 - accuracy: 0.5325 - val_loss: 0.9859 - val_accuracy: 0.5272\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9706 - accuracy: 0.5313 - val_loss: 0.9858 - val_accuracy: 0.5272\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9704 - accuracy: 0.5322 - val_loss: 0.9862 - val_accuracy: 0.5250\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9708 - accuracy: 0.5331 - val_loss: 0.9870 - val_accuracy: 0.5290\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9707 - accuracy: 0.5331 - val_loss: 0.9860 - val_accuracy: 0.5277\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9705 - accuracy: 0.5321 - val_loss: 0.9860 - val_accuracy: 0.5272\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9708 - accuracy: 0.5320 - val_loss: 0.9858 - val_accuracy: 0.5259\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9707 - accuracy: 0.5307 - val_loss: 0.9862 - val_accuracy: 0.5277\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9706 - accuracy: 0.5327 - val_loss: 0.9859 - val_accuracy: 0.5263\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9707 - accuracy: 0.5327 - val_loss: 0.9854 - val_accuracy: 0.5255\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9707 - accuracy: 0.5328 - val_loss: 0.9855 - val_accuracy: 0.5263\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9708 - accuracy: 0.5317 - val_loss: 0.9861 - val_accuracy: 0.5263\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9706 - accuracy: 0.5335 - val_loss: 0.9854 - val_accuracy: 0.5286\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9707 - accuracy: 0.5316 - val_loss: 0.9863 - val_accuracy: 0.5246\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9704 - accuracy: 0.5318 - val_loss: 0.9864 - val_accuracy: 0.5259\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9705 - accuracy: 0.5325 - val_loss: 0.9856 - val_accuracy: 0.5272\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9707 - accuracy: 0.5320 - val_loss: 0.9862 - val_accuracy: 0.5286\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9706 - accuracy: 0.5323 - val_loss: 0.9858 - val_accuracy: 0.5250\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9703 - accuracy: 0.5320 - val_loss: 0.9863 - val_accuracy: 0.5268\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9707 - accuracy: 0.5316 - val_loss: 0.9861 - val_accuracy: 0.5250\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9705 - accuracy: 0.5317 - val_loss: 0.9858 - val_accuracy: 0.5250\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9706 - accuracy: 0.5328 - val_loss: 0.9861 - val_accuracy: 0.5294\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9705 - accuracy: 0.5323 - val_loss: 0.9858 - val_accuracy: 0.5286\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9704 - accuracy: 0.5321 - val_loss: 0.9864 - val_accuracy: 0.5259\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9705 - accuracy: 0.5314 - val_loss: 0.9856 - val_accuracy: 0.5250\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9706 - accuracy: 0.5323 - val_loss: 0.9859 - val_accuracy: 0.5277\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9703 - accuracy: 0.5325 - val_loss: 0.9858 - val_accuracy: 0.5259\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9705 - accuracy: 0.5335 - val_loss: 0.9857 - val_accuracy: 0.5255\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9705 - accuracy: 0.5319 - val_loss: 0.9867 - val_accuracy: 0.5241\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9706 - accuracy: 0.5319 - val_loss: 0.9861 - val_accuracy: 0.5277\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9703 - accuracy: 0.5323 - val_loss: 0.9860 - val_accuracy: 0.5299\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9705 - accuracy: 0.5327 - val_loss: 0.9859 - val_accuracy: 0.5268\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9706 - accuracy: 0.5320 - val_loss: 0.9864 - val_accuracy: 0.5294\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9703 - accuracy: 0.5306 - val_loss: 0.9873 - val_accuracy: 0.5237\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9704 - accuracy: 0.5339 - val_loss: 0.9857 - val_accuracy: 0.5272\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9706 - accuracy: 0.5328 - val_loss: 0.9860 - val_accuracy: 0.5277\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9704 - accuracy: 0.5326 - val_loss: 0.9862 - val_accuracy: 0.5268\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9704 - accuracy: 0.5330 - val_loss: 0.9891 - val_accuracy: 0.5197\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9706 - accuracy: 0.5313 - val_loss: 0.9857 - val_accuracy: 0.5263\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9703 - accuracy: 0.5325 - val_loss: 0.9865 - val_accuracy: 0.5286\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9706 - accuracy: 0.5330 - val_loss: 0.9864 - val_accuracy: 0.5268\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9706 - accuracy: 0.5329 - val_loss: 0.9862 - val_accuracy: 0.5277\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9703 - accuracy: 0.5316 - val_loss: 0.9872 - val_accuracy: 0.5281\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9701 - accuracy: 0.5318 - val_loss: 0.9881 - val_accuracy: 0.5210\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9703 - accuracy: 0.5323 - val_loss: 0.9862 - val_accuracy: 0.5255\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9706 - accuracy: 0.5333 - val_loss: 0.9863 - val_accuracy: 0.5259\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9706 - accuracy: 0.5327 - val_loss: 0.9859 - val_accuracy: 0.5259\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9703 - accuracy: 0.5333 - val_loss: 0.9859 - val_accuracy: 0.5255\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9702 - accuracy: 0.5321 - val_loss: 0.9863 - val_accuracy: 0.5259\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9704 - accuracy: 0.5324 - val_loss: 0.9865 - val_accuracy: 0.5272\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 567us/step - loss: 0.9703 - accuracy: 0.5332 - val_loss: 0.9860 - val_accuracy: 0.5277\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9703 - accuracy: 0.5315 - val_loss: 0.9862 - val_accuracy: 0.5286\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9703 - accuracy: 0.5329 - val_loss: 0.9863 - val_accuracy: 0.5277\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9703 - accuracy: 0.5332 - val_loss: 0.9869 - val_accuracy: 0.5312\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9705 - accuracy: 0.5321 - val_loss: 0.9862 - val_accuracy: 0.5268\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9704 - accuracy: 0.5312 - val_loss: 0.9862 - val_accuracy: 0.5268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9704 - accuracy: 0.5330 - val_loss: 0.9866 - val_accuracy: 0.5224\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9703 - accuracy: 0.5336 - val_loss: 0.9867 - val_accuracy: 0.5219\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9702 - accuracy: 0.5322 - val_loss: 0.9864 - val_accuracy: 0.5268\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9705 - accuracy: 0.5322 - val_loss: 0.9863 - val_accuracy: 0.5259\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9704 - accuracy: 0.5321 - val_loss: 0.9868 - val_accuracy: 0.5241\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9703 - accuracy: 0.5327 - val_loss: 0.9881 - val_accuracy: 0.5219\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9704 - accuracy: 0.5340 - val_loss: 0.9864 - val_accuracy: 0.5259\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9704 - accuracy: 0.5318 - val_loss: 0.9872 - val_accuracy: 0.5286\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9703 - accuracy: 0.5334 - val_loss: 0.9877 - val_accuracy: 0.5215\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9704 - accuracy: 0.5322 - val_loss: 0.9862 - val_accuracy: 0.5268\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9703 - accuracy: 0.5319 - val_loss: 0.9860 - val_accuracy: 0.5259\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9702 - accuracy: 0.5329 - val_loss: 0.9861 - val_accuracy: 0.5277\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9704 - accuracy: 0.5334 - val_loss: 0.9865 - val_accuracy: 0.5312\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9703 - accuracy: 0.5325 - val_loss: 0.9864 - val_accuracy: 0.5268\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9704 - accuracy: 0.5322 - val_loss: 0.9864 - val_accuracy: 0.5250\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9703 - accuracy: 0.5332 - val_loss: 0.9865 - val_accuracy: 0.5268\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9704 - accuracy: 0.5329 - val_loss: 0.9869 - val_accuracy: 0.5286\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9704 - accuracy: 0.5325 - val_loss: 0.9870 - val_accuracy: 0.5224\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9703 - accuracy: 0.5311 - val_loss: 0.9863 - val_accuracy: 0.5277\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9701 - accuracy: 0.5320 - val_loss: 0.9865 - val_accuracy: 0.5259\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9703 - accuracy: 0.5332 - val_loss: 0.9865 - val_accuracy: 0.5259\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9702 - accuracy: 0.5334 - val_loss: 0.9864 - val_accuracy: 0.5277\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9701 - accuracy: 0.5324 - val_loss: 0.9865 - val_accuracy: 0.5255\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 572us/step - loss: 0.9700 - accuracy: 0.5318 - val_loss: 0.9862 - val_accuracy: 0.5268\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 581us/step - loss: 0.9704 - accuracy: 0.5326 - val_loss: 0.9867 - val_accuracy: 0.5290\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 576us/step - loss: 0.9704 - accuracy: 0.5336 - val_loss: 0.9868 - val_accuracy: 0.5219\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9701 - accuracy: 0.5321 - val_loss: 0.9868 - val_accuracy: 0.5277\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9701 - accuracy: 0.5325 - val_loss: 0.9892 - val_accuracy: 0.5290\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9703 - accuracy: 0.5334 - val_loss: 0.9867 - val_accuracy: 0.5268\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9702 - accuracy: 0.5325 - val_loss: 0.9865 - val_accuracy: 0.5250\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9701 - accuracy: 0.5328 - val_loss: 0.9873 - val_accuracy: 0.5277\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9705 - accuracy: 0.5324 - val_loss: 0.9872 - val_accuracy: 0.5246\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9702 - accuracy: 0.5317 - val_loss: 0.9874 - val_accuracy: 0.5241\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9703 - accuracy: 0.5319 - val_loss: 0.9874 - val_accuracy: 0.5259\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9704 - accuracy: 0.5317 - val_loss: 0.9869 - val_accuracy: 0.5246\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9704 - accuracy: 0.5321 - val_loss: 0.9868 - val_accuracy: 0.5259\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9702 - accuracy: 0.5326 - val_loss: 0.9866 - val_accuracy: 0.5268\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9703 - accuracy: 0.5327 - val_loss: 0.9867 - val_accuracy: 0.5277\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9704 - accuracy: 0.5320 - val_loss: 0.9873 - val_accuracy: 0.5224\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9701 - accuracy: 0.5329 - val_loss: 0.9871 - val_accuracy: 0.5246\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9702 - accuracy: 0.5334 - val_loss: 0.9881 - val_accuracy: 0.5246\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9701 - accuracy: 0.5324 - val_loss: 0.9873 - val_accuracy: 0.5294\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9700 - accuracy: 0.5318 - val_loss: 0.9876 - val_accuracy: 0.5224\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 549us/step - loss: 0.9704 - accuracy: 0.5329 - val_loss: 0.9867 - val_accuracy: 0.5277\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9700 - accuracy: 0.5329 - val_loss: 0.9871 - val_accuracy: 0.5268\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9702 - accuracy: 0.5325 - val_loss: 0.9873 - val_accuracy: 0.5250\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9700 - accuracy: 0.5336 - val_loss: 0.9873 - val_accuracy: 0.5290\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9701 - accuracy: 0.5321 - val_loss: 0.9875 - val_accuracy: 0.5272\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9702 - accuracy: 0.5327 - val_loss: 0.9872 - val_accuracy: 0.5290\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9701 - accuracy: 0.5328 - val_loss: 0.9883 - val_accuracy: 0.5237\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9704 - accuracy: 0.5314 - val_loss: 0.9869 - val_accuracy: 0.5250\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9702 - accuracy: 0.5326 - val_loss: 0.9877 - val_accuracy: 0.5268\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9702 - accuracy: 0.5321 - val_loss: 0.9871 - val_accuracy: 0.5268\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9701 - accuracy: 0.5326 - val_loss: 0.9869 - val_accuracy: 0.5268\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9700 - accuracy: 0.5318 - val_loss: 0.9872 - val_accuracy: 0.5294\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9700 - accuracy: 0.5329 - val_loss: 0.9873 - val_accuracy: 0.5219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9702 - accuracy: 0.5326 - val_loss: 0.9875 - val_accuracy: 0.5281\n",
      "\n",
      "Train split:\n",
      "  1/636 [..............................] - ETA: 0s - loss: 1.1724 - accuracy: 0.3438WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "636/636 [==============================] - 0s 364us/step - loss: 0.9696 - accuracy: 0.5333\n",
      "Accuracy : 0.5332710146903992\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9875 - accuracy: 0.5281\n",
      "Accuracy : 0.5281097888946533\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 681us/step - loss: 1.0657 - accuracy: 0.4425 - val_loss: 1.0441 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 1.0251 - accuracy: 0.4964 - val_loss: 1.0021 - val_accuracy: 0.5383\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9974 - accuracy: 0.5266 - val_loss: 0.9829 - val_accuracy: 0.5392\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9896 - accuracy: 0.5266 - val_loss: 0.9781 - val_accuracy: 0.5392\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9872 - accuracy: 0.5270 - val_loss: 0.9769 - val_accuracy: 0.5392\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9854 - accuracy: 0.5268 - val_loss: 0.9764 - val_accuracy: 0.5392\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9837 - accuracy: 0.5269 - val_loss: 0.9735 - val_accuracy: 0.5401\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9821 - accuracy: 0.5272 - val_loss: 0.9722 - val_accuracy: 0.5423\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9807 - accuracy: 0.5294 - val_loss: 0.9712 - val_accuracy: 0.5409\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9797 - accuracy: 0.5282 - val_loss: 0.9701 - val_accuracy: 0.5436\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9787 - accuracy: 0.5299 - val_loss: 0.9695 - val_accuracy: 0.5423\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 551us/step - loss: 0.9780 - accuracy: 0.5286 - val_loss: 0.9689 - val_accuracy: 0.5423\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9690 - val_accuracy: 0.5418\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9767 - accuracy: 0.5303 - val_loss: 0.9694 - val_accuracy: 0.5396\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9767 - accuracy: 0.5302 - val_loss: 0.9684 - val_accuracy: 0.5436\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9763 - accuracy: 0.5316 - val_loss: 0.9679 - val_accuracy: 0.5414\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9758 - accuracy: 0.5315 - val_loss: 0.9676 - val_accuracy: 0.5396\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9756 - accuracy: 0.5312 - val_loss: 0.9684 - val_accuracy: 0.5414\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9755 - accuracy: 0.5306 - val_loss: 0.9683 - val_accuracy: 0.5432\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5322 - val_loss: 0.9671 - val_accuracy: 0.5405\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9749 - accuracy: 0.5297 - val_loss: 0.9684 - val_accuracy: 0.5401\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9749 - accuracy: 0.5303 - val_loss: 0.9680 - val_accuracy: 0.5405\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9748 - accuracy: 0.5298 - val_loss: 0.9669 - val_accuracy: 0.5414\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9745 - accuracy: 0.5322 - val_loss: 0.9672 - val_accuracy: 0.5401\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9747 - accuracy: 0.5304 - val_loss: 0.9672 - val_accuracy: 0.5396\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9746 - accuracy: 0.5309 - val_loss: 0.9668 - val_accuracy: 0.5401\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9745 - accuracy: 0.5310 - val_loss: 0.9678 - val_accuracy: 0.5405\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9742 - accuracy: 0.5304 - val_loss: 0.9669 - val_accuracy: 0.5387\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 549us/step - loss: 0.9744 - accuracy: 0.5297 - val_loss: 0.9676 - val_accuracy: 0.5409\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9742 - accuracy: 0.5311 - val_loss: 0.9667 - val_accuracy: 0.5405\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 0.9698 - val_accuracy: 0.5401\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9740 - accuracy: 0.5300 - val_loss: 0.9676 - val_accuracy: 0.5414\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 563us/step - loss: 0.9742 - accuracy: 0.5300 - val_loss: 0.9681 - val_accuracy: 0.5396\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9742 - accuracy: 0.5300 - val_loss: 0.9671 - val_accuracy: 0.5396\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9740 - accuracy: 0.5310 - val_loss: 0.9669 - val_accuracy: 0.5405\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 0.9667 - val_accuracy: 0.5409\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9740 - accuracy: 0.5307 - val_loss: 0.9675 - val_accuracy: 0.5392\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9740 - accuracy: 0.5307 - val_loss: 0.9671 - val_accuracy: 0.5405\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9739 - accuracy: 0.5300 - val_loss: 0.9665 - val_accuracy: 0.5405\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9738 - accuracy: 0.5308 - val_loss: 0.9668 - val_accuracy: 0.5409\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9738 - accuracy: 0.5308 - val_loss: 0.9670 - val_accuracy: 0.5409\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9741 - accuracy: 0.5302 - val_loss: 0.9666 - val_accuracy: 0.5401\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 0.9675 - val_accuracy: 0.5401\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9737 - accuracy: 0.5312 - val_loss: 0.9671 - val_accuracy: 0.5387\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9739 - accuracy: 0.5315 - val_loss: 0.9671 - val_accuracy: 0.5401\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9739 - accuracy: 0.5307 - val_loss: 0.9668 - val_accuracy: 0.5405\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9739 - accuracy: 0.5310 - val_loss: 0.9668 - val_accuracy: 0.5396\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5310 - val_loss: 0.9666 - val_accuracy: 0.5396\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9737 - accuracy: 0.5309 - val_loss: 0.9666 - val_accuracy: 0.5387\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9669 - val_accuracy: 0.5392\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9737 - accuracy: 0.5309 - val_loss: 0.9667 - val_accuracy: 0.5401\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9736 - accuracy: 0.5305 - val_loss: 0.9669 - val_accuracy: 0.5409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9739 - accuracy: 0.5298 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9736 - accuracy: 0.5305 - val_loss: 0.9674 - val_accuracy: 0.5409\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9735 - accuracy: 0.5305 - val_loss: 0.9664 - val_accuracy: 0.5401\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5310 - val_loss: 0.9661 - val_accuracy: 0.5418\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9735 - accuracy: 0.5311 - val_loss: 0.9668 - val_accuracy: 0.5401\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9738 - accuracy: 0.5304 - val_loss: 0.9669 - val_accuracy: 0.5401\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9733 - accuracy: 0.5308 - val_loss: 0.9661 - val_accuracy: 0.5409\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9734 - accuracy: 0.5301 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9736 - accuracy: 0.5313 - val_loss: 0.9672 - val_accuracy: 0.5409\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9734 - accuracy: 0.5316 - val_loss: 0.9664 - val_accuracy: 0.5401\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9734 - accuracy: 0.5314 - val_loss: 0.9660 - val_accuracy: 0.5409\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9735 - accuracy: 0.5315 - val_loss: 0.9666 - val_accuracy: 0.5387\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 0.9660 - val_accuracy: 0.5401\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9733 - accuracy: 0.5307 - val_loss: 0.9660 - val_accuracy: 0.5401\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5305 - val_loss: 0.9668 - val_accuracy: 0.5401\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9732 - accuracy: 0.5303 - val_loss: 0.9676 - val_accuracy: 0.5405\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9734 - accuracy: 0.5303 - val_loss: 0.9672 - val_accuracy: 0.5401\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9732 - accuracy: 0.5315 - val_loss: 0.9669 - val_accuracy: 0.5409\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9735 - accuracy: 0.5304 - val_loss: 0.9658 - val_accuracy: 0.5387\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9731 - accuracy: 0.5319 - val_loss: 0.9659 - val_accuracy: 0.5392\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9734 - accuracy: 0.5302 - val_loss: 0.9665 - val_accuracy: 0.5405\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9734 - accuracy: 0.5312 - val_loss: 0.9662 - val_accuracy: 0.5387\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9734 - accuracy: 0.5312 - val_loss: 0.9656 - val_accuracy: 0.5392\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9734 - accuracy: 0.5296 - val_loss: 0.9659 - val_accuracy: 0.5392\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9656 - val_accuracy: 0.5396\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9733 - accuracy: 0.5305 - val_loss: 0.9658 - val_accuracy: 0.5405\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9735 - accuracy: 0.5299 - val_loss: 0.9667 - val_accuracy: 0.5405\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9731 - accuracy: 0.5311 - val_loss: 0.9660 - val_accuracy: 0.5383\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9733 - accuracy: 0.5301 - val_loss: 0.9675 - val_accuracy: 0.5396\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9733 - accuracy: 0.5316 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9732 - accuracy: 0.5310 - val_loss: 0.9656 - val_accuracy: 0.5396\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9733 - accuracy: 0.5302 - val_loss: 0.9656 - val_accuracy: 0.5405\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9735 - accuracy: 0.5306 - val_loss: 0.9660 - val_accuracy: 0.5401\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9735 - accuracy: 0.5310 - val_loss: 0.9655 - val_accuracy: 0.5405\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9734 - accuracy: 0.5311 - val_loss: 0.9660 - val_accuracy: 0.5387\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9734 - accuracy: 0.5320 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9655 - val_accuracy: 0.5387\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9733 - accuracy: 0.5318 - val_loss: 0.9664 - val_accuracy: 0.5387\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9733 - accuracy: 0.5306 - val_loss: 0.9654 - val_accuracy: 0.5401\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9732 - accuracy: 0.5296 - val_loss: 0.9663 - val_accuracy: 0.5401\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9733 - accuracy: 0.5316 - val_loss: 0.9657 - val_accuracy: 0.5374\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5314 - val_loss: 0.9670 - val_accuracy: 0.5414\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9733 - accuracy: 0.5311 - val_loss: 0.9657 - val_accuracy: 0.5401\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 0.9654 - val_accuracy: 0.5409\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9733 - accuracy: 0.5290 - val_loss: 0.9660 - val_accuracy: 0.5392\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9733 - accuracy: 0.5307 - val_loss: 0.9656 - val_accuracy: 0.5401\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9731 - accuracy: 0.5311 - val_loss: 0.9661 - val_accuracy: 0.5405\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9733 - accuracy: 0.5303 - val_loss: 0.9653 - val_accuracy: 0.5392\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5307 - val_loss: 0.9654 - val_accuracy: 0.5387\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9653 - val_accuracy: 0.5401\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 0.9655 - val_accuracy: 0.5383\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9733 - accuracy: 0.5299 - val_loss: 0.9650 - val_accuracy: 0.5392\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9732 - accuracy: 0.5310 - val_loss: 0.9650 - val_accuracy: 0.5392\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9659 - val_accuracy: 0.5414\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9731 - accuracy: 0.5316 - val_loss: 0.9656 - val_accuracy: 0.5409\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 516us/step - loss: 0.9733 - accuracy: 0.5310 - val_loss: 0.9650 - val_accuracy: 0.5392\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9657 - val_accuracy: 0.5405\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5315 - val_loss: 0.9660 - val_accuracy: 0.5409\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9733 - accuracy: 0.5314 - val_loss: 0.9655 - val_accuracy: 0.5401\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9730 - accuracy: 0.5302 - val_loss: 0.9653 - val_accuracy: 0.5392\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9731 - accuracy: 0.5319 - val_loss: 0.9649 - val_accuracy: 0.5405\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9731 - accuracy: 0.5297 - val_loss: 0.9652 - val_accuracy: 0.5401\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5305 - val_loss: 0.9655 - val_accuracy: 0.5401\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9729 - accuracy: 0.5305 - val_loss: 0.9649 - val_accuracy: 0.5405\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5304 - val_loss: 0.9649 - val_accuracy: 0.5405\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9732 - accuracy: 0.5310 - val_loss: 0.9660 - val_accuracy: 0.5396\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5301 - val_loss: 0.9647 - val_accuracy: 0.5405\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9732 - accuracy: 0.5303 - val_loss: 0.9658 - val_accuracy: 0.5396\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9730 - accuracy: 0.5312 - val_loss: 0.9652 - val_accuracy: 0.5405\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9732 - accuracy: 0.5295 - val_loss: 0.9647 - val_accuracy: 0.5405\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9730 - accuracy: 0.5310 - val_loss: 0.9651 - val_accuracy: 0.5383\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9730 - accuracy: 0.5310 - val_loss: 0.9648 - val_accuracy: 0.5405\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9733 - accuracy: 0.5310 - val_loss: 0.9649 - val_accuracy: 0.5392\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9731 - accuracy: 0.5316 - val_loss: 0.9648 - val_accuracy: 0.5409\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9654 - val_accuracy: 0.5409\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 0.9656 - val_accuracy: 0.5396\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 582us/step - loss: 0.9730 - accuracy: 0.5307 - val_loss: 0.9648 - val_accuracy: 0.5396\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 0.9658 - val_accuracy: 0.5405\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9733 - accuracy: 0.5300 - val_loss: 0.9663 - val_accuracy: 0.5396\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9731 - accuracy: 0.5299 - val_loss: 0.9646 - val_accuracy: 0.5405\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9730 - accuracy: 0.5296 - val_loss: 0.9658 - val_accuracy: 0.5405\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9732 - accuracy: 0.5300 - val_loss: 0.9646 - val_accuracy: 0.5405\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9727 - accuracy: 0.5314 - val_loss: 0.9646 - val_accuracy: 0.5396\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9731 - accuracy: 0.5316 - val_loss: 0.9646 - val_accuracy: 0.5396\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9732 - accuracy: 0.5299 - val_loss: 0.9645 - val_accuracy: 0.5392\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5309 - val_loss: 0.9644 - val_accuracy: 0.5405\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9730 - accuracy: 0.5307 - val_loss: 0.9649 - val_accuracy: 0.5405\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9731 - accuracy: 0.5306 - val_loss: 0.9659 - val_accuracy: 0.5387\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9730 - accuracy: 0.5316 - val_loss: 0.9660 - val_accuracy: 0.5409\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9731 - accuracy: 0.5309 - val_loss: 0.9652 - val_accuracy: 0.5405\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9732 - accuracy: 0.5305 - val_loss: 0.9647 - val_accuracy: 0.5405\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9731 - accuracy: 0.5306 - val_loss: 0.9667 - val_accuracy: 0.5409\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9731 - accuracy: 0.5316 - val_loss: 0.9645 - val_accuracy: 0.5405\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 0.9656 - val_accuracy: 0.5387\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 0.9667 - val_accuracy: 0.5414\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9732 - accuracy: 0.5305 - val_loss: 0.9649 - val_accuracy: 0.5387\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9732 - accuracy: 0.5301 - val_loss: 0.9649 - val_accuracy: 0.5392\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9729 - accuracy: 0.5306 - val_loss: 0.9648 - val_accuracy: 0.5383\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5306 - val_loss: 0.9646 - val_accuracy: 0.5396\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9730 - accuracy: 0.5312 - val_loss: 0.9643 - val_accuracy: 0.5392\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 0.9644 - val_accuracy: 0.5409\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9731 - accuracy: 0.5302 - val_loss: 0.9646 - val_accuracy: 0.5396\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9734 - accuracy: 0.5300 - val_loss: 0.9644 - val_accuracy: 0.5405\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9729 - accuracy: 0.5306 - val_loss: 0.9643 - val_accuracy: 0.5392\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9730 - accuracy: 0.5304 - val_loss: 0.9648 - val_accuracy: 0.5387\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 0.9645 - val_accuracy: 0.5387\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9732 - accuracy: 0.5317 - val_loss: 0.9646 - val_accuracy: 0.5383\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9730 - accuracy: 0.5301 - val_loss: 0.9644 - val_accuracy: 0.5401\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9730 - accuracy: 0.5297 - val_loss: 0.9649 - val_accuracy: 0.5392\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9730 - accuracy: 0.5305 - val_loss: 0.9641 - val_accuracy: 0.5392\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9731 - accuracy: 0.5310 - val_loss: 0.9643 - val_accuracy: 0.5401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9730 - accuracy: 0.5306 - val_loss: 0.9646 - val_accuracy: 0.5401\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 0.9644 - val_accuracy: 0.5401\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 0.9643 - val_accuracy: 0.5396\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9732 - accuracy: 0.5303 - val_loss: 0.9643 - val_accuracy: 0.5405\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9730 - accuracy: 0.5321 - val_loss: 0.9641 - val_accuracy: 0.5401\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9728 - accuracy: 0.5311 - val_loss: 0.9646 - val_accuracy: 0.5405\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9730 - accuracy: 0.5306 - val_loss: 0.9644 - val_accuracy: 0.5405\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9730 - accuracy: 0.5305 - val_loss: 0.9644 - val_accuracy: 0.5396\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9730 - accuracy: 0.5312 - val_loss: 0.9651 - val_accuracy: 0.5396\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5299 - val_loss: 0.9642 - val_accuracy: 0.5405\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9729 - accuracy: 0.5317 - val_loss: 0.9645 - val_accuracy: 0.5405\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9729 - accuracy: 0.5305 - val_loss: 0.9642 - val_accuracy: 0.5401\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9727 - accuracy: 0.5320 - val_loss: 0.9652 - val_accuracy: 0.5401\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9728 - accuracy: 0.5314 - val_loss: 0.9643 - val_accuracy: 0.5396\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 544us/step - loss: 0.9731 - accuracy: 0.5304 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9650 - val_accuracy: 0.5418\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9728 - accuracy: 0.5316 - val_loss: 0.9646 - val_accuracy: 0.5405\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9731 - accuracy: 0.5312 - val_loss: 0.9644 - val_accuracy: 0.5396\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9729 - accuracy: 0.5300 - val_loss: 0.9654 - val_accuracy: 0.5401\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9728 - accuracy: 0.5319 - val_loss: 0.9642 - val_accuracy: 0.5383\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9728 - accuracy: 0.5308 - val_loss: 0.9639 - val_accuracy: 0.5392\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9729 - accuracy: 0.5307 - val_loss: 0.9643 - val_accuracy: 0.5378\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9732 - accuracy: 0.5306 - val_loss: 0.9645 - val_accuracy: 0.5396\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 0.9648 - val_accuracy: 0.5405\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9728 - accuracy: 0.5310 - val_loss: 0.9659 - val_accuracy: 0.5405\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 0.9640 - val_accuracy: 0.5405\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9729 - accuracy: 0.5304 - val_loss: 0.9646 - val_accuracy: 0.5396\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9731 - accuracy: 0.5315 - val_loss: 0.9648 - val_accuracy: 0.5387\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9642 - val_accuracy: 0.5387\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 0.9641 - val_accuracy: 0.5396\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9729 - accuracy: 0.5309 - val_loss: 0.9651 - val_accuracy: 0.5414\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9730 - accuracy: 0.5314 - val_loss: 0.9639 - val_accuracy: 0.5401\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9729 - accuracy: 0.5309 - val_loss: 0.9643 - val_accuracy: 0.5392\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9728 - accuracy: 0.5301 - val_loss: 0.9651 - val_accuracy: 0.5392\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9729 - accuracy: 0.5315 - val_loss: 0.9638 - val_accuracy: 0.5392\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9730 - accuracy: 0.5319 - val_loss: 0.9637 - val_accuracy: 0.5396\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 353us/step - loss: 0.9724 - accuracy: 0.5315\n",
      "Accuracy : 0.5314513444900513\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9637 - accuracy: 0.5396\n",
      "Accuracy : 0.5396193265914917\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 665us/step - loss: 1.0433 - accuracy: 0.4591 - val_loss: 1.0103 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 1.0048 - accuracy: 0.5197 - val_loss: 0.9785 - val_accuracy: 0.5458\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9913 - accuracy: 0.5263 - val_loss: 0.9708 - val_accuracy: 0.5445\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9875 - accuracy: 0.5263 - val_loss: 0.9671 - val_accuracy: 0.5463\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9846 - accuracy: 0.5261 - val_loss: 0.9653 - val_accuracy: 0.5449\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9824 - accuracy: 0.5264 - val_loss: 0.9641 - val_accuracy: 0.5471\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9810 - accuracy: 0.5278 - val_loss: 0.9627 - val_accuracy: 0.5440\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9798 - accuracy: 0.5278 - val_loss: 0.9622 - val_accuracy: 0.5445\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9791 - accuracy: 0.5280 - val_loss: 0.9616 - val_accuracy: 0.5476\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9781 - accuracy: 0.5284 - val_loss: 0.9612 - val_accuracy: 0.5458\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9778 - accuracy: 0.5283 - val_loss: 0.9618 - val_accuracy: 0.5427\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9773 - accuracy: 0.5289 - val_loss: 0.9604 - val_accuracy: 0.5467\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9768 - accuracy: 0.5297 - val_loss: 0.9600 - val_accuracy: 0.5467\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9766 - accuracy: 0.5280 - val_loss: 0.9604 - val_accuracy: 0.5458\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9761 - accuracy: 0.5300 - val_loss: 0.9602 - val_accuracy: 0.5418\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9760 - accuracy: 0.5302 - val_loss: 0.9598 - val_accuracy: 0.5476\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9758 - accuracy: 0.5305 - val_loss: 0.9596 - val_accuracy: 0.5454\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9611 - val_accuracy: 0.5432\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5294 - val_loss: 0.9598 - val_accuracy: 0.5423\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9754 - accuracy: 0.5300 - val_loss: 0.9598 - val_accuracy: 0.5423\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9753 - accuracy: 0.5305 - val_loss: 0.9599 - val_accuracy: 0.5423\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9752 - accuracy: 0.5312 - val_loss: 0.9600 - val_accuracy: 0.5432\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9598 - val_accuracy: 0.5423\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5303 - val_loss: 0.9611 - val_accuracy: 0.5467\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 567us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9592 - val_accuracy: 0.5449\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9598 - val_accuracy: 0.5423\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9749 - accuracy: 0.5297 - val_loss: 0.9593 - val_accuracy: 0.5449\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9747 - accuracy: 0.5298 - val_loss: 0.9603 - val_accuracy: 0.5458\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9747 - accuracy: 0.5295 - val_loss: 0.9595 - val_accuracy: 0.5445\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9749 - accuracy: 0.5302 - val_loss: 0.9592 - val_accuracy: 0.5445\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9746 - accuracy: 0.5314 - val_loss: 0.9588 - val_accuracy: 0.5480\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9746 - accuracy: 0.5307 - val_loss: 0.9592 - val_accuracy: 0.5423\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9747 - accuracy: 0.5292 - val_loss: 0.9589 - val_accuracy: 0.5418\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5296 - val_loss: 0.9604 - val_accuracy: 0.5471\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9745 - accuracy: 0.5303 - val_loss: 0.9614 - val_accuracy: 0.5471\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9745 - accuracy: 0.5312 - val_loss: 0.9601 - val_accuracy: 0.5471\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9744 - accuracy: 0.5306 - val_loss: 0.9600 - val_accuracy: 0.5471\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5296 - val_loss: 0.9606 - val_accuracy: 0.5471\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9743 - accuracy: 0.5304 - val_loss: 0.9588 - val_accuracy: 0.5418\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9742 - accuracy: 0.5307 - val_loss: 0.9595 - val_accuracy: 0.5432\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9742 - accuracy: 0.5305 - val_loss: 0.9604 - val_accuracy: 0.5458\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9590 - val_accuracy: 0.5423\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9741 - accuracy: 0.5312 - val_loss: 0.9585 - val_accuracy: 0.5445\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9741 - accuracy: 0.5306 - val_loss: 0.9589 - val_accuracy: 0.5440\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9742 - accuracy: 0.5300 - val_loss: 0.9588 - val_accuracy: 0.5440\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9742 - accuracy: 0.5284 - val_loss: 0.9586 - val_accuracy: 0.5418\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9742 - accuracy: 0.5294 - val_loss: 0.9594 - val_accuracy: 0.5423\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9742 - accuracy: 0.5299 - val_loss: 0.9586 - val_accuracy: 0.5471\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9741 - accuracy: 0.5298 - val_loss: 0.9585 - val_accuracy: 0.5449\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9740 - accuracy: 0.5299 - val_loss: 0.9593 - val_accuracy: 0.5449\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9739 - accuracy: 0.5306 - val_loss: 0.9613 - val_accuracy: 0.5432\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9739 - accuracy: 0.5297 - val_loss: 0.9603 - val_accuracy: 0.5449\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9738 - accuracy: 0.5309 - val_loss: 0.9589 - val_accuracy: 0.5440\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9739 - accuracy: 0.5307 - val_loss: 0.9595 - val_accuracy: 0.5440\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9739 - accuracy: 0.5302 - val_loss: 0.9602 - val_accuracy: 0.5476\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9740 - accuracy: 0.5301 - val_loss: 0.9588 - val_accuracy: 0.5423\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9583 - val_accuracy: 0.5423\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9737 - accuracy: 0.5301 - val_loss: 0.9589 - val_accuracy: 0.5440\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9739 - accuracy: 0.5306 - val_loss: 0.9583 - val_accuracy: 0.5440\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9738 - accuracy: 0.5298 - val_loss: 0.9585 - val_accuracy: 0.5423\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9738 - accuracy: 0.5303 - val_loss: 0.9602 - val_accuracy: 0.5445\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9739 - accuracy: 0.5303 - val_loss: 0.9594 - val_accuracy: 0.5445\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9741 - accuracy: 0.5303 - val_loss: 0.9594 - val_accuracy: 0.5418\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9737 - accuracy: 0.5295 - val_loss: 0.9600 - val_accuracy: 0.5432\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9737 - accuracy: 0.5293 - val_loss: 0.9579 - val_accuracy: 0.5440\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9734 - accuracy: 0.5300 - val_loss: 0.9596 - val_accuracy: 0.5418\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9736 - accuracy: 0.5318 - val_loss: 0.9626 - val_accuracy: 0.5423\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9738 - accuracy: 0.5297 - val_loss: 0.9597 - val_accuracy: 0.5418\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9736 - accuracy: 0.5309 - val_loss: 0.9588 - val_accuracy: 0.5440\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 0.9611 - val_accuracy: 0.5458\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9737 - accuracy: 0.5303 - val_loss: 0.9592 - val_accuracy: 0.5418\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9737 - accuracy: 0.5300 - val_loss: 0.9583 - val_accuracy: 0.5440\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9737 - accuracy: 0.5312 - val_loss: 0.9585 - val_accuracy: 0.5418\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9734 - accuracy: 0.5295 - val_loss: 0.9624 - val_accuracy: 0.5423\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 557us/step - loss: 0.9737 - accuracy: 0.5298 - val_loss: 0.9585 - val_accuracy: 0.5432\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9736 - accuracy: 0.5309 - val_loss: 0.9579 - val_accuracy: 0.5427\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9737 - accuracy: 0.5318 - val_loss: 0.9608 - val_accuracy: 0.5467\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9735 - accuracy: 0.5306 - val_loss: 0.9603 - val_accuracy: 0.5476\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9734 - accuracy: 0.5312 - val_loss: 0.9594 - val_accuracy: 0.5440\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9735 - accuracy: 0.5293 - val_loss: 0.9610 - val_accuracy: 0.5440\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9734 - accuracy: 0.5305 - val_loss: 0.9595 - val_accuracy: 0.5445\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9733 - accuracy: 0.5296 - val_loss: 0.9584 - val_accuracy: 0.5432\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9734 - accuracy: 0.5295 - val_loss: 0.9613 - val_accuracy: 0.5436\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9734 - accuracy: 0.5304 - val_loss: 0.9604 - val_accuracy: 0.5436\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9733 - accuracy: 0.5296 - val_loss: 0.9586 - val_accuracy: 0.5445\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5315 - val_loss: 0.9595 - val_accuracy: 0.5418\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9734 - accuracy: 0.5313 - val_loss: 0.9583 - val_accuracy: 0.5449\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9735 - accuracy: 0.5306 - val_loss: 0.9622 - val_accuracy: 0.5471\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9735 - accuracy: 0.5290 - val_loss: 0.9580 - val_accuracy: 0.5440\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9734 - accuracy: 0.5307 - val_loss: 0.9596 - val_accuracy: 0.5418\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9734 - accuracy: 0.5317 - val_loss: 0.9589 - val_accuracy: 0.5454\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5311 - val_loss: 0.9590 - val_accuracy: 0.5414\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9734 - accuracy: 0.5299 - val_loss: 0.9588 - val_accuracy: 0.5423\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9734 - accuracy: 0.5292 - val_loss: 0.9589 - val_accuracy: 0.5445\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9735 - accuracy: 0.5309 - val_loss: 0.9598 - val_accuracy: 0.5418\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9733 - accuracy: 0.5300 - val_loss: 0.9607 - val_accuracy: 0.5436\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9734 - accuracy: 0.5302 - val_loss: 0.9597 - val_accuracy: 0.5440\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9736 - accuracy: 0.5306 - val_loss: 0.9595 - val_accuracy: 0.5432\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9733 - accuracy: 0.5314 - val_loss: 0.9587 - val_accuracy: 0.5445\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9600 - val_accuracy: 0.5432\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5319 - val_loss: 0.9595 - val_accuracy: 0.5418\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9731 - accuracy: 0.5301 - val_loss: 0.9584 - val_accuracy: 0.5449\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9734 - accuracy: 0.5301 - val_loss: 0.9584 - val_accuracy: 0.5454\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9732 - accuracy: 0.5311 - val_loss: 0.9614 - val_accuracy: 0.5445\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9734 - accuracy: 0.5307 - val_loss: 0.9603 - val_accuracy: 0.5418\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9733 - accuracy: 0.5313 - val_loss: 0.9611 - val_accuracy: 0.5471\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9731 - accuracy: 0.5298 - val_loss: 0.9603 - val_accuracy: 0.5445\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9733 - accuracy: 0.5306 - val_loss: 0.9584 - val_accuracy: 0.5423\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9734 - accuracy: 0.5306 - val_loss: 0.9591 - val_accuracy: 0.5440\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9733 - accuracy: 0.5301 - val_loss: 0.9586 - val_accuracy: 0.5418\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9733 - accuracy: 0.5308 - val_loss: 0.9620 - val_accuracy: 0.5471\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9734 - accuracy: 0.5314 - val_loss: 0.9615 - val_accuracy: 0.5467\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9733 - accuracy: 0.5304 - val_loss: 0.9617 - val_accuracy: 0.5467\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9732 - accuracy: 0.5301 - val_loss: 0.9646 - val_accuracy: 0.5454\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9734 - accuracy: 0.5300 - val_loss: 0.9602 - val_accuracy: 0.5432\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9733 - accuracy: 0.5303 - val_loss: 0.9585 - val_accuracy: 0.5445\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9733 - accuracy: 0.5304 - val_loss: 0.9592 - val_accuracy: 0.5445\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9733 - accuracy: 0.5305 - val_loss: 0.9598 - val_accuracy: 0.5418\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9731 - accuracy: 0.5293 - val_loss: 0.9584 - val_accuracy: 0.5449\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9735 - accuracy: 0.5300 - val_loss: 0.9611 - val_accuracy: 0.5436\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9734 - accuracy: 0.5305 - val_loss: 0.9609 - val_accuracy: 0.5423\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9600 - val_accuracy: 0.5436\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5302 - val_loss: 0.9622 - val_accuracy: 0.5440\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9735 - accuracy: 0.5306 - val_loss: 0.9608 - val_accuracy: 0.5432\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9733 - accuracy: 0.5317 - val_loss: 0.9604 - val_accuracy: 0.5423\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9734 - accuracy: 0.5311 - val_loss: 0.9618 - val_accuracy: 0.5458\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9734 - accuracy: 0.5305 - val_loss: 0.9592 - val_accuracy: 0.5423\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9733 - accuracy: 0.5298 - val_loss: 0.9585 - val_accuracy: 0.5423\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9734 - accuracy: 0.5297 - val_loss: 0.9582 - val_accuracy: 0.5423\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9734 - accuracy: 0.5299 - val_loss: 0.9600 - val_accuracy: 0.5418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 0.9598 - val_accuracy: 0.5432\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9728 - accuracy: 0.5316 - val_loss: 0.9587 - val_accuracy: 0.5423\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9595 - val_accuracy: 0.5423\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 0.9600 - val_accuracy: 0.5423\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9734 - accuracy: 0.5299 - val_loss: 0.9618 - val_accuracy: 0.5432\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9731 - accuracy: 0.5319 - val_loss: 0.9582 - val_accuracy: 0.5449\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9735 - accuracy: 0.5299 - val_loss: 0.9591 - val_accuracy: 0.5432\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9731 - accuracy: 0.5305 - val_loss: 0.9580 - val_accuracy: 0.5445\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9731 - accuracy: 0.5313 - val_loss: 0.9589 - val_accuracy: 0.5423\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9616 - val_accuracy: 0.5458\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9732 - accuracy: 0.5306 - val_loss: 0.9612 - val_accuracy: 0.5432\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9733 - accuracy: 0.5314 - val_loss: 0.9592 - val_accuracy: 0.5423\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9730 - accuracy: 0.5299 - val_loss: 0.9592 - val_accuracy: 0.5454\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9729 - accuracy: 0.5294 - val_loss: 0.9584 - val_accuracy: 0.5423\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9733 - accuracy: 0.5306 - val_loss: 0.9623 - val_accuracy: 0.5436\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 0.9588 - val_accuracy: 0.5471\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9610 - val_accuracy: 0.5440\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9589 - val_accuracy: 0.5449\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5295 - val_loss: 0.9603 - val_accuracy: 0.5432\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9734 - accuracy: 0.5313 - val_loss: 0.9619 - val_accuracy: 0.5432\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9732 - accuracy: 0.5305 - val_loss: 0.9580 - val_accuracy: 0.5458\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5312 - val_loss: 0.9594 - val_accuracy: 0.5440\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9734 - accuracy: 0.5296 - val_loss: 0.9596 - val_accuracy: 0.5414\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9731 - accuracy: 0.5312 - val_loss: 0.9588 - val_accuracy: 0.5445\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9733 - accuracy: 0.5308 - val_loss: 0.9596 - val_accuracy: 0.5432\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9733 - accuracy: 0.5303 - val_loss: 0.9596 - val_accuracy: 0.5432\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9732 - accuracy: 0.5297 - val_loss: 0.9596 - val_accuracy: 0.5458\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9732 - accuracy: 0.5320 - val_loss: 0.9616 - val_accuracy: 0.5432\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9731 - accuracy: 0.5311 - val_loss: 0.9617 - val_accuracy: 0.5467\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9730 - accuracy: 0.5300 - val_loss: 0.9582 - val_accuracy: 0.5440\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9730 - accuracy: 0.5314 - val_loss: 0.9627 - val_accuracy: 0.5423\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9730 - accuracy: 0.5320 - val_loss: 0.9584 - val_accuracy: 0.5467\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9731 - accuracy: 0.5306 - val_loss: 0.9622 - val_accuracy: 0.5423\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 0.9619 - val_accuracy: 0.5414\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9729 - accuracy: 0.5314 - val_loss: 0.9628 - val_accuracy: 0.5467\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9732 - accuracy: 0.5322 - val_loss: 0.9597 - val_accuracy: 0.5423\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9732 - accuracy: 0.5311 - val_loss: 0.9590 - val_accuracy: 0.5427\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9732 - accuracy: 0.5297 - val_loss: 0.9587 - val_accuracy: 0.5445\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9731 - accuracy: 0.5304 - val_loss: 0.9596 - val_accuracy: 0.5427\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9730 - accuracy: 0.5318 - val_loss: 0.9590 - val_accuracy: 0.5418\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9629 - val_accuracy: 0.5427\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9732 - accuracy: 0.5304 - val_loss: 0.9591 - val_accuracy: 0.5409\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 566us/step - loss: 0.9730 - accuracy: 0.5307 - val_loss: 0.9592 - val_accuracy: 0.5449\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9730 - accuracy: 0.5319 - val_loss: 0.9590 - val_accuracy: 0.5418\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 0.9595 - val_accuracy: 0.5423\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9731 - accuracy: 0.5311 - val_loss: 0.9613 - val_accuracy: 0.5436\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9591 - val_accuracy: 0.5449\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9729 - accuracy: 0.5305 - val_loss: 0.9610 - val_accuracy: 0.5467\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 0.9588 - val_accuracy: 0.5432\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9730 - accuracy: 0.5321 - val_loss: 0.9641 - val_accuracy: 0.5471\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5318 - val_loss: 0.9600 - val_accuracy: 0.5436\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9731 - accuracy: 0.5306 - val_loss: 0.9587 - val_accuracy: 0.5449\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9729 - accuracy: 0.5322 - val_loss: 0.9610 - val_accuracy: 0.5449\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9728 - accuracy: 0.5294 - val_loss: 0.9585 - val_accuracy: 0.5467\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5315 - val_loss: 0.9603 - val_accuracy: 0.5414\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9731 - accuracy: 0.5306 - val_loss: 0.9602 - val_accuracy: 0.5418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 0.9607 - val_accuracy: 0.5427\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5315 - val_loss: 0.9599 - val_accuracy: 0.5423\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9731 - accuracy: 0.5311 - val_loss: 0.9622 - val_accuracy: 0.5467\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9732 - accuracy: 0.5311 - val_loss: 0.9594 - val_accuracy: 0.5414\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 0.9602 - val_accuracy: 0.5427\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9729 - accuracy: 0.5309 - val_loss: 0.9593 - val_accuracy: 0.5467\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9731 - accuracy: 0.5311 - val_loss: 0.9603 - val_accuracy: 0.5414\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9730 - accuracy: 0.5305 - val_loss: 0.9602 - val_accuracy: 0.5414\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5319 - val_loss: 0.9589 - val_accuracy: 0.5409\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9731 - accuracy: 0.5311 - val_loss: 0.9591 - val_accuracy: 0.5427\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9731 - accuracy: 0.5309 - val_loss: 0.9586 - val_accuracy: 0.5458\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 0.9652 - val_accuracy: 0.5458\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9731 - accuracy: 0.5310 - val_loss: 0.9605 - val_accuracy: 0.5414\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9729 - accuracy: 0.5308 - val_loss: 0.9613 - val_accuracy: 0.5427\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 362us/step - loss: 0.9725 - accuracy: 0.5317\n",
      "Accuracy : 0.5316972136497498\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9613 - accuracy: 0.5427\n",
      "Accuracy : 0.5427179932594299\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 664us/step - loss: 1.0494 - accuracy: 0.4608 - val_loss: 1.0254 - val_accuracy: 0.5237\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 1.0182 - accuracy: 0.5157 - val_loss: 0.9902 - val_accuracy: 0.5489\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9979 - accuracy: 0.5297 - val_loss: 0.9715 - val_accuracy: 0.5423\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9912 - accuracy: 0.5266 - val_loss: 0.9651 - val_accuracy: 0.5423\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9886 - accuracy: 0.5265 - val_loss: 0.9592 - val_accuracy: 0.5423\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9864 - accuracy: 0.5270 - val_loss: 0.9556 - val_accuracy: 0.5423\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9846 - accuracy: 0.5269 - val_loss: 0.9520 - val_accuracy: 0.5432\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9829 - accuracy: 0.5282 - val_loss: 0.9532 - val_accuracy: 0.5423\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9821 - accuracy: 0.5280 - val_loss: 0.9477 - val_accuracy: 0.5445\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9813 - accuracy: 0.5285 - val_loss: 0.9460 - val_accuracy: 0.5440\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9806 - accuracy: 0.5296 - val_loss: 0.9456 - val_accuracy: 0.5423\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9801 - accuracy: 0.5280 - val_loss: 0.9454 - val_accuracy: 0.5423\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9798 - accuracy: 0.5291 - val_loss: 0.9427 - val_accuracy: 0.5485\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9420 - val_accuracy: 0.5476\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9794 - accuracy: 0.5302 - val_loss: 0.9416 - val_accuracy: 0.5480\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9790 - accuracy: 0.5280 - val_loss: 0.9409 - val_accuracy: 0.5485\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9789 - accuracy: 0.5294 - val_loss: 0.9416 - val_accuracy: 0.5476\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9787 - accuracy: 0.5287 - val_loss: 0.9415 - val_accuracy: 0.5423\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9785 - accuracy: 0.5299 - val_loss: 0.9396 - val_accuracy: 0.5489\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9783 - accuracy: 0.5293 - val_loss: 0.9406 - val_accuracy: 0.5480\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9784 - accuracy: 0.5302 - val_loss: 0.9404 - val_accuracy: 0.5445\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9782 - accuracy: 0.5297 - val_loss: 0.9399 - val_accuracy: 0.5507\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9782 - accuracy: 0.5301 - val_loss: 0.9392 - val_accuracy: 0.5480\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9781 - accuracy: 0.5288 - val_loss: 0.9390 - val_accuracy: 0.5507\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9779 - accuracy: 0.5304 - val_loss: 0.9393 - val_accuracy: 0.5480\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9779 - accuracy: 0.5309 - val_loss: 0.9402 - val_accuracy: 0.5480\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9780 - accuracy: 0.5307 - val_loss: 0.9386 - val_accuracy: 0.5454\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9779 - accuracy: 0.5303 - val_loss: 0.9382 - val_accuracy: 0.5454\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9779 - accuracy: 0.5291 - val_loss: 0.9388 - val_accuracy: 0.5489\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9779 - accuracy: 0.5302 - val_loss: 0.9394 - val_accuracy: 0.5476\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9777 - accuracy: 0.5303 - val_loss: 0.9382 - val_accuracy: 0.5445\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9776 - accuracy: 0.5297 - val_loss: 0.9398 - val_accuracy: 0.5445\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9778 - accuracy: 0.5293 - val_loss: 0.9390 - val_accuracy: 0.5476\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9779 - accuracy: 0.5297 - val_loss: 0.9380 - val_accuracy: 0.5454\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9775 - accuracy: 0.5301 - val_loss: 0.9381 - val_accuracy: 0.5489\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9776 - accuracy: 0.5301 - val_loss: 0.9385 - val_accuracy: 0.5476\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9775 - accuracy: 0.5303 - val_loss: 0.9386 - val_accuracy: 0.5485\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9774 - accuracy: 0.5290 - val_loss: 0.9382 - val_accuracy: 0.5458\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9773 - accuracy: 0.5293 - val_loss: 0.9377 - val_accuracy: 0.5445\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9773 - accuracy: 0.5301 - val_loss: 0.9382 - val_accuracy: 0.5489\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 523us/step - loss: 0.9773 - accuracy: 0.5306 - val_loss: 0.9381 - val_accuracy: 0.5476\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9773 - accuracy: 0.5295 - val_loss: 0.9384 - val_accuracy: 0.5476\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9775 - accuracy: 0.5288 - val_loss: 0.9398 - val_accuracy: 0.5440\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9771 - accuracy: 0.5311 - val_loss: 0.9377 - val_accuracy: 0.5467\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9773 - accuracy: 0.5299 - val_loss: 0.9400 - val_accuracy: 0.5454\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9773 - accuracy: 0.5303 - val_loss: 0.9384 - val_accuracy: 0.5480\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9773 - accuracy: 0.5306 - val_loss: 0.9374 - val_accuracy: 0.5476\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9771 - accuracy: 0.5298 - val_loss: 0.9392 - val_accuracy: 0.5440\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9771 - accuracy: 0.5296 - val_loss: 0.9391 - val_accuracy: 0.5471\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9771 - accuracy: 0.5303 - val_loss: 0.9381 - val_accuracy: 0.5480\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9770 - accuracy: 0.5307 - val_loss: 0.9374 - val_accuracy: 0.5440\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9772 - accuracy: 0.5293 - val_loss: 0.9385 - val_accuracy: 0.5454\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9770 - accuracy: 0.5309 - val_loss: 0.9379 - val_accuracy: 0.5476\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9770 - accuracy: 0.5306 - val_loss: 0.9389 - val_accuracy: 0.5476\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9771 - accuracy: 0.5293 - val_loss: 0.9381 - val_accuracy: 0.5476\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9767 - accuracy: 0.5314 - val_loss: 0.9371 - val_accuracy: 0.5440\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9769 - accuracy: 0.5309 - val_loss: 0.9375 - val_accuracy: 0.5494\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9767 - accuracy: 0.5320 - val_loss: 0.9385 - val_accuracy: 0.5480\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9768 - accuracy: 0.5304 - val_loss: 0.9377 - val_accuracy: 0.5476\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9766 - accuracy: 0.5312 - val_loss: 0.9376 - val_accuracy: 0.5432\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9770 - accuracy: 0.5295 - val_loss: 0.9380 - val_accuracy: 0.5454\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9767 - accuracy: 0.5297 - val_loss: 0.9398 - val_accuracy: 0.5480\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9384 - val_accuracy: 0.5480\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9372 - val_accuracy: 0.5476\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9766 - accuracy: 0.5310 - val_loss: 0.9372 - val_accuracy: 0.5489\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9768 - accuracy: 0.5305 - val_loss: 0.9401 - val_accuracy: 0.5463\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9767 - accuracy: 0.5312 - val_loss: 0.9378 - val_accuracy: 0.5489\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9765 - accuracy: 0.5305 - val_loss: 0.9395 - val_accuracy: 0.5454\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 550us/step - loss: 0.9767 - accuracy: 0.5307 - val_loss: 0.9371 - val_accuracy: 0.5440\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9384 - val_accuracy: 0.5476\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9765 - accuracy: 0.5309 - val_loss: 0.9378 - val_accuracy: 0.5494\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9767 - accuracy: 0.5305 - val_loss: 0.9394 - val_accuracy: 0.5463\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9763 - accuracy: 0.5299 - val_loss: 0.9387 - val_accuracy: 0.5476\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9764 - accuracy: 0.5301 - val_loss: 0.9376 - val_accuracy: 0.5494\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9763 - accuracy: 0.5307 - val_loss: 0.9367 - val_accuracy: 0.5445\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9768 - accuracy: 0.5304 - val_loss: 0.9375 - val_accuracy: 0.5454\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9763 - accuracy: 0.5303 - val_loss: 0.9416 - val_accuracy: 0.5436\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9763 - accuracy: 0.5299 - val_loss: 0.9382 - val_accuracy: 0.5480\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9765 - accuracy: 0.5308 - val_loss: 0.9385 - val_accuracy: 0.5454\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9765 - accuracy: 0.5299 - val_loss: 0.9376 - val_accuracy: 0.5449\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9765 - accuracy: 0.5305 - val_loss: 0.9372 - val_accuracy: 0.5476\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9764 - accuracy: 0.5297 - val_loss: 0.9375 - val_accuracy: 0.5480\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9765 - accuracy: 0.5299 - val_loss: 0.9368 - val_accuracy: 0.5432\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9764 - accuracy: 0.5297 - val_loss: 0.9382 - val_accuracy: 0.5471\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9764 - accuracy: 0.5307 - val_loss: 0.9382 - val_accuracy: 0.5449\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9763 - accuracy: 0.5309 - val_loss: 0.9377 - val_accuracy: 0.5476\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9764 - accuracy: 0.5304 - val_loss: 0.9372 - val_accuracy: 0.5476\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9762 - accuracy: 0.5302 - val_loss: 0.9374 - val_accuracy: 0.5489\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9762 - accuracy: 0.5307 - val_loss: 0.9384 - val_accuracy: 0.5480\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9763 - accuracy: 0.5304 - val_loss: 0.9366 - val_accuracy: 0.5440\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9763 - accuracy: 0.5299 - val_loss: 0.9393 - val_accuracy: 0.5454\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9763 - accuracy: 0.5304 - val_loss: 0.9392 - val_accuracy: 0.5454\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9762 - accuracy: 0.5309 - val_loss: 0.9371 - val_accuracy: 0.5440\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9761 - accuracy: 0.5310 - val_loss: 0.9373 - val_accuracy: 0.5480\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9761 - accuracy: 0.5292 - val_loss: 0.9409 - val_accuracy: 0.5432\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9763 - accuracy: 0.5312 - val_loss: 0.9395 - val_accuracy: 0.5454\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 523us/step - loss: 0.9762 - accuracy: 0.5295 - val_loss: 0.9393 - val_accuracy: 0.5480\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9762 - accuracy: 0.5296 - val_loss: 0.9387 - val_accuracy: 0.5476\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9762 - accuracy: 0.5306 - val_loss: 0.9374 - val_accuracy: 0.5476\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9765 - accuracy: 0.5308 - val_loss: 0.9395 - val_accuracy: 0.5454\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9761 - accuracy: 0.5306 - val_loss: 0.9392 - val_accuracy: 0.5476\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9761 - accuracy: 0.5302 - val_loss: 0.9374 - val_accuracy: 0.5480\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9760 - accuracy: 0.5287 - val_loss: 0.9376 - val_accuracy: 0.5480\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9761 - accuracy: 0.5294 - val_loss: 0.9366 - val_accuracy: 0.5445\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9761 - accuracy: 0.5303 - val_loss: 0.9378 - val_accuracy: 0.5476\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9762 - accuracy: 0.5301 - val_loss: 0.9381 - val_accuracy: 0.5471\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9762 - accuracy: 0.5303 - val_loss: 0.9371 - val_accuracy: 0.5471\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9368 - val_accuracy: 0.5489\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9762 - accuracy: 0.5302 - val_loss: 0.9372 - val_accuracy: 0.5480\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9761 - accuracy: 0.5302 - val_loss: 0.9399 - val_accuracy: 0.5454\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9761 - accuracy: 0.5299 - val_loss: 0.9378 - val_accuracy: 0.5463\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9759 - accuracy: 0.5304 - val_loss: 0.9370 - val_accuracy: 0.5480\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9761 - accuracy: 0.5292 - val_loss: 0.9377 - val_accuracy: 0.5480\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9759 - accuracy: 0.5304 - val_loss: 0.9374 - val_accuracy: 0.5449\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9760 - accuracy: 0.5291 - val_loss: 0.9391 - val_accuracy: 0.5454\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9762 - accuracy: 0.5293 - val_loss: 0.9379 - val_accuracy: 0.5476\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9760 - accuracy: 0.5303 - val_loss: 0.9398 - val_accuracy: 0.5454\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9758 - accuracy: 0.5311 - val_loss: 0.9381 - val_accuracy: 0.5480\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 552us/step - loss: 0.9760 - accuracy: 0.5309 - val_loss: 0.9379 - val_accuracy: 0.5471\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9761 - accuracy: 0.5294 - val_loss: 0.9368 - val_accuracy: 0.5476\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9760 - accuracy: 0.5299 - val_loss: 0.9406 - val_accuracy: 0.5440\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9759 - accuracy: 0.5302 - val_loss: 0.9372 - val_accuracy: 0.5467\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9762 - accuracy: 0.5300 - val_loss: 0.9382 - val_accuracy: 0.5458\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9759 - accuracy: 0.5308 - val_loss: 0.9395 - val_accuracy: 0.5440\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9761 - accuracy: 0.5303 - val_loss: 0.9372 - val_accuracy: 0.5476\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9759 - accuracy: 0.5310 - val_loss: 0.9381 - val_accuracy: 0.5480\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9761 - accuracy: 0.5298 - val_loss: 0.9393 - val_accuracy: 0.5476\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9758 - accuracy: 0.5303 - val_loss: 0.9374 - val_accuracy: 0.5449\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9759 - accuracy: 0.5301 - val_loss: 0.9386 - val_accuracy: 0.5458\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9374 - val_accuracy: 0.5467\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9758 - accuracy: 0.5308 - val_loss: 0.9379 - val_accuracy: 0.5471\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9761 - accuracy: 0.5312 - val_loss: 0.9388 - val_accuracy: 0.5471\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5304 - val_loss: 0.9380 - val_accuracy: 0.5498\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9759 - accuracy: 0.5298 - val_loss: 0.9375 - val_accuracy: 0.5445\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9759 - accuracy: 0.5306 - val_loss: 0.9381 - val_accuracy: 0.5458\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9394 - val_accuracy: 0.5454\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9759 - accuracy: 0.5288 - val_loss: 0.9390 - val_accuracy: 0.5480\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9759 - accuracy: 0.5305 - val_loss: 0.9388 - val_accuracy: 0.5471\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9383 - val_accuracy: 0.5480\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5305 - val_loss: 0.9372 - val_accuracy: 0.5489\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9759 - accuracy: 0.5302 - val_loss: 0.9387 - val_accuracy: 0.5471\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9760 - accuracy: 0.5309 - val_loss: 0.9377 - val_accuracy: 0.5476\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9757 - accuracy: 0.5310 - val_loss: 0.9371 - val_accuracy: 0.5476\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9758 - accuracy: 0.5310 - val_loss: 0.9403 - val_accuracy: 0.5454\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9384 - val_accuracy: 0.5476\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9368 - val_accuracy: 0.5423\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9385 - val_accuracy: 0.5467\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5304 - val_loss: 0.9411 - val_accuracy: 0.5432\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9374 - val_accuracy: 0.5502\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9758 - accuracy: 0.5314 - val_loss: 0.9372 - val_accuracy: 0.5467\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9403 - val_accuracy: 0.5485\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9758 - accuracy: 0.5314 - val_loss: 0.9404 - val_accuracy: 0.5440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9758 - accuracy: 0.5303 - val_loss: 0.9378 - val_accuracy: 0.5476\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9756 - accuracy: 0.5308 - val_loss: 0.9425 - val_accuracy: 0.5427\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9758 - accuracy: 0.5303 - val_loss: 0.9405 - val_accuracy: 0.5454\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5287 - val_loss: 0.9374 - val_accuracy: 0.5485\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9756 - accuracy: 0.5306 - val_loss: 0.9395 - val_accuracy: 0.5480\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9759 - accuracy: 0.5292 - val_loss: 0.9383 - val_accuracy: 0.5467\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9760 - accuracy: 0.5304 - val_loss: 0.9378 - val_accuracy: 0.5476\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5310 - val_loss: 0.9378 - val_accuracy: 0.5449\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9759 - accuracy: 0.5302 - val_loss: 0.9381 - val_accuracy: 0.5480\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9755 - accuracy: 0.5304 - val_loss: 0.9385 - val_accuracy: 0.5458\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9758 - accuracy: 0.5308 - val_loss: 0.9381 - val_accuracy: 0.5476\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9757 - accuracy: 0.5306 - val_loss: 0.9377 - val_accuracy: 0.5471\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9381 - val_accuracy: 0.5507\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5311 - val_loss: 0.9374 - val_accuracy: 0.5476\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5310 - val_loss: 0.9384 - val_accuracy: 0.5480\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9758 - accuracy: 0.5296 - val_loss: 0.9384 - val_accuracy: 0.5480\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9759 - accuracy: 0.5306 - val_loss: 0.9391 - val_accuracy: 0.5471\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9756 - accuracy: 0.5301 - val_loss: 0.9394 - val_accuracy: 0.5480\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5307 - val_loss: 0.9385 - val_accuracy: 0.5480\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5306 - val_loss: 0.9374 - val_accuracy: 0.5476\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9759 - accuracy: 0.5306 - val_loss: 0.9385 - val_accuracy: 0.5476\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5312 - val_loss: 0.9395 - val_accuracy: 0.5454\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9759 - accuracy: 0.5294 - val_loss: 0.9374 - val_accuracy: 0.5476\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9756 - accuracy: 0.5314 - val_loss: 0.9373 - val_accuracy: 0.5454\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 551us/step - loss: 0.9759 - accuracy: 0.5302 - val_loss: 0.9375 - val_accuracy: 0.5476\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9756 - accuracy: 0.5318 - val_loss: 0.9368 - val_accuracy: 0.5471\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9758 - accuracy: 0.5298 - val_loss: 0.9374 - val_accuracy: 0.5476\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5302 - val_loss: 0.9379 - val_accuracy: 0.5480\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9757 - accuracy: 0.5303 - val_loss: 0.9381 - val_accuracy: 0.5471\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9757 - accuracy: 0.5308 - val_loss: 0.9396 - val_accuracy: 0.5454\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5303 - val_loss: 0.9392 - val_accuracy: 0.5480\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9758 - accuracy: 0.5316 - val_loss: 0.9378 - val_accuracy: 0.5476\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5303 - val_loss: 0.9386 - val_accuracy: 0.5454\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9757 - accuracy: 0.5303 - val_loss: 0.9373 - val_accuracy: 0.5454\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9755 - accuracy: 0.5304 - val_loss: 0.9387 - val_accuracy: 0.5471\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5292 - val_loss: 0.9402 - val_accuracy: 0.5463\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5306 - val_loss: 0.9388 - val_accuracy: 0.5467\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9757 - accuracy: 0.5296 - val_loss: 0.9374 - val_accuracy: 0.5489\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9756 - accuracy: 0.5302 - val_loss: 0.9385 - val_accuracy: 0.5467\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5308 - val_loss: 0.9384 - val_accuracy: 0.5467\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9754 - accuracy: 0.5305 - val_loss: 0.9376 - val_accuracy: 0.5489\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9756 - accuracy: 0.5308 - val_loss: 0.9396 - val_accuracy: 0.5467\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9756 - accuracy: 0.5313 - val_loss: 0.9380 - val_accuracy: 0.5476\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 0.9382 - val_accuracy: 0.5489\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9757 - accuracy: 0.5304 - val_loss: 0.9375 - val_accuracy: 0.5480\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5304 - val_loss: 0.9377 - val_accuracy: 0.5476\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9367 - val_accuracy: 0.5476\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9756 - accuracy: 0.5307 - val_loss: 0.9397 - val_accuracy: 0.5471\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 345us/step - loss: 0.9753 - accuracy: 0.5304\n",
      "Accuracy : 0.5303693413734436\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9397 - accuracy: 0.5471\n",
      "Accuracy : 0.5471447706222534\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 665us/step - loss: 1.0650 - accuracy: 0.4576 - val_loss: 1.0542 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 1.0405 - accuracy: 0.4591 - val_loss: 1.0248 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 1.0089 - accuracy: 0.4974 - val_loss: 0.9982 - val_accuracy: 0.5334\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9930 - accuracy: 0.5292 - val_loss: 0.9883 - val_accuracy: 0.5259\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9874 - accuracy: 0.5283 - val_loss: 0.9865 - val_accuracy: 0.5259\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9836 - accuracy: 0.5285 - val_loss: 0.9797 - val_accuracy: 0.5299\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 531us/step - loss: 0.9811 - accuracy: 0.5286 - val_loss: 0.9796 - val_accuracy: 0.5259\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9792 - accuracy: 0.5289 - val_loss: 0.9773 - val_accuracy: 0.5259\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9782 - accuracy: 0.5289 - val_loss: 0.9760 - val_accuracy: 0.5255\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9751 - val_accuracy: 0.5290\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9767 - accuracy: 0.5287 - val_loss: 0.9747 - val_accuracy: 0.5246\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9762 - accuracy: 0.5287 - val_loss: 0.9743 - val_accuracy: 0.5237\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9759 - accuracy: 0.5300 - val_loss: 0.9763 - val_accuracy: 0.5259\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9756 - accuracy: 0.5302 - val_loss: 0.9735 - val_accuracy: 0.5330\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9752 - accuracy: 0.5303 - val_loss: 0.9730 - val_accuracy: 0.5268\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 559us/step - loss: 0.9752 - accuracy: 0.5298 - val_loss: 0.9741 - val_accuracy: 0.5294\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9750 - accuracy: 0.5314 - val_loss: 0.9748 - val_accuracy: 0.5255\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9749 - accuracy: 0.5315 - val_loss: 0.9734 - val_accuracy: 0.5325\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9747 - accuracy: 0.5307 - val_loss: 0.9743 - val_accuracy: 0.5330\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9745 - accuracy: 0.5319 - val_loss: 0.9730 - val_accuracy: 0.5312\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9746 - accuracy: 0.5317 - val_loss: 0.9733 - val_accuracy: 0.5312\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5312 - val_loss: 0.9740 - val_accuracy: 0.5299\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9741 - val_accuracy: 0.5325\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9743 - accuracy: 0.5315 - val_loss: 0.9739 - val_accuracy: 0.5299\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9743 - accuracy: 0.5315 - val_loss: 0.9732 - val_accuracy: 0.5325\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9740 - accuracy: 0.5305 - val_loss: 0.9721 - val_accuracy: 0.5259\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9742 - accuracy: 0.5312 - val_loss: 0.9741 - val_accuracy: 0.5294\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9740 - accuracy: 0.5322 - val_loss: 0.9731 - val_accuracy: 0.5294\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9739 - accuracy: 0.5319 - val_loss: 0.9727 - val_accuracy: 0.5308\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 0.9737 - val_accuracy: 0.5246\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9738 - accuracy: 0.5306 - val_loss: 0.9723 - val_accuracy: 0.5330\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9737 - accuracy: 0.5321 - val_loss: 0.9727 - val_accuracy: 0.5325\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9718 - val_accuracy: 0.5317\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9737 - accuracy: 0.5313 - val_loss: 0.9728 - val_accuracy: 0.5325\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 0.9717 - val_accuracy: 0.5317\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9736 - accuracy: 0.5321 - val_loss: 0.9719 - val_accuracy: 0.5325\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9734 - accuracy: 0.5305 - val_loss: 0.9713 - val_accuracy: 0.5321\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9715 - val_accuracy: 0.5321\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9733 - accuracy: 0.5317 - val_loss: 0.9732 - val_accuracy: 0.5246\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9733 - accuracy: 0.5319 - val_loss: 0.9727 - val_accuracy: 0.5294\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9725 - val_accuracy: 0.5299\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9733 - accuracy: 0.5321 - val_loss: 0.9711 - val_accuracy: 0.5317\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9733 - accuracy: 0.5311 - val_loss: 0.9720 - val_accuracy: 0.5294\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9726 - val_accuracy: 0.5241\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9732 - accuracy: 0.5316 - val_loss: 0.9717 - val_accuracy: 0.5321\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9733 - accuracy: 0.5319 - val_loss: 0.9714 - val_accuracy: 0.5317\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9731 - accuracy: 0.5316 - val_loss: 0.9707 - val_accuracy: 0.5312\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 0.9725 - val_accuracy: 0.5255\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 0.9713 - val_accuracy: 0.5317\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9729 - accuracy: 0.5312 - val_loss: 0.9709 - val_accuracy: 0.5317\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5309 - val_loss: 0.9716 - val_accuracy: 0.5294\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 0.9704 - val_accuracy: 0.5321\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9729 - accuracy: 0.5302 - val_loss: 0.9710 - val_accuracy: 0.5308\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 0.9701 - val_accuracy: 0.5299\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9713 - val_accuracy: 0.5294\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9729 - accuracy: 0.5308 - val_loss: 0.9718 - val_accuracy: 0.5294\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9729 - accuracy: 0.5323 - val_loss: 0.9711 - val_accuracy: 0.5294\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9728 - accuracy: 0.5304 - val_loss: 0.9712 - val_accuracy: 0.5294\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9728 - accuracy: 0.5298 - val_loss: 0.9720 - val_accuracy: 0.5246\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 0.9700 - val_accuracy: 0.5317\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9729 - accuracy: 0.5307 - val_loss: 0.9709 - val_accuracy: 0.5294\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9727 - accuracy: 0.5313 - val_loss: 0.9712 - val_accuracy: 0.5294\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 500us/step - loss: 0.9728 - accuracy: 0.5311 - val_loss: 0.9717 - val_accuracy: 0.5330\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9728 - accuracy: 0.5312 - val_loss: 0.9712 - val_accuracy: 0.5294\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 547us/step - loss: 0.9725 - accuracy: 0.5311 - val_loss: 0.9701 - val_accuracy: 0.5321\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9702 - val_accuracy: 0.5312\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9726 - accuracy: 0.5320 - val_loss: 0.9713 - val_accuracy: 0.5294\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9726 - accuracy: 0.5314 - val_loss: 0.9705 - val_accuracy: 0.5312\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9725 - accuracy: 0.5312 - val_loss: 0.9706 - val_accuracy: 0.5294\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9726 - accuracy: 0.5320 - val_loss: 0.9701 - val_accuracy: 0.5334\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9726 - accuracy: 0.5318 - val_loss: 0.9703 - val_accuracy: 0.5330\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 0.9700 - val_accuracy: 0.5308\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9726 - accuracy: 0.5322 - val_loss: 0.9704 - val_accuracy: 0.5312\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9726 - accuracy: 0.5309 - val_loss: 0.9707 - val_accuracy: 0.5334\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9726 - accuracy: 0.5313 - val_loss: 0.9711 - val_accuracy: 0.5294\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9727 - accuracy: 0.5311 - val_loss: 0.9705 - val_accuracy: 0.5286\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9726 - accuracy: 0.5300 - val_loss: 0.9700 - val_accuracy: 0.5321\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9725 - accuracy: 0.5313 - val_loss: 0.9704 - val_accuracy: 0.5312\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9725 - accuracy: 0.5313 - val_loss: 0.9705 - val_accuracy: 0.5312\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9724 - accuracy: 0.5313 - val_loss: 0.9716 - val_accuracy: 0.5250\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9726 - accuracy: 0.5316 - val_loss: 0.9701 - val_accuracy: 0.5321\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9724 - accuracy: 0.5327 - val_loss: 0.9730 - val_accuracy: 0.5259\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9726 - accuracy: 0.5319 - val_loss: 0.9707 - val_accuracy: 0.5294\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9725 - accuracy: 0.5322 - val_loss: 0.9710 - val_accuracy: 0.5286\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9725 - accuracy: 0.5308 - val_loss: 0.9697 - val_accuracy: 0.5303\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9725 - accuracy: 0.5307 - val_loss: 0.9707 - val_accuracy: 0.5330\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9723 - accuracy: 0.5329 - val_loss: 0.9713 - val_accuracy: 0.5290\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9725 - accuracy: 0.5309 - val_loss: 0.9705 - val_accuracy: 0.5303\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9723 - accuracy: 0.5316 - val_loss: 0.9697 - val_accuracy: 0.5317\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9724 - accuracy: 0.5314 - val_loss: 0.9705 - val_accuracy: 0.5286\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9724 - accuracy: 0.5326 - val_loss: 0.9705 - val_accuracy: 0.5286\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9725 - accuracy: 0.5312 - val_loss: 0.9712 - val_accuracy: 0.5286\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9723 - accuracy: 0.5317 - val_loss: 0.9697 - val_accuracy: 0.5321\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9725 - accuracy: 0.5331 - val_loss: 0.9721 - val_accuracy: 0.5250\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9724 - accuracy: 0.5326 - val_loss: 0.9707 - val_accuracy: 0.5290\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9724 - accuracy: 0.5330 - val_loss: 0.9703 - val_accuracy: 0.5303\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9724 - accuracy: 0.5315 - val_loss: 0.9696 - val_accuracy: 0.5294\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9702 - val_accuracy: 0.5330\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9724 - accuracy: 0.5304 - val_loss: 0.9705 - val_accuracy: 0.5294\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9724 - accuracy: 0.5313 - val_loss: 0.9715 - val_accuracy: 0.5232\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9722 - accuracy: 0.5320 - val_loss: 0.9696 - val_accuracy: 0.5308\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9724 - accuracy: 0.5317 - val_loss: 0.9703 - val_accuracy: 0.5325\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9724 - accuracy: 0.5321 - val_loss: 0.9702 - val_accuracy: 0.5312\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9724 - accuracy: 0.5299 - val_loss: 0.9709 - val_accuracy: 0.5294\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9722 - accuracy: 0.5325 - val_loss: 0.9711 - val_accuracy: 0.5277\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9722 - accuracy: 0.5314 - val_loss: 0.9700 - val_accuracy: 0.5308\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9723 - accuracy: 0.5321 - val_loss: 0.9717 - val_accuracy: 0.5294\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9723 - accuracy: 0.5317 - val_loss: 0.9702 - val_accuracy: 0.5286\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9723 - accuracy: 0.5321 - val_loss: 0.9706 - val_accuracy: 0.5294\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9724 - accuracy: 0.5313 - val_loss: 0.9707 - val_accuracy: 0.5321\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9721 - accuracy: 0.5328 - val_loss: 0.9723 - val_accuracy: 0.5250\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9722 - accuracy: 0.5306 - val_loss: 0.9711 - val_accuracy: 0.5277\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9722 - accuracy: 0.5301 - val_loss: 0.9697 - val_accuracy: 0.5299\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9723 - accuracy: 0.5319 - val_loss: 0.9703 - val_accuracy: 0.5303\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9721 - accuracy: 0.5321 - val_loss: 0.9706 - val_accuracy: 0.5308\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9724 - accuracy: 0.5319 - val_loss: 0.9701 - val_accuracy: 0.5317\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9724 - accuracy: 0.5314 - val_loss: 0.9699 - val_accuracy: 0.5321\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9723 - accuracy: 0.5321 - val_loss: 0.9715 - val_accuracy: 0.5277\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 497us/step - loss: 0.9722 - accuracy: 0.5319 - val_loss: 0.9700 - val_accuracy: 0.5334\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9723 - accuracy: 0.5312 - val_loss: 0.9702 - val_accuracy: 0.5321\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9724 - accuracy: 0.5308 - val_loss: 0.9713 - val_accuracy: 0.5294\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9723 - accuracy: 0.5311 - val_loss: 0.9698 - val_accuracy: 0.5272\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9723 - accuracy: 0.5324 - val_loss: 0.9700 - val_accuracy: 0.5312\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9721 - accuracy: 0.5330 - val_loss: 0.9701 - val_accuracy: 0.5317\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9723 - accuracy: 0.5322 - val_loss: 0.9699 - val_accuracy: 0.5312\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 0.9697 - val_accuracy: 0.5321\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9721 - accuracy: 0.5314 - val_loss: 0.9697 - val_accuracy: 0.5321\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9723 - accuracy: 0.5315 - val_loss: 0.9704 - val_accuracy: 0.5330\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9724 - accuracy: 0.5319 - val_loss: 0.9694 - val_accuracy: 0.5290\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9692 - val_accuracy: 0.5317\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9723 - accuracy: 0.5320 - val_loss: 0.9710 - val_accuracy: 0.5294\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9721 - accuracy: 0.5313 - val_loss: 0.9710 - val_accuracy: 0.5294\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5324 - val_loss: 0.9704 - val_accuracy: 0.5294\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9721 - accuracy: 0.5321 - val_loss: 0.9693 - val_accuracy: 0.5294\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9722 - accuracy: 0.5321 - val_loss: 0.9697 - val_accuracy: 0.5308\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9721 - accuracy: 0.5311 - val_loss: 0.9701 - val_accuracy: 0.5334\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9723 - accuracy: 0.5325 - val_loss: 0.9694 - val_accuracy: 0.5321\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9722 - accuracy: 0.5308 - val_loss: 0.9703 - val_accuracy: 0.5312\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9720 - accuracy: 0.5321 - val_loss: 0.9696 - val_accuracy: 0.5312\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9721 - accuracy: 0.5308 - val_loss: 0.9696 - val_accuracy: 0.5303\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9723 - accuracy: 0.5320 - val_loss: 0.9701 - val_accuracy: 0.5330\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9719 - accuracy: 0.5322 - val_loss: 0.9706 - val_accuracy: 0.5228\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9723 - accuracy: 0.5305 - val_loss: 0.9704 - val_accuracy: 0.5286\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9722 - accuracy: 0.5313 - val_loss: 0.9701 - val_accuracy: 0.5325\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9721 - accuracy: 0.5305 - val_loss: 0.9705 - val_accuracy: 0.5312\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9722 - accuracy: 0.5319 - val_loss: 0.9707 - val_accuracy: 0.5294\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9720 - accuracy: 0.5315 - val_loss: 0.9696 - val_accuracy: 0.5312\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9721 - accuracy: 0.5310 - val_loss: 0.9705 - val_accuracy: 0.5286\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9721 - accuracy: 0.5316 - val_loss: 0.9701 - val_accuracy: 0.5312\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9722 - accuracy: 0.5318 - val_loss: 0.9698 - val_accuracy: 0.5308\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9722 - accuracy: 0.5328 - val_loss: 0.9696 - val_accuracy: 0.5312\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 0.9693 - val_accuracy: 0.5299\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9722 - accuracy: 0.5327 - val_loss: 0.9723 - val_accuracy: 0.5250\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9722 - accuracy: 0.5322 - val_loss: 0.9706 - val_accuracy: 0.5312\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9721 - accuracy: 0.5317 - val_loss: 0.9695 - val_accuracy: 0.5317\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9720 - accuracy: 0.5322 - val_loss: 0.9699 - val_accuracy: 0.5286\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 0.9696 - val_accuracy: 0.5308\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5315 - val_loss: 0.9732 - val_accuracy: 0.5259\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9723 - accuracy: 0.5309 - val_loss: 0.9699 - val_accuracy: 0.5321\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9720 - accuracy: 0.5331 - val_loss: 0.9713 - val_accuracy: 0.5277\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9722 - accuracy: 0.5323 - val_loss: 0.9699 - val_accuracy: 0.5308\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9719 - accuracy: 0.5320 - val_loss: 0.9697 - val_accuracy: 0.5294\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9721 - accuracy: 0.5322 - val_loss: 0.9706 - val_accuracy: 0.5321\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 548us/step - loss: 0.9721 - accuracy: 0.5322 - val_loss: 0.9699 - val_accuracy: 0.5317\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9720 - accuracy: 0.5318 - val_loss: 0.9710 - val_accuracy: 0.5294\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5313 - val_loss: 0.9695 - val_accuracy: 0.5312\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9722 - accuracy: 0.5316 - val_loss: 0.9704 - val_accuracy: 0.5334\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9721 - accuracy: 0.5321 - val_loss: 0.9704 - val_accuracy: 0.5286\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9720 - accuracy: 0.5326 - val_loss: 0.9695 - val_accuracy: 0.5321\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9721 - accuracy: 0.5317 - val_loss: 0.9701 - val_accuracy: 0.5312\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9722 - accuracy: 0.5324 - val_loss: 0.9713 - val_accuracy: 0.5294\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9722 - accuracy: 0.5321 - val_loss: 0.9700 - val_accuracy: 0.5312\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9702 - val_accuracy: 0.5308\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9721 - accuracy: 0.5314 - val_loss: 0.9701 - val_accuracy: 0.5317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9721 - accuracy: 0.5310 - val_loss: 0.9706 - val_accuracy: 0.5312\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 0.9714 - val_accuracy: 0.5290\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9721 - accuracy: 0.5324 - val_loss: 0.9692 - val_accuracy: 0.5317\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9722 - accuracy: 0.5317 - val_loss: 0.9708 - val_accuracy: 0.5294\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5320 - val_loss: 0.9696 - val_accuracy: 0.5321\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5324 - val_loss: 0.9717 - val_accuracy: 0.5294\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9720 - accuracy: 0.5312 - val_loss: 0.9695 - val_accuracy: 0.5308\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9721 - accuracy: 0.5313 - val_loss: 0.9695 - val_accuracy: 0.5325\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9720 - accuracy: 0.5309 - val_loss: 0.9718 - val_accuracy: 0.5294\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9720 - accuracy: 0.5316 - val_loss: 0.9697 - val_accuracy: 0.5330\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9720 - accuracy: 0.5318 - val_loss: 0.9702 - val_accuracy: 0.5286\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5324 - val_loss: 0.9706 - val_accuracy: 0.5294\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9720 - accuracy: 0.5321 - val_loss: 0.9698 - val_accuracy: 0.5321\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9722 - accuracy: 0.5320 - val_loss: 0.9698 - val_accuracy: 0.5312\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5314 - val_loss: 0.9713 - val_accuracy: 0.5286\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9721 - accuracy: 0.5314 - val_loss: 0.9694 - val_accuracy: 0.5308\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9720 - accuracy: 0.5315 - val_loss: 0.9703 - val_accuracy: 0.5303\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9720 - accuracy: 0.5324 - val_loss: 0.9703 - val_accuracy: 0.5312\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9719 - accuracy: 0.5322 - val_loss: 0.9711 - val_accuracy: 0.5294\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9719 - accuracy: 0.5322 - val_loss: 0.9737 - val_accuracy: 0.5259\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9722 - accuracy: 0.5319 - val_loss: 0.9707 - val_accuracy: 0.5308\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9700 - val_accuracy: 0.5312\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9720 - accuracy: 0.5313 - val_loss: 0.9706 - val_accuracy: 0.5294\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9718 - accuracy: 0.5321 - val_loss: 0.9699 - val_accuracy: 0.5308\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5314 - val_loss: 0.9694 - val_accuracy: 0.5321\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9720 - accuracy: 0.5320 - val_loss: 0.9698 - val_accuracy: 0.5317\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 345us/step - loss: 0.9718 - accuracy: 0.5323\n",
      "Accuracy : 0.5322874188423157\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9698 - accuracy: 0.5317\n",
      "Accuracy : 0.5316511988639832\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 654us/step - loss: 1.1181 - accuracy: 0.3669 - val_loss: 1.0475 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 1.0357 - accuracy: 0.4735 - val_loss: 1.0204 - val_accuracy: 0.5193\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 1.0081 - accuracy: 0.5247 - val_loss: 0.9909 - val_accuracy: 0.5343\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9903 - accuracy: 0.5304 - val_loss: 0.9775 - val_accuracy: 0.5339\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9849 - accuracy: 0.5293 - val_loss: 0.9735 - val_accuracy: 0.5330\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9829 - accuracy: 0.5300 - val_loss: 0.9682 - val_accuracy: 0.5321\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9813 - accuracy: 0.5297 - val_loss: 0.9659 - val_accuracy: 0.5321\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9802 - accuracy: 0.5307 - val_loss: 0.9637 - val_accuracy: 0.5325\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9795 - accuracy: 0.5297 - val_loss: 0.9625 - val_accuracy: 0.5334\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9788 - accuracy: 0.5314 - val_loss: 0.9607 - val_accuracy: 0.5334\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 549us/step - loss: 0.9781 - accuracy: 0.5315 - val_loss: 0.9612 - val_accuracy: 0.5356\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9776 - accuracy: 0.5319 - val_loss: 0.9583 - val_accuracy: 0.5352\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9771 - accuracy: 0.5317 - val_loss: 0.9580 - val_accuracy: 0.5343\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9769 - accuracy: 0.5304 - val_loss: 0.9565 - val_accuracy: 0.5330\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9766 - accuracy: 0.5302 - val_loss: 0.9567 - val_accuracy: 0.5356\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9765 - accuracy: 0.5312 - val_loss: 0.9547 - val_accuracy: 0.5330\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9763 - accuracy: 0.5320 - val_loss: 0.9553 - val_accuracy: 0.5374\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9759 - accuracy: 0.5310 - val_loss: 0.9536 - val_accuracy: 0.5339\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9761 - accuracy: 0.5316 - val_loss: 0.9536 - val_accuracy: 0.5352\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9761 - accuracy: 0.5326 - val_loss: 0.9541 - val_accuracy: 0.5356\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9758 - accuracy: 0.5312 - val_loss: 0.9529 - val_accuracy: 0.5334\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9757 - accuracy: 0.5315 - val_loss: 0.9547 - val_accuracy: 0.5374\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9755 - accuracy: 0.5309 - val_loss: 0.9539 - val_accuracy: 0.5374\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9757 - accuracy: 0.5305 - val_loss: 0.9520 - val_accuracy: 0.5334\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9756 - accuracy: 0.5310 - val_loss: 0.9525 - val_accuracy: 0.5356\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9755 - accuracy: 0.5318 - val_loss: 0.9523 - val_accuracy: 0.5356\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9755 - accuracy: 0.5312 - val_loss: 0.9522 - val_accuracy: 0.5347\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9754 - accuracy: 0.5315 - val_loss: 0.9519 - val_accuracy: 0.5339\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 498us/step - loss: 0.9754 - accuracy: 0.5306 - val_loss: 0.9519 - val_accuracy: 0.5356\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9756 - accuracy: 0.5324 - val_loss: 0.9527 - val_accuracy: 0.5392\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9752 - accuracy: 0.5313 - val_loss: 0.9519 - val_accuracy: 0.5361\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9537 - val_accuracy: 0.5392\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9752 - accuracy: 0.5313 - val_loss: 0.9525 - val_accuracy: 0.5392\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9517 - val_accuracy: 0.5361\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9752 - accuracy: 0.5315 - val_loss: 0.9522 - val_accuracy: 0.5356\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9751 - accuracy: 0.5309 - val_loss: 0.9507 - val_accuracy: 0.5330\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9754 - accuracy: 0.5321 - val_loss: 0.9511 - val_accuracy: 0.5334\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5315 - val_loss: 0.9514 - val_accuracy: 0.5361\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9510 - val_accuracy: 0.5334\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9753 - accuracy: 0.5302 - val_loss: 0.9514 - val_accuracy: 0.5352\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9752 - accuracy: 0.5311 - val_loss: 0.9526 - val_accuracy: 0.5392\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9751 - accuracy: 0.5305 - val_loss: 0.9522 - val_accuracy: 0.5374\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9752 - accuracy: 0.5313 - val_loss: 0.9508 - val_accuracy: 0.5334\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9751 - accuracy: 0.5322 - val_loss: 0.9506 - val_accuracy: 0.5356\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9751 - accuracy: 0.5306 - val_loss: 0.9525 - val_accuracy: 0.5374\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9750 - accuracy: 0.5319 - val_loss: 0.9507 - val_accuracy: 0.5356\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9751 - accuracy: 0.5312 - val_loss: 0.9519 - val_accuracy: 0.5392\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9750 - accuracy: 0.5305 - val_loss: 0.9507 - val_accuracy: 0.5352\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9751 - accuracy: 0.5315 - val_loss: 0.9521 - val_accuracy: 0.5392\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9752 - accuracy: 0.5303 - val_loss: 0.9507 - val_accuracy: 0.5330\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9750 - accuracy: 0.5308 - val_loss: 0.9516 - val_accuracy: 0.5361\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9750 - accuracy: 0.5308 - val_loss: 0.9508 - val_accuracy: 0.5356\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9513 - val_accuracy: 0.5356\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9749 - accuracy: 0.5311 - val_loss: 0.9513 - val_accuracy: 0.5330\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 0.9507 - val_accuracy: 0.5356\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9751 - accuracy: 0.5306 - val_loss: 0.9513 - val_accuracy: 0.5374\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9751 - accuracy: 0.5294 - val_loss: 0.9511 - val_accuracy: 0.5361\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9750 - accuracy: 0.5315 - val_loss: 0.9527 - val_accuracy: 0.5365\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9750 - accuracy: 0.5316 - val_loss: 0.9513 - val_accuracy: 0.5374\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 578us/step - loss: 0.9748 - accuracy: 0.5314 - val_loss: 0.9502 - val_accuracy: 0.5330\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9749 - accuracy: 0.5315 - val_loss: 0.9524 - val_accuracy: 0.5361\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9752 - accuracy: 0.5309 - val_loss: 0.9506 - val_accuracy: 0.5356\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9749 - accuracy: 0.5311 - val_loss: 0.9519 - val_accuracy: 0.5361\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9748 - accuracy: 0.5312 - val_loss: 0.9503 - val_accuracy: 0.5330\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9751 - accuracy: 0.5309 - val_loss: 0.9509 - val_accuracy: 0.5356\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9749 - accuracy: 0.5316 - val_loss: 0.9505 - val_accuracy: 0.5343\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9748 - accuracy: 0.5311 - val_loss: 0.9521 - val_accuracy: 0.5392\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9750 - accuracy: 0.5315 - val_loss: 0.9511 - val_accuracy: 0.5356\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 0.9508 - val_accuracy: 0.5356\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9748 - accuracy: 0.5320 - val_loss: 0.9503 - val_accuracy: 0.5343\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9748 - accuracy: 0.5307 - val_loss: 0.9510 - val_accuracy: 0.5330\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9750 - accuracy: 0.5302 - val_loss: 0.9507 - val_accuracy: 0.5347\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9750 - accuracy: 0.5315 - val_loss: 0.9503 - val_accuracy: 0.5330\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9750 - accuracy: 0.5314 - val_loss: 0.9506 - val_accuracy: 0.5330\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9749 - accuracy: 0.5314 - val_loss: 0.9504 - val_accuracy: 0.5361\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9748 - accuracy: 0.5313 - val_loss: 0.9508 - val_accuracy: 0.5374\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9748 - accuracy: 0.5318 - val_loss: 0.9503 - val_accuracy: 0.5330\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9748 - accuracy: 0.5309 - val_loss: 0.9505 - val_accuracy: 0.5356\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9509 - val_accuracy: 0.5356\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9749 - accuracy: 0.5319 - val_loss: 0.9521 - val_accuracy: 0.5392\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9749 - accuracy: 0.5313 - val_loss: 0.9507 - val_accuracy: 0.5374\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9746 - accuracy: 0.5312 - val_loss: 0.9502 - val_accuracy: 0.5361\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9749 - accuracy: 0.5312 - val_loss: 0.9513 - val_accuracy: 0.5361\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9746 - accuracy: 0.5315 - val_loss: 0.9503 - val_accuracy: 0.5334\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 514us/step - loss: 0.9748 - accuracy: 0.5304 - val_loss: 0.9510 - val_accuracy: 0.5347\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9748 - accuracy: 0.5311 - val_loss: 0.9508 - val_accuracy: 0.5356\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9747 - accuracy: 0.5313 - val_loss: 0.9522 - val_accuracy: 0.5383\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9748 - accuracy: 0.5315 - val_loss: 0.9503 - val_accuracy: 0.5361\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9747 - accuracy: 0.5313 - val_loss: 0.9511 - val_accuracy: 0.5370\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9514 - val_accuracy: 0.5356\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9748 - accuracy: 0.5307 - val_loss: 0.9504 - val_accuracy: 0.5343\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9747 - accuracy: 0.5319 - val_loss: 0.9507 - val_accuracy: 0.5374\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9748 - accuracy: 0.5304 - val_loss: 0.9502 - val_accuracy: 0.5330\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9746 - accuracy: 0.5324 - val_loss: 0.9506 - val_accuracy: 0.5370\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9748 - accuracy: 0.5314 - val_loss: 0.9505 - val_accuracy: 0.5343\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9748 - accuracy: 0.5311 - val_loss: 0.9504 - val_accuracy: 0.5356\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9748 - accuracy: 0.5299 - val_loss: 0.9515 - val_accuracy: 0.5365\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9745 - accuracy: 0.5323 - val_loss: 0.9499 - val_accuracy: 0.5330\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9749 - accuracy: 0.5319 - val_loss: 0.9509 - val_accuracy: 0.5352\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9747 - accuracy: 0.5313 - val_loss: 0.9506 - val_accuracy: 0.5356\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9747 - accuracy: 0.5312 - val_loss: 0.9506 - val_accuracy: 0.5361\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9747 - accuracy: 0.5323 - val_loss: 0.9502 - val_accuracy: 0.5330\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9747 - accuracy: 0.5314 - val_loss: 0.9515 - val_accuracy: 0.5370\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9746 - accuracy: 0.5315 - val_loss: 0.9518 - val_accuracy: 0.5383\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9746 - accuracy: 0.5319 - val_loss: 0.9506 - val_accuracy: 0.5343\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9746 - accuracy: 0.5315 - val_loss: 0.9502 - val_accuracy: 0.5343\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9747 - accuracy: 0.5304 - val_loss: 0.9507 - val_accuracy: 0.5339\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 559us/step - loss: 0.9748 - accuracy: 0.5312 - val_loss: 0.9501 - val_accuracy: 0.5356\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9749 - accuracy: 0.5315 - val_loss: 0.9501 - val_accuracy: 0.5343\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9745 - accuracy: 0.5298 - val_loss: 0.9512 - val_accuracy: 0.5352\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9747 - accuracy: 0.5313 - val_loss: 0.9508 - val_accuracy: 0.5352\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9747 - accuracy: 0.5312 - val_loss: 0.9500 - val_accuracy: 0.5334\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9747 - accuracy: 0.5311 - val_loss: 0.9509 - val_accuracy: 0.5356\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9748 - accuracy: 0.5314 - val_loss: 0.9504 - val_accuracy: 0.5356\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9747 - accuracy: 0.5310 - val_loss: 0.9502 - val_accuracy: 0.5356\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9747 - accuracy: 0.5314 - val_loss: 0.9503 - val_accuracy: 0.5330\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9747 - accuracy: 0.5309 - val_loss: 0.9500 - val_accuracy: 0.5356\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9746 - accuracy: 0.5307 - val_loss: 0.9508 - val_accuracy: 0.5370\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9747 - accuracy: 0.5304 - val_loss: 0.9511 - val_accuracy: 0.5356\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9748 - accuracy: 0.5316 - val_loss: 0.9516 - val_accuracy: 0.5370\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9746 - accuracy: 0.5316 - val_loss: 0.9512 - val_accuracy: 0.5361\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9748 - accuracy: 0.5313 - val_loss: 0.9509 - val_accuracy: 0.5365\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9746 - accuracy: 0.5312 - val_loss: 0.9502 - val_accuracy: 0.5334\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9746 - accuracy: 0.5311 - val_loss: 0.9501 - val_accuracy: 0.5343\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9746 - accuracy: 0.5316 - val_loss: 0.9504 - val_accuracy: 0.5356\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9747 - accuracy: 0.5322 - val_loss: 0.9517 - val_accuracy: 0.5370\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9743 - accuracy: 0.5306 - val_loss: 0.9524 - val_accuracy: 0.5392\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9748 - accuracy: 0.5314 - val_loss: 0.9505 - val_accuracy: 0.5356\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9747 - accuracy: 0.5304 - val_loss: 0.9505 - val_accuracy: 0.5334\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9748 - accuracy: 0.5316 - val_loss: 0.9509 - val_accuracy: 0.5347\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9746 - accuracy: 0.5307 - val_loss: 0.9511 - val_accuracy: 0.5370\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9745 - accuracy: 0.5308 - val_loss: 0.9504 - val_accuracy: 0.5356\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9745 - accuracy: 0.5314 - val_loss: 0.9520 - val_accuracy: 0.5387\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9745 - accuracy: 0.5317 - val_loss: 0.9501 - val_accuracy: 0.5356\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9745 - accuracy: 0.5310 - val_loss: 0.9503 - val_accuracy: 0.5347\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9747 - accuracy: 0.5311 - val_loss: 0.9522 - val_accuracy: 0.5374\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9746 - accuracy: 0.5308 - val_loss: 0.9505 - val_accuracy: 0.5370\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9747 - accuracy: 0.5316 - val_loss: 0.9502 - val_accuracy: 0.5347\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9745 - accuracy: 0.5318 - val_loss: 0.9524 - val_accuracy: 0.5361\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9747 - accuracy: 0.5320 - val_loss: 0.9507 - val_accuracy: 0.5370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9745 - accuracy: 0.5315 - val_loss: 0.9501 - val_accuracy: 0.5343\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9747 - accuracy: 0.5313 - val_loss: 0.9502 - val_accuracy: 0.5334\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9746 - accuracy: 0.5322 - val_loss: 0.9518 - val_accuracy: 0.5365\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9747 - accuracy: 0.5307 - val_loss: 0.9501 - val_accuracy: 0.5334\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9746 - accuracy: 0.5322 - val_loss: 0.9505 - val_accuracy: 0.5370\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9746 - accuracy: 0.5320 - val_loss: 0.9510 - val_accuracy: 0.5370\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9746 - accuracy: 0.5312 - val_loss: 0.9506 - val_accuracy: 0.5347\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9745 - accuracy: 0.5316 - val_loss: 0.9521 - val_accuracy: 0.5370\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9745 - accuracy: 0.5311 - val_loss: 0.9500 - val_accuracy: 0.5330\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9747 - accuracy: 0.5314 - val_loss: 0.9510 - val_accuracy: 0.5370\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9746 - accuracy: 0.5324 - val_loss: 0.9510 - val_accuracy: 0.5330\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9746 - accuracy: 0.5320 - val_loss: 0.9521 - val_accuracy: 0.5365\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9745 - accuracy: 0.5308 - val_loss: 0.9502 - val_accuracy: 0.5339\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9744 - accuracy: 0.5310 - val_loss: 0.9518 - val_accuracy: 0.5387\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9745 - accuracy: 0.5313 - val_loss: 0.9501 - val_accuracy: 0.5352\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9746 - accuracy: 0.5325 - val_loss: 0.9522 - val_accuracy: 0.5383\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 576us/step - loss: 0.9746 - accuracy: 0.5316 - val_loss: 0.9506 - val_accuracy: 0.5356\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9745 - accuracy: 0.5320 - val_loss: 0.9511 - val_accuracy: 0.5352\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9743 - accuracy: 0.5311 - val_loss: 0.9509 - val_accuracy: 0.5330\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9746 - accuracy: 0.5311 - val_loss: 0.9499 - val_accuracy: 0.5339\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9746 - accuracy: 0.5317 - val_loss: 0.9505 - val_accuracy: 0.5339\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9744 - accuracy: 0.5315 - val_loss: 0.9504 - val_accuracy: 0.5330\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9747 - accuracy: 0.5318 - val_loss: 0.9507 - val_accuracy: 0.5374\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9743 - accuracy: 0.5312 - val_loss: 0.9504 - val_accuracy: 0.5330\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9747 - accuracy: 0.5312 - val_loss: 0.9504 - val_accuracy: 0.5352\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9743 - accuracy: 0.5311 - val_loss: 0.9515 - val_accuracy: 0.5383\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9745 - accuracy: 0.5319 - val_loss: 0.9502 - val_accuracy: 0.5343\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9746 - accuracy: 0.5319 - val_loss: 0.9505 - val_accuracy: 0.5339\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9746 - accuracy: 0.5321 - val_loss: 0.9503 - val_accuracy: 0.5356\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9744 - accuracy: 0.5302 - val_loss: 0.9504 - val_accuracy: 0.5330\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9743 - accuracy: 0.5321 - val_loss: 0.9503 - val_accuracy: 0.5334\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9744 - accuracy: 0.5329 - val_loss: 0.9522 - val_accuracy: 0.5365\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9745 - accuracy: 0.5315 - val_loss: 0.9502 - val_accuracy: 0.5339\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9745 - accuracy: 0.5321 - val_loss: 0.9501 - val_accuracy: 0.5347\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9745 - accuracy: 0.5308 - val_loss: 0.9507 - val_accuracy: 0.5374\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9744 - accuracy: 0.5319 - val_loss: 0.9500 - val_accuracy: 0.5339\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9746 - accuracy: 0.5310 - val_loss: 0.9513 - val_accuracy: 0.5352\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9743 - accuracy: 0.5319 - val_loss: 0.9527 - val_accuracy: 0.5356\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9746 - accuracy: 0.5312 - val_loss: 0.9510 - val_accuracy: 0.5374\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9745 - accuracy: 0.5308 - val_loss: 0.9521 - val_accuracy: 0.5387\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9744 - accuracy: 0.5318 - val_loss: 0.9499 - val_accuracy: 0.5339\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9745 - accuracy: 0.5310 - val_loss: 0.9526 - val_accuracy: 0.5383\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9746 - accuracy: 0.5308 - val_loss: 0.9501 - val_accuracy: 0.5343\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9743 - accuracy: 0.5316 - val_loss: 0.9509 - val_accuracy: 0.5347\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9745 - accuracy: 0.5310 - val_loss: 0.9516 - val_accuracy: 0.5365\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9743 - accuracy: 0.5315 - val_loss: 0.9504 - val_accuracy: 0.5330\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9743 - accuracy: 0.5310 - val_loss: 0.9500 - val_accuracy: 0.5334\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9743 - accuracy: 0.5307 - val_loss: 0.9499 - val_accuracy: 0.5334\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9743 - accuracy: 0.5316 - val_loss: 0.9533 - val_accuracy: 0.5365\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9743 - accuracy: 0.5327 - val_loss: 0.9500 - val_accuracy: 0.5330\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 0.9505 - val_accuracy: 0.5334\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9743 - accuracy: 0.5315 - val_loss: 0.9504 - val_accuracy: 0.5330\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9745 - accuracy: 0.5317 - val_loss: 0.9508 - val_accuracy: 0.5339\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9743 - accuracy: 0.5319 - val_loss: 0.9509 - val_accuracy: 0.5352\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9744 - accuracy: 0.5308 - val_loss: 0.9504 - val_accuracy: 0.5330\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9745 - accuracy: 0.5318 - val_loss: 0.9501 - val_accuracy: 0.5339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9743 - accuracy: 0.5314 - val_loss: 0.9502 - val_accuracy: 0.5334\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9746 - accuracy: 0.5314 - val_loss: 0.9499 - val_accuracy: 0.5339\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9744 - accuracy: 0.5326 - val_loss: 0.9499 - val_accuracy: 0.5334\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9744 - accuracy: 0.5306 - val_loss: 0.9516 - val_accuracy: 0.5383\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 353us/step - loss: 0.9746 - accuracy: 0.5298\n",
      "Accuracy : 0.5298283696174622\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9516 - accuracy: 0.5383\n",
      "Accuracy : 0.5382912755012512\n",
      "\n",
      "The final train accuracy is:0.5319631278514863 \n",
      "\n",
      "The final test accuracy is:0.5327993273735047 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"B365.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data = np.array(df.iloc[:,0:3])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "    \n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "    \n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (3,1)),\n",
    "        keras.layers.Dense(5,activation='sigmoid'),\n",
    "        keras.layers.Dense(5,activation='sigmoid'),\n",
    "        keras.layers.Dense(3,activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "happy-object",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decreased-seeker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eight-shower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxKUlEQVR4nO3dd3wVVfrH8c83hd47BFxRsCGIZRE7NsQKrg3bspYfFnStay9rQV11WXUVV6ysBYxtqYsgNkSXImIBRBAQAhEEgYAgkOT5/TGD3EByc0NuuJnwvH3NK/eemTnn3CE+9+TMOWdkZjjnnIuOtFRXwDnnXNl44HbOuYjxwO2ccxHjgds55yLGA7dzzkWMB27nnIsYD9yu3CTVlDRC0mpJb5Qjn/MljU1m3VJB0n8l9Ul1PVzV5YF7JyLpPElTJa2VlBsGmMOTkPWZQHOgsZmdtb2ZmNmrZtY9CfUpQlI3SSbp7a3S9wvTP0wwn79KeqW048zsRDMbvJ3Vda5UHrh3EpKuBx4DHiAIsrsAA4GeScj+d8B3ZpafhLwqyk/AoZIax6T1Ab5LVgEK+P9TrsL5L9lOQFJ94F6gn5m9bWa/mNkmMxthZn8Jj6ku6TFJS8LtMUnVw33dJOVIukHSsrC1flG47x7gLuCcsCV/ydYtU0m7hi3bjPD9nyTNk7RG0nxJ58ekfxJz3qGSpoRdMFMkHRqz70NJ90maGOYzVlKTOJdhI/AfoHd4fjpwNvDqVtfqcUmLJOVJ+lzSEWF6D+C2mM/5ZUw9+kuaCKwDdgvTLg33Py3pzZj8/yZpvCQl+u/n3NY8cO8cDgFqAO/EOeZ2oCvQGdgP6ALcEbO/BVAfyAIuAZ6S1NDM7iZoxb9uZnXM7Pl4FZFUG3gCONHM6gKHAtOLOa4RMCo8tjEwABi1VYv5POAioBlQDbgxXtnAv4E/hq9PAGYAS7Y6ZgrBNWgEvAa8IamGmY3Z6nPuF3POhUBfoC7ww1b53QB0Cr+UjiC4dn3M15pw5eCBe+fQGFheSlfG+cC9ZrbMzH4C7iEISJttCvdvMrPRwFpgz+2sTyGwr6SaZpZrZjOKOeZkYI6ZvWxm+WY2BPgWODXmmBfN7DszWw9kEwTcEpnZp0AjSXsSBPB/F3PMK2a2Iizz70B1Sv+cL5nZjPCcTVvltw64gOCL5xXgajPLKSU/5+LywL1zWAE02dxVUYJWFG0t/hCm/ZbHVoF/HVCnrBUxs1+Ac4DLgVxJoyTtlUB9NtcpK+b9j9tRn5eBq4CjKeYvkLA7aFbYPbOK4K+MeF0wAIvi7TSzycA8QARfMM6ViwfuncNnwK9ArzjHLCG4ybjZLmzbjZCoX4BaMe9bxO40s3fN7HigJUEr+tkE6rO5Tou3s06bvQxcCYwOW8O/Cbsybibo+25oZg2A1QQBF6Ck7o243R6S+hG03JcAN213zZ0LeeDeCZjZaoIbiE9J6iWplqRMSSdKejg8bAhwh6Sm4U2+uwj+tN8e04EjJe0S3hi9dfMOSc0lnRb2dW8g6HIpKCaP0cAe4RDGDEnnAPsAI7ezTgCY2XzgKII+/a3VBfIJRqBkSLoLqBezfymwa1lGjkjaA7ifoLvkQuAmSZ23r/bOBTxw7yTMbABwPcENx58I/ry/imCkBQTBZSrwFfA1MC1M256yxgGvh3l9TtFgm0Zww24J8DNBEL2ymDxWAKeEx64gaKmeYmbLt6dOW+X9iZkV99fEu8B/CYYI/kDwV0psN8jmyUUrJE0rrZywa+oV4G9m9qWZzSEYmfLy5hE7zm0P+c1t55yLFm9xO+dcxHjgds65iPHA7ZxzEeOB2znnIibehIyUyqiW5XdNK9jIhkekugpV3oBqq1JdhZ3C2EVjyr32y6bl8xKOOZlNdkvpWjPe4nbOuYiptC1u55zboQqLmwdWOXngds45gILKvJx8UR64nXMOMCtMdRUS5oHbOecACj1wO+dctHiL2znnIsZvTjrnXMR4i9s556LFfFSJc85FjN+cdM65iPGuEuecixi/OemccxHjLW7nnIsYvznpnHMR4zcnnXMuWsy8j9s556LF+7idcy5ivKvEOecixlvczjkXMQWbUl2DhPkzJ51zDoKukkS3Uki6TtIMSd9IGiKphqRGksZJmhP+bBhz/K2S5kqaLemE0vL3wO2ccxB0lSS6xSEpC/gzcJCZ7QukA72BW4DxZtYeGB++R9I+4f4OQA9goKT0eGV44HbOOUhqi5ugG7qmpAygFrAE6AkMDvcPBnqFr3sCQ81sg5nNB+YCXeJl7oHbOeegTIFbUl9JU2O2vpuzMbPFwKPAQiAXWG1mY4HmZpYbHpMLNAtPyQIWxdQkJ0wrkd+cdM45wMpwc9LMBgGDitsX9l33BNoCq4A3JF0QJzsVV0S88j1wO+ccJHM44HHAfDP7CUDS28ChwFJJLc0sV1JLYFl4fA7QJub81gRdKyXyrhLnnINk9nEvBLpKqiVJwLHALGA40Cc8pg8wLHw9HOgtqbqktkB7YHK8ArzF7ZxzkLQWt5lNkvQmMA3IB74g6FapA2RLuoQguJ8VHj9DUjYwMzy+n5WycIoHbuecg6ROeTezu4G7t0reQND6Lu74/kD/RPP3wO2cc+BT3p1zLnLy/UEKO5UTundjwIB7SU9L44UXh/DwI0+lukqVS5o4dOwD/PrjSqZd8HCRXbXbtaLj45dTr2NbvnvwdRY8PbLcxalaBp2e7Ee9Tm3ZtHItX/Z9nPWLfqJuh9/R4eFLSK9TEwoL+f6x//DjsM/KXV6qXf/odXQ99mBWrVhF3+MuL/aYTl07ccVfLyM9I4O8lau58aybylVmZrVM/vLYjbTv2J41K/Pof+WDLM1Zym777MafH7iaWnVqUVhYyJB/DuGjER+Xq6wdJkItbh9VUk5paWk88Xh/Tjn1AjrudzTnnNOLvfdun+pqVSq7/t+JrJ1T/OimTavWMvP2l5i/HQG7ZpumdHn7rm3SW593NJtWrWVC12tZ8Mwo9rjzPAAK1m/kq6sGMvGovzC190Psdd8fyahXq8zlVjbj3hjHbRfeUeL+2vVqc3X/ftx18V/pe9xl3H95wl2pNG/dnEeyH94mvUfvE1i7ai0XHXExbz/3DpfcdjEAG9Zv4OFrH6HvcZdx24W3c/ndl1O7Xu0yf6aUSO7MyQrlgbucuvx+f77/fgHz5y9k06ZNZGcP47RTS10jZqdRvWUjmh5/ADmvvl/s/o3L88ibPg/btO1N9JZnHE7XMfdz6PiH6PDIpZBW3DyFbTXvcRBLsoNW3tIRk2h8eAcA1s3LZd38HwHYsHQlG5fnUa1xve35WJXK15O+Yc2qNSXuP6bX0Uwc8yk/LfkJgFUrVv+279jTj+GJEY/z9JinuObBP5OWllhIOKT7IYx78z0APh41gf0P6wzA4vmLWbIg+JL+eenPrFqxivqN6m/Px9rxkrRWyY5QYYFb0l6Sbpb0hKTHw9d7V1R5qdIqqwWLcra0JnMW59KqVYsU1qhy2fu+Psy+91UojDsRbBu127eiZa9DmHTK3Xx67C1YQSGtzjg8oXOrt2zE+sUrALCCQvLXrCezUd0ix9Tff3fSMjNYt2BpmeoVRVlts6hTvw6PZD/MU6P+yXFnBAMb2rRrw1GnHsl1p1/PFT36UVhYwDGnH51Qnk1aNP7ti6CwoJBf1vxCvYZFvwT37LwHmZkZ5P6Qm9wPVFEi1OKukD5uSTcD5wJD2TKQvDUwRNJQM3uoIspNhWB8fVFmZQtSVVXT4w9g4/LV5H01n0aH7lOmcxsf0ZF6ndpyyLvBn/XpNaqxcXkeAPu/eD01d2lGWmYGNVo34dDxwa/TD8/+l8VDPyo+w5h/k+rNGtDpyX589eeBRdKrqvSMdNp3bMfNvW+hWo3qPD7sH8ya9i37H9aZ9p3a8+TIJwCoVqM6q5YHrfG7n72TFm1akJGZQbOsZjw9Jrhv884L/2Fs9jiKm6Ud+3vfqFkjbnrsJh657tHo/P9QCVrSiaqom5OXAB3MrMjkf0kDgBlAsYE7XKilL4DS65OWVvn7xhbn5NKmdavf3rfOaklubtVvxSWiYZc9aHbCgTQ9dn/SamSSUacmnZ7qx1f9Erh5K1iS/THf9R+6za4vLhoABH3cHR+/gsl/uLfI/g25P1MzqzEbcn9G6Wlk1K3JppVrAUivU5MDXr2Z7x56ndWfzy3/h4yA5bnLyfs5j1/Xb+DX9Rv4etI37LbPbkhi3Bvv8cLfXtzmnHv+7z4g6OO+ccAN/OXsojczl/+4nKatmrL8x+WkpadRu27t37pratWpxX0v3ctLjwzm2y++rfgPmCwRGlVSUV0lhUCrYtJbhvuKZWaDzOwgMzsoCkEbYMrU6bRr15Zdd21DZmYmZ5/dkxEjx6a6WpXCd/2H8uH+/fjo91fz5WVPsGLijMSCNrBiwjc0P+VgqjUJ/vzObFCbGq2bJHTusnc/p9XZRwLQ/NSDWfHJDACUmc4BL93Akjc+ZumISdvxiaLp07GfsW+XDqSlp1G9RnX22n9PFs1dyBcTp3PEyYfToHHQB123QR2aZTUrJbfAZ+P+x/FnHgfAkScfwfSJXwKQkZnB3c/eyXtvvceEURMq5gNVFLPEtxSrqBb3tcB4SXPYslzhLkA74KoKKjMlCgoKuObaOxg96jXS09J4afDrzJz5XaqrVam1+WPwP/yif79Htab1OXTsA2TUrYkVGrv2PZEJR9zIL98tZs5D2Rz0+m0oTRRuKmDmrS/wa87yUvPPee0DOj3ZjyP+9xibVq3ly8uCroAWpx1Cw657kdmwDlnnHAXA139+mjUzfqi4D7sD3PrkLXTq2on6jerx6uSXefnvr5CeGazDP+qV0Syau4ipH37OM2Ofxsz475AxLJgdfOaXHhnMg68+gNLSKNiUzz/veIpli5fFKw6AMUPHcPNjN/HihBdYs2oND/R7EICjTjmSjgd3pF7DenQ/63gAHrn+78ybOa+CPn0SVYK+60SpovqfJKURLAaeRdAhlgNMKW0O/mYZ1bJS/7VWxY1seESqq1DlDai2KtVV2CmMXTQmsSFHcax/9c6EY07N8+8rd3nlUWETcMysEPhfReXvnHNJ5TcnnXMuYgoS6gyoFDxwO+ccRKqP2wO3c85BpAK3T3l3zjlI2pR3SXtKmh6z5Um6VlIjSeMkzQl/Now551ZJcyXNllTqmhkeuJ1zDrBCS3iLm4/ZbDPrbGadgQOBdcA7wC3AeDNrD4wP3yNpH6A30AHoAQyUlB6vDA/czjkHFbVWybHA92b2A8GT3weH6YOBXuHrnsBQM9tgZvOBuQRDqUvkgds55yAYVZLgJqmvpKkxW98Scu0NDAlfNzezXIDw5+ZpqllsmagIwZyXrHhV9ZuTzjkHZWpJm9kgggcAl0hSNeA04NZSsituMk/c/hgP3M45BxUxquREYJqZbV51bqmklmaWK6klsHltgRygTcx5rYHinzwS8q4S55yDilhk6ly2dJMADAf6hK/7AMNi0ntLqi6pLdCeLcthF8tb3M45B0ltcUuqBRwPXBaT/BCQLekSYCFwFoCZzZCUDcwE8oF+pa3p5IHbOeegzE9pisfM1gGNt0pbQTDKpLjj+wMJPwzUA7dzzoGvVeKcc1FjEZry7oHbOecgqV0lFc0Dt3POga/H7ZxzkeMtbueci5h8vznpnHPR4l0lzjkXMd5V4pxz0eLDAZ1zLmq8xe2ccxHjgds55yLGp7w751y0lPYsycrEA7dzzoF3lTjnXOT4qBLnnIuYCLW4/dFlzjkHQeBOdCuFpAaS3pT0raRZkg6R1EjSOElzwp8NY46/VdJcSbMlnVBa/h64nXMOsILChLcEPA6MMbO9gP2AWcAtwHgzaw+MD98jaR+gN9AB6AEMlJQeL3PvKtmJHTvjgVRXocq7b79LU10Fl6gkdZVIqgccCfwJwMw2Ahsl9QS6hYcNBj4EbgZ6AkPNbAMwX9JcoAvwWUlleIvbOecIhgMmuknqK2lqzNY3JqvdgJ+AFyV9Iek5SbWB5maWCxD+bBYenwUsijk/J0wrkbe4nXMOytTiNrNBwKASdmcABwBXm9kkSY8TdouUQMUVEa98b3E75xxAYRm2+HKAHDObFL5/kyCQL5XUEiD8uSzm+DYx57cGlsQrwAO3c84Bll+Y8BY3H7MfgUWS9gyTjgVmAsOBPmFaH2BY+Ho40FtSdUltgfbA5HhleFeJc85BIi3psrgaeFVSNWAecBFBQzlb0iXAQuAsADObISmbILjnA/3MLO7CKR64nXOO5K5VYmbTgYOK2XVsCcf3B/onmr8Hbuecg2S3uCuUB27nnMNXB3TOuejxFrdzzkWL5ae6BokrdTigpGsk1VPgeUnTJHXfEZVzzrkdxQoT31ItkXHcF5tZHtAdaEowrOWhCq2Vc87taMmbgFPhEukq2Twd8yTgRTP7UlJxUzSdcy6yKkNLOlGJBO7PJY0F2gK3SqpLpfjOcc655KlqgfsSoDMwz8zWSWpM0F3inHNVhhVEpyOhxMAt6YCtknbzHhLnXFVVVVrcf4+zz4BjklwX55xLGSuMTsO0xMBtZkfvyIo451wqRanFncg47lqS7pA0KHzfXtIpFV8155zbccyU8JZqiYzjfhHYCBwavs8B7q+wGjnnXApEaQJOIqNKdjezcySdC2Bm630ct3OuqimM0KiSRFrcGyXVJHwGmqTdgQ0VWivnnNvBrFAJb6WRtEDS15KmS5oapjWSNE7SnPBnw5jjb5U0V9JsSSeUln8igftuYAzQRtKrwHjgpgTOc865yEhm4A4dbWadzWzzAxVuAcabWXuCOHoLgKR9gN5AB6AHMFBSeryMS+0qMbNxkqYBXQmmv19jZssTrblzzkWBVfxy3D2BbuHrwcCHwM1h+lAz2wDMlzQX6AJ8VlJGiT4s+CiCR+4cDRyxXVV2zrlKrCwtbkl9JU2N2fpunR0wVtLnMfuam1kuQPizWZieBSyKOTcnTCtRqS1uSQOBdsCQMOkySceZWb/SznXOuagoyzA/MxsEDIpzyGFmtkRSM2CcpG/jHFtcwXHb/4mMKjkK2NfMNt+cHAx8ncB5zjkXGQVJHFViZkvCn8skvUPQ9bFUUkszy5XUElgWHp4DtIk5vTWwJF7+iXSVzAZ2iXnfBvgqwfo751wkJGsCjqTa4SqqSKpN8CyDb4DhQJ/wsD7AsPD1cKC3pOqS2gLtgcnxyoi3yNQIguZ6fWCWpMnh+4OBT+PW3DnnIiaJa5U0B94Jp7tkAK+Z2RhJU4BsSZcAC4GzAMxshqRsYCaQD/Qzs4J4BcTrKnk0CR/AOeciIVmjSsxsHrBfMekrCAZ5FHdOf6B/omXEW2Tqo0Qzcc65qIvS6oCJLDLVVdIUSWslbZRUIClvR1TOOed2lILCtIS3VEukBk8C5wJzgJrApWGaC53QvRszvvmYb2d+wk1/8VGSpXk5+z/0uuByep5/GS+//k658xs2ehwnnXMJJ51zCcNGj/st/ea//o1Tel9Krwsu544HBrApP7/cZVVGt/79L4z88i1eHv983OP22m9PPl44jm4nH1nuMjOrZXLv03fy+icvM2jEU7Ro3RyA9h1255nh/+SV919g8LhnOfa0buUua0cxS3xLtYS+OsxsLpBuZgVm9iJbZv/s9NLS0nji8f6ccuoFdNzvaM45pxd7790+1dWqtObMW8Bbw8cw5LnHeGvwQD76dDI/LFqc0Ll/uuomFucuLZK2Om8NT7/4GkOefYwhzz7G0y++xuq8NQCc3P1oRgx5lndefpoNGzby1ogxSf88lcHo7He5/vxb4h6TlpbGlbf3ZfKHU8uUd4vWzfnnGwO2ST/l3BNZs3oN5xx+Ia8/+yZX3h7MMfl1/Qbuu+YhLjjmYm644Bb+/Nd+1KlXu0xlpkqhKeEt1RIJ3OskVQOmS3pY0nVANP4ldoAuv9+f779fwPz5C9m0aRPZ2cM47dRS14jZac1bsIhOHfaiZo0aZGSkc1Dnjoz/+FMW5izhsuvv4OyLr+aPV9zIvB8WlZ4ZMHHS5xzy+/2pX68u9evV5ZDf78/ESZ8DcOShXZCEJDruvSdLl1XNlRq+nPQVeavi916eefHpfDjqY1auWFkkvfsfjuPZkQN5aewg/vK360hLS6wb4IjuhzH6jbEAfDjqIw48PHjS4aJ5OeTMD76Ily9dwcoVq2jQuEEZP1FqVLX1uC8Mj7sK+IVgHPcftrdASVXqQcOtslqwKGfLWPmcxbm0atUihTWq3Nrt9js+//IbVq3OY/2vvzLhsyn8uPQn7nn4CW677gqyX/gnN151Kfc/+lRC+S39aTktmjX97X3zpk1Y+lPRAL0pP58R747n8IMP2vr0nUKTFk04ssfh/OflEUXSf9duF4497Wgu73U1f+rel8KCQrr/odhBD9to2qIJy5YE80cKCgr5Je8X6jesV+SYvTvvRWZmBosXxJ1LUmlEqaskkUWmfghf/grcAyDpdeCc7SzzHoKHM2wjnNPfF0Dp9UlLq/wN++KWJrfK8C9bSe2+6y5cfP5Z/N+1t1GrZk32aLcb6enpTP96Ftff8cBvx23ctAmAd0aN5ZXsYJ7CwsVLuOLGO8nMyCSrVXOeePCuYv8n2vrf5P5Hn+LA/fblwM77VtwHq8SuuacfTz8wiMLCok8AOOjwA9irY3ueH/00ANVrVGfl8lUAPPDcvbTapQUZmRk0z2rOS2OD2d3Zz73N6Owxxf/ex7xu3KwRdz1xK/df+1Bk/n+oDF0giUpkyntxDom3U1JJMytFMDi9WLHz/zOqZUXiX3txTi5tWrf67X3rrJbkbtUP64o649QTOCPsTnrsXy/RpHFD6tatzVuDt21ln35yd04/uTsQ9HH3v/0Gslpu+RVq0awJU77Y8uu29Kfl/H7/Tr+9H/jCq6xctZq7H7ijoj5OpbdXpz24Z+CdANRvVJ9DjjmYgvwCJPHfN8byr4ee2+ac2y69Cwj6uG//x81cfdb1RfYvy/2JZq2a8VPuctLT06hdrzZ5K4Pumlp1avHIvx9k0MMvMGParAr+dMlTGUaLJKqiatoc+CNwajHbigoqMyWmTJ1Ou3Zt2XXXNmRmZnL22T0ZMXJsqqtVqa1YuQqA3B+XMf6jiZx6wjFktWzBu+9PAIK/WL6dMy+hvA47+EA+nTyN1XlrWJ23hk8nT+Owgw8E4M3hY5g46XMevufmhPtuq6KzDjmfM7uex5ldz+PDUR/x6G2PM+HdiUz9ZBrdTjnytz7oug3q0jyrxHZVEZ+M/ZSTzgq+ULudfBSfT/wCgIzMDB58/l7GvDmWD0ZGayqIlWFLtXhT3g8oaReQWUq+I4E6Zja9mHw/TLRyUVBQUMA1197B6FGvkZ6WxkuDX2fmzO9SXa1K7brb7mdVXh4ZGRncfsOV1K9Xl7/dfRP3PfokzwweQn5+PiceexR7td+t1Lzq16vLZX86l96XXgPA5RedR/16dQG479F/0rJ5M87vG7QWjzvqUK64+PyK+2Ap8ten7mD/Q/ajQaP6vDP1dZ5/9CUyMoP/tbfu1461YM4PPPvwCzw25GEkkZ9fwIDbH2fp4tL/Yhw5dDR3PnEbr3/yMnmr1nD3lfcBcMyp3eh8cCfqN6zHSWcHf1X1v+5vzJnxfRI+acWKUleJSup/kvRBvBPN7OgKqVEoKl0lUbZ+yYRUV6HK67bfpamuwk5h4uL3yx11J7Y4M+GYc9iPb6Y0yseb8l6hgdk55yqTSvDw9oRt781J55yrUqzY5xlUTh64nXMOyI9QH7cHbuecI1ot7kRWB5SkCyTdFb7fRVKXiq+ac87tOIVl2BIhKV3SF5JGhu8bSRonaU74s2HMsbdKmitptqRS18xIZHDrQIIJN+eG79cAic1Hds65iDCU8Jaga4DYGUi3AOPNrD0wPnyPpH2A3kAHoAcwUFJ6vIwTCdwHh090/xXAzFYC1RKtuXPORUEyW9ySWgMnA7HTUnsCg8PXg4FeMelDzWyDmc0H5hI8XLhEiQTuTWH03/yU96YJ1t055yKjACW8SeoraWrM1ner7B4DbqJorGxuZrkA4c9mYXoWELscZk6YVqJEbk4+AbwDNJPUHzgT2HkXfnDOVUlleXJZ7LpKW5N0CrDMzD6X1C2B7IorOe5koERWB3xV0ucED7kU0MvMorNyjHPOJaAweaNKDgNOk3QSUAOoJ+kVYKmklmaWK6klsCw8PodguezNWgNx18JNZFTJLsA6YAQwHPglTHPOuSojWYtMmdmtZtbazHYluOn4vpldQBA/+4SH9QGGha+HA70lVZfUFmgPTI5XRiJdJaPCuorg26MtMJvgDqhzzlUJO+DG3UNAtqRLgIXAWQBmNkNSNjATyAf6mVlBvIwS6SrpGPs+XDXwsu2suHPOVUqFxTwcorzM7EPgw/D1CoIu5+KO6w/0TzTfMs+cNLNpkn5f1vOcc64yi9vErWRKDdySYh99kQYcAPxUYTVyzrkUKMuoklRLpMVdN+Z1PkGf91sVUx3nnEuNJI4qqXBxA3c48aaOmf1lB9XHOedSIkpPbon36LIMM8uP8wgz55yrMqpKV8lkgv7s6ZKGA28Av2zeaWZvV3DdnHNuh4nSOh6J9HE3Ingy+zFsGc9tgAdu51yVUVBFWtzNwhEl37AlYG8Wpe4g55wrVVVpcacDddiOBVCccy5qqkrgzjWze3dYTZxzLoUi9MjJuIE7Qh/DOefKp6q0uIudU++cc1VRlZjybmY/78iKOOdcKlWVcdzOObfTqCpdJc45t9OIUuBO5GHBzjlX5SXrCTiSakiaLOlLSTMk3ROmN5I0TtKc8GfDmHNulTRX0mxJJ5RWVw/czjlH0Med6FaKDcAxZrYf0BnoIakrcAsw3szaA+PD90jah+ARZx2AHsDAcIG/Enngds45glEliW7xWGBt+DYz3AzoCQwO0wcDvcLXPYGhZrbBzOYDc4Eu8crwPu6d2Aud70p1Faq8nhmtUl0Fl6DCMkwIl9QX6BuTNMjMBsXsTwc+B9oBT5nZJEnNzSwXIHzSe7Pw8CzgfzF55YRpJfLA7ZxzlO3mZBikB8XZXwB0ltQAeEfSvnGyK/OyIt5V4pxzJO/mZJE8zVYRPCy4B7BUUkuA8Oey8LAcoE3Maa2BJfHy9cDtnHMELe5Et3gkNQ1b2kiqCRwHfAsMB/qEh/UBhoWvhwO9JVWX1BZoT/A8hBJ5V4lzzgH5Stqipy2BwWE/dxqQbWYjJX0GZEu6BFgInAVgZjMkZQMzCZ7r2y/saimRB27nnCN5a1Wb2VfA/sWkr6CENaDMrD/QP9EyPHA75xzRmjnpgds55yjbcMBU88DtnHNE67FeHridcw7vKnHOucgpiFCb2wO3c87hLW7nnIsc8xa3c85Fi7e4nXMuYnw4oHPORUx0wrYHbuecAyA/QqHbA7dzzuE3J51zLnL85qRzzkWMt7idcy5iotTi9ifgOOccUGCW8BaPpDaSPpA0S9IMSdeE6Y0kjZM0J/zZMOacWyXNlTRb0gml1dUDt3POEYzjTnQrRT5wg5ntDXQF+knaB7gFGG9m7YHx4XvCfb2BDgTPphwYPj2nRB64nXOOoI870f/i5mOWa2bTwtdrgFlAFtATGBweNhjoFb7uCQw1sw1mNh+YC3SJV4YHbueco2wPC5bUV9LUmK1vcXlK2pXgMWaTgOZmlgtBcAeahYdlAYtiTssJ00rkNyedc46yTXk3s0HAoHjHSKoDvAVca2Z5kko8tLgi4uXtLW7nnCN5XSUAkjIJgvarZvZ2mLxUUstwf0tgWZieA7SJOb01sCRe/h64nXOOpI4qEfA8MMvMBsTsGg70CV/3AYbFpPeWVF1SW6A9MDleGd5V4pxzJHV1wMOAC4GvJU0P024DHgKyJV0CLATOAjCzGZKygZkEI1L6mVlBvAI8cDvnHMmbgGNmn1B8vzXAsSWc0x/on2gZHridcw6f8u6cc5HjD1LYyZzQvRsDBtxLeloaL7w4hIcfeSrVVaoU0qtnctpbd5BeLQOlpzN/9GSm/v3tYo9tut9u9Br+V9678p/MHzWlXOWmVcvgmMcup0mntvy6cg3vXfEka3OW03ifXTjiwYvIrFMTKyzkiyeG8f2ISeUqqzJIr57JednBdU7LSGf26MlM/EfR69xo95ac+GhfmnfYlQmPvsGUQaPLX261DE4ecDnNO7Zl/co1DL/qSfJyltNsn104vv9FVK9Tk8KCQv735DC+HVn5r7OVctOxMvHAXU5paWk88Xh/epx0Ljk5ufzvs9GMGDmWWbPmpLpqKVewYRMjzn6A/HUbSMtI57R37mThB1+ybNr3RY5Tmjj4tnPI+eirMuVfp3UTjv7HZYw4q2jX4F69u7Fh9S8MPfwGdj+tK11v6817Vz5J/vqNvH/tv8ibv5RazRvwh9H3s+ijr9mYt67cnzWVCjZsYui5D7ApvM7nvXkn8z78ktwvtlznX1f9wvi7X6b9CQeWOf96rZtw0qOXMbR30evc8Zxu/Lr6F5496gb2OrUr3W7pzfCrnmTT+o2Mvu5frFywlDrNGvDHUfcz/+Ov2VDJr3NBhFrcPhywnLr8fn++/34B8+cvZNOmTWRnD+O0U0tdI2ankb9uAwBpGemkZWQUO61g34u6M3/0FNYvzyuS3v4Ph3H6yHs4493+HPHQxSitxAkMReza/QC+e2MCAPNGTabV4R0AWD3/R/LmLwVg3dJV/LpiNTUa193ej1apbIq5zumZ217ndSvy+PGreRRu2nawwj6nH8aFw+6hz+j+dH8g8evc/vgD+Oat4DrPHj2ZXQ4LrvPK+T+yckFwndcuW8W65aup1ajyX+ckrlVS4SoscEvaS9Kx4eyh2PQeFVVmKrTKasGinC1j5XMW59KqVYsU1qhyUZo4493+/PHLgSye8DXLvija2q7VoiG7nngQM18eXyS9QbtW7H7qwQzrdS9vnXA7VlBIu9MPS6jM2i0asjb3ZwCsoJCNeeuo0bDIryFNO+9GWmYGeQuWFZdF5ChN9Bndn6umDWTBhK/Jnf596ScBjdq1Yq9TDubVM+5l8Em3Y4WF7NMrsetcp0VD8pZsuc4b1qyj5lbXucV+u5FeLYOVP1T+62xmCW+pViFdJZL+DPQjWFzleUnXmNnmweYPAGMqotxUKG4aa2X4h60srNB464TbqVavFt2fu5aGe7Zm5eyc3/Yf+tcLmPTAUKyw6DXLOrwDTTq25fRR9wKQUaMa61cELfLuz11L3TZNSc/MoE5WY854N/gT/pvn32V29sdQ7L/Jlte1mjXgmMev4IPr/lV0R4RZoTH4pNupXq8Wpw+6liZ7tGb5dzmlnve7wzrQomNbLhweXOfMGtVYF/7l0+uZa6nfpinp1TKo16oxfUYH1/nzF9/lmzc+LuF3f8vr2s0acMo/rmDUDdG4zpWhJZ2oiurj/j/gQDNbGy6y8qakXc3scUoe30i4UEtfAKXXJy2tdgVVL3kW5+TSpnWr3963zmpJbu7SFNaoctqYt47cz2bRplunIoG7aae2HPfUVQDUaFSXXY7ZD8svBMF3b05g8kPZ2+Q19tLHgJL7uH/J/Zk6LRvxS+7PKD2NavVqsWHVWgAy69Skx+AbmfLwG9v0tVcFG/LWsfCzWbTt1imhwC3BN29O4OOHt73O/7nsMaDkPu41uT9Tr1Uj1v4YXOfqdWvxa3idq9WpyZkv3siER98o0tdemUVpOGBFdZWkm9laADNbAHQDTpQ0gDiB28wGmdlBZnZQFII2wJSp02nXri277tqGzMxMzj67JyNGjk11tSqFGo3qUq1eLQDSa2SSdfi+rJpbdAmGIYdez2uHXMdrh1zHvFGTmXD7Syx493MWfzKD3U7uQo3G9QCo3qA2dbIaJ1TuD+OmscdZRwCw28ldWDJxJgBpmemc8Ny1zHlzAvNGxZ1RHCk1G9WlenidM6pn8rvD9+XnuXGXuvjNDxNnsOdJXagVXuca9WtTL8HrPPe9aex7RnCd9zypCws/3XKdTx90Ld+8NYHZo6NznZM15X1HqKgW94+SOpvZdICw5X0K8ALQsYLKTImCggKuufYORo96jfS0NF4a/DozZ36X6mpVCrWaN+Dof1yG0tOQxPcjJ7Fw/HT2vuAYAGa98n6J566as4QpD7/Bya/djNJE4aYCPrnjJdYuXlFqud8O/YijH7+c3p/8nQ2r1vLelU8CsPupXWlx8J5Ub1iHPc4+EoAPr3uGFTMXJuHTpk6dZg04acBlKC0NpYnZIyfx/fvT6Xx+cJ2nv/o+tZvW548j7qNaOBTyoIt78PxxN7NizhImPPoGZ70cXuf8Asbd+RJ5CVznr17/iJP/cTn/99Hf+XXVWoZfFVznvU7pSusue1KjQR32PTO4zv+98RmWVfLrHKWuElVEf6yk1kC+mf1YzL7DzGxiaXlkVMuKzlWMqKeaHZ3qKlR5q+M+x8Qly00/vJLYUJg4Dsk6OuGY89niD8pdXnlUSIvbzErsXEskaDvn3I4WpUEFPgHHOeeIVleJB27nnCNao0o8cDvnHFBgyVrYteL5lHfnnCO5MyclvSBpmaRvYtIaSRonaU74s2HMvlslzZU0W1Kpa2Z44HbOOZK+VslLwNbLe9wCjDez9sD48D2S9gF6Ax3CcwZKijseyQO3c86R3IcFm9nHwM9bJfcEBoevBwO9YtKHmtkGM5sPzAW6xMvf+7idcw4orPjhgM3NLBfAzHIlNQvTs4D/xRyXE6aVyFvczjlH2VrckvpKmhqz9S1H0cVN5on7LeItbueco2yjSsxsEDCojEUsldQybG23BDavdZsDtIk5rjUQd7EZb3E75xxBV0mi23YaDvQJX/cBhsWk95ZUXVJboD0Qd3Uub3E75xzJnYAjaQjBqqhNJOUAdwMPAdmSLgEWAmcBmNkMSdnATCAf6Gdm2z6qKIYHbuecI7k3J83s3BJ2HVvC8f2B/sXtK44Hbuecw6e8O+dc5BTE752oVDxwO+ccvqyrc85Fji/r6pxzEeMtbueci5gdMOU9aTxwO+ccPqrEOeciJ0oPUvDA7ZxzeB+3c85FjvdxO+dcxHiL2znnIsbHcTvnXMR4i9s55yLGR5U451zE+M1J55yLmCh1lfijy5xzjrI9LLg0knpImi1prqRbkl1Xb3E75xzJa3FLSgeeAo4neBDwFEnDzWxmUgrAA7dzzgFJ7ePuAsw1s3kAkoYCPQmeKZkUlTZw529crFTXoawk9TWzQamuR1Xm17ji7azXuCwxR1JfoG9M0qCYa5YFLIrZlwMcXP4abuF93MnVt/RDXDn5Na54fo1LYWaDzOygmC32i664L4Ck3vn0wO2cc8mVA7SJed8aWJLMAjxwO+dcck0B2ktqK6ka0BsYnswCKm0fd0TtdP2CKeDXuOL5NS4HM8uXdBXwLpAOvGBmM5JZhqI06Nw555x3lTjnXOR44HbOuYjxwJ0EFT291YGkFyQtk/RNqutSVUlqI+kDSbMkzZB0Tarr5IrnfdzlFE5v/Y6Y6a3Aucmc3upA0pHAWuDfZrZvqutTFUlqCbQ0s2mS6gKfA738d7ny8RZ3+f02vdXMNgKbp7e6JDKzj4GfU12PqszMcs1sWvh6DTCLYBagq2Q8cJdfcdNb/ZfdRZqkXYH9gUkproorhgfu8qvw6a3O7UiS6gBvAdeaWV6q6+O25YG7/Cp8eqtzO4qkTIKg/aqZvZ3q+rjieeAuvwqf3urcjiBJwPPALDMbkOr6uJJ54C4nM8sHNk9vnQVkJ3t6qwNJQ4DPgD0l5Ui6JNV1qoIOAy4EjpE0PdxOSnWl3LZ8OKBzzkWMt7idcy5iPHA751zEeOB2zrmI8cDtnHMR44HbOecixgO3K5GkgnBI2DeS3pBUqxx5vSTpzPD1c5L2iXNsN0mHbkcZCyQ1STS9hDz+JOnJZJTrXEXxwO3iWW9mncPV+DYCl8fuDFdGLDMzu7SUFee6AWUO3M7tLDxwu0RNANqFreEPJL0GfC0pXdIjkqZI+krSZRDMwpP0pKSZkkYBzTZnJOlDSQeFr3tImibpS0njw8WNLgeuC1v7R0hqKumtsIwpkg4Lz20saaykLyQ9Q/HrxhRLUhdJn4bnfippz5jdbSSNCddYvzvmnAskTQ7r9cz2fnE5V17+sGBXKkkZwInAmDCpC7Cvmc2X1BdYbWa/l1QdmChpLMHKcnsCHYHmwEzgha3ybQo8CxwZ5tXIzH6W9C9grZk9Gh73GvAPM/tE0i4Es1T3Bu4GPjGzeyWdDPQtw8f6Niw3X9JxwAPAGbGfD1gHTAm/eH4BzgEOM7NNkgYC5wP/LkOZziWFB24XT01J08PXEwjWsTgUmGxm88P07kCnzf3XQH2gPXAkMMTMCoAlkt4vJv+uwMeb8zKzktbbPg7YJ1hKA4B64UL/RwJ/CM8dJWllGT5bfWCwpPYEqzlmxuwbZ2YrACS9DRwO5AMHEgRygJrAsjKU51zSeOB28aw3s86xCWHQ+iU2CbjazN7d6riTKH15WyVwDARdeoeY2fpi6rK9azbcB3xgZqeH3TMfxuzbOk8L6zrYzG7dzvKcSxrv43bl9S5wRbgcKJL2kFQb+BjoHfaBtwSOLubcz4CjJLUNz20Upq8B6sYcN5ZgIS/C4zqHLz8m6K5A0olAwzLUuz6wOHz9p632HS+pkaSaQC9gIjAeOFNSs811lfS7MpTnXNJ44Hbl9RxB//U0BQ/yfYbgL7l3gDnA18DTwEdbn2hmPxH0S78t6Uvg9XDXCOD0zTcngT8DB4U3P2eyZXTLPcCRkqYRdNksjFPPr8JVBXMkDQAeBh6UNBHY+ibjJ8DLwHTgLTObGo6CuQMYK+krYBzQMrFL5Fxy+eqAzjkXMd7ids65iPHA7ZxzEeOB2znnIsYDt3PORYwHbuecixgP3M45FzEeuJ1zLmL+H6kXeAlw3OrMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-alexandria",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
