{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indian-confidentiality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 695us/step - loss: 1.0564 - accuracy: 0.4456 - val_loss: 1.0340 - val_accuracy: 0.4588\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 1.0092 - accuracy: 0.5127 - val_loss: 0.9993 - val_accuracy: 0.5177\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9871 - accuracy: 0.5320 - val_loss: 0.9922 - val_accuracy: 0.5301\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9828 - accuracy: 0.5298 - val_loss: 0.9898 - val_accuracy: 0.5305\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9805 - accuracy: 0.5309 - val_loss: 0.9883 - val_accuracy: 0.5310\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9787 - accuracy: 0.5303 - val_loss: 0.9867 - val_accuracy: 0.5305\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9775 - accuracy: 0.5311 - val_loss: 0.9856 - val_accuracy: 0.5279\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9764 - accuracy: 0.5318 - val_loss: 0.9856 - val_accuracy: 0.5221\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9759 - accuracy: 0.5310 - val_loss: 0.9841 - val_accuracy: 0.5279\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9751 - accuracy: 0.5321 - val_loss: 0.9839 - val_accuracy: 0.5305\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9747 - accuracy: 0.5311 - val_loss: 0.9839 - val_accuracy: 0.5212\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9742 - accuracy: 0.5317 - val_loss: 0.9830 - val_accuracy: 0.5274\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9739 - accuracy: 0.5313 - val_loss: 0.9830 - val_accuracy: 0.5212\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9833 - val_accuracy: 0.5173\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9736 - accuracy: 0.5307 - val_loss: 0.9826 - val_accuracy: 0.5212\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9733 - accuracy: 0.5314 - val_loss: 0.9831 - val_accuracy: 0.5208\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 0.9835 - val_accuracy: 0.5190\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9731 - accuracy: 0.5310 - val_loss: 0.9826 - val_accuracy: 0.5248\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9729 - accuracy: 0.5315 - val_loss: 0.9821 - val_accuracy: 0.5208\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 0.9822 - val_accuracy: 0.5274\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9728 - accuracy: 0.5309 - val_loss: 0.9821 - val_accuracy: 0.5186\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9727 - accuracy: 0.5317 - val_loss: 0.9821 - val_accuracy: 0.5239\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9727 - accuracy: 0.5313 - val_loss: 0.9820 - val_accuracy: 0.5212\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9726 - accuracy: 0.5312 - val_loss: 0.9825 - val_accuracy: 0.5168\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9727 - accuracy: 0.5313 - val_loss: 0.9820 - val_accuracy: 0.5204\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9725 - accuracy: 0.5321 - val_loss: 0.9819 - val_accuracy: 0.5204\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9726 - accuracy: 0.5311 - val_loss: 0.9822 - val_accuracy: 0.5243\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 0.9825 - val_accuracy: 0.5173\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 0.9819 - val_accuracy: 0.5239\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9724 - accuracy: 0.5307 - val_loss: 0.9819 - val_accuracy: 0.5212\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9721 - accuracy: 0.5313 - val_loss: 0.9825 - val_accuracy: 0.5292\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9723 - accuracy: 0.5309 - val_loss: 0.9831 - val_accuracy: 0.5186\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9724 - accuracy: 0.5312 - val_loss: 0.9818 - val_accuracy: 0.5212\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9722 - accuracy: 0.5317 - val_loss: 0.9819 - val_accuracy: 0.5190\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9725 - accuracy: 0.5304 - val_loss: 0.9819 - val_accuracy: 0.5199\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9722 - accuracy: 0.5317 - val_loss: 0.9845 - val_accuracy: 0.5155\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9723 - accuracy: 0.5306 - val_loss: 0.9831 - val_accuracy: 0.5292\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9723 - accuracy: 0.5304 - val_loss: 0.9835 - val_accuracy: 0.5177\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9825 - val_accuracy: 0.5274\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9723 - accuracy: 0.5307 - val_loss: 0.9826 - val_accuracy: 0.5283\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9722 - accuracy: 0.5319 - val_loss: 0.9820 - val_accuracy: 0.5261\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9721 - accuracy: 0.5316 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9722 - accuracy: 0.5306 - val_loss: 0.9828 - val_accuracy: 0.5305\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9721 - accuracy: 0.5326 - val_loss: 0.9821 - val_accuracy: 0.5177\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 0.9824 - val_accuracy: 0.5181\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 551us/step - loss: 0.9720 - accuracy: 0.5306 - val_loss: 0.9819 - val_accuracy: 0.5274\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9720 - accuracy: 0.5317 - val_loss: 0.9840 - val_accuracy: 0.5164\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9720 - accuracy: 0.5306 - val_loss: 0.9825 - val_accuracy: 0.5177\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9721 - accuracy: 0.5309 - val_loss: 0.9823 - val_accuracy: 0.5257\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 0.9820 - val_accuracy: 0.5208\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9721 - accuracy: 0.5313 - val_loss: 0.9821 - val_accuracy: 0.5177\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5316 - val_loss: 0.9824 - val_accuracy: 0.5265\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9720 - accuracy: 0.5312 - val_loss: 0.9820 - val_accuracy: 0.5181\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9719 - accuracy: 0.5311 - val_loss: 0.9821 - val_accuracy: 0.5190\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 0.9822 - val_accuracy: 0.5168\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9722 - accuracy: 0.5314 - val_loss: 0.9820 - val_accuracy: 0.5190\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 508us/step - loss: 0.9720 - accuracy: 0.5314 - val_loss: 0.9819 - val_accuracy: 0.5199\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9720 - accuracy: 0.5311 - val_loss: 0.9820 - val_accuracy: 0.5274\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9719 - accuracy: 0.5307 - val_loss: 0.9822 - val_accuracy: 0.5186\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9720 - accuracy: 0.5309 - val_loss: 0.9821 - val_accuracy: 0.5181\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9720 - accuracy: 0.5314 - val_loss: 0.9819 - val_accuracy: 0.5230\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9719 - accuracy: 0.5318 - val_loss: 0.9821 - val_accuracy: 0.5199\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9720 - accuracy: 0.5305 - val_loss: 0.9819 - val_accuracy: 0.5208\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9719 - accuracy: 0.5317 - val_loss: 0.9829 - val_accuracy: 0.5177\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9720 - accuracy: 0.5316 - val_loss: 0.9823 - val_accuracy: 0.5181\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9719 - accuracy: 0.5323 - val_loss: 0.9818 - val_accuracy: 0.5239\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9718 - accuracy: 0.5318 - val_loss: 0.9822 - val_accuracy: 0.5252\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9719 - accuracy: 0.5304 - val_loss: 0.9819 - val_accuracy: 0.5212\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9718 - accuracy: 0.5319 - val_loss: 0.9820 - val_accuracy: 0.5252\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9717 - accuracy: 0.5307 - val_loss: 0.9831 - val_accuracy: 0.5274\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9721 - accuracy: 0.5323 - val_loss: 0.9826 - val_accuracy: 0.5265\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9719 - accuracy: 0.5320 - val_loss: 0.9819 - val_accuracy: 0.5243\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9719 - accuracy: 0.5321 - val_loss: 0.9822 - val_accuracy: 0.5283\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9719 - accuracy: 0.5301 - val_loss: 0.9822 - val_accuracy: 0.5252\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9719 - accuracy: 0.5315 - val_loss: 0.9829 - val_accuracy: 0.5305\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9720 - accuracy: 0.5320 - val_loss: 0.9820 - val_accuracy: 0.5243\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9718 - accuracy: 0.5321 - val_loss: 0.9828 - val_accuracy: 0.5199\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9717 - accuracy: 0.5316 - val_loss: 0.9823 - val_accuracy: 0.5186\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9719 - accuracy: 0.5329 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9719 - accuracy: 0.5310 - val_loss: 0.9825 - val_accuracy: 0.5292\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9717 - accuracy: 0.5314 - val_loss: 0.9822 - val_accuracy: 0.5243\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9719 - accuracy: 0.5319 - val_loss: 0.9820 - val_accuracy: 0.5261\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9717 - accuracy: 0.5315 - val_loss: 0.9823 - val_accuracy: 0.5186\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9716 - accuracy: 0.5314 - val_loss: 0.9821 - val_accuracy: 0.5243\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9823 - val_accuracy: 0.5270\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9823 - val_accuracy: 0.5239\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9717 - accuracy: 0.5319 - val_loss: 0.9826 - val_accuracy: 0.5186\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9719 - accuracy: 0.5310 - val_loss: 0.9820 - val_accuracy: 0.5252\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9718 - accuracy: 0.5322 - val_loss: 0.9820 - val_accuracy: 0.5274\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9717 - accuracy: 0.5320 - val_loss: 0.9822 - val_accuracy: 0.5257\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9719 - accuracy: 0.5315 - val_loss: 0.9824 - val_accuracy: 0.5168\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9718 - accuracy: 0.5306 - val_loss: 0.9841 - val_accuracy: 0.5292\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9719 - accuracy: 0.5319 - val_loss: 0.9821 - val_accuracy: 0.5212\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9718 - accuracy: 0.5309 - val_loss: 0.9823 - val_accuracy: 0.5204\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 548us/step - loss: 0.9719 - accuracy: 0.5320 - val_loss: 0.9824 - val_accuracy: 0.5168\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9719 - accuracy: 0.5308 - val_loss: 0.9820 - val_accuracy: 0.5212\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9822 - val_accuracy: 0.5257\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9719 - accuracy: 0.5320 - val_loss: 0.9820 - val_accuracy: 0.5252\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9718 - accuracy: 0.5318 - val_loss: 0.9819 - val_accuracy: 0.5204\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9717 - accuracy: 0.5306 - val_loss: 0.9820 - val_accuracy: 0.5199\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9717 - accuracy: 0.5309 - val_loss: 0.9822 - val_accuracy: 0.5270\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9716 - accuracy: 0.5321 - val_loss: 0.9837 - val_accuracy: 0.5181\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9715 - accuracy: 0.5314 - val_loss: 0.9822 - val_accuracy: 0.5195\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9716 - accuracy: 0.5320 - val_loss: 0.9824 - val_accuracy: 0.5270\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9719 - accuracy: 0.5320 - val_loss: 0.9820 - val_accuracy: 0.5257\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9719 - accuracy: 0.5306 - val_loss: 0.9828 - val_accuracy: 0.5186\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9822 - val_accuracy: 0.5261\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9718 - accuracy: 0.5320 - val_loss: 0.9831 - val_accuracy: 0.5301\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9719 - accuracy: 0.5314 - val_loss: 0.9821 - val_accuracy: 0.5243\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9827 - val_accuracy: 0.5274\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9718 - accuracy: 0.5314 - val_loss: 0.9823 - val_accuracy: 0.5283\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9717 - accuracy: 0.5311 - val_loss: 0.9825 - val_accuracy: 0.5230\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 486us/step - loss: 0.9718 - accuracy: 0.5300 - val_loss: 0.9819 - val_accuracy: 0.5252\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9717 - accuracy: 0.5325 - val_loss: 0.9824 - val_accuracy: 0.5283\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9823 - val_accuracy: 0.5283\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9716 - accuracy: 0.5317 - val_loss: 0.9824 - val_accuracy: 0.5212\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9720 - accuracy: 0.5314 - val_loss: 0.9822 - val_accuracy: 0.5208\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9717 - accuracy: 0.5328 - val_loss: 0.9820 - val_accuracy: 0.5243\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9833 - val_accuracy: 0.5265\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9718 - accuracy: 0.5317 - val_loss: 0.9821 - val_accuracy: 0.5181\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9716 - accuracy: 0.5324 - val_loss: 0.9819 - val_accuracy: 0.5235\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9716 - accuracy: 0.5310 - val_loss: 0.9824 - val_accuracy: 0.5279\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9715 - accuracy: 0.5325 - val_loss: 0.9838 - val_accuracy: 0.5305\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9718 - accuracy: 0.5314 - val_loss: 0.9822 - val_accuracy: 0.5261\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9717 - accuracy: 0.5310 - val_loss: 0.9822 - val_accuracy: 0.5221\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9716 - accuracy: 0.5308 - val_loss: 0.9828 - val_accuracy: 0.5181\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9716 - accuracy: 0.5308 - val_loss: 0.9825 - val_accuracy: 0.5186\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9716 - accuracy: 0.5313 - val_loss: 0.9823 - val_accuracy: 0.5186\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9823 - val_accuracy: 0.5186\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9716 - accuracy: 0.5311 - val_loss: 0.9822 - val_accuracy: 0.5274\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9716 - accuracy: 0.5317 - val_loss: 0.9827 - val_accuracy: 0.5181\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9717 - accuracy: 0.5314 - val_loss: 0.9825 - val_accuracy: 0.5261\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9716 - accuracy: 0.5307 - val_loss: 0.9831 - val_accuracy: 0.5305\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - ETA: 0s - loss: 0.9708 - accuracy: 0.53 - 0s 499us/step - loss: 0.9718 - accuracy: 0.5318 - val_loss: 0.9831 - val_accuracy: 0.5292\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9717 - accuracy: 0.5311 - val_loss: 0.9820 - val_accuracy: 0.5261\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9717 - accuracy: 0.5324 - val_loss: 0.9825 - val_accuracy: 0.5257\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9822 - val_accuracy: 0.5279\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9821 - val_accuracy: 0.5195\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9715 - accuracy: 0.5326 - val_loss: 0.9826 - val_accuracy: 0.5279\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9829 - val_accuracy: 0.5190\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9716 - accuracy: 0.5312 - val_loss: 0.9821 - val_accuracy: 0.5208\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9717 - accuracy: 0.5311 - val_loss: 0.9823 - val_accuracy: 0.5186\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9715 - accuracy: 0.5310 - val_loss: 0.9824 - val_accuracy: 0.5221\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 576us/step - loss: 0.9717 - accuracy: 0.5309 - val_loss: 0.9825 - val_accuracy: 0.5283\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9717 - accuracy: 0.5311 - val_loss: 0.9823 - val_accuracy: 0.5208\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9716 - accuracy: 0.5312 - val_loss: 0.9822 - val_accuracy: 0.5257\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9718 - accuracy: 0.5320 - val_loss: 0.9824 - val_accuracy: 0.5279\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9826 - val_accuracy: 0.5181\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9717 - accuracy: 0.5314 - val_loss: 0.9834 - val_accuracy: 0.5186\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9717 - accuracy: 0.5315 - val_loss: 0.9820 - val_accuracy: 0.5257\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9823 - val_accuracy: 0.5212\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9717 - accuracy: 0.5320 - val_loss: 0.9830 - val_accuracy: 0.5177\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9717 - accuracy: 0.5308 - val_loss: 0.9823 - val_accuracy: 0.5186\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9827 - val_accuracy: 0.5208\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9715 - accuracy: 0.5315 - val_loss: 0.9825 - val_accuracy: 0.5195\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9716 - accuracy: 0.5320 - val_loss: 0.9823 - val_accuracy: 0.5261\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9717 - accuracy: 0.5315 - val_loss: 0.9824 - val_accuracy: 0.5195\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9715 - accuracy: 0.5299 - val_loss: 0.9825 - val_accuracy: 0.5221\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9822 - val_accuracy: 0.5208\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9719 - accuracy: 0.5320 - val_loss: 0.9820 - val_accuracy: 0.5226\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9717 - accuracy: 0.5315 - val_loss: 0.9824 - val_accuracy: 0.5181\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9714 - accuracy: 0.5310 - val_loss: 0.9826 - val_accuracy: 0.5243\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9715 - accuracy: 0.5315 - val_loss: 0.9826 - val_accuracy: 0.5296\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9717 - accuracy: 0.5321 - val_loss: 0.9820 - val_accuracy: 0.5257\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9717 - accuracy: 0.5316 - val_loss: 0.9822 - val_accuracy: 0.5274\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9716 - accuracy: 0.5323 - val_loss: 0.9823 - val_accuracy: 0.5208\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9716 - accuracy: 0.5306 - val_loss: 0.9822 - val_accuracy: 0.5248\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 505us/step - loss: 0.9714 - accuracy: 0.5315 - val_loss: 0.9825 - val_accuracy: 0.5190\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9716 - accuracy: 0.5310 - val_loss: 0.9822 - val_accuracy: 0.5239\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9821 - val_accuracy: 0.5248\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9714 - accuracy: 0.5321 - val_loss: 0.9830 - val_accuracy: 0.5265\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9719 - accuracy: 0.5310 - val_loss: 0.9821 - val_accuracy: 0.5208\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9715 - accuracy: 0.5311 - val_loss: 0.9824 - val_accuracy: 0.5252\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9827 - val_accuracy: 0.5305\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9717 - accuracy: 0.5323 - val_loss: 0.9823 - val_accuracy: 0.5208\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9716 - accuracy: 0.5324 - val_loss: 0.9822 - val_accuracy: 0.5208\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9716 - accuracy: 0.5319 - val_loss: 0.9822 - val_accuracy: 0.5208\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9716 - accuracy: 0.5303 - val_loss: 0.9819 - val_accuracy: 0.5257\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9716 - accuracy: 0.5318 - val_loss: 0.9823 - val_accuracy: 0.5283\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9716 - accuracy: 0.5316 - val_loss: 0.9822 - val_accuracy: 0.5261\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9715 - accuracy: 0.5318 - val_loss: 0.9824 - val_accuracy: 0.5283\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9717 - accuracy: 0.5324 - val_loss: 0.9826 - val_accuracy: 0.5301\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9716 - accuracy: 0.5318 - val_loss: 0.9829 - val_accuracy: 0.5177\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9717 - accuracy: 0.5323 - val_loss: 0.9825 - val_accuracy: 0.5279\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9717 - accuracy: 0.5314 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9717 - accuracy: 0.5320 - val_loss: 0.9822 - val_accuracy: 0.5257\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9716 - accuracy: 0.5314 - val_loss: 0.9825 - val_accuracy: 0.5261\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9717 - accuracy: 0.5318 - val_loss: 0.9826 - val_accuracy: 0.5248\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9715 - accuracy: 0.5316 - val_loss: 0.9824 - val_accuracy: 0.5279\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9826 - val_accuracy: 0.5261\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9716 - accuracy: 0.5306 - val_loss: 0.9824 - val_accuracy: 0.5235\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9717 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5261\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 568us/step - loss: 0.9716 - accuracy: 0.5309 - val_loss: 0.9825 - val_accuracy: 0.5279\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 544us/step - loss: 0.9716 - accuracy: 0.5319 - val_loss: 0.9823 - val_accuracy: 0.5212\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9717 - accuracy: 0.5320 - val_loss: 0.9824 - val_accuracy: 0.5221\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9715 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5265\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9718 - accuracy: 0.5309 - val_loss: 0.9821 - val_accuracy: 0.5208\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9824 - val_accuracy: 0.5199\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9823 - val_accuracy: 0.5279\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 0.9835 - val_accuracy: 0.5283\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 350us/step - loss: 0.9725 - accuracy: 0.5311\n",
      "Accuracy : 0.5311331748962402\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9835 - accuracy: 0.5283\n",
      "Accuracy : 0.5283185839653015\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "  1/636 [..............................] - ETA: 0s - loss: 1.1106 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "636/636 [==============================] - 0s 661us/step - loss: 1.0489 - accuracy: 0.4598 - val_loss: 1.0115 - val_accuracy: 0.5186\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 1.0008 - accuracy: 0.5275 - val_loss: 0.9841 - val_accuracy: 0.5385\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9874 - accuracy: 0.5310 - val_loss: 0.9806 - val_accuracy: 0.5381\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9843 - accuracy: 0.5292 - val_loss: 0.9783 - val_accuracy: 0.5358\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9822 - accuracy: 0.5297 - val_loss: 0.9770 - val_accuracy: 0.5372\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9807 - accuracy: 0.5301 - val_loss: 0.9761 - val_accuracy: 0.5381\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9795 - accuracy: 0.5302 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9784 - accuracy: 0.5307 - val_loss: 0.9757 - val_accuracy: 0.5367\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9779 - accuracy: 0.5301 - val_loss: 0.9744 - val_accuracy: 0.5389\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9773 - accuracy: 0.5301 - val_loss: 0.9743 - val_accuracy: 0.5381\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9766 - accuracy: 0.5302 - val_loss: 0.9739 - val_accuracy: 0.5363\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9761 - accuracy: 0.5306 - val_loss: 0.9735 - val_accuracy: 0.5385\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9741 - val_accuracy: 0.5332\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9754 - accuracy: 0.5305 - val_loss: 0.9733 - val_accuracy: 0.5358\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9752 - accuracy: 0.5306 - val_loss: 0.9732 - val_accuracy: 0.5367\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9748 - accuracy: 0.5297 - val_loss: 0.9734 - val_accuracy: 0.5389\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9749 - accuracy: 0.5298 - val_loss: 0.9730 - val_accuracy: 0.5358\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9746 - accuracy: 0.5309 - val_loss: 0.9732 - val_accuracy: 0.5354\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9744 - accuracy: 0.5299 - val_loss: 0.9732 - val_accuracy: 0.5381\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9743 - accuracy: 0.5301 - val_loss: 0.9731 - val_accuracy: 0.5345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9742 - accuracy: 0.5305 - val_loss: 0.9733 - val_accuracy: 0.5327\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9739 - accuracy: 0.5294 - val_loss: 0.9729 - val_accuracy: 0.5358\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9729 - val_accuracy: 0.5363\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9739 - accuracy: 0.5295 - val_loss: 0.9731 - val_accuracy: 0.5385\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9737 - accuracy: 0.5304 - val_loss: 0.9732 - val_accuracy: 0.5381\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 0.9732 - val_accuracy: 0.5358\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9736 - accuracy: 0.5304 - val_loss: 0.9729 - val_accuracy: 0.5363\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9736 - accuracy: 0.5297 - val_loss: 0.9731 - val_accuracy: 0.5345\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9736 - accuracy: 0.5306 - val_loss: 0.9729 - val_accuracy: 0.5358\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9735 - accuracy: 0.5300 - val_loss: 0.9730 - val_accuracy: 0.5358\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9737 - accuracy: 0.5302 - val_loss: 0.9731 - val_accuracy: 0.5332\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9735 - accuracy: 0.5289 - val_loss: 0.9733 - val_accuracy: 0.5358\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9735 - accuracy: 0.5311 - val_loss: 0.9727 - val_accuracy: 0.5358\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9733 - accuracy: 0.5294 - val_loss: 0.9734 - val_accuracy: 0.5354\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9733 - accuracy: 0.5304 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 0.9746 - val_accuracy: 0.5354\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5301 - val_loss: 0.9730 - val_accuracy: 0.5336\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9734 - accuracy: 0.5287 - val_loss: 0.9731 - val_accuracy: 0.5363\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 575us/step - loss: 0.9733 - accuracy: 0.5301 - val_loss: 0.9736 - val_accuracy: 0.5363\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9731 - accuracy: 0.5307 - val_loss: 0.9739 - val_accuracy: 0.5341\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9731 - accuracy: 0.5287 - val_loss: 0.9741 - val_accuracy: 0.5336\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9733 - accuracy: 0.5293 - val_loss: 0.9730 - val_accuracy: 0.5372\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9732 - accuracy: 0.5303 - val_loss: 0.9731 - val_accuracy: 0.5354\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5297 - val_loss: 0.9733 - val_accuracy: 0.5345\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9731 - accuracy: 0.5297 - val_loss: 0.9728 - val_accuracy: 0.5363\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9732 - accuracy: 0.5296 - val_loss: 0.9731 - val_accuracy: 0.5385\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9729 - accuracy: 0.5294 - val_loss: 0.9737 - val_accuracy: 0.5372\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5306 - val_loss: 0.9736 - val_accuracy: 0.5327\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9731 - accuracy: 0.5304 - val_loss: 0.9732 - val_accuracy: 0.5358\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9731 - accuracy: 0.5295 - val_loss: 0.9731 - val_accuracy: 0.5358\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9731 - accuracy: 0.5300 - val_loss: 0.9733 - val_accuracy: 0.5336\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9730 - accuracy: 0.5297 - val_loss: 0.9731 - val_accuracy: 0.5345\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9731 - accuracy: 0.5297 - val_loss: 0.9732 - val_accuracy: 0.5363\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9730 - accuracy: 0.5298 - val_loss: 0.9731 - val_accuracy: 0.5363\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9731 - accuracy: 0.5302 - val_loss: 0.9730 - val_accuracy: 0.5363\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9729 - accuracy: 0.5302 - val_loss: 0.9738 - val_accuracy: 0.5319\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9730 - accuracy: 0.5306 - val_loss: 0.9739 - val_accuracy: 0.5372\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 0.9736 - val_accuracy: 0.5372\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9731 - accuracy: 0.5296 - val_loss: 0.9730 - val_accuracy: 0.5363\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9728 - accuracy: 0.5291 - val_loss: 0.9739 - val_accuracy: 0.5341\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 0.9734 - val_accuracy: 0.5385\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9729 - accuracy: 0.5294 - val_loss: 0.9736 - val_accuracy: 0.5367\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9729 - accuracy: 0.5292 - val_loss: 0.9732 - val_accuracy: 0.5354\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 0.9731 - val_accuracy: 0.5350\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9729 - accuracy: 0.5298 - val_loss: 0.9729 - val_accuracy: 0.5363\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9729 - accuracy: 0.5314 - val_loss: 0.9730 - val_accuracy: 0.5363\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 0.9733 - val_accuracy: 0.5358\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9729 - accuracy: 0.5295 - val_loss: 0.9737 - val_accuracy: 0.5354\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9728 - accuracy: 0.5292 - val_loss: 0.9739 - val_accuracy: 0.5345\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9728 - accuracy: 0.5304 - val_loss: 0.9737 - val_accuracy: 0.5376\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9728 - accuracy: 0.5304 - val_loss: 0.9738 - val_accuracy: 0.5372\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 0.9731 - val_accuracy: 0.5363\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9728 - accuracy: 0.5295 - val_loss: 0.9733 - val_accuracy: 0.5389\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9729 - accuracy: 0.5289 - val_loss: 0.9731 - val_accuracy: 0.5341\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9728 - accuracy: 0.5292 - val_loss: 0.9734 - val_accuracy: 0.5341\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9728 - accuracy: 0.5302 - val_loss: 0.9731 - val_accuracy: 0.5350\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 532us/step - loss: 0.9729 - accuracy: 0.5302 - val_loss: 0.9735 - val_accuracy: 0.5336\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9729 - accuracy: 0.5297 - val_loss: 0.9731 - val_accuracy: 0.5332\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9729 - accuracy: 0.5299 - val_loss: 0.9733 - val_accuracy: 0.5363\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9727 - accuracy: 0.5296 - val_loss: 0.9738 - val_accuracy: 0.5350\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9727 - accuracy: 0.5302 - val_loss: 0.9742 - val_accuracy: 0.5372\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9727 - accuracy: 0.5300 - val_loss: 0.9729 - val_accuracy: 0.5341\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9727 - accuracy: 0.5302 - val_loss: 0.9734 - val_accuracy: 0.5341\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9727 - accuracy: 0.5297 - val_loss: 0.9731 - val_accuracy: 0.5350\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9728 - accuracy: 0.5292 - val_loss: 0.9732 - val_accuracy: 0.5354\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9728 - accuracy: 0.5289 - val_loss: 0.9732 - val_accuracy: 0.5358\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9726 - accuracy: 0.5293 - val_loss: 0.9738 - val_accuracy: 0.5354\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 559us/step - loss: 0.9728 - accuracy: 0.5304 - val_loss: 0.9734 - val_accuracy: 0.5358\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9727 - accuracy: 0.5299 - val_loss: 0.9738 - val_accuracy: 0.5354\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9726 - accuracy: 0.5302 - val_loss: 0.9736 - val_accuracy: 0.5363\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9727 - accuracy: 0.5292 - val_loss: 0.9735 - val_accuracy: 0.5363\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9728 - accuracy: 0.5299 - val_loss: 0.9739 - val_accuracy: 0.5358\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9728 - accuracy: 0.5301 - val_loss: 0.9734 - val_accuracy: 0.5336\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9726 - accuracy: 0.5305 - val_loss: 0.9731 - val_accuracy: 0.5363\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 0.9736 - val_accuracy: 0.5345\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9724 - accuracy: 0.5291 - val_loss: 0.9738 - val_accuracy: 0.5354\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 547us/step - loss: 0.9728 - accuracy: 0.5295 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9724 - accuracy: 0.5308 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9727 - accuracy: 0.5297 - val_loss: 0.9735 - val_accuracy: 0.5327\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9726 - accuracy: 0.5296 - val_loss: 0.9741 - val_accuracy: 0.5358\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9725 - accuracy: 0.5298 - val_loss: 0.9737 - val_accuracy: 0.5385\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9726 - accuracy: 0.5301 - val_loss: 0.9734 - val_accuracy: 0.5363\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9727 - accuracy: 0.5292 - val_loss: 0.9735 - val_accuracy: 0.5350\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9726 - accuracy: 0.5301 - val_loss: 0.9740 - val_accuracy: 0.5381\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9724 - accuracy: 0.5311 - val_loss: 0.9751 - val_accuracy: 0.5332\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9727 - accuracy: 0.5294 - val_loss: 0.9732 - val_accuracy: 0.5354\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9727 - accuracy: 0.5299 - val_loss: 0.9737 - val_accuracy: 0.5363\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9728 - accuracy: 0.5294 - val_loss: 0.9749 - val_accuracy: 0.5358\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9726 - accuracy: 0.5299 - val_loss: 0.9738 - val_accuracy: 0.5358\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9726 - accuracy: 0.5296 - val_loss: 0.9736 - val_accuracy: 0.5336\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9725 - accuracy: 0.5289 - val_loss: 0.9753 - val_accuracy: 0.5350\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9728 - accuracy: 0.5302 - val_loss: 0.9739 - val_accuracy: 0.5381\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9727 - accuracy: 0.5299 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9726 - accuracy: 0.5301 - val_loss: 0.9745 - val_accuracy: 0.5327\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9726 - accuracy: 0.5291 - val_loss: 0.9736 - val_accuracy: 0.5354\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9726 - accuracy: 0.5296 - val_loss: 0.9735 - val_accuracy: 0.5389\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9728 - accuracy: 0.5305 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9724 - accuracy: 0.5301 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9727 - accuracy: 0.5298 - val_loss: 0.9741 - val_accuracy: 0.5341\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9725 - accuracy: 0.5310 - val_loss: 0.9744 - val_accuracy: 0.5363\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9726 - accuracy: 0.5293 - val_loss: 0.9732 - val_accuracy: 0.5358\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9725 - accuracy: 0.5295 - val_loss: 0.9746 - val_accuracy: 0.5341\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9726 - accuracy: 0.5298 - val_loss: 0.9734 - val_accuracy: 0.5363\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9725 - accuracy: 0.5302 - val_loss: 0.9735 - val_accuracy: 0.5358\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9724 - accuracy: 0.5296 - val_loss: 0.9735 - val_accuracy: 0.5354\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9726 - accuracy: 0.5300 - val_loss: 0.9738 - val_accuracy: 0.5385\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9726 - accuracy: 0.5310 - val_loss: 0.9742 - val_accuracy: 0.5336\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9726 - accuracy: 0.5304 - val_loss: 0.9737 - val_accuracy: 0.5363\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9726 - accuracy: 0.5291 - val_loss: 0.9735 - val_accuracy: 0.5367\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9726 - accuracy: 0.5305 - val_loss: 0.9740 - val_accuracy: 0.5385\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9726 - accuracy: 0.5301 - val_loss: 0.9738 - val_accuracy: 0.5372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9723 - accuracy: 0.5305 - val_loss: 0.9745 - val_accuracy: 0.5341\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9725 - accuracy: 0.5299 - val_loss: 0.9734 - val_accuracy: 0.5363\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9727 - accuracy: 0.5294 - val_loss: 0.9733 - val_accuracy: 0.5363\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9727 - accuracy: 0.5295 - val_loss: 0.9739 - val_accuracy: 0.5354\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 544us/step - loss: 0.9728 - accuracy: 0.5307 - val_loss: 0.9739 - val_accuracy: 0.5336\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9724 - accuracy: 0.5296 - val_loss: 0.9739 - val_accuracy: 0.5372\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9726 - accuracy: 0.5303 - val_loss: 0.9733 - val_accuracy: 0.5341\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9725 - accuracy: 0.5296 - val_loss: 0.9738 - val_accuracy: 0.5354\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9725 - accuracy: 0.5302 - val_loss: 0.9738 - val_accuracy: 0.5354\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9725 - accuracy: 0.5297 - val_loss: 0.9732 - val_accuracy: 0.5358\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9723 - accuracy: 0.5304 - val_loss: 0.9742 - val_accuracy: 0.5341\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9725 - accuracy: 0.5298 - val_loss: 0.9738 - val_accuracy: 0.5327\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9726 - accuracy: 0.5292 - val_loss: 0.9744 - val_accuracy: 0.5354\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9726 - accuracy: 0.5311 - val_loss: 0.9734 - val_accuracy: 0.5341\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9724 - accuracy: 0.5313 - val_loss: 0.9738 - val_accuracy: 0.5376\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9723 - accuracy: 0.5301 - val_loss: 0.9738 - val_accuracy: 0.5389\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 0.9738 - val_accuracy: 0.5385\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9723 - accuracy: 0.5297 - val_loss: 0.9735 - val_accuracy: 0.5363\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9725 - accuracy: 0.5289 - val_loss: 0.9746 - val_accuracy: 0.5363\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9725 - accuracy: 0.5305 - val_loss: 0.9735 - val_accuracy: 0.5327\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9724 - accuracy: 0.5306 - val_loss: 0.9741 - val_accuracy: 0.5350\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9726 - accuracy: 0.5294 - val_loss: 0.9736 - val_accuracy: 0.5350\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9724 - accuracy: 0.5300 - val_loss: 0.9742 - val_accuracy: 0.5367\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9725 - accuracy: 0.5298 - val_loss: 0.9735 - val_accuracy: 0.5363\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9725 - accuracy: 0.5303 - val_loss: 0.9735 - val_accuracy: 0.5367\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9724 - accuracy: 0.5304 - val_loss: 0.9738 - val_accuracy: 0.5336\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9724 - accuracy: 0.5290 - val_loss: 0.9745 - val_accuracy: 0.5336\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9724 - accuracy: 0.5302 - val_loss: 0.9749 - val_accuracy: 0.5358\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9723 - accuracy: 0.5293 - val_loss: 0.9745 - val_accuracy: 0.5327\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9724 - accuracy: 0.5297 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9725 - accuracy: 0.5305 - val_loss: 0.9737 - val_accuracy: 0.5376\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9724 - accuracy: 0.5296 - val_loss: 0.9738 - val_accuracy: 0.5358\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9725 - accuracy: 0.5304 - val_loss: 0.9737 - val_accuracy: 0.5354\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9723 - accuracy: 0.5296 - val_loss: 0.9738 - val_accuracy: 0.5376\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9723 - accuracy: 0.5296 - val_loss: 0.9737 - val_accuracy: 0.5327\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9726 - accuracy: 0.5290 - val_loss: 0.9747 - val_accuracy: 0.5332\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9726 - accuracy: 0.5308 - val_loss: 0.9739 - val_accuracy: 0.5354\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9725 - accuracy: 0.5300 - val_loss: 0.9736 - val_accuracy: 0.5367\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9725 - accuracy: 0.5301 - val_loss: 0.9734 - val_accuracy: 0.5336\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9723 - accuracy: 0.5303 - val_loss: 0.9733 - val_accuracy: 0.5363\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9723 - accuracy: 0.5315 - val_loss: 0.9737 - val_accuracy: 0.5354\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9725 - accuracy: 0.5304 - val_loss: 0.9738 - val_accuracy: 0.5345\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9724 - accuracy: 0.5306 - val_loss: 0.9744 - val_accuracy: 0.5363\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9724 - accuracy: 0.5300 - val_loss: 0.9737 - val_accuracy: 0.5332\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9725 - accuracy: 0.5302 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9724 - accuracy: 0.5302 - val_loss: 0.9746 - val_accuracy: 0.5354\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 0.9739 - val_accuracy: 0.5363\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9725 - accuracy: 0.5299 - val_loss: 0.9737 - val_accuracy: 0.5358\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9724 - accuracy: 0.5296 - val_loss: 0.9741 - val_accuracy: 0.5354\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9725 - accuracy: 0.5304 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9724 - accuracy: 0.5299 - val_loss: 0.9744 - val_accuracy: 0.5376\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9724 - accuracy: 0.5313 - val_loss: 0.9746 - val_accuracy: 0.5358\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 557us/step - loss: 0.9726 - accuracy: 0.5296 - val_loss: 0.9736 - val_accuracy: 0.5381\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9724 - accuracy: 0.5309 - val_loss: 0.9746 - val_accuracy: 0.5358\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9724 - accuracy: 0.5299 - val_loss: 0.9745 - val_accuracy: 0.5363\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9724 - accuracy: 0.5303 - val_loss: 0.9737 - val_accuracy: 0.5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9723 - accuracy: 0.5309 - val_loss: 0.9746 - val_accuracy: 0.5358\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9725 - accuracy: 0.5298 - val_loss: 0.9743 - val_accuracy: 0.5363\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9722 - accuracy: 0.5295 - val_loss: 0.9754 - val_accuracy: 0.5341\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9724 - accuracy: 0.5308 - val_loss: 0.9735 - val_accuracy: 0.5345\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9725 - accuracy: 0.5300 - val_loss: 0.9738 - val_accuracy: 0.5332\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9724 - accuracy: 0.5300 - val_loss: 0.9745 - val_accuracy: 0.5381\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9724 - accuracy: 0.5304 - val_loss: 0.9739 - val_accuracy: 0.5350\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9722 - accuracy: 0.5309 - val_loss: 0.9769 - val_accuracy: 0.5345\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9724 - accuracy: 0.5302 - val_loss: 0.9758 - val_accuracy: 0.5332\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9723 - accuracy: 0.5311 - val_loss: 0.9740 - val_accuracy: 0.5332\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9722 - accuracy: 0.5309 - val_loss: 0.9732 - val_accuracy: 0.5354\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9724 - accuracy: 0.5287 - val_loss: 0.9743 - val_accuracy: 0.5358\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 345us/step - loss: 0.9721 - accuracy: 0.5306\n",
      "Accuracy : 0.530592143535614\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9743 - accuracy: 0.5358\n",
      "Accuracy : 0.5358406901359558\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 665us/step - loss: 1.0735 - accuracy: 0.4248 - val_loss: 1.0632 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 1.0600 - accuracy: 0.4591 - val_loss: 1.0568 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 1.0423 - accuracy: 0.4591 - val_loss: 1.0330 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 1.0077 - accuracy: 0.5139 - val_loss: 1.0114 - val_accuracy: 0.5228\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9895 - accuracy: 0.5315 - val_loss: 1.0088 - val_accuracy: 0.5188\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9844 - accuracy: 0.5304 - val_loss: 1.0049 - val_accuracy: 0.5219\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9807 - accuracy: 0.5315 - val_loss: 1.0030 - val_accuracy: 0.5215\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9783 - accuracy: 0.5323 - val_loss: 1.0014 - val_accuracy: 0.5215\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9766 - accuracy: 0.5324 - val_loss: 1.0008 - val_accuracy: 0.5215\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9755 - accuracy: 0.5322 - val_loss: 1.0005 - val_accuracy: 0.5215\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9743 - accuracy: 0.5308 - val_loss: 1.0004 - val_accuracy: 0.5224\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9738 - accuracy: 0.5322 - val_loss: 1.0003 - val_accuracy: 0.5210\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5320 - val_loss: 1.0004 - val_accuracy: 0.5224\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9727 - accuracy: 0.5307 - val_loss: 1.0000 - val_accuracy: 0.5210\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9722 - accuracy: 0.5313 - val_loss: 1.0002 - val_accuracy: 0.5206\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9721 - accuracy: 0.5300 - val_loss: 1.0006 - val_accuracy: 0.5219\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9718 - accuracy: 0.5310 - val_loss: 1.0000 - val_accuracy: 0.5228\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9717 - accuracy: 0.5307 - val_loss: 1.0002 - val_accuracy: 0.5224\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9713 - accuracy: 0.5319 - val_loss: 1.0013 - val_accuracy: 0.5197\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9710 - accuracy: 0.5317 - val_loss: 1.0004 - val_accuracy: 0.5210\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9712 - accuracy: 0.5310 - val_loss: 1.0003 - val_accuracy: 0.5224\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5306 - val_loss: 1.0006 - val_accuracy: 0.5206\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9711 - accuracy: 0.5310 - val_loss: 0.9998 - val_accuracy: 0.5232\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9709 - accuracy: 0.5308 - val_loss: 1.0001 - val_accuracy: 0.5206\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9709 - accuracy: 0.5313 - val_loss: 1.0005 - val_accuracy: 0.5228\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9708 - accuracy: 0.5309 - val_loss: 0.9996 - val_accuracy: 0.5224\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9707 - accuracy: 0.5307 - val_loss: 1.0006 - val_accuracy: 0.5224\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9706 - accuracy: 0.5309 - val_loss: 1.0013 - val_accuracy: 0.5224\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9706 - accuracy: 0.5304 - val_loss: 1.0007 - val_accuracy: 0.5224\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9707 - accuracy: 0.5311 - val_loss: 1.0006 - val_accuracy: 0.5224\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 554us/step - loss: 0.9705 - accuracy: 0.5309 - val_loss: 0.9997 - val_accuracy: 0.5224\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9704 - accuracy: 0.5304 - val_loss: 1.0008 - val_accuracy: 0.5206\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9705 - accuracy: 0.5313 - val_loss: 0.9998 - val_accuracy: 0.5228\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9702 - accuracy: 0.5307 - val_loss: 0.9999 - val_accuracy: 0.5215\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9704 - accuracy: 0.5324 - val_loss: 1.0002 - val_accuracy: 0.5219\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9703 - accuracy: 0.5315 - val_loss: 1.0012 - val_accuracy: 0.5197\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9702 - accuracy: 0.5310 - val_loss: 0.9997 - val_accuracy: 0.5206\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9703 - accuracy: 0.5320 - val_loss: 1.0003 - val_accuracy: 0.5201\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9703 - accuracy: 0.5311 - val_loss: 1.0002 - val_accuracy: 0.5219\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9702 - accuracy: 0.5313 - val_loss: 0.9998 - val_accuracy: 0.5224\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9702 - accuracy: 0.5323 - val_loss: 0.9996 - val_accuracy: 0.5224\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9701 - accuracy: 0.5325 - val_loss: 1.0017 - val_accuracy: 0.5197\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 498us/step - loss: 0.9703 - accuracy: 0.5315 - val_loss: 0.9996 - val_accuracy: 0.5228\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9701 - accuracy: 0.5320 - val_loss: 0.9995 - val_accuracy: 0.5219\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9699 - accuracy: 0.5322 - val_loss: 1.0001 - val_accuracy: 0.5215\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9699 - accuracy: 0.5329 - val_loss: 1.0006 - val_accuracy: 0.5206\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9701 - accuracy: 0.5315 - val_loss: 1.0015 - val_accuracy: 0.5206\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9701 - accuracy: 0.5319 - val_loss: 0.9994 - val_accuracy: 0.5228\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9701 - accuracy: 0.5311 - val_loss: 0.9992 - val_accuracy: 0.5219\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9700 - accuracy: 0.5314 - val_loss: 0.9992 - val_accuracy: 0.5228\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9698 - accuracy: 0.5331 - val_loss: 1.0000 - val_accuracy: 0.5219\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9699 - accuracy: 0.5324 - val_loss: 0.9997 - val_accuracy: 0.5219\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9701 - accuracy: 0.5314 - val_loss: 1.0002 - val_accuracy: 0.5241\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9700 - accuracy: 0.5322 - val_loss: 1.0015 - val_accuracy: 0.5197\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9700 - accuracy: 0.5308 - val_loss: 0.9995 - val_accuracy: 0.5219\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9700 - accuracy: 0.5312 - val_loss: 0.9995 - val_accuracy: 0.5210\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9699 - accuracy: 0.5312 - val_loss: 0.9999 - val_accuracy: 0.5219\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9699 - accuracy: 0.5313 - val_loss: 0.9998 - val_accuracy: 0.5224\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9699 - accuracy: 0.5315 - val_loss: 0.9994 - val_accuracy: 0.5228\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9699 - accuracy: 0.5307 - val_loss: 0.9993 - val_accuracy: 0.5206\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9698 - accuracy: 0.5320 - val_loss: 0.9998 - val_accuracy: 0.5228\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9697 - accuracy: 0.5324 - val_loss: 0.9997 - val_accuracy: 0.5237\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9696 - accuracy: 0.5323 - val_loss: 0.9997 - val_accuracy: 0.5241\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9697 - accuracy: 0.5312 - val_loss: 0.9999 - val_accuracy: 0.5232\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9699 - accuracy: 0.5311 - val_loss: 0.9992 - val_accuracy: 0.5215\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9699 - accuracy: 0.5315 - val_loss: 0.9989 - val_accuracy: 0.5219\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9696 - accuracy: 0.5321 - val_loss: 1.0006 - val_accuracy: 0.5219\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9699 - accuracy: 0.5317 - val_loss: 0.9999 - val_accuracy: 0.5210\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9696 - accuracy: 0.5321 - val_loss: 0.9999 - val_accuracy: 0.5215\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9698 - accuracy: 0.5320 - val_loss: 0.9994 - val_accuracy: 0.5215\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9696 - accuracy: 0.5310 - val_loss: 0.9990 - val_accuracy: 0.5219\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9698 - accuracy: 0.5328 - val_loss: 0.9994 - val_accuracy: 0.5215\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9698 - accuracy: 0.5315 - val_loss: 0.9997 - val_accuracy: 0.5215\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9697 - accuracy: 0.5312 - val_loss: 0.9999 - val_accuracy: 0.5228\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9698 - accuracy: 0.5315 - val_loss: 0.9993 - val_accuracy: 0.5228\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9697 - accuracy: 0.5317 - val_loss: 1.0008 - val_accuracy: 0.5210\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9697 - accuracy: 0.5309 - val_loss: 1.0008 - val_accuracy: 0.5219\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9697 - accuracy: 0.5332 - val_loss: 0.9989 - val_accuracy: 0.5219\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 553us/step - loss: 0.9694 - accuracy: 0.5320 - val_loss: 0.9997 - val_accuracy: 0.5210\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9697 - accuracy: 0.5317 - val_loss: 0.9997 - val_accuracy: 0.5237\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9698 - accuracy: 0.5311 - val_loss: 1.0000 - val_accuracy: 0.5224\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9695 - accuracy: 0.5304 - val_loss: 1.0002 - val_accuracy: 0.5224\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9695 - accuracy: 0.5322 - val_loss: 0.9994 - val_accuracy: 0.5215\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5334 - val_loss: 0.9998 - val_accuracy: 0.5224\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9696 - accuracy: 0.5325 - val_loss: 0.9997 - val_accuracy: 0.5219\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9694 - accuracy: 0.5317 - val_loss: 1.0018 - val_accuracy: 0.5219\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9698 - accuracy: 0.5318 - val_loss: 1.0006 - val_accuracy: 0.5224\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9695 - accuracy: 0.5312 - val_loss: 0.9999 - val_accuracy: 0.5224\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5325 - val_loss: 0.9994 - val_accuracy: 0.5201\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5327 - val_loss: 1.0002 - val_accuracy: 0.5215\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9697 - accuracy: 0.5324 - val_loss: 0.9990 - val_accuracy: 0.5215\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9694 - accuracy: 0.5319 - val_loss: 0.9990 - val_accuracy: 0.5219\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5322 - val_loss: 0.9998 - val_accuracy: 0.5201\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9696 - accuracy: 0.5312 - val_loss: 1.0000 - val_accuracy: 0.5215\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5315 - val_loss: 1.0001 - val_accuracy: 0.5215\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9695 - accuracy: 0.5331 - val_loss: 0.9999 - val_accuracy: 0.5219\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9695 - accuracy: 0.5305 - val_loss: 1.0004 - val_accuracy: 0.5215\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9697 - accuracy: 0.5313 - val_loss: 1.0001 - val_accuracy: 0.5210\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 502us/step - loss: 0.9695 - accuracy: 0.5322 - val_loss: 0.9994 - val_accuracy: 0.5219\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9696 - accuracy: 0.5311 - val_loss: 0.9993 - val_accuracy: 0.5219\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9694 - accuracy: 0.5320 - val_loss: 1.0002 - val_accuracy: 0.5219\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9695 - accuracy: 0.5319 - val_loss: 0.9998 - val_accuracy: 0.5219\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9695 - accuracy: 0.5315 - val_loss: 1.0002 - val_accuracy: 0.5219\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9695 - accuracy: 0.5320 - val_loss: 0.9995 - val_accuracy: 0.5215\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9697 - accuracy: 0.5314 - val_loss: 0.9997 - val_accuracy: 0.5232\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9695 - accuracy: 0.5313 - val_loss: 1.0002 - val_accuracy: 0.5215\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9694 - accuracy: 0.5329 - val_loss: 0.9993 - val_accuracy: 0.5228\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9697 - accuracy: 0.5313 - val_loss: 0.9994 - val_accuracy: 0.5241\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9694 - accuracy: 0.5309 - val_loss: 1.0005 - val_accuracy: 0.5237\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9694 - accuracy: 0.5317 - val_loss: 0.9988 - val_accuracy: 0.5201\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9697 - accuracy: 0.5314 - val_loss: 0.9996 - val_accuracy: 0.5219\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9694 - accuracy: 0.5320 - val_loss: 0.9996 - val_accuracy: 0.5210\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9695 - accuracy: 0.5320 - val_loss: 0.9994 - val_accuracy: 0.5219\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9695 - accuracy: 0.5320 - val_loss: 0.9993 - val_accuracy: 0.5219\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9695 - accuracy: 0.5316 - val_loss: 1.0001 - val_accuracy: 0.5241\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9694 - accuracy: 0.5323 - val_loss: 0.9999 - val_accuracy: 0.5224\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9695 - accuracy: 0.5309 - val_loss: 1.0012 - val_accuracy: 0.5215\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5313 - val_loss: 0.9991 - val_accuracy: 0.5210\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9696 - accuracy: 0.5328 - val_loss: 1.0012 - val_accuracy: 0.5215\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9695 - accuracy: 0.5318 - val_loss: 0.9992 - val_accuracy: 0.5219\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9695 - accuracy: 0.5330 - val_loss: 1.0009 - val_accuracy: 0.5219\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9695 - accuracy: 0.5318 - val_loss: 1.0016 - val_accuracy: 0.5201\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9695 - accuracy: 0.5315 - val_loss: 1.0009 - val_accuracy: 0.5219\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9694 - accuracy: 0.5322 - val_loss: 1.0017 - val_accuracy: 0.5228\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5324 - val_loss: 0.9999 - val_accuracy: 0.5219\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9693 - accuracy: 0.5313 - val_loss: 0.9995 - val_accuracy: 0.5241\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9695 - accuracy: 0.5328 - val_loss: 0.9994 - val_accuracy: 0.5210\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9695 - accuracy: 0.5318 - val_loss: 1.0001 - val_accuracy: 0.5215\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 551us/step - loss: 0.9694 - accuracy: 0.5319 - val_loss: 1.0000 - val_accuracy: 0.5219\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9694 - accuracy: 0.5311 - val_loss: 1.0002 - val_accuracy: 0.5219\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9694 - accuracy: 0.5319 - val_loss: 1.0013 - val_accuracy: 0.5215\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9694 - accuracy: 0.5320 - val_loss: 0.9992 - val_accuracy: 0.5215\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9694 - accuracy: 0.5326 - val_loss: 1.0001 - val_accuracy: 0.5219\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5309 - val_loss: 0.9989 - val_accuracy: 0.5206\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9697 - accuracy: 0.5315 - val_loss: 0.9996 - val_accuracy: 0.5215\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9693 - accuracy: 0.5314 - val_loss: 1.0005 - val_accuracy: 0.5215\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5314 - val_loss: 1.0007 - val_accuracy: 0.5219\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9693 - accuracy: 0.5322 - val_loss: 1.0004 - val_accuracy: 0.5219\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9693 - accuracy: 0.5319 - val_loss: 0.9996 - val_accuracy: 0.5219\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9694 - accuracy: 0.5330 - val_loss: 0.9992 - val_accuracy: 0.5210\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9694 - accuracy: 0.5328 - val_loss: 1.0001 - val_accuracy: 0.5224\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9692 - accuracy: 0.5328 - val_loss: 1.0005 - val_accuracy: 0.5215\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9696 - accuracy: 0.5313 - val_loss: 0.9991 - val_accuracy: 0.5210\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9695 - accuracy: 0.5321 - val_loss: 1.0001 - val_accuracy: 0.5219\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9695 - accuracy: 0.5326 - val_loss: 0.9999 - val_accuracy: 0.5224\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9694 - accuracy: 0.5333 - val_loss: 0.9996 - val_accuracy: 0.5219\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9693 - accuracy: 0.5328 - val_loss: 0.9993 - val_accuracy: 0.5215\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9693 - accuracy: 0.5324 - val_loss: 1.0005 - val_accuracy: 0.5237\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9695 - accuracy: 0.5313 - val_loss: 0.9997 - val_accuracy: 0.5219\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9692 - accuracy: 0.5323 - val_loss: 0.9998 - val_accuracy: 0.5219\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9693 - accuracy: 0.5318 - val_loss: 1.0010 - val_accuracy: 0.5219\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9694 - accuracy: 0.5315 - val_loss: 1.0002 - val_accuracy: 0.5210\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9693 - accuracy: 0.5320 - val_loss: 1.0019 - val_accuracy: 0.5188\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9694 - accuracy: 0.5318 - val_loss: 1.0002 - val_accuracy: 0.5219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9693 - accuracy: 0.5327 - val_loss: 1.0006 - val_accuracy: 0.5232\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9693 - accuracy: 0.5322 - val_loss: 0.9998 - val_accuracy: 0.5219\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9693 - accuracy: 0.5329 - val_loss: 1.0003 - val_accuracy: 0.5210\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5315 - val_loss: 1.0011 - val_accuracy: 0.5206\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9694 - accuracy: 0.5324 - val_loss: 1.0006 - val_accuracy: 0.5215\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9694 - accuracy: 0.5322 - val_loss: 0.9997 - val_accuracy: 0.5224\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9691 - accuracy: 0.5322 - val_loss: 1.0011 - val_accuracy: 0.5224\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9693 - accuracy: 0.5312 - val_loss: 0.9996 - val_accuracy: 0.5210\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9693 - accuracy: 0.5312 - val_loss: 0.9996 - val_accuracy: 0.5224\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9692 - accuracy: 0.5317 - val_loss: 0.9992 - val_accuracy: 0.5219\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9694 - accuracy: 0.5316 - val_loss: 1.0015 - val_accuracy: 0.5193\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9694 - accuracy: 0.5318 - val_loss: 1.0007 - val_accuracy: 0.5219\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9692 - accuracy: 0.5319 - val_loss: 1.0001 - val_accuracy: 0.5206\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9693 - accuracy: 0.5322 - val_loss: 1.0001 - val_accuracy: 0.5201\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9695 - accuracy: 0.5313 - val_loss: 0.9995 - val_accuracy: 0.5215\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9692 - accuracy: 0.5317 - val_loss: 0.9992 - val_accuracy: 0.5215\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9692 - accuracy: 0.5315 - val_loss: 1.0008 - val_accuracy: 0.5201\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - ETA: 0s - loss: 0.9697 - accuracy: 0.53 - 0s 498us/step - loss: 0.9694 - accuracy: 0.5315 - val_loss: 1.0004 - val_accuracy: 0.5224\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9693 - accuracy: 0.5323 - val_loss: 1.0002 - val_accuracy: 0.5219\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9693 - accuracy: 0.5319 - val_loss: 1.0001 - val_accuracy: 0.5237\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9692 - accuracy: 0.5319 - val_loss: 1.0010 - val_accuracy: 0.5215\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9694 - accuracy: 0.5313 - val_loss: 1.0000 - val_accuracy: 0.5215\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9694 - accuracy: 0.5316 - val_loss: 0.9996 - val_accuracy: 0.5232\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9694 - accuracy: 0.5323 - val_loss: 1.0000 - val_accuracy: 0.5219\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9691 - accuracy: 0.5323 - val_loss: 1.0002 - val_accuracy: 0.5215\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9694 - accuracy: 0.5318 - val_loss: 1.0000 - val_accuracy: 0.5219\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9691 - accuracy: 0.5323 - val_loss: 0.9996 - val_accuracy: 0.5219\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5320 - val_loss: 1.0002 - val_accuracy: 0.5219\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9693 - accuracy: 0.5319 - val_loss: 0.9990 - val_accuracy: 0.5206\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9693 - accuracy: 0.5318 - val_loss: 1.0002 - val_accuracy: 0.5210\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9692 - accuracy: 0.5323 - val_loss: 1.0008 - val_accuracy: 0.5206\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5306 - val_loss: 1.0006 - val_accuracy: 0.5210\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9693 - accuracy: 0.5327 - val_loss: 1.0000 - val_accuracy: 0.5215\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9695 - accuracy: 0.5308 - val_loss: 0.9999 - val_accuracy: 0.5215\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9693 - accuracy: 0.5317 - val_loss: 1.0012 - val_accuracy: 0.5210\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9694 - accuracy: 0.5327 - val_loss: 0.9996 - val_accuracy: 0.5219\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9693 - accuracy: 0.5314 - val_loss: 1.0018 - val_accuracy: 0.5219\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9692 - accuracy: 0.5321 - val_loss: 0.9995 - val_accuracy: 0.5210\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9692 - accuracy: 0.5324 - val_loss: 1.0015 - val_accuracy: 0.5201\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9693 - accuracy: 0.5315 - val_loss: 1.0001 - val_accuracy: 0.5224\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9691 - accuracy: 0.5314 - val_loss: 1.0001 - val_accuracy: 0.5215\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9691 - accuracy: 0.5319 - val_loss: 1.0021 - val_accuracy: 0.5197\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9692 - accuracy: 0.5317 - val_loss: 1.0000 - val_accuracy: 0.5237\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9693 - accuracy: 0.5319 - val_loss: 0.9996 - val_accuracy: 0.5215\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9694 - accuracy: 0.5330 - val_loss: 1.0003 - val_accuracy: 0.5215\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9692 - accuracy: 0.5316 - val_loss: 0.9996 - val_accuracy: 0.5219\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 344us/step - loss: 0.9693 - accuracy: 0.5318\n",
      "Accuracy : 0.5317956209182739\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9996 - accuracy: 0.5219\n",
      "Accuracy : 0.5219123363494873\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 663us/step - loss: 1.1155 - accuracy: 0.3713 - val_loss: 1.0630 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 1.0583 - accuracy: 0.4591 - val_loss: 1.0555 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 1.0410 - accuracy: 0.4591 - val_loss: 1.0348 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 1.0064 - accuracy: 0.5026 - val_loss: 1.0135 - val_accuracy: 0.5113\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9879 - accuracy: 0.5327 - val_loss: 1.0098 - val_accuracy: 0.5024\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9835 - accuracy: 0.5309 - val_loss: 1.0089 - val_accuracy: 0.5069\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9814 - accuracy: 0.5315 - val_loss: 1.0075 - val_accuracy: 0.5011\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9794 - accuracy: 0.5328 - val_loss: 1.0061 - val_accuracy: 0.5077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9778 - accuracy: 0.5330 - val_loss: 1.0058 - val_accuracy: 0.5108\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9764 - accuracy: 0.5341 - val_loss: 1.0060 - val_accuracy: 0.5135\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9755 - accuracy: 0.5340 - val_loss: 1.0049 - val_accuracy: 0.5100\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9748 - accuracy: 0.5327 - val_loss: 1.0047 - val_accuracy: 0.5077\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9741 - accuracy: 0.5345 - val_loss: 1.0044 - val_accuracy: 0.5108\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9738 - accuracy: 0.5331 - val_loss: 1.0045 - val_accuracy: 0.5131\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9734 - accuracy: 0.5332 - val_loss: 1.0037 - val_accuracy: 0.5095\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5335 - val_loss: 1.0041 - val_accuracy: 0.5117\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9727 - accuracy: 0.5314 - val_loss: 1.0037 - val_accuracy: 0.5095\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9725 - accuracy: 0.5324 - val_loss: 1.0041 - val_accuracy: 0.5095\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9725 - accuracy: 0.5327 - val_loss: 1.0035 - val_accuracy: 0.5095\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9721 - accuracy: 0.5324 - val_loss: 1.0037 - val_accuracy: 0.5131\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9720 - accuracy: 0.5320 - val_loss: 1.0033 - val_accuracy: 0.5122\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9718 - accuracy: 0.5323 - val_loss: 1.0043 - val_accuracy: 0.5104\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9720 - accuracy: 0.5322 - val_loss: 1.0034 - val_accuracy: 0.5104\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9716 - accuracy: 0.5322 - val_loss: 1.0034 - val_accuracy: 0.5104\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 1.0030 - val_accuracy: 0.5095\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9716 - accuracy: 0.5331 - val_loss: 1.0034 - val_accuracy: 0.5113\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9713 - accuracy: 0.5323 - val_loss: 1.0031 - val_accuracy: 0.5091\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9715 - accuracy: 0.5322 - val_loss: 1.0032 - val_accuracy: 0.5095\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9713 - accuracy: 0.5325 - val_loss: 1.0049 - val_accuracy: 0.5122\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9712 - accuracy: 0.5325 - val_loss: 1.0040 - val_accuracy: 0.5144\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9711 - accuracy: 0.5319 - val_loss: 1.0031 - val_accuracy: 0.5091\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5318 - val_loss: 1.0034 - val_accuracy: 0.5126\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9711 - accuracy: 0.5318 - val_loss: 1.0036 - val_accuracy: 0.5095\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9710 - accuracy: 0.5328 - val_loss: 1.0036 - val_accuracy: 0.5073\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9710 - accuracy: 0.5325 - val_loss: 1.0038 - val_accuracy: 0.5135\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 1.0039 - val_accuracy: 0.5082\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9711 - accuracy: 0.5322 - val_loss: 1.0032 - val_accuracy: 0.5139\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9709 - accuracy: 0.5318 - val_loss: 1.0041 - val_accuracy: 0.5113\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9707 - accuracy: 0.5319 - val_loss: 1.0031 - val_accuracy: 0.5122\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9708 - accuracy: 0.5327 - val_loss: 1.0032 - val_accuracy: 0.5091\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5318 - val_loss: 1.0033 - val_accuracy: 0.5095\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9707 - accuracy: 0.5322 - val_loss: 1.0032 - val_accuracy: 0.5086\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9706 - accuracy: 0.5318 - val_loss: 1.0045 - val_accuracy: 0.5117\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9707 - accuracy: 0.5319 - val_loss: 1.0033 - val_accuracy: 0.5086\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9706 - accuracy: 0.5332 - val_loss: 1.0037 - val_accuracy: 0.5148\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9706 - accuracy: 0.5325 - val_loss: 1.0032 - val_accuracy: 0.5148\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9708 - accuracy: 0.5325 - val_loss: 1.0032 - val_accuracy: 0.5077\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9705 - accuracy: 0.5316 - val_loss: 1.0027 - val_accuracy: 0.5095\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9706 - accuracy: 0.5331 - val_loss: 1.0041 - val_accuracy: 0.5126\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9705 - accuracy: 0.5328 - val_loss: 1.0034 - val_accuracy: 0.5086\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9704 - accuracy: 0.5322 - val_loss: 1.0039 - val_accuracy: 0.5073\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9705 - accuracy: 0.5337 - val_loss: 1.0032 - val_accuracy: 0.5091\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9705 - accuracy: 0.5314 - val_loss: 1.0034 - val_accuracy: 0.5086\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9706 - accuracy: 0.5316 - val_loss: 1.0026 - val_accuracy: 0.5086\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9703 - accuracy: 0.5310 - val_loss: 1.0031 - val_accuracy: 0.5086\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9705 - accuracy: 0.5336 - val_loss: 1.0026 - val_accuracy: 0.5104\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9702 - accuracy: 0.5324 - val_loss: 1.0029 - val_accuracy: 0.5091\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9703 - accuracy: 0.5318 - val_loss: 1.0036 - val_accuracy: 0.5131\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9704 - accuracy: 0.5318 - val_loss: 1.0025 - val_accuracy: 0.5091\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9703 - accuracy: 0.5321 - val_loss: 1.0027 - val_accuracy: 0.5086\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9703 - accuracy: 0.5321 - val_loss: 1.0029 - val_accuracy: 0.5086\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9702 - accuracy: 0.5320 - val_loss: 1.0031 - val_accuracy: 0.5086\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9702 - accuracy: 0.5330 - val_loss: 1.0029 - val_accuracy: 0.5117\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9700 - accuracy: 0.5326 - val_loss: 1.0041 - val_accuracy: 0.5077\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 499us/step - loss: 0.9702 - accuracy: 0.5318 - val_loss: 1.0023 - val_accuracy: 0.5086\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9704 - accuracy: 0.5313 - val_loss: 1.0024 - val_accuracy: 0.5113\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9700 - accuracy: 0.5329 - val_loss: 1.0021 - val_accuracy: 0.5086\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9701 - accuracy: 0.5315 - val_loss: 1.0028 - val_accuracy: 0.5095\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9701 - accuracy: 0.5321 - val_loss: 1.0028 - val_accuracy: 0.5113\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9701 - accuracy: 0.5328 - val_loss: 1.0026 - val_accuracy: 0.5073\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9700 - accuracy: 0.5340 - val_loss: 1.0021 - val_accuracy: 0.5086\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9702 - accuracy: 0.5325 - val_loss: 1.0023 - val_accuracy: 0.5126\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9703 - accuracy: 0.5328 - val_loss: 1.0030 - val_accuracy: 0.5135\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9700 - accuracy: 0.5335 - val_loss: 1.0031 - val_accuracy: 0.5069\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9702 - accuracy: 0.5325 - val_loss: 1.0021 - val_accuracy: 0.5126\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9702 - accuracy: 0.5330 - val_loss: 1.0023 - val_accuracy: 0.5113\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9702 - accuracy: 0.5320 - val_loss: 1.0023 - val_accuracy: 0.5126\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9699 - accuracy: 0.5327 - val_loss: 1.0022 - val_accuracy: 0.5113\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9699 - accuracy: 0.5313 - val_loss: 1.0024 - val_accuracy: 0.5095\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9699 - accuracy: 0.5326 - val_loss: 1.0022 - val_accuracy: 0.5095\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9699 - accuracy: 0.5334 - val_loss: 1.0032 - val_accuracy: 0.5144\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9700 - accuracy: 0.5321 - val_loss: 1.0018 - val_accuracy: 0.5113\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9699 - accuracy: 0.5325 - val_loss: 1.0025 - val_accuracy: 0.5091\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9700 - accuracy: 0.5324 - val_loss: 1.0026 - val_accuracy: 0.5113\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9698 - accuracy: 0.5342 - val_loss: 1.0020 - val_accuracy: 0.5144\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9700 - accuracy: 0.5304 - val_loss: 1.0024 - val_accuracy: 0.5091\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9701 - accuracy: 0.5325 - val_loss: 1.0023 - val_accuracy: 0.5144\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9699 - accuracy: 0.5325 - val_loss: 1.0026 - val_accuracy: 0.5122\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9701 - accuracy: 0.5330 - val_loss: 1.0031 - val_accuracy: 0.5126\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9699 - accuracy: 0.5324 - val_loss: 1.0020 - val_accuracy: 0.5100\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9698 - accuracy: 0.5333 - val_loss: 1.0031 - val_accuracy: 0.5073\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9695 - accuracy: 0.5321 - val_loss: 1.0032 - val_accuracy: 0.5139\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9701 - accuracy: 0.5321 - val_loss: 1.0021 - val_accuracy: 0.5131\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9696 - accuracy: 0.5333 - val_loss: 1.0033 - val_accuracy: 0.5064\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9699 - accuracy: 0.5314 - val_loss: 1.0019 - val_accuracy: 0.5104\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9696 - accuracy: 0.5321 - val_loss: 1.0018 - val_accuracy: 0.5086\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5335 - val_loss: 1.0018 - val_accuracy: 0.5077\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9699 - accuracy: 0.5319 - val_loss: 1.0026 - val_accuracy: 0.5135\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9699 - accuracy: 0.5322 - val_loss: 1.0020 - val_accuracy: 0.5091\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9698 - accuracy: 0.5325 - val_loss: 1.0018 - val_accuracy: 0.5100\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9697 - accuracy: 0.5324 - val_loss: 1.0016 - val_accuracy: 0.5091\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9699 - accuracy: 0.5323 - val_loss: 1.0030 - val_accuracy: 0.5064\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9697 - accuracy: 0.5321 - val_loss: 1.0028 - val_accuracy: 0.5086\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9698 - accuracy: 0.5332 - val_loss: 1.0013 - val_accuracy: 0.5091\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9697 - accuracy: 0.5322 - val_loss: 1.0019 - val_accuracy: 0.5086\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9699 - accuracy: 0.5332 - val_loss: 1.0024 - val_accuracy: 0.5144\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9699 - accuracy: 0.5326 - val_loss: 1.0016 - val_accuracy: 0.5095\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9698 - accuracy: 0.5325 - val_loss: 1.0014 - val_accuracy: 0.5095\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9697 - accuracy: 0.5319 - val_loss: 1.0013 - val_accuracy: 0.5091\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9696 - accuracy: 0.5325 - val_loss: 1.0014 - val_accuracy: 0.5100\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9697 - accuracy: 0.5323 - val_loss: 1.0012 - val_accuracy: 0.5095\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9695 - accuracy: 0.5322 - val_loss: 1.0020 - val_accuracy: 0.5126\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9697 - accuracy: 0.5325 - val_loss: 1.0015 - val_accuracy: 0.5100\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9696 - accuracy: 0.5316 - val_loss: 1.0031 - val_accuracy: 0.5131\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9698 - accuracy: 0.5326 - val_loss: 1.0021 - val_accuracy: 0.5139\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9696 - accuracy: 0.5331 - val_loss: 1.0015 - val_accuracy: 0.5104\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9698 - accuracy: 0.5323 - val_loss: 1.0017 - val_accuracy: 0.5086\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9696 - accuracy: 0.5325 - val_loss: 1.0016 - val_accuracy: 0.5091\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5328 - val_loss: 1.0022 - val_accuracy: 0.5108\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9696 - accuracy: 0.5334 - val_loss: 1.0017 - val_accuracy: 0.5122\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 499us/step - loss: 0.9696 - accuracy: 0.5327 - val_loss: 1.0016 - val_accuracy: 0.5122\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5335 - val_loss: 1.0014 - val_accuracy: 0.5144\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 550us/step - loss: 0.9695 - accuracy: 0.5331 - val_loss: 1.0018 - val_accuracy: 0.5082\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9696 - accuracy: 0.5327 - val_loss: 1.0019 - val_accuracy: 0.5122\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9694 - accuracy: 0.5326 - val_loss: 1.0017 - val_accuracy: 0.5126\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9697 - accuracy: 0.5323 - val_loss: 1.0013 - val_accuracy: 0.5108\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9696 - accuracy: 0.5329 - val_loss: 1.0021 - val_accuracy: 0.5073\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9695 - accuracy: 0.5338 - val_loss: 1.0010 - val_accuracy: 0.5095\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5329 - val_loss: 1.0015 - val_accuracy: 0.5091\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9696 - accuracy: 0.5318 - val_loss: 1.0015 - val_accuracy: 0.5104\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5334 - val_loss: 1.0012 - val_accuracy: 0.5100\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9696 - accuracy: 0.5323 - val_loss: 1.0014 - val_accuracy: 0.5077\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9695 - accuracy: 0.5328 - val_loss: 1.0011 - val_accuracy: 0.5095\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9697 - accuracy: 0.5333 - val_loss: 1.0017 - val_accuracy: 0.5086\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9696 - accuracy: 0.5330 - val_loss: 1.0010 - val_accuracy: 0.5108\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9695 - accuracy: 0.5327 - val_loss: 1.0012 - val_accuracy: 0.5117\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9697 - accuracy: 0.5329 - val_loss: 1.0010 - val_accuracy: 0.5077\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9696 - accuracy: 0.5322 - val_loss: 1.0007 - val_accuracy: 0.5117\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9697 - accuracy: 0.5328 - val_loss: 1.0014 - val_accuracy: 0.5108\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9696 - accuracy: 0.5317 - val_loss: 1.0018 - val_accuracy: 0.5108\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5322 - val_loss: 1.0009 - val_accuracy: 0.5077\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9696 - accuracy: 0.5324 - val_loss: 1.0014 - val_accuracy: 0.5104\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9695 - accuracy: 0.5328 - val_loss: 1.0013 - val_accuracy: 0.5095\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5326 - val_loss: 1.0008 - val_accuracy: 0.5117\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9697 - accuracy: 0.5330 - val_loss: 1.0009 - val_accuracy: 0.5126\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5327 - val_loss: 1.0007 - val_accuracy: 0.5113\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9697 - accuracy: 0.5330 - val_loss: 1.0012 - val_accuracy: 0.5082\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9696 - accuracy: 0.5320 - val_loss: 1.0009 - val_accuracy: 0.5100\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9694 - accuracy: 0.5321 - val_loss: 1.0010 - val_accuracy: 0.5100\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5326 - val_loss: 1.0022 - val_accuracy: 0.5073\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9695 - accuracy: 0.5328 - val_loss: 1.0013 - val_accuracy: 0.5135\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9694 - accuracy: 0.5327 - val_loss: 1.0011 - val_accuracy: 0.5117\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9697 - accuracy: 0.5336 - val_loss: 1.0017 - val_accuracy: 0.5117\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9697 - accuracy: 0.5317 - val_loss: 1.0007 - val_accuracy: 0.5100\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9696 - accuracy: 0.5329 - val_loss: 1.0014 - val_accuracy: 0.5131\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9695 - accuracy: 0.5324 - val_loss: 1.0012 - val_accuracy: 0.5095\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9695 - accuracy: 0.5315 - val_loss: 1.0010 - val_accuracy: 0.5108\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5322 - val_loss: 1.0010 - val_accuracy: 0.5108\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9695 - accuracy: 0.5324 - val_loss: 1.0008 - val_accuracy: 0.5077\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9695 - accuracy: 0.5328 - val_loss: 1.0013 - val_accuracy: 0.5095\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9696 - accuracy: 0.5326 - val_loss: 1.0007 - val_accuracy: 0.5122\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5340 - val_loss: 1.0006 - val_accuracy: 0.5104\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9694 - accuracy: 0.5325 - val_loss: 1.0012 - val_accuracy: 0.5100\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9695 - accuracy: 0.5327 - val_loss: 1.0019 - val_accuracy: 0.5144\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9697 - accuracy: 0.5322 - val_loss: 1.0019 - val_accuracy: 0.5131\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9695 - accuracy: 0.5330 - val_loss: 1.0008 - val_accuracy: 0.5095\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9695 - accuracy: 0.5314 - val_loss: 1.0008 - val_accuracy: 0.5100\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9694 - accuracy: 0.5329 - val_loss: 1.0008 - val_accuracy: 0.5126\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9696 - accuracy: 0.5323 - val_loss: 1.0009 - val_accuracy: 0.5126\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9694 - accuracy: 0.5333 - val_loss: 1.0010 - val_accuracy: 0.5095\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9696 - accuracy: 0.5325 - val_loss: 1.0010 - val_accuracy: 0.5095\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9695 - accuracy: 0.5330 - val_loss: 1.0012 - val_accuracy: 0.5100\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9697 - accuracy: 0.5335 - val_loss: 1.0006 - val_accuracy: 0.5135\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9696 - accuracy: 0.5322 - val_loss: 1.0011 - val_accuracy: 0.5104\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9696 - accuracy: 0.5323 - val_loss: 1.0009 - val_accuracy: 0.5108\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9695 - accuracy: 0.5337 - val_loss: 1.0006 - val_accuracy: 0.5113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9692 - accuracy: 0.5324 - val_loss: 1.0016 - val_accuracy: 0.5117\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9695 - accuracy: 0.5326 - val_loss: 1.0009 - val_accuracy: 0.5095\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5317 - val_loss: 1.0008 - val_accuracy: 0.5095\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9694 - accuracy: 0.5328 - val_loss: 1.0013 - val_accuracy: 0.5095\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9693 - accuracy: 0.5342 - val_loss: 1.0012 - val_accuracy: 0.5100\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9695 - accuracy: 0.5325 - val_loss: 1.0010 - val_accuracy: 0.5131\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9694 - accuracy: 0.5330 - val_loss: 1.0006 - val_accuracy: 0.5113\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9695 - accuracy: 0.5326 - val_loss: 1.0011 - val_accuracy: 0.5100\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9695 - accuracy: 0.5323 - val_loss: 1.0007 - val_accuracy: 0.5131\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9694 - accuracy: 0.5332 - val_loss: 1.0013 - val_accuracy: 0.5091\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9695 - accuracy: 0.5326 - val_loss: 1.0006 - val_accuracy: 0.5100\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9694 - accuracy: 0.5334 - val_loss: 1.0014 - val_accuracy: 0.5095\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9695 - accuracy: 0.5332 - val_loss: 1.0013 - val_accuracy: 0.5100\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9695 - accuracy: 0.5328 - val_loss: 1.0009 - val_accuracy: 0.5091\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9695 - accuracy: 0.5329 - val_loss: 1.0011 - val_accuracy: 0.5135\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9694 - accuracy: 0.5332 - val_loss: 1.0010 - val_accuracy: 0.5100\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9695 - accuracy: 0.5326 - val_loss: 1.0011 - val_accuracy: 0.5100\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9694 - accuracy: 0.5329 - val_loss: 1.0015 - val_accuracy: 0.5108\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9694 - accuracy: 0.5328 - val_loss: 1.0014 - val_accuracy: 0.5135\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9694 - accuracy: 0.5328 - val_loss: 1.0005 - val_accuracy: 0.5104\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9695 - accuracy: 0.5332 - val_loss: 1.0013 - val_accuracy: 0.5100\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9694 - accuracy: 0.5332 - val_loss: 1.0005 - val_accuracy: 0.5135\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9694 - accuracy: 0.5329 - val_loss: 1.0014 - val_accuracy: 0.5117\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9694 - accuracy: 0.5337 - val_loss: 1.0015 - val_accuracy: 0.5117\n",
      "\n",
      "Train split:\n",
      "  1/636 [..............................] - ETA: 0s - loss: 1.1969 - accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "636/636 [==============================] - 0s 352us/step - loss: 0.9694 - accuracy: 0.5315\n",
      "Accuracy : 0.5314513444900513\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0015 - accuracy: 0.5117\n",
      "Accuracy : 0.5117308497428894\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 658us/step - loss: 1.0673 - accuracy: 0.4214 - val_loss: 1.0400 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 1.0170 - accuracy: 0.4986 - val_loss: 1.0089 - val_accuracy: 0.5237\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9915 - accuracy: 0.5313 - val_loss: 0.9984 - val_accuracy: 0.5215\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9846 - accuracy: 0.5310 - val_loss: 0.9965 - val_accuracy: 0.5157\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9816 - accuracy: 0.5308 - val_loss: 0.9944 - val_accuracy: 0.5170\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9794 - accuracy: 0.5321 - val_loss: 0.9925 - val_accuracy: 0.5215\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9776 - accuracy: 0.5326 - val_loss: 0.9915 - val_accuracy: 0.5232\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9765 - accuracy: 0.5322 - val_loss: 0.9913 - val_accuracy: 0.5215\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9756 - accuracy: 0.5318 - val_loss: 0.9903 - val_accuracy: 0.5201\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9748 - accuracy: 0.5328 - val_loss: 0.9896 - val_accuracy: 0.5237\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9743 - accuracy: 0.5319 - val_loss: 0.9893 - val_accuracy: 0.5241\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9740 - accuracy: 0.5317 - val_loss: 0.9895 - val_accuracy: 0.5210\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9734 - accuracy: 0.5317 - val_loss: 0.9887 - val_accuracy: 0.5272\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9733 - accuracy: 0.5326 - val_loss: 0.9888 - val_accuracy: 0.5232\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9730 - accuracy: 0.5317 - val_loss: 0.9883 - val_accuracy: 0.5272\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9727 - accuracy: 0.5302 - val_loss: 0.9893 - val_accuracy: 0.5228\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9727 - accuracy: 0.5313 - val_loss: 0.9882 - val_accuracy: 0.5286\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9726 - accuracy: 0.5316 - val_loss: 0.9896 - val_accuracy: 0.5237\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9723 - accuracy: 0.5326 - val_loss: 0.9897 - val_accuracy: 0.5263\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9723 - accuracy: 0.5311 - val_loss: 0.9888 - val_accuracy: 0.5228\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9721 - accuracy: 0.5312 - val_loss: 0.9880 - val_accuracy: 0.5277\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9719 - accuracy: 0.5307 - val_loss: 0.9883 - val_accuracy: 0.5232\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9878 - val_accuracy: 0.5281\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9719 - accuracy: 0.5308 - val_loss: 0.9882 - val_accuracy: 0.5241\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9722 - accuracy: 0.5313 - val_loss: 0.9880 - val_accuracy: 0.5277\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9719 - accuracy: 0.5315 - val_loss: 0.9878 - val_accuracy: 0.5268\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9720 - accuracy: 0.5298 - val_loss: 0.9881 - val_accuracy: 0.5277\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9718 - accuracy: 0.5307 - val_loss: 0.9881 - val_accuracy: 0.5241\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9879 - val_accuracy: 0.5268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9719 - accuracy: 0.5311 - val_loss: 0.9881 - val_accuracy: 0.5241\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9718 - accuracy: 0.5305 - val_loss: 0.9878 - val_accuracy: 0.5272\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9716 - accuracy: 0.5308 - val_loss: 0.9879 - val_accuracy: 0.5272\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9715 - accuracy: 0.5308 - val_loss: 0.9893 - val_accuracy: 0.5215\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9717 - accuracy: 0.5300 - val_loss: 0.9879 - val_accuracy: 0.5272\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9716 - accuracy: 0.5307 - val_loss: 0.9885 - val_accuracy: 0.5237\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9716 - accuracy: 0.5314 - val_loss: 0.9878 - val_accuracy: 0.5263\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9717 - accuracy: 0.5311 - val_loss: 0.9881 - val_accuracy: 0.5277\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9718 - accuracy: 0.5303 - val_loss: 0.9881 - val_accuracy: 0.5263\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9717 - accuracy: 0.5301 - val_loss: 0.9876 - val_accuracy: 0.5263\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9716 - accuracy: 0.5296 - val_loss: 0.9879 - val_accuracy: 0.5277\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9715 - accuracy: 0.5314 - val_loss: 0.9882 - val_accuracy: 0.5272\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9714 - accuracy: 0.5310 - val_loss: 0.9878 - val_accuracy: 0.5268\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9717 - accuracy: 0.5309 - val_loss: 0.9886 - val_accuracy: 0.5237\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9716 - accuracy: 0.5312 - val_loss: 0.9883 - val_accuracy: 0.5268\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9878 - val_accuracy: 0.5259\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9716 - accuracy: 0.5303 - val_loss: 0.9879 - val_accuracy: 0.5281\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9715 - accuracy: 0.5317 - val_loss: 0.9880 - val_accuracy: 0.5268\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9717 - accuracy: 0.5314 - val_loss: 0.9878 - val_accuracy: 0.5272\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9715 - accuracy: 0.5314 - val_loss: 0.9880 - val_accuracy: 0.5272\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9717 - accuracy: 0.5319 - val_loss: 0.9879 - val_accuracy: 0.5281\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9715 - accuracy: 0.5314 - val_loss: 0.9888 - val_accuracy: 0.5228\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9715 - accuracy: 0.5311 - val_loss: 0.9891 - val_accuracy: 0.5201\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9714 - accuracy: 0.5310 - val_loss: 0.9883 - val_accuracy: 0.5259\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 0.9882 - val_accuracy: 0.5241\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9714 - accuracy: 0.5315 - val_loss: 0.9883 - val_accuracy: 0.5237\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5310 - val_loss: 0.9885 - val_accuracy: 0.5232\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9715 - accuracy: 0.5321 - val_loss: 0.9877 - val_accuracy: 0.5277\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9712 - accuracy: 0.5321 - val_loss: 0.9882 - val_accuracy: 0.5232\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5312 - val_loss: 0.9881 - val_accuracy: 0.5263\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9715 - accuracy: 0.5318 - val_loss: 0.9880 - val_accuracy: 0.5281\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9714 - accuracy: 0.5306 - val_loss: 0.9886 - val_accuracy: 0.5272\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5311 - val_loss: 0.9880 - val_accuracy: 0.5277\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9714 - accuracy: 0.5315 - val_loss: 0.9882 - val_accuracy: 0.5250\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9714 - accuracy: 0.5307 - val_loss: 0.9879 - val_accuracy: 0.5268\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9716 - accuracy: 0.5311 - val_loss: 0.9880 - val_accuracy: 0.5237\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9714 - accuracy: 0.5310 - val_loss: 0.9880 - val_accuracy: 0.5232\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9714 - accuracy: 0.5313 - val_loss: 0.9883 - val_accuracy: 0.5263\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5307 - val_loss: 0.9878 - val_accuracy: 0.5259\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 561us/step - loss: 0.9715 - accuracy: 0.5314 - val_loss: 0.9883 - val_accuracy: 0.5259\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9711 - accuracy: 0.5325 - val_loss: 0.9881 - val_accuracy: 0.5237\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9712 - accuracy: 0.5312 - val_loss: 0.9877 - val_accuracy: 0.5259\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9714 - accuracy: 0.5316 - val_loss: 0.9879 - val_accuracy: 0.5263\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5322 - val_loss: 0.9886 - val_accuracy: 0.5237\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 0.9888 - val_accuracy: 0.5228\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9712 - accuracy: 0.5319 - val_loss: 0.9888 - val_accuracy: 0.5263\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9714 - accuracy: 0.5308 - val_loss: 0.9881 - val_accuracy: 0.5277\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5313 - val_loss: 0.9885 - val_accuracy: 0.5259\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9713 - accuracy: 0.5308 - val_loss: 0.9880 - val_accuracy: 0.5268\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5315 - val_loss: 0.9878 - val_accuracy: 0.5272\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5316 - val_loss: 0.9880 - val_accuracy: 0.5232\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5318 - val_loss: 0.9881 - val_accuracy: 0.5263\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9712 - accuracy: 0.5321 - val_loss: 0.9880 - val_accuracy: 0.5268\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9713 - accuracy: 0.5318 - val_loss: 0.9882 - val_accuracy: 0.5232\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5322 - val_loss: 0.9884 - val_accuracy: 0.5232\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9712 - accuracy: 0.5311 - val_loss: 0.9881 - val_accuracy: 0.5224\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 499us/step - loss: 0.9713 - accuracy: 0.5309 - val_loss: 0.9879 - val_accuracy: 0.5263\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9714 - accuracy: 0.5314 - val_loss: 0.9879 - val_accuracy: 0.5268\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5319 - val_loss: 0.9886 - val_accuracy: 0.5232\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9714 - accuracy: 0.5311 - val_loss: 0.9883 - val_accuracy: 0.5228\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9713 - accuracy: 0.5318 - val_loss: 0.9882 - val_accuracy: 0.5237\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5318 - val_loss: 0.9882 - val_accuracy: 0.5259\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5323 - val_loss: 0.9878 - val_accuracy: 0.5268\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5311 - val_loss: 0.9878 - val_accuracy: 0.5277\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9713 - accuracy: 0.5317 - val_loss: 0.9884 - val_accuracy: 0.5250\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5316 - val_loss: 0.9885 - val_accuracy: 0.5228\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5311 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9711 - accuracy: 0.5317 - val_loss: 0.9886 - val_accuracy: 0.5255\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9715 - accuracy: 0.5319 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9713 - accuracy: 0.5325 - val_loss: 0.9881 - val_accuracy: 0.5268\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9714 - accuracy: 0.5315 - val_loss: 0.9885 - val_accuracy: 0.5277\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9712 - accuracy: 0.5315 - val_loss: 0.9879 - val_accuracy: 0.5259\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9710 - accuracy: 0.5308 - val_loss: 0.9884 - val_accuracy: 0.5281\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 0.9881 - val_accuracy: 0.5263\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9713 - accuracy: 0.5310 - val_loss: 0.9887 - val_accuracy: 0.5224\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5317 - val_loss: 0.9882 - val_accuracy: 0.5232\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5315 - val_loss: 0.9883 - val_accuracy: 0.5255\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9714 - accuracy: 0.5312 - val_loss: 0.9879 - val_accuracy: 0.5263\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5318 - val_loss: 0.9882 - val_accuracy: 0.5277\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9713 - accuracy: 0.5311 - val_loss: 0.9887 - val_accuracy: 0.5224\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5321 - val_loss: 0.9885 - val_accuracy: 0.5263\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9712 - accuracy: 0.5316 - val_loss: 0.9881 - val_accuracy: 0.5259\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9711 - accuracy: 0.5318 - val_loss: 0.9879 - val_accuracy: 0.5250\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5313 - val_loss: 0.9883 - val_accuracy: 0.5263\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5314 - val_loss: 0.9881 - val_accuracy: 0.5263\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9711 - accuracy: 0.5317 - val_loss: 0.9885 - val_accuracy: 0.5232\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9711 - accuracy: 0.5324 - val_loss: 0.9881 - val_accuracy: 0.5263\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5310 - val_loss: 0.9879 - val_accuracy: 0.5255\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9711 - accuracy: 0.5319 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9712 - accuracy: 0.5306 - val_loss: 0.9882 - val_accuracy: 0.5241\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9712 - accuracy: 0.5308 - val_loss: 0.9883 - val_accuracy: 0.5250\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9712 - accuracy: 0.5315 - val_loss: 0.9883 - val_accuracy: 0.5272\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9712 - accuracy: 0.5331 - val_loss: 0.9885 - val_accuracy: 0.5272\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5313 - val_loss: 0.9885 - val_accuracy: 0.5268\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9710 - accuracy: 0.5313 - val_loss: 0.9891 - val_accuracy: 0.5259\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9711 - accuracy: 0.5316 - val_loss: 0.9886 - val_accuracy: 0.5272\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5314 - val_loss: 0.9884 - val_accuracy: 0.5272\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5318 - val_loss: 0.9884 - val_accuracy: 0.5228\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5320 - val_loss: 0.9882 - val_accuracy: 0.5277\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5307 - val_loss: 0.9881 - val_accuracy: 0.5259\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9711 - accuracy: 0.5318 - val_loss: 0.9881 - val_accuracy: 0.5268\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9710 - accuracy: 0.5309 - val_loss: 0.9888 - val_accuracy: 0.5228\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9710 - accuracy: 0.5303 - val_loss: 0.9880 - val_accuracy: 0.5263\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 0.9882 - val_accuracy: 0.5272\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9712 - accuracy: 0.5316 - val_loss: 0.9880 - val_accuracy: 0.5272\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9710 - accuracy: 0.5320 - val_loss: 0.9883 - val_accuracy: 0.5228\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9712 - accuracy: 0.5306 - val_loss: 0.9884 - val_accuracy: 0.5268\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9710 - accuracy: 0.5308 - val_loss: 0.9881 - val_accuracy: 0.5263\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9711 - accuracy: 0.5306 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9712 - accuracy: 0.5317 - val_loss: 0.9885 - val_accuracy: 0.5232\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5318 - val_loss: 0.9884 - val_accuracy: 0.5255\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9711 - accuracy: 0.5327 - val_loss: 0.9883 - val_accuracy: 0.5268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9710 - accuracy: 0.5313 - val_loss: 0.9890 - val_accuracy: 0.5215\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9712 - accuracy: 0.5313 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5308 - val_loss: 0.9885 - val_accuracy: 0.5286\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5313 - val_loss: 0.9880 - val_accuracy: 0.5277\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9711 - accuracy: 0.5317 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9710 - accuracy: 0.5317 - val_loss: 0.9889 - val_accuracy: 0.5228\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9710 - accuracy: 0.5319 - val_loss: 0.9887 - val_accuracy: 0.5277\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5321 - val_loss: 0.9887 - val_accuracy: 0.5277\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9712 - accuracy: 0.5311 - val_loss: 0.9880 - val_accuracy: 0.5255\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9711 - accuracy: 0.5319 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5322 - val_loss: 0.9880 - val_accuracy: 0.5277\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5302 - val_loss: 0.9883 - val_accuracy: 0.5255\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9710 - accuracy: 0.5313 - val_loss: 0.9893 - val_accuracy: 0.5206\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9711 - accuracy: 0.5318 - val_loss: 0.9889 - val_accuracy: 0.5224\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9710 - accuracy: 0.5322 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9711 - accuracy: 0.5321 - val_loss: 0.9892 - val_accuracy: 0.5215\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9711 - accuracy: 0.5311 - val_loss: 0.9883 - val_accuracy: 0.5232\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9708 - accuracy: 0.5315 - val_loss: 0.9886 - val_accuracy: 0.5224\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9710 - accuracy: 0.5320 - val_loss: 0.9885 - val_accuracy: 0.5255\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9711 - accuracy: 0.5325 - val_loss: 0.9885 - val_accuracy: 0.5224\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9711 - accuracy: 0.5311 - val_loss: 0.9886 - val_accuracy: 0.5255\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5316 - val_loss: 0.9881 - val_accuracy: 0.5268\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9708 - accuracy: 0.5316 - val_loss: 0.9884 - val_accuracy: 0.5263\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9708 - accuracy: 0.5311 - val_loss: 0.9885 - val_accuracy: 0.5259\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9709 - accuracy: 0.5324 - val_loss: 0.9882 - val_accuracy: 0.5259\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9709 - accuracy: 0.5320 - val_loss: 0.9883 - val_accuracy: 0.5255\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9709 - accuracy: 0.5315 - val_loss: 0.9889 - val_accuracy: 0.5232\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 557us/step - loss: 0.9711 - accuracy: 0.5311 - val_loss: 0.9888 - val_accuracy: 0.5277\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 0.9882 - val_accuracy: 0.5263\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9709 - accuracy: 0.5316 - val_loss: 0.9884 - val_accuracy: 0.5259\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9708 - accuracy: 0.5311 - val_loss: 0.9882 - val_accuracy: 0.5255\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9710 - accuracy: 0.5323 - val_loss: 0.9887 - val_accuracy: 0.5255\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9706 - accuracy: 0.5315 - val_loss: 0.9884 - val_accuracy: 0.5250\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9709 - accuracy: 0.5315 - val_loss: 0.9891 - val_accuracy: 0.5281\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5320 - val_loss: 0.9885 - val_accuracy: 0.5250\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5315 - val_loss: 0.9883 - val_accuracy: 0.5255\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9709 - accuracy: 0.5315 - val_loss: 0.9886 - val_accuracy: 0.5281\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9709 - accuracy: 0.5314 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5315 - val_loss: 0.9885 - val_accuracy: 0.5224\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5330 - val_loss: 0.9882 - val_accuracy: 0.5259\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5321 - val_loss: 0.9880 - val_accuracy: 0.5263\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9710 - accuracy: 0.5308 - val_loss: 0.9884 - val_accuracy: 0.5246\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5325 - val_loss: 0.9881 - val_accuracy: 0.5255\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9710 - accuracy: 0.5317 - val_loss: 0.9884 - val_accuracy: 0.5259\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9708 - accuracy: 0.5311 - val_loss: 0.9884 - val_accuracy: 0.5255\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9711 - accuracy: 0.5314 - val_loss: 0.9886 - val_accuracy: 0.5228\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9708 - accuracy: 0.5316 - val_loss: 0.9893 - val_accuracy: 0.5206\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9708 - accuracy: 0.5318 - val_loss: 0.9886 - val_accuracy: 0.5250\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9710 - accuracy: 0.5318 - val_loss: 0.9885 - val_accuracy: 0.5263\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9708 - accuracy: 0.5315 - val_loss: 0.9892 - val_accuracy: 0.5206\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9708 - accuracy: 0.5315 - val_loss: 0.9886 - val_accuracy: 0.5232\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9709 - accuracy: 0.5313 - val_loss: 0.9882 - val_accuracy: 0.5246\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9709 - accuracy: 0.5312 - val_loss: 0.9884 - val_accuracy: 0.5250\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9708 - accuracy: 0.5313 - val_loss: 0.9891 - val_accuracy: 0.5224\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9709 - accuracy: 0.5319 - val_loss: 0.9889 - val_accuracy: 0.5224\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9708 - accuracy: 0.5318 - val_loss: 0.9891 - val_accuracy: 0.5259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9709 - accuracy: 0.5330 - val_loss: 0.9915 - val_accuracy: 0.5157\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9709 - accuracy: 0.5314 - val_loss: 0.9894 - val_accuracy: 0.5272\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9708 - accuracy: 0.5312 - val_loss: 0.9894 - val_accuracy: 0.5263\n",
      "\n",
      "Train split:\n",
      "  1/636 [..............................] - ETA: 0s - loss: 1.2104 - accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "636/636 [==============================] - 0s 353us/step - loss: 0.9715 - accuracy: 0.5302\n",
      "Accuracy : 0.5301726460456848\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9894 - accuracy: 0.5263\n",
      "Accuracy : 0.5263391137123108\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 679us/step - loss: 1.0487 - accuracy: 0.4591 - val_loss: 1.0260 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 1.0108 - accuracy: 0.4670 - val_loss: 1.0007 - val_accuracy: 0.5104\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9977 - accuracy: 0.5236 - val_loss: 0.9928 - val_accuracy: 0.5414\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9926 - accuracy: 0.5289 - val_loss: 0.9872 - val_accuracy: 0.5365\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9888 - accuracy: 0.5296 - val_loss: 0.9834 - val_accuracy: 0.5392\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9857 - accuracy: 0.5280 - val_loss: 0.9801 - val_accuracy: 0.5374\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9835 - accuracy: 0.5272 - val_loss: 0.9768 - val_accuracy: 0.5370\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9819 - accuracy: 0.5277 - val_loss: 0.9750 - val_accuracy: 0.5378\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9807 - accuracy: 0.5286 - val_loss: 0.9738 - val_accuracy: 0.5396\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9798 - accuracy: 0.5284 - val_loss: 0.9736 - val_accuracy: 0.5405\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9790 - accuracy: 0.5283 - val_loss: 0.9723 - val_accuracy: 0.5427\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9783 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5387\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9777 - accuracy: 0.5296 - val_loss: 0.9707 - val_accuracy: 0.5418\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9703 - val_accuracy: 0.5409\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 563us/step - loss: 0.9768 - accuracy: 0.5281 - val_loss: 0.9700 - val_accuracy: 0.5383\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9766 - accuracy: 0.5294 - val_loss: 0.9695 - val_accuracy: 0.5427\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9699 - val_accuracy: 0.5423\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9760 - accuracy: 0.5299 - val_loss: 0.9693 - val_accuracy: 0.5387\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9685 - val_accuracy: 0.5427\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9682 - val_accuracy: 0.5405\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9755 - accuracy: 0.5286 - val_loss: 0.9682 - val_accuracy: 0.5414\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9753 - accuracy: 0.5304 - val_loss: 0.9681 - val_accuracy: 0.5427\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9751 - accuracy: 0.5291 - val_loss: 0.9697 - val_accuracy: 0.5387\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5284 - val_loss: 0.9677 - val_accuracy: 0.5401\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9752 - accuracy: 0.5290 - val_loss: 0.9681 - val_accuracy: 0.5396\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9680 - val_accuracy: 0.5401\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9749 - accuracy: 0.5297 - val_loss: 0.9679 - val_accuracy: 0.5401\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9674 - val_accuracy: 0.5387\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9748 - accuracy: 0.5299 - val_loss: 0.9672 - val_accuracy: 0.5418\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9747 - accuracy: 0.5307 - val_loss: 0.9676 - val_accuracy: 0.5418\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9747 - accuracy: 0.5289 - val_loss: 0.9675 - val_accuracy: 0.5432\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9746 - accuracy: 0.5295 - val_loss: 0.9674 - val_accuracy: 0.5436\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9746 - accuracy: 0.5299 - val_loss: 0.9674 - val_accuracy: 0.5432\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9745 - accuracy: 0.5292 - val_loss: 0.9672 - val_accuracy: 0.5414\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9746 - accuracy: 0.5286 - val_loss: 0.9672 - val_accuracy: 0.5401\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9746 - accuracy: 0.5285 - val_loss: 0.9676 - val_accuracy: 0.5423\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9745 - accuracy: 0.5290 - val_loss: 0.9677 - val_accuracy: 0.5396\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9745 - accuracy: 0.5299 - val_loss: 0.9680 - val_accuracy: 0.5423\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9745 - accuracy: 0.5295 - val_loss: 0.9671 - val_accuracy: 0.5418\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9743 - accuracy: 0.5305 - val_loss: 0.9682 - val_accuracy: 0.5423\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9744 - accuracy: 0.5292 - val_loss: 0.9671 - val_accuracy: 0.5414\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5296 - val_loss: 0.9674 - val_accuracy: 0.5427\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9671 - val_accuracy: 0.5427\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5291 - val_loss: 0.9668 - val_accuracy: 0.5409\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9743 - accuracy: 0.5296 - val_loss: 0.9668 - val_accuracy: 0.5414\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9744 - accuracy: 0.5293 - val_loss: 0.9684 - val_accuracy: 0.5405\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9743 - accuracy: 0.5295 - val_loss: 0.9668 - val_accuracy: 0.5432\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9743 - accuracy: 0.5296 - val_loss: 0.9668 - val_accuracy: 0.5432\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9743 - accuracy: 0.5299 - val_loss: 0.9670 - val_accuracy: 0.5427\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9741 - accuracy: 0.5297 - val_loss: 0.9671 - val_accuracy: 0.5418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9743 - accuracy: 0.5293 - val_loss: 0.9679 - val_accuracy: 0.5409\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9744 - accuracy: 0.5298 - val_loss: 0.9668 - val_accuracy: 0.5427\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9741 - accuracy: 0.5295 - val_loss: 0.9680 - val_accuracy: 0.5409\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9739 - accuracy: 0.5291 - val_loss: 0.9667 - val_accuracy: 0.5427\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9742 - accuracy: 0.5295 - val_loss: 0.9672 - val_accuracy: 0.5423\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9741 - accuracy: 0.5297 - val_loss: 0.9668 - val_accuracy: 0.5423\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9742 - accuracy: 0.5299 - val_loss: 0.9670 - val_accuracy: 0.5427\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9741 - accuracy: 0.5291 - val_loss: 0.9673 - val_accuracy: 0.5423\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9743 - accuracy: 0.5283 - val_loss: 0.9668 - val_accuracy: 0.5427\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9741 - accuracy: 0.5282 - val_loss: 0.9665 - val_accuracy: 0.5427\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9742 - accuracy: 0.5298 - val_loss: 0.9663 - val_accuracy: 0.5427\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9742 - accuracy: 0.5296 - val_loss: 0.9665 - val_accuracy: 0.5423\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9740 - accuracy: 0.5296 - val_loss: 0.9669 - val_accuracy: 0.5427\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9740 - accuracy: 0.5300 - val_loss: 0.9664 - val_accuracy: 0.5427\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 551us/step - loss: 0.9740 - accuracy: 0.5293 - val_loss: 0.9669 - val_accuracy: 0.5423\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9742 - accuracy: 0.5283 - val_loss: 0.9664 - val_accuracy: 0.5409\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9741 - accuracy: 0.5305 - val_loss: 0.9666 - val_accuracy: 0.5423\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9742 - accuracy: 0.5292 - val_loss: 0.9663 - val_accuracy: 0.5423\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9740 - accuracy: 0.5297 - val_loss: 0.9672 - val_accuracy: 0.5414\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9739 - accuracy: 0.5291 - val_loss: 0.9664 - val_accuracy: 0.5387\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9740 - accuracy: 0.5295 - val_loss: 0.9664 - val_accuracy: 0.5396\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9739 - accuracy: 0.5287 - val_loss: 0.9669 - val_accuracy: 0.5423\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9739 - accuracy: 0.5289 - val_loss: 0.9665 - val_accuracy: 0.5383\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9740 - accuracy: 0.5293 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9739 - accuracy: 0.5282 - val_loss: 0.9665 - val_accuracy: 0.5396\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9740 - accuracy: 0.5288 - val_loss: 0.9663 - val_accuracy: 0.5418\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9737 - accuracy: 0.5296 - val_loss: 0.9669 - val_accuracy: 0.5418\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9740 - accuracy: 0.5306 - val_loss: 0.9668 - val_accuracy: 0.5409\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9736 - accuracy: 0.5279 - val_loss: 0.9662 - val_accuracy: 0.5423\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9739 - accuracy: 0.5296 - val_loss: 0.9665 - val_accuracy: 0.5423\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9740 - accuracy: 0.5285 - val_loss: 0.9666 - val_accuracy: 0.5418\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9737 - accuracy: 0.5289 - val_loss: 0.9683 - val_accuracy: 0.5427\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9739 - accuracy: 0.5289 - val_loss: 0.9664 - val_accuracy: 0.5423\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9738 - accuracy: 0.5292 - val_loss: 0.9663 - val_accuracy: 0.5418\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9738 - accuracy: 0.5289 - val_loss: 0.9661 - val_accuracy: 0.5423\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9737 - accuracy: 0.5293 - val_loss: 0.9659 - val_accuracy: 0.5409\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5294 - val_loss: 0.9667 - val_accuracy: 0.5414\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9738 - accuracy: 0.5298 - val_loss: 0.9663 - val_accuracy: 0.5414\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9739 - accuracy: 0.5297 - val_loss: 0.9659 - val_accuracy: 0.5423\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 0.9668 - val_accuracy: 0.5418\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9738 - accuracy: 0.5284 - val_loss: 0.9660 - val_accuracy: 0.5414\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9739 - accuracy: 0.5298 - val_loss: 0.9661 - val_accuracy: 0.5414\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9737 - accuracy: 0.5289 - val_loss: 0.9664 - val_accuracy: 0.5392\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9739 - accuracy: 0.5294 - val_loss: 0.9675 - val_accuracy: 0.5432\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9740 - accuracy: 0.5293 - val_loss: 0.9663 - val_accuracy: 0.5423\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9738 - accuracy: 0.5296 - val_loss: 0.9660 - val_accuracy: 0.5409\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9736 - accuracy: 0.5290 - val_loss: 0.9671 - val_accuracy: 0.5414\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9738 - accuracy: 0.5287 - val_loss: 0.9668 - val_accuracy: 0.5405\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 0.9663 - val_accuracy: 0.5414\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9738 - accuracy: 0.5298 - val_loss: 0.9661 - val_accuracy: 0.5423\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9738 - accuracy: 0.5304 - val_loss: 0.9669 - val_accuracy: 0.5418\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9737 - accuracy: 0.5291 - val_loss: 0.9679 - val_accuracy: 0.5409\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9739 - accuracy: 0.5297 - val_loss: 0.9677 - val_accuracy: 0.5414\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9737 - accuracy: 0.5294 - val_loss: 0.9670 - val_accuracy: 0.5392\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9739 - accuracy: 0.5307 - val_loss: 0.9664 - val_accuracy: 0.5423\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9740 - accuracy: 0.5283 - val_loss: 0.9661 - val_accuracy: 0.5414\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 524us/step - loss: 0.9736 - accuracy: 0.5292 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5295 - val_loss: 0.9669 - val_accuracy: 0.5405\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9737 - accuracy: 0.5296 - val_loss: 0.9665 - val_accuracy: 0.5405\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9738 - accuracy: 0.5296 - val_loss: 0.9665 - val_accuracy: 0.5427\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9735 - accuracy: 0.5295 - val_loss: 0.9664 - val_accuracy: 0.5383\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9738 - accuracy: 0.5297 - val_loss: 0.9665 - val_accuracy: 0.5396\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9738 - accuracy: 0.5290 - val_loss: 0.9661 - val_accuracy: 0.5383\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 561us/step - loss: 0.9737 - accuracy: 0.5298 - val_loss: 0.9666 - val_accuracy: 0.5418\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9737 - accuracy: 0.5303 - val_loss: 0.9662 - val_accuracy: 0.5414\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9738 - accuracy: 0.5296 - val_loss: 0.9671 - val_accuracy: 0.5414\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9737 - accuracy: 0.5296 - val_loss: 0.9659 - val_accuracy: 0.5392\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9736 - accuracy: 0.5298 - val_loss: 0.9660 - val_accuracy: 0.5405\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9738 - accuracy: 0.5296 - val_loss: 0.9659 - val_accuracy: 0.5414\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9739 - accuracy: 0.5280 - val_loss: 0.9669 - val_accuracy: 0.5418\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9736 - accuracy: 0.5304 - val_loss: 0.9662 - val_accuracy: 0.5414\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9735 - accuracy: 0.5294 - val_loss: 0.9662 - val_accuracy: 0.5414\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9737 - accuracy: 0.5292 - val_loss: 0.9660 - val_accuracy: 0.5423\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9735 - accuracy: 0.5303 - val_loss: 0.9666 - val_accuracy: 0.5414\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9735 - accuracy: 0.5308 - val_loss: 0.9661 - val_accuracy: 0.5387\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9735 - accuracy: 0.5288 - val_loss: 0.9669 - val_accuracy: 0.5414\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 0.9660 - val_accuracy: 0.5409\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9735 - accuracy: 0.5292 - val_loss: 0.9663 - val_accuracy: 0.5414\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9735 - accuracy: 0.5297 - val_loss: 0.9667 - val_accuracy: 0.5414\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9736 - accuracy: 0.5294 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9735 - accuracy: 0.5302 - val_loss: 0.9660 - val_accuracy: 0.5414\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9737 - accuracy: 0.5305 - val_loss: 0.9661 - val_accuracy: 0.5392\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9737 - accuracy: 0.5289 - val_loss: 0.9661 - val_accuracy: 0.5418\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9736 - accuracy: 0.5300 - val_loss: 0.9661 - val_accuracy: 0.5414\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9737 - accuracy: 0.5301 - val_loss: 0.9661 - val_accuracy: 0.5414\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9733 - accuracy: 0.5282 - val_loss: 0.9665 - val_accuracy: 0.5432\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9738 - accuracy: 0.5290 - val_loss: 0.9661 - val_accuracy: 0.5418\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9735 - accuracy: 0.5290 - val_loss: 0.9663 - val_accuracy: 0.5392\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9735 - accuracy: 0.5300 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 0.9661 - val_accuracy: 0.5414\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9734 - accuracy: 0.5291 - val_loss: 0.9669 - val_accuracy: 0.5418\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9734 - accuracy: 0.5290 - val_loss: 0.9657 - val_accuracy: 0.5392\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5305 - val_loss: 0.9655 - val_accuracy: 0.5414\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9734 - accuracy: 0.5298 - val_loss: 0.9658 - val_accuracy: 0.5414\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9736 - accuracy: 0.5291 - val_loss: 0.9667 - val_accuracy: 0.5418\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9735 - accuracy: 0.5289 - val_loss: 0.9661 - val_accuracy: 0.5401\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9737 - accuracy: 0.5286 - val_loss: 0.9659 - val_accuracy: 0.5414\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9735 - accuracy: 0.5292 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9736 - accuracy: 0.5286 - val_loss: 0.9663 - val_accuracy: 0.5414\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9735 - accuracy: 0.5293 - val_loss: 0.9672 - val_accuracy: 0.5418\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9737 - accuracy: 0.5303 - val_loss: 0.9663 - val_accuracy: 0.5414\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5291 - val_loss: 0.9662 - val_accuracy: 0.5409\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9736 - accuracy: 0.5288 - val_loss: 0.9657 - val_accuracy: 0.5405\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 0.9665 - val_accuracy: 0.5423\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9735 - accuracy: 0.5286 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9734 - accuracy: 0.5294 - val_loss: 0.9668 - val_accuracy: 0.5414\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9736 - accuracy: 0.5295 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9734 - accuracy: 0.5289 - val_loss: 0.9660 - val_accuracy: 0.5409\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9736 - accuracy: 0.5299 - val_loss: 0.9669 - val_accuracy: 0.5432\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9736 - accuracy: 0.5288 - val_loss: 0.9660 - val_accuracy: 0.5409\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9735 - accuracy: 0.5303 - val_loss: 0.9664 - val_accuracy: 0.5409\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9734 - accuracy: 0.5290 - val_loss: 0.9668 - val_accuracy: 0.5414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 548us/step - loss: 0.9735 - accuracy: 0.5287 - val_loss: 0.9680 - val_accuracy: 0.5396\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9735 - accuracy: 0.5294 - val_loss: 0.9664 - val_accuracy: 0.5418\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9735 - accuracy: 0.5288 - val_loss: 0.9660 - val_accuracy: 0.5405\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9734 - accuracy: 0.5299 - val_loss: 0.9667 - val_accuracy: 0.5409\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5294 - val_loss: 0.9657 - val_accuracy: 0.5409\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9735 - accuracy: 0.5303 - val_loss: 0.9663 - val_accuracy: 0.5401\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5297 - val_loss: 0.9671 - val_accuracy: 0.5418\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9734 - accuracy: 0.5296 - val_loss: 0.9659 - val_accuracy: 0.5401\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5295 - val_loss: 0.9661 - val_accuracy: 0.5392\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9735 - accuracy: 0.5292 - val_loss: 0.9659 - val_accuracy: 0.5387\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9734 - accuracy: 0.5293 - val_loss: 0.9665 - val_accuracy: 0.5409\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9735 - accuracy: 0.5292 - val_loss: 0.9662 - val_accuracy: 0.5414\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9735 - accuracy: 0.5297 - val_loss: 0.9665 - val_accuracy: 0.5405\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 0.9664 - val_accuracy: 0.5409\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9734 - accuracy: 0.5296 - val_loss: 0.9662 - val_accuracy: 0.5405\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9734 - accuracy: 0.5303 - val_loss: 0.9662 - val_accuracy: 0.5401\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9737 - accuracy: 0.5288 - val_loss: 0.9670 - val_accuracy: 0.5414\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9736 - accuracy: 0.5303 - val_loss: 0.9666 - val_accuracy: 0.5409\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9733 - accuracy: 0.5284 - val_loss: 0.9667 - val_accuracy: 0.5405\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9733 - accuracy: 0.5304 - val_loss: 0.9683 - val_accuracy: 0.5423\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9736 - accuracy: 0.5295 - val_loss: 0.9669 - val_accuracy: 0.5418\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5296 - val_loss: 0.9668 - val_accuracy: 0.5401\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9735 - accuracy: 0.5287 - val_loss: 0.9660 - val_accuracy: 0.5405\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 554us/step - loss: 0.9734 - accuracy: 0.5285 - val_loss: 0.9666 - val_accuracy: 0.5405\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 638us/step - loss: 0.9735 - accuracy: 0.5291 - val_loss: 0.9659 - val_accuracy: 0.5409\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9736 - accuracy: 0.5299 - val_loss: 0.9667 - val_accuracy: 0.5427\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9736 - accuracy: 0.5299 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9734 - accuracy: 0.5300 - val_loss: 0.9665 - val_accuracy: 0.5427\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9737 - accuracy: 0.5305 - val_loss: 0.9658 - val_accuracy: 0.5401\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9737 - accuracy: 0.5305 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9735 - accuracy: 0.5300 - val_loss: 0.9664 - val_accuracy: 0.5405\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5288 - val_loss: 0.9666 - val_accuracy: 0.5414\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9735 - accuracy: 0.5308 - val_loss: 0.9659 - val_accuracy: 0.5405\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9734 - accuracy: 0.5298 - val_loss: 0.9664 - val_accuracy: 0.5387\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9736 - accuracy: 0.5296 - val_loss: 0.9661 - val_accuracy: 0.5405\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9736 - accuracy: 0.5294 - val_loss: 0.9661 - val_accuracy: 0.5405\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5291 - val_loss: 0.9663 - val_accuracy: 0.5409\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9734 - accuracy: 0.5299 - val_loss: 0.9663 - val_accuracy: 0.5405\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 351us/step - loss: 0.9738 - accuracy: 0.5289\n",
      "Accuracy : 0.5289431214332581\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9663 - accuracy: 0.5405\n",
      "Accuracy : 0.5405046343803406\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 656us/step - loss: 1.0603 - accuracy: 0.4467 - val_loss: 1.0478 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 1.0378 - accuracy: 0.4681 - val_loss: 1.0105 - val_accuracy: 0.5215\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 1.0051 - accuracy: 0.5241 - val_loss: 0.9804 - val_accuracy: 0.5427\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9902 - accuracy: 0.5292 - val_loss: 0.9694 - val_accuracy: 0.5418\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9853 - accuracy: 0.5288 - val_loss: 0.9685 - val_accuracy: 0.5401\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9831 - accuracy: 0.5288 - val_loss: 0.9662 - val_accuracy: 0.5423\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9816 - accuracy: 0.5305 - val_loss: 0.9654 - val_accuracy: 0.5440\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9806 - accuracy: 0.5306 - val_loss: 0.9651 - val_accuracy: 0.5418\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 559us/step - loss: 0.9796 - accuracy: 0.5293 - val_loss: 0.9647 - val_accuracy: 0.5409\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9791 - accuracy: 0.5295 - val_loss: 0.9641 - val_accuracy: 0.5458\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9787 - accuracy: 0.5295 - val_loss: 0.9633 - val_accuracy: 0.5392\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9782 - accuracy: 0.5298 - val_loss: 0.9637 - val_accuracy: 0.5383\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9780 - accuracy: 0.5303 - val_loss: 0.9631 - val_accuracy: 0.5387\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9775 - accuracy: 0.5294 - val_loss: 0.9627 - val_accuracy: 0.5392\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9774 - accuracy: 0.5300 - val_loss: 0.9631 - val_accuracy: 0.5440\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9772 - accuracy: 0.5280 - val_loss: 0.9628 - val_accuracy: 0.5445\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 500us/step - loss: 0.9766 - accuracy: 0.5294 - val_loss: 0.9637 - val_accuracy: 0.5440\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9772 - accuracy: 0.5295 - val_loss: 0.9626 - val_accuracy: 0.5392\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9769 - accuracy: 0.5277 - val_loss: 0.9621 - val_accuracy: 0.5392\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9768 - accuracy: 0.5284 - val_loss: 0.9621 - val_accuracy: 0.5396\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9622 - val_accuracy: 0.5378\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9629 - val_accuracy: 0.5409\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9764 - accuracy: 0.5286 - val_loss: 0.9615 - val_accuracy: 0.5436\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9762 - accuracy: 0.5294 - val_loss: 0.9621 - val_accuracy: 0.5445\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9626 - val_accuracy: 0.5405\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9762 - accuracy: 0.5291 - val_loss: 0.9624 - val_accuracy: 0.5387\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9761 - accuracy: 0.5285 - val_loss: 0.9620 - val_accuracy: 0.5387\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9761 - accuracy: 0.5280 - val_loss: 0.9617 - val_accuracy: 0.5436\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9758 - accuracy: 0.5286 - val_loss: 0.9614 - val_accuracy: 0.5378\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9758 - accuracy: 0.5288 - val_loss: 0.9616 - val_accuracy: 0.5405\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9759 - accuracy: 0.5295 - val_loss: 0.9616 - val_accuracy: 0.5392\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9758 - accuracy: 0.5282 - val_loss: 0.9614 - val_accuracy: 0.5392\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9758 - accuracy: 0.5287 - val_loss: 0.9611 - val_accuracy: 0.5392\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9757 - accuracy: 0.5294 - val_loss: 0.9617 - val_accuracy: 0.5396\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9754 - accuracy: 0.5292 - val_loss: 0.9617 - val_accuracy: 0.5414\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9755 - accuracy: 0.5281 - val_loss: 0.9626 - val_accuracy: 0.5401\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5286 - val_loss: 0.9610 - val_accuracy: 0.5392\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9755 - accuracy: 0.5288 - val_loss: 0.9613 - val_accuracy: 0.5440\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9754 - accuracy: 0.5293 - val_loss: 0.9612 - val_accuracy: 0.5383\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9753 - accuracy: 0.5301 - val_loss: 0.9615 - val_accuracy: 0.5392\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9754 - accuracy: 0.5289 - val_loss: 0.9618 - val_accuracy: 0.5414\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9753 - accuracy: 0.5290 - val_loss: 0.9615 - val_accuracy: 0.5383\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9753 - accuracy: 0.5286 - val_loss: 0.9609 - val_accuracy: 0.5383\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9753 - accuracy: 0.5287 - val_loss: 0.9614 - val_accuracy: 0.5392\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9750 - accuracy: 0.5297 - val_loss: 0.9621 - val_accuracy: 0.5392\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5292 - val_loss: 0.9607 - val_accuracy: 0.5383\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9634 - val_accuracy: 0.5383\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9630 - val_accuracy: 0.5405\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9753 - accuracy: 0.5280 - val_loss: 0.9611 - val_accuracy: 0.5401\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9753 - accuracy: 0.5290 - val_loss: 0.9608 - val_accuracy: 0.5396\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9751 - accuracy: 0.5290 - val_loss: 0.9607 - val_accuracy: 0.5392\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9751 - accuracy: 0.5285 - val_loss: 0.9608 - val_accuracy: 0.5401\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9750 - accuracy: 0.5290 - val_loss: 0.9610 - val_accuracy: 0.5396\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9751 - accuracy: 0.5290 - val_loss: 0.9608 - val_accuracy: 0.5392\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9749 - accuracy: 0.5289 - val_loss: 0.9607 - val_accuracy: 0.5396\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9752 - accuracy: 0.5287 - val_loss: 0.9604 - val_accuracy: 0.5383\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9748 - accuracy: 0.5285 - val_loss: 0.9624 - val_accuracy: 0.5414\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9751 - accuracy: 0.5283 - val_loss: 0.9605 - val_accuracy: 0.5392\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9750 - accuracy: 0.5287 - val_loss: 0.9606 - val_accuracy: 0.5383\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9748 - accuracy: 0.5283 - val_loss: 0.9604 - val_accuracy: 0.5392\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9750 - accuracy: 0.5287 - val_loss: 0.9607 - val_accuracy: 0.5396\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9750 - accuracy: 0.5285 - val_loss: 0.9608 - val_accuracy: 0.5401\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9750 - accuracy: 0.5281 - val_loss: 0.9604 - val_accuracy: 0.5401\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9748 - accuracy: 0.5292 - val_loss: 0.9604 - val_accuracy: 0.5401\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9747 - accuracy: 0.5294 - val_loss: 0.9602 - val_accuracy: 0.5392\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9747 - accuracy: 0.5281 - val_loss: 0.9600 - val_accuracy: 0.5405\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9749 - accuracy: 0.5287 - val_loss: 0.9607 - val_accuracy: 0.5458\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9749 - accuracy: 0.5290 - val_loss: 0.9604 - val_accuracy: 0.5396\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9747 - accuracy: 0.5286 - val_loss: 0.9600 - val_accuracy: 0.5405\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9746 - accuracy: 0.5295 - val_loss: 0.9605 - val_accuracy: 0.5392\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9747 - accuracy: 0.5293 - val_loss: 0.9605 - val_accuracy: 0.5401\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9749 - accuracy: 0.5285 - val_loss: 0.9602 - val_accuracy: 0.5396\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 498us/step - loss: 0.9745 - accuracy: 0.5283 - val_loss: 0.9600 - val_accuracy: 0.5405\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9747 - accuracy: 0.5280 - val_loss: 0.9604 - val_accuracy: 0.5467\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9747 - accuracy: 0.5287 - val_loss: 0.9603 - val_accuracy: 0.5396\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9744 - accuracy: 0.5295 - val_loss: 0.9607 - val_accuracy: 0.5392\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9746 - accuracy: 0.5290 - val_loss: 0.9605 - val_accuracy: 0.5383\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9748 - accuracy: 0.5290 - val_loss: 0.9604 - val_accuracy: 0.5392\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9746 - accuracy: 0.5285 - val_loss: 0.9604 - val_accuracy: 0.5383\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9745 - accuracy: 0.5287 - val_loss: 0.9602 - val_accuracy: 0.5392\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9746 - accuracy: 0.5296 - val_loss: 0.9604 - val_accuracy: 0.5383\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9746 - accuracy: 0.5289 - val_loss: 0.9610 - val_accuracy: 0.5387\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9745 - accuracy: 0.5296 - val_loss: 0.9606 - val_accuracy: 0.5401\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9744 - accuracy: 0.5290 - val_loss: 0.9600 - val_accuracy: 0.5401\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9746 - accuracy: 0.5287 - val_loss: 0.9606 - val_accuracy: 0.5396\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9744 - accuracy: 0.5293 - val_loss: 0.9606 - val_accuracy: 0.5392\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9744 - accuracy: 0.5299 - val_loss: 0.9599 - val_accuracy: 0.5383\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5293 - val_loss: 0.9602 - val_accuracy: 0.5392\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9746 - accuracy: 0.5292 - val_loss: 0.9604 - val_accuracy: 0.5396\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9747 - accuracy: 0.5285 - val_loss: 0.9597 - val_accuracy: 0.5396\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9747 - accuracy: 0.5288 - val_loss: 0.9600 - val_accuracy: 0.5401\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9746 - accuracy: 0.5287 - val_loss: 0.9600 - val_accuracy: 0.5392\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9745 - accuracy: 0.5291 - val_loss: 0.9598 - val_accuracy: 0.5440\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9743 - accuracy: 0.5300 - val_loss: 0.9615 - val_accuracy: 0.5392\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9744 - accuracy: 0.5292 - val_loss: 0.9601 - val_accuracy: 0.5405\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9746 - accuracy: 0.5289 - val_loss: 0.9599 - val_accuracy: 0.5458\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9744 - accuracy: 0.5293 - val_loss: 0.9599 - val_accuracy: 0.5396\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9743 - accuracy: 0.5285 - val_loss: 0.9602 - val_accuracy: 0.5383\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9743 - accuracy: 0.5284 - val_loss: 0.9610 - val_accuracy: 0.5396\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9745 - accuracy: 0.5285 - val_loss: 0.9600 - val_accuracy: 0.5392\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5292 - val_loss: 0.9612 - val_accuracy: 0.5436\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9745 - accuracy: 0.5291 - val_loss: 0.9607 - val_accuracy: 0.5392\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9742 - accuracy: 0.5285 - val_loss: 0.9617 - val_accuracy: 0.5414\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9744 - accuracy: 0.5289 - val_loss: 0.9595 - val_accuracy: 0.5383\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9744 - accuracy: 0.5290 - val_loss: 0.9600 - val_accuracy: 0.5387\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9742 - accuracy: 0.5300 - val_loss: 0.9601 - val_accuracy: 0.5396\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9743 - accuracy: 0.5285 - val_loss: 0.9612 - val_accuracy: 0.5401\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 555us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9601 - val_accuracy: 0.5392\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9741 - accuracy: 0.5290 - val_loss: 0.9600 - val_accuracy: 0.5396\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9620 - val_accuracy: 0.5409\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9741 - accuracy: 0.5306 - val_loss: 0.9599 - val_accuracy: 0.5463\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9742 - accuracy: 0.5306 - val_loss: 0.9616 - val_accuracy: 0.5409\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9740 - accuracy: 0.5279 - val_loss: 0.9598 - val_accuracy: 0.5467\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9742 - accuracy: 0.5286 - val_loss: 0.9603 - val_accuracy: 0.5387\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9742 - accuracy: 0.5288 - val_loss: 0.9600 - val_accuracy: 0.5405\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9743 - accuracy: 0.5306 - val_loss: 0.9598 - val_accuracy: 0.5396\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9743 - accuracy: 0.5289 - val_loss: 0.9604 - val_accuracy: 0.5449\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9743 - accuracy: 0.5285 - val_loss: 0.9602 - val_accuracy: 0.5396\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9743 - accuracy: 0.5299 - val_loss: 0.9603 - val_accuracy: 0.5392\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9742 - accuracy: 0.5286 - val_loss: 0.9606 - val_accuracy: 0.5405\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9743 - accuracy: 0.5294 - val_loss: 0.9601 - val_accuracy: 0.5392\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9743 - accuracy: 0.5298 - val_loss: 0.9599 - val_accuracy: 0.5392\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9744 - accuracy: 0.5287 - val_loss: 0.9595 - val_accuracy: 0.5440\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5298 - val_loss: 0.9599 - val_accuracy: 0.5392\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9742 - accuracy: 0.5285 - val_loss: 0.9608 - val_accuracy: 0.5392\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9743 - accuracy: 0.5296 - val_loss: 0.9603 - val_accuracy: 0.5392\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9743 - accuracy: 0.5297 - val_loss: 0.9600 - val_accuracy: 0.5392\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9740 - accuracy: 0.5295 - val_loss: 0.9599 - val_accuracy: 0.5392\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 498us/step - loss: 0.9738 - accuracy: 0.5311 - val_loss: 0.9597 - val_accuracy: 0.5405\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9743 - accuracy: 0.5293 - val_loss: 0.9595 - val_accuracy: 0.5378\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9740 - accuracy: 0.5294 - val_loss: 0.9596 - val_accuracy: 0.5436\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9741 - accuracy: 0.5289 - val_loss: 0.9597 - val_accuracy: 0.5401\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9743 - accuracy: 0.5289 - val_loss: 0.9610 - val_accuracy: 0.5378\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9741 - accuracy: 0.5280 - val_loss: 0.9599 - val_accuracy: 0.5392\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9741 - accuracy: 0.5292 - val_loss: 0.9600 - val_accuracy: 0.5392\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9741 - accuracy: 0.5284 - val_loss: 0.9603 - val_accuracy: 0.5378\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9741 - accuracy: 0.5289 - val_loss: 0.9610 - val_accuracy: 0.5396\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9740 - accuracy: 0.5297 - val_loss: 0.9595 - val_accuracy: 0.5458\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9741 - accuracy: 0.5293 - val_loss: 0.9609 - val_accuracy: 0.5392\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9740 - accuracy: 0.5298 - val_loss: 0.9600 - val_accuracy: 0.5392\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9740 - accuracy: 0.5296 - val_loss: 0.9605 - val_accuracy: 0.5414\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9741 - accuracy: 0.5292 - val_loss: 0.9618 - val_accuracy: 0.5405\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5302 - val_loss: 0.9598 - val_accuracy: 0.5378\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9741 - accuracy: 0.5294 - val_loss: 0.9608 - val_accuracy: 0.5392\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9624 - val_accuracy: 0.5392\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9740 - accuracy: 0.5303 - val_loss: 0.9598 - val_accuracy: 0.5387\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9740 - accuracy: 0.5291 - val_loss: 0.9603 - val_accuracy: 0.5449\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9740 - accuracy: 0.5301 - val_loss: 0.9620 - val_accuracy: 0.5409\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9741 - accuracy: 0.5285 - val_loss: 0.9594 - val_accuracy: 0.5440\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9740 - accuracy: 0.5297 - val_loss: 0.9610 - val_accuracy: 0.5392\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9741 - accuracy: 0.5287 - val_loss: 0.9617 - val_accuracy: 0.5387\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9740 - accuracy: 0.5296 - val_loss: 0.9625 - val_accuracy: 0.5392\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9740 - accuracy: 0.5299 - val_loss: 0.9603 - val_accuracy: 0.5401\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9740 - accuracy: 0.5301 - val_loss: 0.9597 - val_accuracy: 0.5378\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9739 - accuracy: 0.5286 - val_loss: 0.9617 - val_accuracy: 0.5392\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9741 - accuracy: 0.5296 - val_loss: 0.9598 - val_accuracy: 0.5387\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 560us/step - loss: 0.9741 - accuracy: 0.5287 - val_loss: 0.9604 - val_accuracy: 0.5392\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9742 - accuracy: 0.5287 - val_loss: 0.9609 - val_accuracy: 0.5401\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9741 - accuracy: 0.5297 - val_loss: 0.9609 - val_accuracy: 0.5401\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9739 - accuracy: 0.5281 - val_loss: 0.9610 - val_accuracy: 0.5383\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9740 - accuracy: 0.5288 - val_loss: 0.9607 - val_accuracy: 0.5383\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9739 - accuracy: 0.5297 - val_loss: 0.9613 - val_accuracy: 0.5387\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 547us/step - loss: 0.9742 - accuracy: 0.5293 - val_loss: 0.9611 - val_accuracy: 0.5383\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 555us/step - loss: 0.9739 - accuracy: 0.5301 - val_loss: 0.9623 - val_accuracy: 0.5401\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 557us/step - loss: 0.9738 - accuracy: 0.5291 - val_loss: 0.9610 - val_accuracy: 0.5383\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9740 - accuracy: 0.5286 - val_loss: 0.9609 - val_accuracy: 0.5383\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9741 - accuracy: 0.5297 - val_loss: 0.9600 - val_accuracy: 0.5401\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 555us/step - loss: 0.9741 - accuracy: 0.5292 - val_loss: 0.9597 - val_accuracy: 0.5440\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9740 - accuracy: 0.5287 - val_loss: 0.9601 - val_accuracy: 0.5378\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9739 - accuracy: 0.5298 - val_loss: 0.9600 - val_accuracy: 0.5458\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9737 - accuracy: 0.5293 - val_loss: 0.9600 - val_accuracy: 0.5392\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9740 - accuracy: 0.5293 - val_loss: 0.9615 - val_accuracy: 0.5396\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9739 - accuracy: 0.5295 - val_loss: 0.9621 - val_accuracy: 0.5392\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9739 - accuracy: 0.5298 - val_loss: 0.9615 - val_accuracy: 0.5387\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9741 - accuracy: 0.5290 - val_loss: 0.9604 - val_accuracy: 0.5378\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9740 - accuracy: 0.5299 - val_loss: 0.9600 - val_accuracy: 0.5454\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9739 - accuracy: 0.5292 - val_loss: 0.9608 - val_accuracy: 0.5392\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9740 - accuracy: 0.5289 - val_loss: 0.9600 - val_accuracy: 0.5409\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9740 - accuracy: 0.5301 - val_loss: 0.9612 - val_accuracy: 0.5378\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9739 - accuracy: 0.5285 - val_loss: 0.9604 - val_accuracy: 0.5383\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9741 - accuracy: 0.5302 - val_loss: 0.9603 - val_accuracy: 0.5378\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9739 - accuracy: 0.5295 - val_loss: 0.9605 - val_accuracy: 0.5378\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9739 - accuracy: 0.5289 - val_loss: 0.9596 - val_accuracy: 0.5392\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9740 - accuracy: 0.5300 - val_loss: 0.9610 - val_accuracy: 0.5418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9739 - accuracy: 0.5292 - val_loss: 0.9609 - val_accuracy: 0.5387\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9740 - accuracy: 0.5295 - val_loss: 0.9620 - val_accuracy: 0.5387\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9738 - accuracy: 0.5284 - val_loss: 0.9611 - val_accuracy: 0.5383\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9740 - accuracy: 0.5291 - val_loss: 0.9600 - val_accuracy: 0.5396\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9736 - accuracy: 0.5291 - val_loss: 0.9637 - val_accuracy: 0.5405\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9743 - accuracy: 0.5294 - val_loss: 0.9616 - val_accuracy: 0.5392\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9741 - accuracy: 0.5286 - val_loss: 0.9609 - val_accuracy: 0.5396\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9741 - accuracy: 0.5288 - val_loss: 0.9601 - val_accuracy: 0.5463\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9740 - accuracy: 0.5287 - val_loss: 0.9605 - val_accuracy: 0.5383\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9739 - accuracy: 0.5289 - val_loss: 0.9617 - val_accuracy: 0.5463\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9740 - accuracy: 0.5285 - val_loss: 0.9599 - val_accuracy: 0.5432\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9740 - accuracy: 0.5295 - val_loss: 0.9603 - val_accuracy: 0.5392\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9739 - accuracy: 0.5297 - val_loss: 0.9620 - val_accuracy: 0.5383\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9739 - accuracy: 0.5298 - val_loss: 0.9603 - val_accuracy: 0.5396\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9739 - accuracy: 0.5291 - val_loss: 0.9602 - val_accuracy: 0.5432\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9741 - accuracy: 0.5283 - val_loss: 0.9605 - val_accuracy: 0.5387\n",
      "\n",
      "Train split:\n",
      "  1/636 [..............................] - ETA: 0s - loss: 1.1745 - accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "636/636 [==============================] - 0s 354us/step - loss: 0.9749 - accuracy: 0.5288\n",
      "Accuracy : 0.5288447141647339\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9605 - accuracy: 0.5387\n",
      "Accuracy : 0.538733959197998\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 655us/step - loss: 1.0469 - accuracy: 0.4694 - val_loss: 0.9990 - val_accuracy: 0.5374\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9984 - accuracy: 0.5286 - val_loss: 0.9641 - val_accuracy: 0.5445\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9891 - accuracy: 0.5282 - val_loss: 0.9582 - val_accuracy: 0.5445\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9874 - accuracy: 0.5282 - val_loss: 0.9560 - val_accuracy: 0.5454\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9861 - accuracy: 0.5282 - val_loss: 0.9536 - val_accuracy: 0.5409\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9845 - accuracy: 0.5286 - val_loss: 0.9513 - val_accuracy: 0.5432\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9832 - accuracy: 0.5268 - val_loss: 0.9497 - val_accuracy: 0.5458\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9822 - accuracy: 0.5289 - val_loss: 0.9490 - val_accuracy: 0.5427\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9815 - accuracy: 0.5291 - val_loss: 0.9469 - val_accuracy: 0.5409\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9810 - accuracy: 0.5294 - val_loss: 0.9452 - val_accuracy: 0.5445\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - ETA: 0s - loss: 0.9783 - accuracy: 0.53 - 0s 498us/step - loss: 0.9801 - accuracy: 0.5293 - val_loss: 0.9452 - val_accuracy: 0.5445\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9800 - accuracy: 0.5278 - val_loss: 0.9439 - val_accuracy: 0.5414\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9795 - accuracy: 0.5297 - val_loss: 0.9426 - val_accuracy: 0.5449\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9792 - accuracy: 0.5293 - val_loss: 0.9426 - val_accuracy: 0.5436\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9789 - accuracy: 0.5294 - val_loss: 0.9418 - val_accuracy: 0.5423\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9787 - accuracy: 0.5299 - val_loss: 0.9418 - val_accuracy: 0.5418\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9784 - accuracy: 0.5288 - val_loss: 0.9421 - val_accuracy: 0.5432\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9783 - accuracy: 0.5290 - val_loss: 0.9404 - val_accuracy: 0.5436\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9783 - accuracy: 0.5293 - val_loss: 0.9411 - val_accuracy: 0.5449\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9780 - accuracy: 0.5291 - val_loss: 0.9409 - val_accuracy: 0.5423\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9779 - accuracy: 0.5298 - val_loss: 0.9400 - val_accuracy: 0.5414\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9779 - accuracy: 0.5296 - val_loss: 0.9392 - val_accuracy: 0.5432\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9779 - accuracy: 0.5294 - val_loss: 0.9396 - val_accuracy: 0.5432\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9778 - accuracy: 0.5293 - val_loss: 0.9399 - val_accuracy: 0.5432\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9778 - accuracy: 0.5293 - val_loss: 0.9398 - val_accuracy: 0.5449\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9777 - accuracy: 0.5297 - val_loss: 0.9402 - val_accuracy: 0.5427\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9777 - accuracy: 0.5277 - val_loss: 0.9390 - val_accuracy: 0.5423\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9776 - accuracy: 0.5296 - val_loss: 0.9392 - val_accuracy: 0.5432\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9776 - accuracy: 0.5297 - val_loss: 0.9414 - val_accuracy: 0.5432\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9774 - accuracy: 0.5294 - val_loss: 0.9392 - val_accuracy: 0.5414\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9775 - accuracy: 0.5293 - val_loss: 0.9396 - val_accuracy: 0.5409\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9777 - accuracy: 0.5284 - val_loss: 0.9391 - val_accuracy: 0.5432\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9391 - val_accuracy: 0.5432\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9773 - accuracy: 0.5300 - val_loss: 0.9391 - val_accuracy: 0.5432\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9774 - accuracy: 0.5306 - val_loss: 0.9386 - val_accuracy: 0.5409\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9389 - val_accuracy: 0.5414\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 505us/step - loss: 0.9774 - accuracy: 0.5286 - val_loss: 0.9387 - val_accuracy: 0.5449\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9776 - accuracy: 0.5281 - val_loss: 0.9388 - val_accuracy: 0.5454\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9774 - accuracy: 0.5288 - val_loss: 0.9392 - val_accuracy: 0.5427\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9772 - accuracy: 0.5290 - val_loss: 0.9391 - val_accuracy: 0.5449\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9773 - accuracy: 0.5302 - val_loss: 0.9387 - val_accuracy: 0.5409\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9773 - accuracy: 0.5290 - val_loss: 0.9390 - val_accuracy: 0.5432\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9773 - accuracy: 0.5296 - val_loss: 0.9400 - val_accuracy: 0.5418\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9774 - accuracy: 0.5287 - val_loss: 0.9395 - val_accuracy: 0.5454\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9400 - val_accuracy: 0.5427\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9771 - accuracy: 0.5295 - val_loss: 0.9392 - val_accuracy: 0.5454\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9772 - accuracy: 0.5286 - val_loss: 0.9388 - val_accuracy: 0.5414\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9772 - accuracy: 0.5295 - val_loss: 0.9393 - val_accuracy: 0.5418\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9772 - accuracy: 0.5296 - val_loss: 0.9385 - val_accuracy: 0.5445\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9771 - accuracy: 0.5295 - val_loss: 0.9385 - val_accuracy: 0.5427\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9772 - accuracy: 0.5280 - val_loss: 0.9391 - val_accuracy: 0.5432\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9772 - accuracy: 0.5290 - val_loss: 0.9405 - val_accuracy: 0.5423\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 565us/step - loss: 0.9772 - accuracy: 0.5286 - val_loss: 0.9384 - val_accuracy: 0.5418\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9390 - val_accuracy: 0.5440\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9391 - val_accuracy: 0.5418\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9772 - accuracy: 0.5298 - val_loss: 0.9386 - val_accuracy: 0.5409\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9770 - accuracy: 0.5285 - val_loss: 0.9384 - val_accuracy: 0.5418\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9768 - accuracy: 0.5290 - val_loss: 0.9390 - val_accuracy: 0.5445\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9771 - accuracy: 0.5292 - val_loss: 0.9384 - val_accuracy: 0.5445\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9771 - accuracy: 0.5293 - val_loss: 0.9393 - val_accuracy: 0.5418\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9769 - accuracy: 0.5291 - val_loss: 0.9390 - val_accuracy: 0.5440\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9772 - accuracy: 0.5287 - val_loss: 0.9388 - val_accuracy: 0.5440\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9387 - val_accuracy: 0.5409\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9399 - val_accuracy: 0.5418\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9769 - accuracy: 0.5299 - val_loss: 0.9388 - val_accuracy: 0.5423\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9383 - val_accuracy: 0.5445\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9771 - accuracy: 0.5294 - val_loss: 0.9380 - val_accuracy: 0.5440\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9769 - accuracy: 0.5285 - val_loss: 0.9387 - val_accuracy: 0.5432\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9770 - accuracy: 0.5280 - val_loss: 0.9395 - val_accuracy: 0.5418\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9768 - accuracy: 0.5299 - val_loss: 0.9384 - val_accuracy: 0.5427\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9768 - accuracy: 0.5289 - val_loss: 0.9382 - val_accuracy: 0.5409\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9384 - val_accuracy: 0.5449\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9769 - accuracy: 0.5289 - val_loss: 0.9395 - val_accuracy: 0.5432\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9769 - accuracy: 0.5297 - val_loss: 0.9388 - val_accuracy: 0.5423\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9770 - accuracy: 0.5294 - val_loss: 0.9388 - val_accuracy: 0.5423\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9768 - accuracy: 0.5285 - val_loss: 0.9384 - val_accuracy: 0.5436\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9768 - accuracy: 0.5296 - val_loss: 0.9389 - val_accuracy: 0.5423\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9385 - val_accuracy: 0.5414\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9768 - accuracy: 0.5287 - val_loss: 0.9391 - val_accuracy: 0.5449\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9769 - accuracy: 0.5283 - val_loss: 0.9389 - val_accuracy: 0.5432\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9768 - accuracy: 0.5296 - val_loss: 0.9396 - val_accuracy: 0.5418\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9768 - accuracy: 0.5294 - val_loss: 0.9395 - val_accuracy: 0.5423\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9768 - accuracy: 0.5289 - val_loss: 0.9382 - val_accuracy: 0.5414\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9769 - accuracy: 0.5277 - val_loss: 0.9393 - val_accuracy: 0.5423\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9768 - accuracy: 0.5293 - val_loss: 0.9383 - val_accuracy: 0.5418\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9769 - accuracy: 0.5291 - val_loss: 0.9395 - val_accuracy: 0.5423\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9388 - val_accuracy: 0.5427\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9769 - accuracy: 0.5288 - val_loss: 0.9386 - val_accuracy: 0.5414\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9768 - accuracy: 0.5295 - val_loss: 0.9389 - val_accuracy: 0.5432\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9766 - accuracy: 0.5288 - val_loss: 0.9390 - val_accuracy: 0.5432\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9767 - accuracy: 0.5292 - val_loss: 0.9391 - val_accuracy: 0.5409\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9767 - accuracy: 0.5291 - val_loss: 0.9390 - val_accuracy: 0.5432\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 500us/step - loss: 0.9769 - accuracy: 0.5291 - val_loss: 0.9387 - val_accuracy: 0.5423\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9768 - accuracy: 0.5301 - val_loss: 0.9386 - val_accuracy: 0.5423\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9766 - accuracy: 0.5294 - val_loss: 0.9388 - val_accuracy: 0.5423\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9396 - val_accuracy: 0.5436\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9398 - val_accuracy: 0.5418\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9768 - accuracy: 0.5295 - val_loss: 0.9391 - val_accuracy: 0.5454\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9384 - val_accuracy: 0.5427\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9770 - accuracy: 0.5284 - val_loss: 0.9388 - val_accuracy: 0.5436\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9768 - accuracy: 0.5283 - val_loss: 0.9387 - val_accuracy: 0.5423\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9767 - accuracy: 0.5290 - val_loss: 0.9388 - val_accuracy: 0.5454\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9766 - accuracy: 0.5305 - val_loss: 0.9405 - val_accuracy: 0.5409\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9767 - accuracy: 0.5284 - val_loss: 0.9401 - val_accuracy: 0.5436\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9768 - accuracy: 0.5286 - val_loss: 0.9398 - val_accuracy: 0.5427\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9406 - val_accuracy: 0.5427\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9766 - accuracy: 0.5284 - val_loss: 0.9401 - val_accuracy: 0.5440\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9766 - accuracy: 0.5291 - val_loss: 0.9395 - val_accuracy: 0.5418\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9768 - accuracy: 0.5281 - val_loss: 0.9393 - val_accuracy: 0.5418\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9765 - accuracy: 0.5296 - val_loss: 0.9406 - val_accuracy: 0.5436\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9385 - val_accuracy: 0.5436\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9765 - accuracy: 0.5287 - val_loss: 0.9391 - val_accuracy: 0.5427\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9768 - accuracy: 0.5289 - val_loss: 0.9394 - val_accuracy: 0.5418\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9388 - val_accuracy: 0.5436\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9766 - accuracy: 0.5296 - val_loss: 0.9382 - val_accuracy: 0.5432\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9765 - accuracy: 0.5292 - val_loss: 0.9385 - val_accuracy: 0.5418\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9767 - accuracy: 0.5289 - val_loss: 0.9392 - val_accuracy: 0.5436\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9767 - accuracy: 0.5296 - val_loss: 0.9389 - val_accuracy: 0.5427\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9767 - accuracy: 0.5293 - val_loss: 0.9392 - val_accuracy: 0.5436\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9766 - accuracy: 0.5297 - val_loss: 0.9402 - val_accuracy: 0.5440\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9766 - accuracy: 0.5295 - val_loss: 0.9390 - val_accuracy: 0.5432\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9393 - val_accuracy: 0.5432\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9767 - accuracy: 0.5291 - val_loss: 0.9393 - val_accuracy: 0.5427\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9765 - accuracy: 0.5292 - val_loss: 0.9404 - val_accuracy: 0.5436\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9766 - accuracy: 0.5293 - val_loss: 0.9386 - val_accuracy: 0.5405\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9766 - accuracy: 0.5299 - val_loss: 0.9393 - val_accuracy: 0.5418\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9765 - accuracy: 0.5289 - val_loss: 0.9395 - val_accuracy: 0.5418\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9767 - accuracy: 0.5283 - val_loss: 0.9386 - val_accuracy: 0.5436\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9766 - accuracy: 0.5297 - val_loss: 0.9386 - val_accuracy: 0.5414\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9766 - accuracy: 0.5293 - val_loss: 0.9389 - val_accuracy: 0.5432\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9766 - accuracy: 0.5288 - val_loss: 0.9388 - val_accuracy: 0.5418\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9766 - accuracy: 0.5289 - val_loss: 0.9385 - val_accuracy: 0.5427\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9764 - accuracy: 0.5292 - val_loss: 0.9395 - val_accuracy: 0.5427\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9390 - val_accuracy: 0.5418\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9766 - accuracy: 0.5299 - val_loss: 0.9394 - val_accuracy: 0.5414\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9766 - accuracy: 0.5298 - val_loss: 0.9394 - val_accuracy: 0.5436\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9766 - accuracy: 0.5287 - val_loss: 0.9380 - val_accuracy: 0.5423\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9394 - val_accuracy: 0.5432\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9766 - accuracy: 0.5291 - val_loss: 0.9402 - val_accuracy: 0.5436\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9764 - accuracy: 0.5289 - val_loss: 0.9386 - val_accuracy: 0.5423\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9766 - accuracy: 0.5297 - val_loss: 0.9393 - val_accuracy: 0.5418\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9384 - val_accuracy: 0.5423\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9767 - accuracy: 0.5280 - val_loss: 0.9400 - val_accuracy: 0.5440\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9765 - accuracy: 0.5286 - val_loss: 0.9384 - val_accuracy: 0.5405\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9407 - val_accuracy: 0.5440\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9767 - accuracy: 0.5297 - val_loss: 0.9394 - val_accuracy: 0.5440\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9416 - val_accuracy: 0.5418\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9765 - accuracy: 0.5287 - val_loss: 0.9392 - val_accuracy: 0.5432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9765 - accuracy: 0.5284 - val_loss: 0.9388 - val_accuracy: 0.5423\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9767 - accuracy: 0.5292 - val_loss: 0.9400 - val_accuracy: 0.5427\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9766 - accuracy: 0.5299 - val_loss: 0.9400 - val_accuracy: 0.5440\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9765 - accuracy: 0.5289 - val_loss: 0.9389 - val_accuracy: 0.5418\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9766 - accuracy: 0.5290 - val_loss: 0.9401 - val_accuracy: 0.5440\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9389 - val_accuracy: 0.5436\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9765 - accuracy: 0.5296 - val_loss: 0.9393 - val_accuracy: 0.5440\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9766 - accuracy: 0.5293 - val_loss: 0.9395 - val_accuracy: 0.5440\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9765 - accuracy: 0.5288 - val_loss: 0.9385 - val_accuracy: 0.5409\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9766 - accuracy: 0.5291 - val_loss: 0.9399 - val_accuracy: 0.5432\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9764 - accuracy: 0.5285 - val_loss: 0.9405 - val_accuracy: 0.5440\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9764 - accuracy: 0.5305 - val_loss: 0.9391 - val_accuracy: 0.5440\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9410 - val_accuracy: 0.5427\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9766 - accuracy: 0.5295 - val_loss: 0.9389 - val_accuracy: 0.5432\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9391 - val_accuracy: 0.5418\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9766 - accuracy: 0.5300 - val_loss: 0.9392 - val_accuracy: 0.5414\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9392 - val_accuracy: 0.5414\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9765 - accuracy: 0.5288 - val_loss: 0.9395 - val_accuracy: 0.5440\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9763 - accuracy: 0.5298 - val_loss: 0.9390 - val_accuracy: 0.5436\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9389 - val_accuracy: 0.5418\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9765 - accuracy: 0.5291 - val_loss: 0.9391 - val_accuracy: 0.5414\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9394 - val_accuracy: 0.5436\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9764 - accuracy: 0.5285 - val_loss: 0.9394 - val_accuracy: 0.5414\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9384 - val_accuracy: 0.5405\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9765 - accuracy: 0.5307 - val_loss: 0.9400 - val_accuracy: 0.5436\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9765 - accuracy: 0.5296 - val_loss: 0.9393 - val_accuracy: 0.5436\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9764 - accuracy: 0.5298 - val_loss: 0.9410 - val_accuracy: 0.5427\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9764 - accuracy: 0.5289 - val_loss: 0.9390 - val_accuracy: 0.5427\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9765 - accuracy: 0.5302 - val_loss: 0.9388 - val_accuracy: 0.5440\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9765 - accuracy: 0.5300 - val_loss: 0.9386 - val_accuracy: 0.5409\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9764 - accuracy: 0.5305 - val_loss: 0.9401 - val_accuracy: 0.5418\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9766 - accuracy: 0.5293 - val_loss: 0.9388 - val_accuracy: 0.5418\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9765 - accuracy: 0.5288 - val_loss: 0.9391 - val_accuracy: 0.5418\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9764 - accuracy: 0.5305 - val_loss: 0.9421 - val_accuracy: 0.5432\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9764 - accuracy: 0.5309 - val_loss: 0.9394 - val_accuracy: 0.5436\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9764 - accuracy: 0.5291 - val_loss: 0.9382 - val_accuracy: 0.5423\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9764 - accuracy: 0.5292 - val_loss: 0.9386 - val_accuracy: 0.5409\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9763 - accuracy: 0.5300 - val_loss: 0.9388 - val_accuracy: 0.5436\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9382 - val_accuracy: 0.5440\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 572us/step - loss: 0.9765 - accuracy: 0.5299 - val_loss: 0.9389 - val_accuracy: 0.5427\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 576us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9385 - val_accuracy: 0.5423\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 564us/step - loss: 0.9764 - accuracy: 0.5291 - val_loss: 0.9402 - val_accuracy: 0.5440\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9764 - accuracy: 0.5298 - val_loss: 0.9387 - val_accuracy: 0.5427\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9764 - accuracy: 0.5290 - val_loss: 0.9406 - val_accuracy: 0.5432\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9764 - accuracy: 0.5299 - val_loss: 0.9401 - val_accuracy: 0.5436\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9386 - val_accuracy: 0.5414\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9765 - accuracy: 0.5298 - val_loss: 0.9397 - val_accuracy: 0.5418\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9761 - accuracy: 0.5297 - val_loss: 0.9391 - val_accuracy: 0.5405\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9764 - accuracy: 0.5288 - val_loss: 0.9383 - val_accuracy: 0.5423\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9765 - accuracy: 0.5300 - val_loss: 0.9401 - val_accuracy: 0.5436\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 554us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9390 - val_accuracy: 0.5440\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 576us/step - loss: 0.9765 - accuracy: 0.5291 - val_loss: 0.9385 - val_accuracy: 0.5423\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 356us/step - loss: 0.9763 - accuracy: 0.5285\n",
      "Accuracy : 0.5285496711730957\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9385 - accuracy: 0.5423\n",
      "Accuracy : 0.5422753691673279\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 653us/step - loss: 1.0392 - accuracy: 0.4625 - val_loss: 1.0156 - val_accuracy: 0.5082\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 1.0003 - accuracy: 0.5204 - val_loss: 0.9914 - val_accuracy: 0.5299\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 512us/step - loss: 0.9881 - accuracy: 0.5314 - val_loss: 0.9866 - val_accuracy: 0.5294\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9847 - accuracy: 0.5302 - val_loss: 0.9819 - val_accuracy: 0.5343\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9827 - accuracy: 0.5316 - val_loss: 0.9803 - val_accuracy: 0.5343\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9809 - accuracy: 0.5306 - val_loss: 0.9807 - val_accuracy: 0.5277\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9795 - accuracy: 0.5313 - val_loss: 0.9775 - val_accuracy: 0.5325\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9784 - accuracy: 0.5310 - val_loss: 0.9762 - val_accuracy: 0.5321\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9774 - accuracy: 0.5301 - val_loss: 0.9751 - val_accuracy: 0.5325\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9769 - accuracy: 0.5304 - val_loss: 0.9749 - val_accuracy: 0.5334\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9761 - accuracy: 0.5310 - val_loss: 0.9736 - val_accuracy: 0.5308\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9757 - accuracy: 0.5314 - val_loss: 0.9745 - val_accuracy: 0.5312\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9755 - accuracy: 0.5298 - val_loss: 0.9741 - val_accuracy: 0.5317\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9727 - val_accuracy: 0.5286\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9749 - accuracy: 0.5307 - val_loss: 0.9732 - val_accuracy: 0.5317\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9749 - accuracy: 0.5300 - val_loss: 0.9734 - val_accuracy: 0.5325\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9746 - accuracy: 0.5305 - val_loss: 0.9736 - val_accuracy: 0.5325\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9746 - accuracy: 0.5300 - val_loss: 0.9717 - val_accuracy: 0.5299\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9745 - accuracy: 0.5307 - val_loss: 0.9750 - val_accuracy: 0.5347\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9743 - accuracy: 0.5300 - val_loss: 0.9713 - val_accuracy: 0.5286\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9744 - accuracy: 0.5304 - val_loss: 0.9717 - val_accuracy: 0.5308\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9741 - accuracy: 0.5306 - val_loss: 0.9709 - val_accuracy: 0.5259\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9741 - accuracy: 0.5304 - val_loss: 0.9717 - val_accuracy: 0.5308\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9740 - accuracy: 0.5309 - val_loss: 0.9713 - val_accuracy: 0.5272\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9739 - accuracy: 0.5306 - val_loss: 0.9710 - val_accuracy: 0.5286\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9740 - accuracy: 0.5309 - val_loss: 0.9718 - val_accuracy: 0.5303\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9741 - accuracy: 0.5306 - val_loss: 0.9710 - val_accuracy: 0.5281\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9738 - accuracy: 0.5303 - val_loss: 0.9709 - val_accuracy: 0.5272\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9738 - accuracy: 0.5306 - val_loss: 0.9734 - val_accuracy: 0.5330\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9737 - accuracy: 0.5298 - val_loss: 0.9706 - val_accuracy: 0.5255\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9738 - accuracy: 0.5307 - val_loss: 0.9709 - val_accuracy: 0.5277\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9708 - val_accuracy: 0.5299\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9737 - accuracy: 0.5300 - val_loss: 0.9709 - val_accuracy: 0.5277\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9738 - accuracy: 0.5299 - val_loss: 0.9710 - val_accuracy: 0.5299\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9737 - accuracy: 0.5301 - val_loss: 0.9713 - val_accuracy: 0.5299\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9737 - accuracy: 0.5300 - val_loss: 0.9703 - val_accuracy: 0.5272\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9736 - accuracy: 0.5302 - val_loss: 0.9723 - val_accuracy: 0.5325\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9709 - val_accuracy: 0.5317\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9708 - val_accuracy: 0.5272\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9711 - val_accuracy: 0.5277\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9734 - accuracy: 0.5308 - val_loss: 0.9703 - val_accuracy: 0.5263\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9735 - accuracy: 0.5305 - val_loss: 0.9708 - val_accuracy: 0.5294\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9735 - accuracy: 0.5292 - val_loss: 0.9724 - val_accuracy: 0.5308\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9735 - accuracy: 0.5296 - val_loss: 0.9711 - val_accuracy: 0.5286\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9735 - val_accuracy: 0.5352\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 559us/step - loss: 0.9736 - accuracy: 0.5303 - val_loss: 0.9710 - val_accuracy: 0.5299\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9736 - accuracy: 0.5297 - val_loss: 0.9714 - val_accuracy: 0.5294\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9736 - accuracy: 0.5304 - val_loss: 0.9708 - val_accuracy: 0.5272\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9735 - accuracy: 0.5309 - val_loss: 0.9711 - val_accuracy: 0.5290\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9735 - accuracy: 0.5298 - val_loss: 0.9699 - val_accuracy: 0.5272\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9734 - accuracy: 0.5290 - val_loss: 0.9716 - val_accuracy: 0.5321\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9736 - accuracy: 0.5297 - val_loss: 0.9741 - val_accuracy: 0.5339\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9735 - accuracy: 0.5317 - val_loss: 0.9700 - val_accuracy: 0.5286\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9737 - accuracy: 0.5300 - val_loss: 0.9699 - val_accuracy: 0.5277\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9735 - accuracy: 0.5303 - val_loss: 0.9712 - val_accuracy: 0.5321\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9735 - accuracy: 0.5309 - val_loss: 0.9704 - val_accuracy: 0.5299\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9735 - accuracy: 0.5299 - val_loss: 0.9705 - val_accuracy: 0.5277\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9734 - accuracy: 0.5310 - val_loss: 0.9717 - val_accuracy: 0.5317\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 531us/step - loss: 0.9733 - accuracy: 0.5296 - val_loss: 0.9715 - val_accuracy: 0.5299\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9735 - accuracy: 0.5297 - val_loss: 0.9707 - val_accuracy: 0.5303\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9733 - accuracy: 0.5301 - val_loss: 0.9709 - val_accuracy: 0.5308\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9734 - accuracy: 0.5305 - val_loss: 0.9702 - val_accuracy: 0.5277\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9734 - accuracy: 0.5295 - val_loss: 0.9723 - val_accuracy: 0.5312\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9734 - accuracy: 0.5311 - val_loss: 0.9718 - val_accuracy: 0.5330\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9698 - val_accuracy: 0.5272\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9731 - accuracy: 0.5302 - val_loss: 0.9702 - val_accuracy: 0.5259\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9733 - accuracy: 0.5294 - val_loss: 0.9703 - val_accuracy: 0.5299\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9732 - accuracy: 0.5306 - val_loss: 0.9704 - val_accuracy: 0.5321\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5298 - val_loss: 0.9697 - val_accuracy: 0.5272\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9734 - accuracy: 0.5301 - val_loss: 0.9702 - val_accuracy: 0.5299\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 0.9704 - val_accuracy: 0.5317\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9730 - accuracy: 0.5302 - val_loss: 0.9728 - val_accuracy: 0.5352\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9733 - accuracy: 0.5313 - val_loss: 0.9700 - val_accuracy: 0.5299\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9733 - accuracy: 0.5302 - val_loss: 0.9706 - val_accuracy: 0.5303\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9733 - accuracy: 0.5305 - val_loss: 0.9710 - val_accuracy: 0.5308\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9732 - accuracy: 0.5302 - val_loss: 0.9697 - val_accuracy: 0.5299\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9732 - accuracy: 0.5307 - val_loss: 0.9705 - val_accuracy: 0.5259\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9732 - accuracy: 0.5299 - val_loss: 0.9712 - val_accuracy: 0.5308\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9731 - accuracy: 0.5316 - val_loss: 0.9700 - val_accuracy: 0.5255\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9733 - accuracy: 0.5298 - val_loss: 0.9736 - val_accuracy: 0.5356\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5310 - val_loss: 0.9698 - val_accuracy: 0.5290\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9733 - accuracy: 0.5314 - val_loss: 0.9697 - val_accuracy: 0.5259\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9732 - accuracy: 0.5304 - val_loss: 0.9701 - val_accuracy: 0.5299\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9734 - accuracy: 0.5309 - val_loss: 0.9704 - val_accuracy: 0.5312\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9721 - val_accuracy: 0.5352\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9731 - accuracy: 0.5310 - val_loss: 0.9694 - val_accuracy: 0.5281\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9734 - accuracy: 0.5299 - val_loss: 0.9711 - val_accuracy: 0.5317\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9733 - accuracy: 0.5308 - val_loss: 0.9711 - val_accuracy: 0.5317\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9730 - accuracy: 0.5316 - val_loss: 0.9700 - val_accuracy: 0.5250\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 0.9703 - val_accuracy: 0.5317\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9731 - accuracy: 0.5311 - val_loss: 0.9714 - val_accuracy: 0.5317\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9731 - accuracy: 0.5309 - val_loss: 0.9706 - val_accuracy: 0.5308\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9732 - accuracy: 0.5306 - val_loss: 0.9702 - val_accuracy: 0.5277\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 556us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 0.9698 - val_accuracy: 0.5268\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 547us/step - loss: 0.9732 - accuracy: 0.5295 - val_loss: 0.9702 - val_accuracy: 0.5277\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9734 - accuracy: 0.5301 - val_loss: 0.9700 - val_accuracy: 0.5299\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9734 - accuracy: 0.5295 - val_loss: 0.9696 - val_accuracy: 0.5290\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9707 - val_accuracy: 0.5317\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9731 - accuracy: 0.5310 - val_loss: 0.9693 - val_accuracy: 0.5294\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9732 - accuracy: 0.5315 - val_loss: 0.9715 - val_accuracy: 0.5334\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9730 - accuracy: 0.5311 - val_loss: 0.9705 - val_accuracy: 0.5308\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 0.9696 - val_accuracy: 0.5281\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9732 - accuracy: 0.5309 - val_loss: 0.9697 - val_accuracy: 0.5268\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9730 - accuracy: 0.5299 - val_loss: 0.9713 - val_accuracy: 0.5317\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9731 - accuracy: 0.5315 - val_loss: 0.9706 - val_accuracy: 0.5312\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 0.9707 - val_accuracy: 0.5303\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9731 - accuracy: 0.5296 - val_loss: 0.9697 - val_accuracy: 0.5294\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9732 - accuracy: 0.5305 - val_loss: 0.9701 - val_accuracy: 0.5299\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5300 - val_loss: 0.9705 - val_accuracy: 0.5299\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9732 - accuracy: 0.5294 - val_loss: 0.9710 - val_accuracy: 0.5317\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9731 - accuracy: 0.5294 - val_loss: 0.9699 - val_accuracy: 0.5281\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9731 - accuracy: 0.5306 - val_loss: 0.9699 - val_accuracy: 0.5299\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9730 - accuracy: 0.5290 - val_loss: 0.9695 - val_accuracy: 0.5277\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9731 - accuracy: 0.5297 - val_loss: 0.9705 - val_accuracy: 0.5268\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 507us/step - loss: 0.9731 - accuracy: 0.5313 - val_loss: 0.9696 - val_accuracy: 0.5263\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 0.9701 - val_accuracy: 0.5299\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9731 - accuracy: 0.5302 - val_loss: 0.9710 - val_accuracy: 0.5317\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9731 - accuracy: 0.5296 - val_loss: 0.9713 - val_accuracy: 0.5308\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9730 - accuracy: 0.5300 - val_loss: 0.9700 - val_accuracy: 0.5303\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9730 - accuracy: 0.5298 - val_loss: 0.9737 - val_accuracy: 0.5347\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9702 - val_accuracy: 0.5317\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 0.9700 - val_accuracy: 0.5294\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9730 - accuracy: 0.5301 - val_loss: 0.9697 - val_accuracy: 0.5299\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9730 - accuracy: 0.5303 - val_loss: 0.9710 - val_accuracy: 0.5321\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9698 - val_accuracy: 0.5299\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9729 - accuracy: 0.5309 - val_loss: 0.9696 - val_accuracy: 0.5272\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 0.9714 - val_accuracy: 0.5308\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5310 - val_loss: 0.9703 - val_accuracy: 0.5317\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 0.9697 - val_accuracy: 0.5259\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9732 - accuracy: 0.5314 - val_loss: 0.9699 - val_accuracy: 0.5303\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 0.9697 - val_accuracy: 0.5294\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9703 - val_accuracy: 0.5317\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 0.9695 - val_accuracy: 0.5299\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9729 - accuracy: 0.5321 - val_loss: 0.9710 - val_accuracy: 0.5268\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9731 - accuracy: 0.5298 - val_loss: 0.9703 - val_accuracy: 0.5294\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9733 - accuracy: 0.5302 - val_loss: 0.9699 - val_accuracy: 0.5299\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9730 - accuracy: 0.5304 - val_loss: 0.9713 - val_accuracy: 0.5299\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 0.9695 - val_accuracy: 0.5268\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9729 - accuracy: 0.5300 - val_loss: 0.9707 - val_accuracy: 0.5299\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9706 - val_accuracy: 0.5308\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9731 - accuracy: 0.5306 - val_loss: 0.9700 - val_accuracy: 0.5312\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9695 - val_accuracy: 0.5294\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 548us/step - loss: 0.9732 - accuracy: 0.5304 - val_loss: 0.9698 - val_accuracy: 0.5290\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9731 - accuracy: 0.5302 - val_loss: 0.9710 - val_accuracy: 0.5334\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9729 - accuracy: 0.5307 - val_loss: 0.9694 - val_accuracy: 0.5263\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9699 - val_accuracy: 0.5294\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9728 - accuracy: 0.5305 - val_loss: 0.9693 - val_accuracy: 0.5255\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 0.9699 - val_accuracy: 0.5299\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9730 - accuracy: 0.5302 - val_loss: 0.9699 - val_accuracy: 0.5277\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9704 - val_accuracy: 0.5312\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 0.9698 - val_accuracy: 0.5321\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9729 - accuracy: 0.5316 - val_loss: 0.9694 - val_accuracy: 0.5277\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9729 - accuracy: 0.5315 - val_loss: 0.9695 - val_accuracy: 0.5281\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9697 - val_accuracy: 0.5299\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9727 - accuracy: 0.5304 - val_loss: 0.9717 - val_accuracy: 0.5312\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9731 - accuracy: 0.5307 - val_loss: 0.9699 - val_accuracy: 0.5308\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9729 - accuracy: 0.5304 - val_loss: 0.9708 - val_accuracy: 0.5334\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9731 - accuracy: 0.5307 - val_loss: 0.9702 - val_accuracy: 0.5312\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9729 - accuracy: 0.5309 - val_loss: 0.9706 - val_accuracy: 0.5321\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 0.9702 - val_accuracy: 0.5294\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9729 - accuracy: 0.5303 - val_loss: 0.9701 - val_accuracy: 0.5308\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9728 - accuracy: 0.5297 - val_loss: 0.9695 - val_accuracy: 0.5268\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9729 - accuracy: 0.5306 - val_loss: 0.9700 - val_accuracy: 0.5312\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9730 - accuracy: 0.5309 - val_loss: 0.9696 - val_accuracy: 0.5294\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9727 - accuracy: 0.5320 - val_loss: 0.9700 - val_accuracy: 0.5299\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9703 - val_accuracy: 0.5308\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9728 - accuracy: 0.5305 - val_loss: 0.9725 - val_accuracy: 0.5347\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9730 - accuracy: 0.5307 - val_loss: 0.9702 - val_accuracy: 0.5294\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9728 - accuracy: 0.5307 - val_loss: 0.9711 - val_accuracy: 0.5308\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5310 - val_loss: 0.9704 - val_accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9727 - accuracy: 0.5304 - val_loss: 0.9699 - val_accuracy: 0.5308\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9729 - accuracy: 0.5303 - val_loss: 0.9698 - val_accuracy: 0.5299\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9727 - accuracy: 0.5302 - val_loss: 0.9706 - val_accuracy: 0.5272\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9728 - accuracy: 0.5309 - val_loss: 0.9695 - val_accuracy: 0.5272\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 0.9701 - val_accuracy: 0.5317\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9728 - accuracy: 0.5303 - val_loss: 0.9702 - val_accuracy: 0.5308\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9729 - accuracy: 0.5307 - val_loss: 0.9695 - val_accuracy: 0.5308\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9731 - accuracy: 0.5299 - val_loss: 0.9698 - val_accuracy: 0.5299\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9730 - accuracy: 0.5300 - val_loss: 0.9698 - val_accuracy: 0.5290\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9730 - accuracy: 0.5310 - val_loss: 0.9696 - val_accuracy: 0.5299\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9729 - accuracy: 0.5298 - val_loss: 0.9704 - val_accuracy: 0.5317\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9694 - val_accuracy: 0.5272\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9731 - accuracy: 0.5304 - val_loss: 0.9701 - val_accuracy: 0.5317\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9730 - accuracy: 0.5307 - val_loss: 0.9698 - val_accuracy: 0.5281\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9728 - accuracy: 0.5304 - val_loss: 0.9710 - val_accuracy: 0.5325\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9728 - accuracy: 0.5309 - val_loss: 0.9702 - val_accuracy: 0.5317\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9732 - accuracy: 0.5303 - val_loss: 0.9700 - val_accuracy: 0.5303\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9728 - accuracy: 0.5314 - val_loss: 0.9694 - val_accuracy: 0.5246\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9730 - accuracy: 0.5301 - val_loss: 0.9697 - val_accuracy: 0.5290\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9728 - accuracy: 0.5303 - val_loss: 0.9697 - val_accuracy: 0.5303\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9729 - accuracy: 0.5306 - val_loss: 0.9701 - val_accuracy: 0.5299\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9728 - accuracy: 0.5308 - val_loss: 0.9695 - val_accuracy: 0.5303\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9729 - accuracy: 0.5305 - val_loss: 0.9694 - val_accuracy: 0.5263\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 0.9692 - val_accuracy: 0.5299\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 0.9707 - val_accuracy: 0.5330\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9728 - accuracy: 0.5296 - val_loss: 0.9696 - val_accuracy: 0.5263\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9728 - accuracy: 0.5318 - val_loss: 0.9715 - val_accuracy: 0.5325\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9728 - accuracy: 0.5303 - val_loss: 0.9709 - val_accuracy: 0.5330\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9727 - accuracy: 0.5304 - val_loss: 0.9707 - val_accuracy: 0.5325\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9730 - accuracy: 0.5302 - val_loss: 0.9696 - val_accuracy: 0.5299\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 344us/step - loss: 0.9724 - accuracy: 0.5306\n",
      "Accuracy : 0.5306152701377869\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9696 - accuracy: 0.5299\n",
      "Accuracy : 0.5298804640769958\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 649us/step - loss: 1.0590 - accuracy: 0.4591 - val_loss: 1.0331 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 1.0147 - accuracy: 0.4972 - val_loss: 0.9892 - val_accuracy: 0.5378\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9920 - accuracy: 0.5298 - val_loss: 0.9771 - val_accuracy: 0.5343\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9883 - accuracy: 0.5278 - val_loss: 0.9767 - val_accuracy: 0.5361\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9869 - accuracy: 0.5270 - val_loss: 0.9747 - val_accuracy: 0.5361\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9853 - accuracy: 0.5306 - val_loss: 0.9705 - val_accuracy: 0.5365\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9841 - accuracy: 0.5286 - val_loss: 0.9686 - val_accuracy: 0.5361\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9830 - accuracy: 0.5287 - val_loss: 0.9664 - val_accuracy: 0.5352\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9819 - accuracy: 0.5291 - val_loss: 0.9643 - val_accuracy: 0.5361\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9810 - accuracy: 0.5294 - val_loss: 0.9629 - val_accuracy: 0.5361\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9805 - accuracy: 0.5303 - val_loss: 0.9618 - val_accuracy: 0.5321\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9798 - accuracy: 0.5300 - val_loss: 0.9605 - val_accuracy: 0.5325\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9795 - accuracy: 0.5289 - val_loss: 0.9600 - val_accuracy: 0.5356\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9790 - accuracy: 0.5295 - val_loss: 0.9604 - val_accuracy: 0.5370\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9786 - accuracy: 0.5300 - val_loss: 0.9576 - val_accuracy: 0.5321\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9785 - accuracy: 0.5302 - val_loss: 0.9571 - val_accuracy: 0.5321\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9777 - accuracy: 0.5301 - val_loss: 0.9567 - val_accuracy: 0.5317\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9777 - accuracy: 0.5312 - val_loss: 0.9560 - val_accuracy: 0.5356\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9774 - accuracy: 0.5302 - val_loss: 0.9558 - val_accuracy: 0.5356\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9774 - accuracy: 0.5298 - val_loss: 0.9551 - val_accuracy: 0.5334\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9771 - accuracy: 0.5298 - val_loss: 0.9545 - val_accuracy: 0.5334\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9769 - accuracy: 0.5310 - val_loss: 0.9544 - val_accuracy: 0.5330\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9769 - accuracy: 0.5305 - val_loss: 0.9542 - val_accuracy: 0.5352\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9766 - accuracy: 0.5301 - val_loss: 0.9539 - val_accuracy: 0.5352\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 498us/step - loss: 0.9767 - accuracy: 0.5296 - val_loss: 0.9537 - val_accuracy: 0.5352\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9764 - accuracy: 0.5309 - val_loss: 0.9534 - val_accuracy: 0.5365\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9765 - accuracy: 0.5306 - val_loss: 0.9543 - val_accuracy: 0.5378\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9766 - accuracy: 0.5298 - val_loss: 0.9538 - val_accuracy: 0.5356\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9763 - accuracy: 0.5308 - val_loss: 0.9538 - val_accuracy: 0.5374\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9762 - accuracy: 0.5311 - val_loss: 0.9534 - val_accuracy: 0.5378\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9762 - accuracy: 0.5304 - val_loss: 0.9525 - val_accuracy: 0.5356\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9763 - accuracy: 0.5300 - val_loss: 0.9525 - val_accuracy: 0.5356\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9763 - accuracy: 0.5300 - val_loss: 0.9522 - val_accuracy: 0.5356\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9762 - accuracy: 0.5298 - val_loss: 0.9536 - val_accuracy: 0.5370\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9760 - accuracy: 0.5306 - val_loss: 0.9520 - val_accuracy: 0.5347\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9520 - val_accuracy: 0.5352\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9760 - accuracy: 0.5316 - val_loss: 0.9524 - val_accuracy: 0.5374\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9760 - accuracy: 0.5295 - val_loss: 0.9522 - val_accuracy: 0.5325\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9518 - val_accuracy: 0.5352\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9533 - val_accuracy: 0.5365\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5308 - val_loss: 0.9518 - val_accuracy: 0.5374\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9759 - accuracy: 0.5304 - val_loss: 0.9518 - val_accuracy: 0.5352\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9759 - accuracy: 0.5307 - val_loss: 0.9516 - val_accuracy: 0.5347\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9760 - accuracy: 0.5310 - val_loss: 0.9517 - val_accuracy: 0.5343\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9758 - accuracy: 0.5302 - val_loss: 0.9518 - val_accuracy: 0.5374\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9519 - val_accuracy: 0.5356\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9759 - accuracy: 0.5304 - val_loss: 0.9514 - val_accuracy: 0.5343\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9519 - val_accuracy: 0.5370\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 0.9513 - val_accuracy: 0.5356\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9759 - accuracy: 0.5296 - val_loss: 0.9523 - val_accuracy: 0.5365\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9759 - accuracy: 0.5302 - val_loss: 0.9512 - val_accuracy: 0.5356\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9757 - accuracy: 0.5305 - val_loss: 0.9515 - val_accuracy: 0.5378\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5302 - val_loss: 0.9527 - val_accuracy: 0.5370\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9757 - accuracy: 0.5306 - val_loss: 0.9514 - val_accuracy: 0.5356\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9758 - accuracy: 0.5298 - val_loss: 0.9517 - val_accuracy: 0.5356\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5300 - val_loss: 0.9527 - val_accuracy: 0.5370\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 0.9512 - val_accuracy: 0.5334\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9758 - accuracy: 0.5309 - val_loss: 0.9522 - val_accuracy: 0.5370\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5292 - val_loss: 0.9512 - val_accuracy: 0.5356\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5304 - val_loss: 0.9510 - val_accuracy: 0.5356\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9757 - accuracy: 0.5288 - val_loss: 0.9510 - val_accuracy: 0.5356\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9508 - val_accuracy: 0.5361\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5302 - val_loss: 0.9522 - val_accuracy: 0.5365\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9755 - accuracy: 0.5305 - val_loss: 0.9513 - val_accuracy: 0.5374\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9753 - accuracy: 0.5308 - val_loss: 0.9516 - val_accuracy: 0.5356\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5309 - val_loss: 0.9509 - val_accuracy: 0.5361\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9753 - accuracy: 0.5294 - val_loss: 0.9516 - val_accuracy: 0.5356\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9756 - accuracy: 0.5305 - val_loss: 0.9532 - val_accuracy: 0.5370\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5306 - val_loss: 0.9512 - val_accuracy: 0.5356\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9507 - val_accuracy: 0.5334\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9510 - val_accuracy: 0.5356\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9538 - val_accuracy: 0.5374\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9756 - accuracy: 0.5297 - val_loss: 0.9508 - val_accuracy: 0.5343\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9755 - accuracy: 0.5301 - val_loss: 0.9507 - val_accuracy: 0.5352\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9755 - accuracy: 0.5307 - val_loss: 0.9512 - val_accuracy: 0.5352\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5302 - val_loss: 0.9509 - val_accuracy: 0.5356\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9755 - accuracy: 0.5300 - val_loss: 0.9508 - val_accuracy: 0.5356\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9507 - val_accuracy: 0.5352\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5299 - val_loss: 0.9511 - val_accuracy: 0.5378\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9754 - accuracy: 0.5296 - val_loss: 0.9515 - val_accuracy: 0.5356\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 496us/step - loss: 0.9754 - accuracy: 0.5316 - val_loss: 0.9511 - val_accuracy: 0.5352\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9754 - accuracy: 0.5307 - val_loss: 0.9512 - val_accuracy: 0.5378\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9754 - accuracy: 0.5315 - val_loss: 0.9512 - val_accuracy: 0.5378\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9510 - val_accuracy: 0.5339\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9755 - accuracy: 0.5301 - val_loss: 0.9509 - val_accuracy: 0.5347\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9753 - accuracy: 0.5293 - val_loss: 0.9526 - val_accuracy: 0.5374\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9756 - accuracy: 0.5302 - val_loss: 0.9514 - val_accuracy: 0.5365\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9751 - accuracy: 0.5298 - val_loss: 0.9510 - val_accuracy: 0.5374\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9509 - val_accuracy: 0.5378\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9508 - val_accuracy: 0.5347\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9753 - accuracy: 0.5308 - val_loss: 0.9510 - val_accuracy: 0.5334\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9754 - accuracy: 0.5303 - val_loss: 0.9509 - val_accuracy: 0.5361\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9752 - accuracy: 0.5308 - val_loss: 0.9508 - val_accuracy: 0.5361\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5299 - val_loss: 0.9516 - val_accuracy: 0.5361\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9507 - val_accuracy: 0.5352\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5302 - val_loss: 0.9507 - val_accuracy: 0.5356\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9753 - accuracy: 0.5302 - val_loss: 0.9512 - val_accuracy: 0.5365\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9752 - accuracy: 0.5299 - val_loss: 0.9504 - val_accuracy: 0.5352\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9754 - accuracy: 0.5300 - val_loss: 0.9504 - val_accuracy: 0.5347\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9508 - val_accuracy: 0.5356\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9751 - accuracy: 0.5288 - val_loss: 0.9508 - val_accuracy: 0.5378\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9754 - accuracy: 0.5296 - val_loss: 0.9506 - val_accuracy: 0.5352\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9753 - accuracy: 0.5307 - val_loss: 0.9505 - val_accuracy: 0.5347\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9754 - accuracy: 0.5299 - val_loss: 0.9508 - val_accuracy: 0.5361\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9751 - accuracy: 0.5315 - val_loss: 0.9520 - val_accuracy: 0.5374\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9754 - accuracy: 0.5306 - val_loss: 0.9508 - val_accuracy: 0.5378\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9754 - accuracy: 0.5303 - val_loss: 0.9506 - val_accuracy: 0.5352\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9751 - accuracy: 0.5304 - val_loss: 0.9508 - val_accuracy: 0.5365\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9752 - accuracy: 0.5308 - val_loss: 0.9506 - val_accuracy: 0.5361\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5304 - val_loss: 0.9514 - val_accuracy: 0.5352\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9752 - accuracy: 0.5294 - val_loss: 0.9504 - val_accuracy: 0.5361\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9752 - accuracy: 0.5298 - val_loss: 0.9505 - val_accuracy: 0.5356\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9753 - accuracy: 0.5315 - val_loss: 0.9503 - val_accuracy: 0.5339\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5311 - val_loss: 0.9510 - val_accuracy: 0.5378\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9508 - val_accuracy: 0.5361\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9753 - accuracy: 0.5314 - val_loss: 0.9508 - val_accuracy: 0.5365\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9752 - accuracy: 0.5300 - val_loss: 0.9506 - val_accuracy: 0.5352\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9754 - accuracy: 0.5299 - val_loss: 0.9506 - val_accuracy: 0.5352\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5307 - val_loss: 0.9515 - val_accuracy: 0.5370\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9751 - accuracy: 0.5308 - val_loss: 0.9505 - val_accuracy: 0.5343\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9753 - accuracy: 0.5301 - val_loss: 0.9507 - val_accuracy: 0.5356\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9512 - val_accuracy: 0.5352\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9752 - accuracy: 0.5297 - val_loss: 0.9504 - val_accuracy: 0.5347\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9512 - val_accuracy: 0.5365\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 625us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9508 - val_accuracy: 0.5361\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 560us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9506 - val_accuracy: 0.5356\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9752 - accuracy: 0.5307 - val_loss: 0.9507 - val_accuracy: 0.5352\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9752 - accuracy: 0.5294 - val_loss: 0.9513 - val_accuracy: 0.5365\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9751 - accuracy: 0.5294 - val_loss: 0.9508 - val_accuracy: 0.5356\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9512 - val_accuracy: 0.5361\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9752 - accuracy: 0.5310 - val_loss: 0.9504 - val_accuracy: 0.5361\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 603us/step - loss: 0.9751 - accuracy: 0.5291 - val_loss: 0.9505 - val_accuracy: 0.5352\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 641us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9505 - val_accuracy: 0.5352\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 600us/step - loss: 0.9750 - accuracy: 0.5305 - val_loss: 0.9506 - val_accuracy: 0.5356\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 601us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9515 - val_accuracy: 0.5365\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 567us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9519 - val_accuracy: 0.5365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 688us/step - loss: 0.9752 - accuracy: 0.5307 - val_loss: 0.9508 - val_accuracy: 0.5365\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 722us/step - loss: 0.9751 - accuracy: 0.5310 - val_loss: 0.9506 - val_accuracy: 0.5339\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 614us/step - loss: 0.9751 - accuracy: 0.5304 - val_loss: 0.9502 - val_accuracy: 0.5361\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 746us/step - loss: 0.9751 - accuracy: 0.5303 - val_loss: 0.9506 - val_accuracy: 0.5343\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 653us/step - loss: 0.9751 - accuracy: 0.5304 - val_loss: 0.9506 - val_accuracy: 0.5361\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 658us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9505 - val_accuracy: 0.5334\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 592us/step - loss: 0.9751 - accuracy: 0.5310 - val_loss: 0.9504 - val_accuracy: 0.5339\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9751 - accuracy: 0.5309 - val_loss: 0.9507 - val_accuracy: 0.5339\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9750 - accuracy: 0.5313 - val_loss: 0.9506 - val_accuracy: 0.5347\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9753 - accuracy: 0.5314 - val_loss: 0.9511 - val_accuracy: 0.5356\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9751 - accuracy: 0.5309 - val_loss: 0.9507 - val_accuracy: 0.5361\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9506 - val_accuracy: 0.5361\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9750 - accuracy: 0.5296 - val_loss: 0.9506 - val_accuracy: 0.5352\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9504 - val_accuracy: 0.5365\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9749 - accuracy: 0.5311 - val_loss: 0.9505 - val_accuracy: 0.5334\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9749 - accuracy: 0.5305 - val_loss: 0.9507 - val_accuracy: 0.5356\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9753 - accuracy: 0.5296 - val_loss: 0.9508 - val_accuracy: 0.5361\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9751 - accuracy: 0.5305 - val_loss: 0.9503 - val_accuracy: 0.5339\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9752 - accuracy: 0.5309 - val_loss: 0.9507 - val_accuracy: 0.5365\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9752 - accuracy: 0.5302 - val_loss: 0.9505 - val_accuracy: 0.5352\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9751 - accuracy: 0.5312 - val_loss: 0.9505 - val_accuracy: 0.5347\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9750 - accuracy: 0.5299 - val_loss: 0.9503 - val_accuracy: 0.5347\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9751 - accuracy: 0.5313 - val_loss: 0.9507 - val_accuracy: 0.5347\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9506 - val_accuracy: 0.5352\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9752 - accuracy: 0.5313 - val_loss: 0.9508 - val_accuracy: 0.5356\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 577us/step - loss: 0.9752 - accuracy: 0.5313 - val_loss: 0.9508 - val_accuracy: 0.5361\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 562us/step - loss: 0.9751 - accuracy: 0.5297 - val_loss: 0.9507 - val_accuracy: 0.5347\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9753 - accuracy: 0.5293 - val_loss: 0.9514 - val_accuracy: 0.5361\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9752 - accuracy: 0.5307 - val_loss: 0.9507 - val_accuracy: 0.5343\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9751 - accuracy: 0.5309 - val_loss: 0.9507 - val_accuracy: 0.5361\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9512 - val_accuracy: 0.5356\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9749 - accuracy: 0.5310 - val_loss: 0.9508 - val_accuracy: 0.5347\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9751 - accuracy: 0.5301 - val_loss: 0.9505 - val_accuracy: 0.5361\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9750 - accuracy: 0.5310 - val_loss: 0.9507 - val_accuracy: 0.5361\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9751 - accuracy: 0.5306 - val_loss: 0.9514 - val_accuracy: 0.5374\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9522 - val_accuracy: 0.5374\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9752 - accuracy: 0.5304 - val_loss: 0.9510 - val_accuracy: 0.5370\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9508 - val_accuracy: 0.5356\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9750 - accuracy: 0.5310 - val_loss: 0.9501 - val_accuracy: 0.5339\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9750 - accuracy: 0.5303 - val_loss: 0.9504 - val_accuracy: 0.5352\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9507 - val_accuracy: 0.5352\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9752 - accuracy: 0.5313 - val_loss: 0.9504 - val_accuracy: 0.5352\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 581us/step - loss: 0.9751 - accuracy: 0.5301 - val_loss: 0.9505 - val_accuracy: 0.5334\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 620us/step - loss: 0.9751 - accuracy: 0.5315 - val_loss: 0.9508 - val_accuracy: 0.5356\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 746us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9505 - val_accuracy: 0.5352\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 670us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9517 - val_accuracy: 0.5374\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 667us/step - loss: 0.9750 - accuracy: 0.5305 - val_loss: 0.9526 - val_accuracy: 0.5374\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 574us/step - loss: 0.9750 - accuracy: 0.5293 - val_loss: 0.9506 - val_accuracy: 0.5365\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 570us/step - loss: 0.9750 - accuracy: 0.5319 - val_loss: 0.9510 - val_accuracy: 0.5374\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 573us/step - loss: 0.9751 - accuracy: 0.5305 - val_loss: 0.9512 - val_accuracy: 0.5365\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 634us/step - loss: 0.9751 - accuracy: 0.5305 - val_loss: 0.9511 - val_accuracy: 0.5365\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 630us/step - loss: 0.9752 - accuracy: 0.5297 - val_loss: 0.9507 - val_accuracy: 0.5352\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 703us/step - loss: 0.9749 - accuracy: 0.5301 - val_loss: 0.9518 - val_accuracy: 0.5365\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 773us/step - loss: 0.9752 - accuracy: 0.5299 - val_loss: 0.9503 - val_accuracy: 0.5343\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 574us/step - loss: 0.9750 - accuracy: 0.5320 - val_loss: 0.9510 - val_accuracy: 0.5365\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 781us/step - loss: 0.9749 - accuracy: 0.5327 - val_loss: 0.9524 - val_accuracy: 0.5374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 759us/step - loss: 0.9750 - accuracy: 0.5317 - val_loss: 0.9509 - val_accuracy: 0.5361\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 700us/step - loss: 0.9749 - accuracy: 0.5304 - val_loss: 0.9506 - val_accuracy: 0.5339\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 548us/step - loss: 0.9750 - accuracy: 0.5300 - val_loss: 0.9510 - val_accuracy: 0.5352\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9748 - accuracy: 0.5315 - val_loss: 0.9522 - val_accuracy: 0.5370\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9751 - accuracy: 0.5305 - val_loss: 0.9502 - val_accuracy: 0.5334\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9752 - accuracy: 0.5294 - val_loss: 0.9505 - val_accuracy: 0.5334\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9750 - accuracy: 0.5305 - val_loss: 0.9512 - val_accuracy: 0.5356\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9751 - accuracy: 0.5309 - val_loss: 0.9516 - val_accuracy: 0.5356\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 372us/step - loss: 0.9749 - accuracy: 0.5308\n",
      "Accuracy : 0.5308119654655457\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9516 - accuracy: 0.5356\n",
      "Accuracy : 0.535635232925415\n",
      "\n",
      "The final train accuracy is:0.5302909672260284 \n",
      "\n",
      "The final test accuracy is:0.5311171233654022 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"BW.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data = np.array(df.iloc[:,0:3])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "    \n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "    \n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (3,1)),\n",
    "        keras.layers.Dense(5,activation='sigmoid'),\n",
    "        keras.layers.Dense(5,activation='sigmoid'),\n",
    "        keras.layers.Dense(3,activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impossible-partner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dense-melissa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA4wElEQVR4nO3dd3wc1bn/8c+zRc2S5SK5yrhhDDauCDAQagg9EEgIOLSQwiWBAJebAmn43t9NbiokJFwIIbTQQ7sQIKEEUxKaDe42brgIN1m21cuW8/vjjOS1vZJl2as19vf9eu1L2jOzs8/M7s4z55yZM+acQ0REZHuhbAcgIiJ7JyUIERFJSwlCRETSUoIQEZG0lCBERCQtJQgREUlLCULkE8jMVpjZyZ2Yb5iZOTOLdEdcsm9RgpD9Qmd3qBl433uDHfTZ25X/Jij/cnfHJNJZShAimbcYuKz1SXA0fz6wLGsRiXSCEoTs18wsNziaXxM8fmNmucG0EjP7q5ltMbNNZvaGmYWCad8zs4/NrNbMPjSzT3fwNs8Cx5hZ7+D5acAcYF1KHCEz+6GZrTSzDWZ2v5kVp0y/JJhWZWY/2G4dQmZ2g5ktC6Y/ZmZ99tAmkv2YEoTs734ATAEmAhOAI4AfBtP+A6gASoH+wPcBZ2ajgauBw51zRcCpwIoO3qMJeAa4MHh+KXD/dvN8OXicCIwACoHfA5jZGOB24BJgENAXKEt57TXA54Djg+mbgdt2vuoiHVOCkP3dRcB/Oec2OOcqgf/E74gBYsBAYKhzLuace8P5wcsSQC4wxsyizrkVzrmdNRfdD1wa1AqOB55OE8fNzrnlzrk64EbgwqA56gvAX51zrzvnmoEfAcmU1/4b8APnXEUwfRrwBXVMy+5SgpD93SBgZcrzlUEZwC+BpcCLZrbczG4AcM4tBa7D74g3mNkjZjaIDjjn3sTXRH6I39k3diKOCL7mMghYnbKseqAqZd6hwFNBU9gWYCE+ifXvKCaRnVGCkP3dGvwOttUBQRnOuVrn3H8450YAnwWub+1rcM495Jz7VPBaB/y8E+/1AL7ZavvmpfbiiAPrgbXAkNYJZlaAb2ZqtRo43TnXK+WR55z7uBMxibRLCUL2J1Ezy0t5RICHgR+aWamZlQA/xu/IMbOzzOxAMzOgBn9UnjCz0WZ2UtCZ3QQ0BtN25lbgM8DraaY9DPy7mQ03s0Lgp8Cjzrk48Dhwlpl9ysxygP9i29/uHcBPzGxoEHepmZ2zi9tGZAdKELI/eR6/M299TAP+G5iBP6toLvB+UAYwCngZqAPeAv7XOTcd3//wM2Aj/kykfvgO7A455zY5515x6W/CcjfwZ3zy+AifeL4VvG4+cBXwEL42sRnfed7qt/hO8BfNrBZ4GzhyZ/GI7IzphkEiIpKOahAiIpKWEoSIiKSlBCEiImkpQYiISFr71JWWJSUlbtiwYdkOQ0TkE2PmzJkbnXOl6abtUwli2LBhzJgxI9thiIh8YpjZyvamqYlJRETSUoIQEZG0lCBERCStjPVBmNndwFnABufcoWmmG36IgDOABuDLzrn3g2m9gLuAQ/EDoX3FOfdWV+KIxWJUVFTQ1NTUpfWQvUdeXh5lZWVEo9FshyKyX8hkJ/W9+BuepBu5EuB0/Fg3o/DjxtzO1vFjfgv8zTn3hWBwsoKuBlFRUUFRURHDhg3D5yT5JHLOUVVVRUVFBcOHD892OCL7hYw1MTnnXgc2dTDLOcD9znsb6GVmA82sJ3Ac8KdgOS3OuS1djaOpqYm+ffsqOXzCmRl9+/ZVTVCkG2WzD2IwKTdBwY9OORh/u8VK4B4z+8DM7jKzHu0txMyuMLMZZjajsrKyvXn2YNiSLfocRbpXNhNEul+7wzd7TQZud85NAuqBG9pbiHPuTudcuXOuvLQ07bUeO7W+ponapliXXisisq/KZoKoIOUuWfibsK8Jyiucc+8E5Y/jE0bGVNY2U9cU3+PLraqqYuLEiUycOJEBAwYwePDgtuctLS0dvnbGjBlcc801ezwmEZHOyuaV1M8AV5vZI/jO6Wrn3FoAM1ttZqOdcx8CnwYWZDIQM1912dP69u3LrFmzAJg2bRqFhYV8+9vfbpsej8eJRNJ/BOXl5ZSXl2cgKhGRzsnkaa4PAycAJWZWAdwERAGcc3fg7+51Bv6m8A3A5Skv/xbwYHAG0/Ltpu35WDG668ZJX/7yl+nTpw8ffPABkydP5oILLuC6666jsbGR/Px87rnnHkaPHs306dP51a9+xV//+lemTZvGqlWrWL58OatWreK6665T7UJEMi5jCcI5N3Un0x3+Norpps0C9vjh838+O58Fa2p2KG9oSRAOGbmRXW9xGzOoJzd9duwuvWbx4sW8/PLLhMNhampqeP3114lEIrz88st8//vf54knntjhNYsWLeLVV1+ltraW0aNH841vfEPXA4hIRu1Tg/V9Upx//vmEw2EAqqurueyyy1iyZAlmRiyWvrP8zDPPJDc3l9zcXPr168f69espKyvrzrBFZD+zXyWI9o70F62roSAnwgF9unw93i7p0WPrWbs/+tGPOPHEE3nqqadYsWIFJ5xwQtrX5Obmtv0fDoeJx/d8p7qISCqNxUT39kFsr7q6msGDBwNw7733ZiUGEZF0lCDwZzFly3e/+11uvPFGjjnmGBKJRPYCERHZjmXryDkTysvL3fY3DFq4cCGHHHJIh69bsr6WaDjEsJJ2L9iWvURnPk8R6Twzm+mcS3tSkGoQ+CEc9p00KSKyZyhB4Mf82JdqUiIie4ISBICB8oOIyLaUIAhqENkOQkRkL6MEQWsfhFKEiEgqJQha+yCyHYWIyN5FCYLgOogMJoh169Zx4YUXMnLkSMaMGcMZZ5zB4sWLM/eG+Ivupk7ddjisjRs3UlpaSnNzc7uvufrqqwG44447uP/+He8Wu2LFCg49dIdbjO8wz0MPPdT2XEOXi3wyKUEQXEmdoWU75zj33HM54YQTWLZsGQsWLOCnP/0p69ev32a+PX2R3HnnncdLL71EQ0NDW9njjz/O2Wefvc2wHe258sorufTSS7v03tsniPLycm699dYuLUtEskcJguB+EBlqY3r11VeJRqNceeWVbWUTJ07k2GOPZfr06Zx44ol86UtfYty4cTQ1NXH55Zczbtw4Jk2axKuvvgrA/PnzOeKII5g4cSLjx49nyZIl1NfXc+aZZzJhwgQOPfRQHn300W3et2fPnhx33HE8++yzbWWPPPIIU6dO5dlnn+XII49k0qRJnHzyyTskK/D3r/jVr34FwMyZM5kwYQJHHXUUt912W9s8K1as4Nhjj2Xy5MlMnjyZf/3rXwDccMMNvPHGG0ycOJFbbrmF6dOnc9ZZZwGwadMmPve5zzF+/HimTJnCnDlz2t7vK1/5CieccAIjRoxQQhHZC+xXg/Xxwg2wbu4Oxf3iCeJJBzld2BwDxsHpP2t38rx58zjssMPanf7uu+8yb948hg8fzq9//WsA5s6dy6JFizjllFNYvHgxd9xxB9deey0XXXQRLS0tJBIJnn/+eQYNGsRzzz0H+DGdtjd16lQeeughLrjgAtasWcPixYs58cQTqamp4e2338bMuOuuu/jFL37R9t7pXH755fzud7/j+OOP5zvf+U5beb9+/XjppZfIy8tjyZIlTJ06lRkzZvCzn/2s7V4WANOnT297zU033cSkSZN4+umn+cc//sGll17adlMlDWkusndRDSLLjjjiCIYPHw7Am2++ySWXXALAwQcfzNChQ1m8eDFHHXUUP/3pT/n5z3/OypUryc/PZ9y4cbz88st873vf44033qC4uHiHZZ911lm8+eab1NTU8Nhjj/GFL3yBcDhMRUUFp556KuPGjeOXv/wl8+fPbze+6upqtmzZwvHHHw/QFh9ALBbj61//OuPGjeP8889nwYKd3/gvdR1POukkqqqq2pJb65DmJSUlbUOai0j27F81iHaO9DduaWRLQwtjB+24k91dY8eO5fHHH293eurQ3+01c33pS1/iyCOP5LnnnuPUU0/lrrvu4qSTTmLmzJk8//zz3HjjjZxyyin8+Mc/3uZ1+fn5nHbaaTz11FM88sgj3HLLLQB861vf4vrrr+fss89m+vTpTJs2rd34nHNYO6MZ3nLLLfTv35/Zs2eTTCbJy8trdzkdrWPr8jWkucjeRTUI/GmumeqlPumkk2hubuaPf/xjW9l7773Ha6+9tsO8xx13HA8++CDg7zq3atUqRo8ezfLlyxkxYgTXXHMNZ599NnPmzGHNmjUUFBRw8cUX8+1vf5v3338/7ftPnTqVm2++mfXr1zNlyhRg2yHG77vvvg7j79WrF8XFxbz55psAbfG1LmfgwIGEQiH+/Oc/t3W0FxUVUVtbm3Z5qes4ffp0SkpK6NmzZ4cxiEh2KEEQdFJnbNnGU089xUsvvcTIkSMZO3Ys06ZNY9CgQTvM+81vfpNEIsG4ceO44IILuPfee8nNzeXRRx/l0EMPZeLEiSxatIhLL72UuXPntnVc/+QnP+GHP/xh2vc/5ZRTWLNmDRdccEHbkfq0adM4//zzOfbYYykpKdnpOtxzzz1cddVVHHXUUeTn528T73333ceUKVNYvHhxW21o/PjxRCIRJkyY0FZraTVt2jRmzJjB+PHjueGGG3aaoEQkezTcN7CuupHK2hbGle35JibZszTct8iepeG+d6J1qI19KVmKiOwuJQiCPgg0YJ+ISKr9IkHstGZgrfNlPhbpOtXwRLrXPp8g8vLyqKqq6nDnYkGG0Iiuey/nHFVVVZ06lVZE9ox9/jqIsrIyKioqqKysbHeeuuY4WxpihKrzCIfSn/Mv2ZeXl0dZWVm2wxDZb+zzCSIajbZdqdyeB95eyQ+fmce73/80/XrqCFVEBPaDJqbOiIZ9rSGWVBOTiEgrJQggEvKbIZ5IZjkSEZG9R8YShJndbWYbzGxeO9PNzG41s6VmNsfMJm83PWxmH5jZXzMVY6tIaw0ioRqEiEirTNYg7gVO62D66cCo4HEFcPt2068FFmYksu1Ew0ENIqkahIhIq4wlCOfc68CmDmY5B7jfeW8DvcxsIICZlQFnAndlKr5UkeDMpbhqECIibbLZBzEYWJ3yvCIoA/gN8F1gp4f0ZnaFmc0wsxkdncrakdYaREx9ECIibbKZINJdcODM7Cxgg3NuZmcW4py70zlX7pwrLy0t7VIgrX0QcZ3FJCLSJpsJogIYkvK8DFgDHAOcbWYrgEeAk8zsgUwG0npxnGoQIiJbZTNBPANcGpzNNAWods6tdc7d6Jwrc84NAy4E/uGcuziTgbQ2MSVUgxARaZOxK6nN7GHgBKDEzCqAm4AogHPuDuB54AxgKdAAXJ6pWHZGndQiIjvKWIJwzk3dyXQHXLWTeaYD0/dcVOmpk1pEZEe6khp1UouIpKMEwdahNlSDEBHZSgmCrYP1qQ9CRGQrJQggoqE2RER2oATB1rOYNFifiMhWShBA4Yzfc3Ronq6DEBFJoQQBFLz1a04IzVYntYhICiUIgFCEKHGd5ioikkIJAiAcJUJCd5QTEUmhBAEQ8glCndQiIlspQQAWjpJjCZ3mKiKSQgkCIBQmakldKCcikkIJAiDkaxBqYhIR2UoJAiAcJWoJEmpiEhFpowQB/jRXSxDTaa4iIm2UIMDXIHSaq4jINpQgAEK+iUmd1CIiWylBQFsNQk1MIiJbKUFAWx+EmphERLZSgoC2oTZ0mquIyFZKEOD7INCV1CIiqZQgAMIRIsTVSS0ikkIJAtoG61MNQkRkKyUIgHCUMDrNVUQklRIEQCjsO6l1mquISBslCIBQlLCL6zRXEZEUShCQckc51SBERFplLEGY2d1mtsHM5rUz3czsVjNbamZzzGxyUD7EzF41s4VmNt/Mrs1UjG2CGkRMndQiIm0yWYO4Fzitg+mnA6OCxxXA7UF5HPgP59whwBTgKjMbk8E4IRwhrNNcRUS2kbEE4Zx7HdjUwSznAPc7722gl5kNdM6tdc69HyyjFlgIDM5UnEBQg9BQGyIiqbLZBzEYWJ3yvILtEoGZDQMmAe+0txAzu8LMZpjZjMrKyq5FEo4SIkkikeja60VE9kHZTBCWpqytjcfMCoEngOucczXtLcQ5d6dzrtw5V15aWtq1SEIR/zcZ79rrRUT2QdlMEBXAkJTnZcAaADOL4pPDg865JzMeSTgKgEvGMv5WIiKfFNlMEM8AlwZnM00Bqp1za83MgD8BC51zN3dLJCGfICyhBCEi0iqSqQWb2cPACUCJmVUANwFRAOfcHcDzwBnAUqABuDx46THAJcBcM5sVlH3fOfd8pmJtrUGgGoSISJuMJQjn3NSdTHfAVWnK3yR9/0TmBH0QLpHAOYevxIiI7N90JTW01SCixEloPCYREUAJwgv6ICKWIK4EISICKEF4oTBAcNtRXSwnIgJKEF5bE5MG7BMRaaUEAVubmIjTHFcNQkQElCC8lBpEY0zDbYiIgBKEF5zmGiFBkxKEiAigBOGFt57FpBqEiIinBAFtfRBR4qpBiIgElCAAwmpiEhHZnhIEpNQgEjTFdBaTiAgoQXhBH0RYNQgRkTZKEJByHYQ6qUVEWilBQFsfhJqYRES26lSCMLMeZhYK/j/IzM4O7vq2b0gZrE9NTCIiXmdrEK8DeWY2GHgFf3OfezMVVLcL+iBydJqriEibziYIc841AOcBv3POnQuMyVxY3Sy4kjo/7GhsUYIQEYFdSBBmdhRwEfBcUJaxu9F1uyBB5IWTNMWVIEREoPMJ4jrgRuAp59x8MxsBvJqxqLpb0MSUH07S2KJOahER6GQtwDn3GvAaQNBZvdE5d00mA+tWQSd1bkg1CBGRVp09i+khM+tpZj2ABcCHZvadzIbWjYI7yuWHkjSpD0JEBOh8E9MY51wN8DngeeAA4JJMBdXtzCAUVQ1CRCRFZxNENLju4XPA/znnYsC+dW/OsE8QOotJRMTrbIL4A7AC6AG8bmZDgZpMBZUVoSg5oaSupBYRCXS2k/pW4NaUopVmdmJmQsqScIRcXUktItKms53UxWZ2s5nNCB6/xtcm9h1tNQglCBER6HwT091ALfDF4FED3JOpoLIiHCVHtxwVEWnT2QQx0jl3k3NuefD4T2BERy8ws7vNbIOZzWtnupnZrWa21MzmmNnklGmnmdmHwbQbOr86uyEU0WiuIiIpOpsgGs3sU61PzOwYoHEnr7kXOK2D6acDo4LHFcDtwbLDwG3B9DHAVDPL/LhPKTUI5/atE7RERLqis+MpXQncb2bFwfPNwGUdvcA597qZDetglnOA+53fG79tZr3MbCAwDFjqnFsOYGaPBPMu6GSsXROKEkn65qXmeJK8aDijbycisrfrVA3COTfbOTcBGA+Md85NAk7azfceDKxOeV4RlLVXnpaZXdHaeV5ZWdn1aEJhogQJQs1MIiK7dkc551xNcEU1wPW7+d6W7i06KG8vpjudc+XOufLS0tKuRxOOEgkShDqqRUR2b8judDvyXVEBDEl5XgasAXLaKc+sUJQIcQCd6ioiwu7dk3p3e3KfAS4NzmaaAlQ759YC7wGjzGy4meUAFwbzZpZqECIi2+iwBmFmtaRPBAbk7+S1DwMnACVmVgHcBEQBnHN34Af9OwNYCjTgb2OKcy5uZlcDfwfCwN3OufmdX6UuCkUIO9UgRERadZggnHNFXV2wc27qTqY74Kp2pj2PTyDdJxwlrBqEiEib3Wli2reEooSdzmISEWmlBNEqHCEUNDGpBiEiogSxVSjaliDUByEiogSxVThKKBkDVIMQEQEliK1CESzZWoNQH4SIiBJEq3AUUxOTiEgbJYhWoSgkYpgpQYiIgBLEVuEoloyTHw3T2KIEISKiBNEqFIZEjPxomAbVIERElCDahKKQjHFA3wKWrq/LdjQiIlmnBNEqHAWX5LAhxcyu2EJLXGcyicj+TQmiVcgPS3XYAUU0x5MsWFuzkxeIiOzblCBahaMATC4rBGDmys3ZjEZEJOuUIFqFfILoXxBicK983leCEJH9nBJEq1xfc6C5jsOG9mbGyk34EclFRPZPShCt8nv7v01bKB/Wm/U1zcz7WP0QIrL/UoJo1ZogGjdzzsTB9O2Rw03PzCOZVC1CRPZPShCtUhJEcX6UG884hPdXbeHxmRXZjUtEJEuUIFqlJAiA8yYNZvIBvfjlix/S0BLPYmAiItmhBNEqr5f/GySIUMj4wZmHUFnbzJ/e+Ch7cYmIZIkSRKtoPoRz2xIEwGFD+3DKmP784fXlrK9pymJwIiLdTwmilZlvZmrc9vqHG04/mHgyyX88Nlsd1iKyX1GCSJUmQYwoLeSmz47lzaUbufON5VkKTESk+ylBpMrvDY1bdii+8PAhnDFuAL/6+4fMXr3jdBGRfZESRKp2EoSZ8T/njqd/zzyueeQDapti3R+biEg3U4JIlaaJqVVxQZTfXDiRis2NXK/+CBHZDyhBpMrv1W6CADh8WB9+cMYhvLRgPb99ZUn3xSUikgUZTRBmdpqZfWhmS83shjTTe5vZU2Y2x8zeNbNDU6b9u5nNN7N5ZvawmeVlMlbAJ4hYPcSb253l8mOG8YXDyvjtK0v4y4zVGQ9JRCRbMpYgzCwM3AacDowBpprZmO1m+z4wyzk3HrgU+G3w2sHANUC5c+5QIAxcmKlY27RdTb2l3VnMjJ+eO45jR5Vww5Nz+e3LS2hs0T2sRWTfk8kaxBHAUufccudcC/AIcM5284wBXgFwzi0ChplZ/2BaBMg3swhQAKzJYKzedsNttCcnEuL2iw/jtLEDuOXlxZxx6xss3aD7WIvIviWTCWIwkNoGUxGUpZoNnAdgZkcAQ4Ey59zHwK+AVcBaoNo592IGY/U6mSAACnMj3HbRZB782pHUNsU497Z/cturS9lY137zlIjIJ0kmE4SlKdv+1J+fAb3NbBbwLeADIG5mvfG1jeHAIKCHmV2c9k3MrjCzGWY2o7Kycvci3oUE0eqYA0v4v6s/xcQDevHLv3/IsT9/lVtfWUJ9swb4E5FPtkgGl10BDEl5XsZ2zUTOuRrgcgAzM+Cj4HEq8JFzrjKY9iRwNPDA9m/inLsTuBOgvLx898497UKCABjcK58/f/VIlm6o5eaXFnPzS4v505sfcc7EQYwsLeTM8QMpKczdrdBERLpbJhPEe8AoMxsOfIzvZP5S6gxm1gtoCPoovga87pyrMbNVwBQzKwAagU8DMzIYq9c6omvTli69/MB+RfzvRYfxwarN/OG15Tw2YzVNsSR/fGM5915+BAf2K9xjoYqIZFrGEoRzLm5mVwN/x5+FdLdzbr6ZXRlMvwM4BLjfzBLAAuCrwbR3zOxx4H0gjm96ujNTsbbJ7QkW2uUaxPYmHdCbOy45DOccH6zewhX3z+Dkm18jGjbGDirmuFEllBblMnZwMZOG9MJXnkRE9i7m3L5zRXB5ebmbMWM3Kxq/GAHFQ+Dzf4KSA/dIXKs3NfDM7DVUN8Z4Z3kVsyuq26b175lL+bA+DCrOIz8nwmcO6c/BA4tojicpzM1kBU9EBMxspnOuPO00JYjtfPAAvHADJOPwzbegz/A9E1yK5niCLQ0x/rVsI68s3MAHq7awuaGFpliC1BE8DupfyKj+RTS1JPh4SyO50TDHjyphVP8i+vbIAYNVVQ1samihpDCX0qJchvQuYGRpD5IOtjS00Lsgh1DI11ASSYdB23MRESWIXbV5BfzuMDjiCjjtf3Z/eZ1U3RDjhXlrWV/TTMjgreVVrKtuIjcaZlBxHlsaY3ywajM7GwaqtCiXhuY49S0JciIhivOjAFTVNZMbCTOitAcjSwspzItQ3xynvjlBfXOc5niCkaWFlA/rzZHD+/La4kqWbqhjQHEe4ZBR2xTj482NxBKOwtwI44cUU5wfJZF0FOVF2FwfY2NdM0P7FjCoVz4hM2au3ExjLMGQ3gUc0KeApHNUbG4kPydEcX4OvQui9C7IoTg/SihkNMV8LH0Lc0kkHYvX1/LRxnpKi3I5dFAxedFQW5NcPJGkOZ4kEjZyI2GcczTHk+RGQl1utnPOEU86omGNQiP7ByWIrnjia/Dh3+D6BZDXc88scw+oa46zZksjVXUtOOco611ASVEOVXUtbKhtZsn6Wt5aXkXPvCjDSnqwvqaJ2qYYzvnEUd+cYFllHUs31NEUS9AjN0KP3AiFuWEioRAfrq9lU31L2/sV5UaoDU7ZDYeMgcV55EXDbKpv2Wa+3VWUG2HiAb2YvXoLNU1xDhvam1WbGqis3fa6knDIGNwrn35FucxfU0NjzF/F3jMvQtL57VOUG2Fw73zKeuczqFc+SedYtqGehHNEw0YkFCIaDhENGyEzPtpYz6b6FsYO6smSDXWsrW7ky0cPozA3yoyVmygtzCUnEqKhJUFDS5yeeVFG9iskEjJWVDWwaF0NBw/oyfCSAjbVx8iPhqlrjjF7dTU98yOM6l/E4cN6M2vVFuavqWFInwKfCFsSlA/tzeaGFmat3sKm+haG9Cng1LEDcM7R2JIg4RzJpCOR9ImrvjlBJGwM6OmT9qb6FlZW1VNckENO2Jj7cTUlhbkcPLAnvfKjVNU1s6m+haF9e1CYF6GhJU7Fpkaa4glyI2FGlhYSDhnrqhvJzwlTnJ9DUV6EpliCuuY4DS0J+hXlsrkhxisL1zN2UE9OHtOfxpYE1Y0xapri1DTGKM6PMrh3Pj1yfLNoLJEMHo6k8wcQ0XCIpHP0yInw0cZ63v1oE4N755MfDbN0Qx2HDOzJoYN70hRLUtY7nx65ERJJx6uLNjBvTTUjSwuJJ5NU1bVQmBuhMC9Cr/wcRpT2IBwyNtY1EwmF2FTfwqpN9YTMyIuGMYP5a2qobYoxoqSQEaU9KCnMpaElwbC+BfTpkcOKqnqSzp+b//GWRgDyomHqmuKEQ0ZRXoSivGjbeqzaVE9VXQtJByWFOfTI9QdbcyqqiSWSTBnRl94FOZgRPIx4IsnmhhibG1qobohR3RhjXFkxhwzoyXNz15IXDXH8QaUU5fkDOuccZoZzjoYW/1t1zrGsso75a2oAOHpkCU2xBJvqW5gwpFeXfntKEF1RMRPuOglO+zlMuXLPLPMTwDnHwrW1vPNRFeVD+zCurJiGljjO+R9MOGiecs6xOtjRhAxqm+IU50fpW5jLyqp61lU30RxPMnFIL3oVRFm9qZFVm+oB44A+BW3NbFsaW9hcH2PJhlpmrtzM2EHFHNCngJcXrueAPgV8Zkx/DupfxNrqJhavr6W+Oc7KTQ2sq25i3OBiBvXKozmWZENtM+GQUVqUS2VtMxWbG6nY3MCaLY04YFS/QnIiIeIJ17bjiieTxBOOwb3z6dMjh3kfVzO4dwG9C6I8M9ufkT26fxG1TXFiiSQFOWHycyJsqm9mfY1PXEW5EUYPKGLRulrqmuNEw0Ys4cgJhxg7uCeNLT4hxxIOMziwtJA1W/zOOBoOsba6CTM4eEBPSotymfdx9S4n3sLcCPXBZzSsbwFV9S3UNnV8HU4kZMR3cUTiksLcbrsQNBzySbCmKbbTdemMSMjIzwmnXVZXtsWelBsJ0RxPtj3PCWqvsWSS0sJcmmIJaprijCjtQTLpWFHVsMMySgpzmfHDk7v0/koQXXX7p6CgN1z27J5bpnwirKpqICcSYkBx+jEiW5NmfjRMKGTEEkkaYwmKciPEEv43lRPxP/T65jizVm9hRGkPBhbnty3DBc1thbkRevfIAfyR98K1NRTkRMjPCRMJ+VpOJGSEQkaPnDCxhGNdcI/0orwIfXvk0JJI0hJPUpQXJZl0VNY1U90Yo1fQhLdqUwONLQnyc8IM7pVPXjRMUyzB0g11JJ1jUK98mmK+VlDXFCcvGqYwL0JeNMy66ibCIWNCWTEfbaxn7sfV9MyL0jM/QnF+lKK8KJvqW1hb3UhjSxIzv9ONRkJEQyFCBjVNMeJJR8iM+uY4JYW5TBnRl/U1TTTFEwwv6cGcimpWbKwnNxpmyfpaKjY30iM3zDEjSzh+dCkfbawnNxKmtDCXhlic2qY4G+uaWVZZD0BpYQ7xpKNnXpThJT0AaIoliCUcI0p7kBsJUVXfwrINdWxpjJEXvE9lXTOj+xeREwmRSDoG98rHzGiOJSjMixBPOuqa/PvVNsVojic5oE8BJYW5mMHGumYaWxLkRcMcPLCIcMiYsWIzjS0Jks7hgs86HArRuyBKrwLftNojN8KLC9Yzr6KacycPJhwy3v1oEzVNMQz/mW+obSIaDtGvKI/3V/mzK08dO4DJQ3vRFEvy7kdVFOdHOaBPD6aM6NOlplUliK569lqY/xR8b6WvJ4qI7GM6ShDqievIwInQVO07rUVE9jNKEB0ZOMH/XTs7u3GIiGSBEkRH+o2BUEQJQkT2S0oQHYnmQb9DYO2sbEciItLtlCB2ZuAEX4PYhzrzRUQ6QwliZwZOhIYq2LIq25GIiHQrJYidGXmS/zvrwezGISLSzZQgdqbvSDjodHjvTxBrzHY0IiLdRgmiM476JjRshDmPZTsSEZFuowTRGcOOhf7j4N071VktIvsNJYjOMIPyy2H9PPj4/WxHIyLSLZQgOmvc+RAtgPfvzXYkIiLdQgmis/J6wqHnwdwnoLk229GIiGScEsSumPxliNXD3MezHYmISMYpQeyKsnLoNxZm3pvtSEREMk4JYleYwWGX+bGZ1szKdjQiIhmlBLGrxn8RInmqRYjIPk8JYlfl9/ZJ4oMHoGpZtqMREckYJYiuOPEHEMmFv/8g25GIiGSMEkRXFA2A474Di1/w96wWEdkHKUF01ZRvQtnh8PRVsG5etqMREdnjlCC6KpIDFzzgL6B77FKN9Coi+5yMJggzO83MPjSzpWZ2Q5rpvc3sKTObY2bvmtmhKdN6mdnjZrbIzBaa2VGZjLVLigbAuXfApmXw+q+yHY2IyB6VsQRhZmHgNuB0YAww1czGbDfb94FZzrnxwKXAb1Om/Rb4m3PuYGACsDBTse6WESfA+Avhn7+BxS9CzVp47RdQXZHtyEREdkskg8s+AljqnFsOYGaPAOcAC1LmGQP8D4BzbpGZDTOz/kAjcBzw5WBaC9CSwVh3z6k/gTXvw0PnQzgHEi3QsAlO/1m2IxMR6bJMNjENBlanPK8IylLNBs4DMLMjgKFAGTACqATuMbMPzOwuM+uR7k3M7Aozm2FmMyorK/f0OnROjxK48k04eRpMugSGTIEPn9e9I0TkEy2TCcLSlG2/x/wZ0NvMZgHfAj4A4viazWTgdufcJKAe2KEPA8A5d6dzrtw5V15aWrqnYt91kVz41L/DWTfDhAtgy0qoXJS9eEREdlMmE0QFMCTleRmwJnUG51yNc+5y59xEfB9EKfBR8NoK59w7wayP4xPGJ8NBp/m/H76Q3ThERHZDJhPEe8AoMxtuZjnAhcAzqTMEZyrlBE+/BrweJI11wGozGx1M+zTb9l3s3XoOgoETYcHTEGvKdjQiIl2SsQThnIsDVwN/x5+B9Jhzbr6ZXWlmVwazHQLMN7NF+LOdrk1ZxLeAB81sDjAR+GmmYs2IyZfC2tlw2xGw8Fn1R4jIJ465fWjHVV5e7mbMmJHtMLZa/hr87QbYsABGngTn3gmFWewnERHZjpnNdM6Vp5umK6kzacTx8G9vwOm/gJX/gjtP8MOEV36Y7chERHZKCSLTwhE48t/gK3+DUAievRZuOxJe+6WanURkr6YE0V0GTYJrZsO33odx58Or/+3HcGquy3ZkIiJpZfJKatleKAR9R8J5d8LA8fDSj+EP82Do0dD/0K1/Q+Gtr0kmYMmLMPQYPzCgiEg3UYLIBjM4+lvQf6wft2nJS/4OdQC5xTD0KJ8QDj4Tpv8M5j4Ghf1hwlTAwYGfgWGf8stJlUxCw0Yo7Nftq9Stmuv8lerjzt9xG4jIHqOzmPYW1RW+I3vFm7Dyn1C1dOu0Kd+Eivf8IxSBZBwOOBouegxyi7bO99d/h1kPw1VvQ+9h6d+ncQvM/YsfEiSal8k12n2bV/rtMemibcvf+DW88l/wlb/DAVOyE5vIPqKjs5hUg9hbFJf5e12P/6J/vnklzHvC1wYmXezLkklINPvaxgvfg0cv8WdIFQ2AjYthxj2A87WSz/2vf03rAUDrkfZLP4L374fGzXD8d3c/7i2rYfHfoPyrvgkNYOZ90OsAGHni7i372Wth+aswYJxvkmu16Dn/d+krezZBfDwTeg+Hgj57bpmy/2qqgcZN7R+sfQKok3pv1XsoHHv91uQAfgcczYcjvg5n3+p3nrcdDj8fCn8+1yeKw74Msx/2F+e99yf49cHwq4Pg8a/A7Efg/T9DTiG8eQvUrEn/3s5Bc+3W5/VVW8v+cjkset6XJ2Lw6MXw/Ldh5t2+7P374dlr/Ps1VcP8p2Hx39O/TyIGb9/hk8z2Vrzp1w9g5j1by2vW+h05wNKXd7YVO2/TcrjrM/DA5yER33PL3ZmqZX47fRI5By0N2Y4iM1b8E/56fddvBFZfBXd9Gu44zieKzkom4aEL0t/v/qPXYcke/M53gmoQn1STLoZ+Y/yObeMSWP02HHW1P1tq/tN+xw1+ZNneQ/1Oet4TUNAXLnkK7joZfn8E5PTwR+gFfaHmY9/UVbPG11QOORv6HujvdTHyJLCQ7zBf/De4/HmY+zisneWPkF7+T6ir9M0/Ayf68kcvho/e8J3uFz/prwtJ9a/fwSv/CW/9Hk79qb/yfMw5UHqwb0IqGuhrCHMeg8/8l29OWxyMbzX2XL+e9VXQo2/H2yre7H9cAye2f6Hi678GnB+2/V+3+uS8M6vehniTvydIV1R+CH84HkpGwdde8Xcp3F7jFsjvtWvLbdzil33Akbv2Ouf8I9SJ48Z5T/qaas0a+Porfh32Zk3VPpn1HLjzeT98AR67zP8GcgrglP/etfeKNcKDX4DNK/zQ/7MehCnfSD/vgmfg3Tvhi/f7musH9/vfF8DY86DsMP//unnw4PkQisL1C7aesJKIw7J/QNUSOOqqXYuzE9QHsS+qq4TKhf7eFEOO9M1LTTXw/n0+GYw4wf8IFv/d7zzXvO87fosH+6aunoPBJeHdP/ofyYEn+x1sogWOvwFm3A31G/x7TbwIjv0P+N+j/LyjToHz/gjPXe8T0uByaKn3O5KJX/JncYXCkN8bnrrST9+wwFfFAaI9oN8h8PEM+NztPkH96TNwxBVw5JXw9DegbgN8/i5/hPb5P/kO+1d/4t9n3PkwYLxPLsk4zHrA7/xrKiCS73eatev89sjpAaM+4xPc326Ew78GtWth0V99ojrodJ9ci4dA9WpYM8snqd5Dfa3nmav9djrvjzDuC/7o7q3fwZHfgNHBgI3JBGxZ5f8Wl23t94k1+SS9aTnE6v1IwJ++yX9WyaTfSb/+S/jHf8OZN8PhX936+SYT/rMr7Oe3Z3OdX99wxN+H5N6zYMN8H9f4L8L6+fDij6CsHI6+Bp68wr/PsdfDoMn+/3Xz4Okr/c7tpB/55Sea4ezf+e2Uaua9vvmv3xi/LYsGwtde9jvTzqpc7L+PI07w36+OTjZo2OTXeVdGIUgmAPPbce0ceHiqb1Y9/1446BS/vv/6HfQZARMu9J8pwJy/wFP/BgMn+KQ39y/w2d/C8ON23lTUuAXyiuGF7/qd/oUPwT9v9d+pz/7G17yrlvp1LR7i1/3pb0K80X+3j/sO/P5w/53fvMLHdNmzULceHviC/801VcNpP/MJZ80seOQi/90uGgTXzk5/kLETHfVBKEFI+6qW+S/3sE/5L+OGhTBxKlTM9M1Yo0+DESf6Hf6aD/wOuN/B/rU1a+Cfv4Vjvw2xBt/stOod/2NoldsTrnrX79jXz/U79r9cBhsWwTm/9z9c5/wPds6jW193yk/8D+SXB0JLna/ZuKRvOmtNNOEc3xzXVA1lh/v5l/3D7xiKy/xRee36IPE1Q7TAX6OSU+B3zDPvh+adNP0ccLT/sa/8l1+X5mr/vsmE798p6Avv/MEf3YE/+us/xifg1e/6M86mPuIT0gcPQOEAvy5166HPcL8z6VHqd5An/dAvu9cQv4Ne9o9tY8kp9DWv2nVQXwmlB/laRNkRsOotCEd9badwgN/R5Bb5bdOjH+QW+h1SQV+/HbashEiePyAYNBlGn+63c3Otf828J32NcurDfjiZBz/vXzvyJD8GWdVS309kYX+vlF5DfZ/Uxg993OFc/31JxnzshQP8kb2F/IHDiBP9uq6f6+/SWLfOL+vwr/l1W/GGP4joOdivd/+xvja36K9+eyXjPqHD1u9Gz8GQ38cnzp5lfqcaLfDrBf6swVDY13iHfcqvG/jRD6qWAuZvDDb2XF+jnfe4P2Hk4LN8TMun++H9+43xBzxTvgmn/Y+v5f7lsq2fUckovy6Vi/x7t9aSFzzjY6xbB19/FdbN8QdDucX+9xMKw8VPwCv/z/8mT7jB90PmFfv3GXVql5IDKEHI3iLe4ncwiRb/oyvsvzWhtIo1+R1ncdm25RUz/I7uoNOh5EBftuwf/hFv8VerFw/x82xa5nd4dZVw6HkdH6HGm32NJJwDRf23Ld+80h/9b1npd3RlR/gEV7Xc78THnut3Pm/dBg1V/mh0/Bfhia9u3YGXHuL7jHJ6+AS7bq5vxisdDeWX+51qrMkn3FVvA87XDNbN882Fn7oO7j3Tv65VOMc3ybU2C+YU+umblvlpU77hm9MeOM8n2BEnwDHX+ua/d/4A5/3Bb5N5T/rtFW/2yeWIr/uk+uELfodZ8Z6vbcQbfXLLLfLJZMB4OPcP/n/wO/H5T/qmkcbNvqzvKL+s+o1+h4bzO8ahRwfTD/RJdPl0399Ut8HPs2WVP+ECIKcIRp0Mgw/z35eZ9/l1PehUv64NVf6ovbnG7+zHnutrQKGwP9kgFPbJIhSBwy73n8Gbt/htVtjfb5OWOt83N/8pH++QKfDpH/n/W78HGxb6bbcwZTDqssP993jtbP/egw/zO/pFz/nkevkLvraYiPvrnfodDOMv8PeNAb+dZj8Kw4/1sfxusq89f/F+GHK4n+ej1/1ZibmFvobZc9C2CadkNFzy5I6/lV2kBCHSnZzzR/KxBt8skXrhY1ckYn4nm1MImz7ybdV9hndtWbHGrTu/Ts3f5JNr646tIy0N/vqUwv7bXqcTb/ZJMa/XzvuLwJ+IEIr49UzddtUVPknlFW8tc8430xX03fW+ml2RTMK7f/AHOOPO90174BNgfp/O9dt0pPpjnwhS1629OBY87ZufBkzwzYq7SQlCRETS0miuIiKyy5QgREQkLSUIERFJSwlCRETSUoIQEZG0lCBERCQtJQgREUlLCUJERNLapy6UM7NKYGUXX14CbNyD4ewpimvX7a2xKa5do7h2XVdiG+qcSzsS4j6VIHaHmc1o72rCbFJcu25vjU1x7RrFtev2dGxqYhIRkbSUIEREJC0liK3uzHYA7VBcu25vjU1x7RrFtev2aGzqgxARkbRUgxARkbSUIEREJK39PkGY2Wlm9qGZLTWzG7IYxxAze9XMFprZfDO7NiifZmYfm9ms4HFGluJbYWZzgxhmBGV9zOwlM1sS/O3dzTGNTtkus8ysxsyuy8Y2M7O7zWyDmc1LKWt3+5jZjcF37kMzOzULsf3SzBaZ2Rwze8rMegXlw8ysMWXb3dHNcbX72XXXNmsnrkdTYlphZrOC8u7cXu3tIzL3PXPO7bcPIAwsA0YAOcBsYEyWYhkITA7+LwIWA2OAacC394JttQIo2a7sF8ANwf83AD/P8me5DhiajW0GHAdMBubtbPsEn+tsIBcYHnwHw90c2ylAJPj/5ymxDUudLwvbLO1n153bLF1c203/NfDjLGyv9vYRGfue7e81iCOApc655c65FuAR4JxsBOKcW+ucez/4vxZYCAzORiy74BzgvuD/+4DPZS8UPg0sc8519Ur63eKcex3YtF1xe9vnHOAR51yzc+4jYCn+u9htsTnnXnTOxYOnbwNlmXr/XYmrA922zTqKy8wM+CLwcCbeuyMd7CMy9j3b3xPEYGB1yvMK9oKdspkNAyYB7wRFVwdNAXd3dzNOCge8aGYzzeyKoKy/c24t+C8v0C9LsQFcyLY/2r1hm7W3ffa2791XgBdSng83sw/M7DUzOzYL8aT77PaWbXYssN45tySlrNu313b7iIx9z/b3BGFpyrJ63q+ZFQJPANc552qA24GRwERgLb56mw3HOOcmA6cDV5nZcVmKYwdmlgOcDfwlKNpbtll79prvnZn9AIgDDwZFa4EDnHOTgOuBh8ysZzeG1N5nt7dss6lseyDS7dsrzT6i3VnTlO3SNtvfE0QFMCTleRmwJkuxYGZR/Af/oHPuSQDn3HrnXMI5lwT+SAabIjrinFsT/N0APBXEsd7MBgaxDwQ2ZCM2fNJ63zm3Pohxr9hmtL999orvnZldBpwFXOSCRuugOaIq+H8mvt36oO6KqYPPLuvbzMwiwHnAo61l3b290u0jyOD3bH9PEO8Bo8xseHAUeiHwTDYCCdo2/wQsdM7dnFI+MGW2c4F527+2G2LrYWZFrf/jOzjn4bfVZcFslwH/192xBbY5qtsbtlmgve3zDHChmeWa2XBgFPBudwZmZqcB3wPOds41pJSXmlk4+H9EENvyboyrvc8u69sMOBlY5JyraC3ozu3V3j6CTH7PuqP3fW9+AGfgzwZYBvwgi3F8Cl/9mwPMCh5nAH8G5gblzwADsxDbCPzZELOB+a3bCegLvAIsCf72yUJsBUAVUJxS1u3bDJ+g1gIx/JHbVzvaPsAPgu/ch8DpWYhtKb59uvW7dkcw7+eDz3g28D7w2W6Oq93Prru2Wbq4gvJ7gSu3m7c7t1d7+4iMfc801IaIiKS1vzcxiYhIO5QgREQkLSUIERFJSwlCRETSUoIQEZG0lCBEdsLMErbtqLF7bNTfYDTQbF2nIdKhSLYDEPkEaHTOTcx2ECLdTTUIkS4K7gvwczN7N3gcGJQPNbNXggHnXjGzA4Ly/ubvvTA7eBwdLCpsZn8Mxvh/0czyg/mvMbMFwXIeydJqyn5MCUJk5/K3a2K6IGVajXPuCOD3wG+Cst8D9zvnxuMHwbs1KL8VeM05NwF/v4H5Qfko4Dbn3FhgC/7qXPBj+08KlnNlZlZNpH26klpkJ8yszjlXmKZ8BXCSc255MIjaOudcXzPbiB8iIhaUr3XOlZhZJVDmnGtOWcYw4CXn3Kjg+feAqHPuv83sb0Ad8DTwtHOuLsOrKrIN1SBEdo9r5//25kmnOeX/BFv7Bs8EbgMOA2YGo4mKdBslCJHdc0HK37eC//+FHxkY4CLgzeD/V4BvAJhZuKP7BphZCBjinHsV+C7QC9ihFiOSSToiEdm5fAtuUh/4m3Ou9VTXXDN7B3+wNTUouwa428y+A1QClwfl1wJ3mtlX8TWFb+BHDU0nDDxgZsX4G7/c4pzbsofWR6RT1Ach0kVBH0S5c25jtmMRyQQ1MYmISFqqQYiISFqqQYiISFpKECIikpYShIiIpKUEISIiaSlBiIhIWv8fN94xOXG3J0oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "south-penalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-envelope",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
