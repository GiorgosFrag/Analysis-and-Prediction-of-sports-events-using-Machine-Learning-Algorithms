{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "orange-seattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 696us/step - loss: 1.0527 - accuracy: 0.4591 - val_loss: 1.0357 - val_accuracy: 0.4588\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 1.0154 - accuracy: 0.4926 - val_loss: 1.0054 - val_accuracy: 0.5164\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9933 - accuracy: 0.5313 - val_loss: 0.9954 - val_accuracy: 0.5301\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9866 - accuracy: 0.5299 - val_loss: 0.9932 - val_accuracy: 0.5283\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9840 - accuracy: 0.5294 - val_loss: 0.9917 - val_accuracy: 0.5252\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9822 - accuracy: 0.5297 - val_loss: 0.9904 - val_accuracy: 0.5257\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9806 - accuracy: 0.5307 - val_loss: 0.9889 - val_accuracy: 0.5292\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9793 - accuracy: 0.5311 - val_loss: 0.9881 - val_accuracy: 0.5296\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9783 - accuracy: 0.5310 - val_loss: 0.9874 - val_accuracy: 0.5292\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9774 - accuracy: 0.5306 - val_loss: 0.9869 - val_accuracy: 0.5301\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9767 - accuracy: 0.5311 - val_loss: 0.9864 - val_accuracy: 0.5279\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9761 - accuracy: 0.5304 - val_loss: 0.9860 - val_accuracy: 0.5279\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9757 - accuracy: 0.5316 - val_loss: 0.9857 - val_accuracy: 0.5199\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9753 - accuracy: 0.5310 - val_loss: 0.9854 - val_accuracy: 0.5208\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9747 - accuracy: 0.5303 - val_loss: 0.9854 - val_accuracy: 0.5283\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9749 - accuracy: 0.5312 - val_loss: 0.9855 - val_accuracy: 0.5181\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9744 - accuracy: 0.5310 - val_loss: 0.9849 - val_accuracy: 0.5208\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 551us/step - loss: 0.9743 - accuracy: 0.5310 - val_loss: 0.9849 - val_accuracy: 0.5270\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 606us/step - loss: 0.9740 - accuracy: 0.5317 - val_loss: 0.9852 - val_accuracy: 0.5186\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9742 - accuracy: 0.5315 - val_loss: 0.9852 - val_accuracy: 0.5150\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9741 - accuracy: 0.5317 - val_loss: 0.9847 - val_accuracy: 0.5221\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9738 - accuracy: 0.5321 - val_loss: 0.9850 - val_accuracy: 0.5155\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9739 - accuracy: 0.5315 - val_loss: 0.9847 - val_accuracy: 0.5190\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 584us/step - loss: 0.9737 - accuracy: 0.5320 - val_loss: 0.9859 - val_accuracy: 0.5265\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 582us/step - loss: 0.9739 - accuracy: 0.5313 - val_loss: 0.9848 - val_accuracy: 0.5221\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 568us/step - loss: 0.9736 - accuracy: 0.5322 - val_loss: 0.9849 - val_accuracy: 0.5208\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 615us/step - loss: 0.9733 - accuracy: 0.5308 - val_loss: 0.9852 - val_accuracy: 0.5270\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 589us/step - loss: 0.9736 - accuracy: 0.5328 - val_loss: 0.9846 - val_accuracy: 0.5288\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 612us/step - loss: 0.9736 - accuracy: 0.5319 - val_loss: 0.9849 - val_accuracy: 0.5150\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9735 - accuracy: 0.5324 - val_loss: 0.9851 - val_accuracy: 0.5283\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9733 - accuracy: 0.5318 - val_loss: 0.9848 - val_accuracy: 0.5181\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 552us/step - loss: 0.9733 - accuracy: 0.5321 - val_loss: 0.9858 - val_accuracy: 0.5142\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9732 - accuracy: 0.5317 - val_loss: 0.9851 - val_accuracy: 0.5279\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 548us/step - loss: 0.9732 - accuracy: 0.5322 - val_loss: 0.9848 - val_accuracy: 0.5279\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9732 - accuracy: 0.5329 - val_loss: 0.9852 - val_accuracy: 0.5164\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 0.9843 - val_accuracy: 0.5204\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9733 - accuracy: 0.5319 - val_loss: 0.9843 - val_accuracy: 0.5195\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9731 - accuracy: 0.5323 - val_loss: 0.9852 - val_accuracy: 0.5150\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9732 - accuracy: 0.5315 - val_loss: 0.9846 - val_accuracy: 0.5292\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9731 - accuracy: 0.5324 - val_loss: 0.9846 - val_accuracy: 0.5208\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9731 - accuracy: 0.5319 - val_loss: 0.9843 - val_accuracy: 0.5270\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9734 - accuracy: 0.5323 - val_loss: 0.9843 - val_accuracy: 0.5288\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9731 - accuracy: 0.5312 - val_loss: 0.9843 - val_accuracy: 0.5181\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9730 - accuracy: 0.5322 - val_loss: 0.9843 - val_accuracy: 0.5186\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 623us/step - loss: 0.9730 - accuracy: 0.5329 - val_loss: 0.9848 - val_accuracy: 0.5296\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 552us/step - loss: 0.9732 - accuracy: 0.5314 - val_loss: 0.9842 - val_accuracy: 0.5208\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9728 - accuracy: 0.5317 - val_loss: 0.9847 - val_accuracy: 0.5150\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 565us/step - loss: 0.9731 - accuracy: 0.5331 - val_loss: 0.9844 - val_accuracy: 0.5288\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 551us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 0.9843 - val_accuracy: 0.5186\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 611us/step - loss: 0.9731 - accuracy: 0.5319 - val_loss: 0.9845 - val_accuracy: 0.5292\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 556us/step - loss: 0.9729 - accuracy: 0.5313 - val_loss: 0.9844 - val_accuracy: 0.5288\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 554us/step - loss: 0.9728 - accuracy: 0.5326 - val_loss: 0.9848 - val_accuracy: 0.5288\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9727 - accuracy: 0.5318 - val_loss: 0.9844 - val_accuracy: 0.5235\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 557us/step - loss: 0.9730 - accuracy: 0.5313 - val_loss: 0.9841 - val_accuracy: 0.5217\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9728 - accuracy: 0.5316 - val_loss: 0.9844 - val_accuracy: 0.5283\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 0.9841 - val_accuracy: 0.5217\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 518us/step - loss: 0.9729 - accuracy: 0.5323 - val_loss: 0.9844 - val_accuracy: 0.5279\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9727 - accuracy: 0.5320 - val_loss: 0.9843 - val_accuracy: 0.5177\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9728 - accuracy: 0.5322 - val_loss: 0.9839 - val_accuracy: 0.5270\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9730 - accuracy: 0.5312 - val_loss: 0.9840 - val_accuracy: 0.5199\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9728 - accuracy: 0.5324 - val_loss: 0.9840 - val_accuracy: 0.5283\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9729 - accuracy: 0.5331 - val_loss: 0.9840 - val_accuracy: 0.5217\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9729 - accuracy: 0.5320 - val_loss: 0.9842 - val_accuracy: 0.5177\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9729 - accuracy: 0.5326 - val_loss: 0.9840 - val_accuracy: 0.5190\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 554us/step - loss: 0.9728 - accuracy: 0.5319 - val_loss: 0.9843 - val_accuracy: 0.5150\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 560us/step - loss: 0.9727 - accuracy: 0.5322 - val_loss: 0.9848 - val_accuracy: 0.5296\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9726 - accuracy: 0.5321 - val_loss: 0.9848 - val_accuracy: 0.5296\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9728 - accuracy: 0.5308 - val_loss: 0.9841 - val_accuracy: 0.5288\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9728 - accuracy: 0.5323 - val_loss: 0.9841 - val_accuracy: 0.5283\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9729 - accuracy: 0.5319 - val_loss: 0.9841 - val_accuracy: 0.5199\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9730 - accuracy: 0.5317 - val_loss: 0.9839 - val_accuracy: 0.5217\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9729 - accuracy: 0.5319 - val_loss: 0.9839 - val_accuracy: 0.5204\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9727 - accuracy: 0.5321 - val_loss: 0.9840 - val_accuracy: 0.5186\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9726 - accuracy: 0.5313 - val_loss: 0.9841 - val_accuracy: 0.5235\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9728 - accuracy: 0.5314 - val_loss: 0.9844 - val_accuracy: 0.5190\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 552us/step - loss: 0.9727 - accuracy: 0.5320 - val_loss: 0.9841 - val_accuracy: 0.5235\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9728 - accuracy: 0.5331 - val_loss: 0.9845 - val_accuracy: 0.5177\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 563us/step - loss: 0.9729 - accuracy: 0.5323 - val_loss: 0.9843 - val_accuracy: 0.5296\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9726 - accuracy: 0.5311 - val_loss: 0.9838 - val_accuracy: 0.5217\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9728 - accuracy: 0.5316 - val_loss: 0.9839 - val_accuracy: 0.5274\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9728 - accuracy: 0.5320 - val_loss: 0.9841 - val_accuracy: 0.5181\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9727 - accuracy: 0.5327 - val_loss: 0.9839 - val_accuracy: 0.5190\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9727 - accuracy: 0.5320 - val_loss: 0.9838 - val_accuracy: 0.5274\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 552us/step - loss: 0.9727 - accuracy: 0.5317 - val_loss: 0.9841 - val_accuracy: 0.5181\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9727 - accuracy: 0.5329 - val_loss: 0.9843 - val_accuracy: 0.5296\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 554us/step - loss: 0.9726 - accuracy: 0.5318 - val_loss: 0.9845 - val_accuracy: 0.5150\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9728 - accuracy: 0.5323 - val_loss: 0.9839 - val_accuracy: 0.5296\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9727 - accuracy: 0.5323 - val_loss: 0.9838 - val_accuracy: 0.5288\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9727 - accuracy: 0.5322 - val_loss: 0.9839 - val_accuracy: 0.5283\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9726 - accuracy: 0.5319 - val_loss: 0.9838 - val_accuracy: 0.5190\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9727 - accuracy: 0.5317 - val_loss: 0.9844 - val_accuracy: 0.5150\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 556us/step - loss: 0.9724 - accuracy: 0.5316 - val_loss: 0.9839 - val_accuracy: 0.5204\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9728 - accuracy: 0.5309 - val_loss: 0.9838 - val_accuracy: 0.5217\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9726 - accuracy: 0.5305 - val_loss: 0.9853 - val_accuracy: 0.5164\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9726 - accuracy: 0.5328 - val_loss: 0.9843 - val_accuracy: 0.5177\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9727 - accuracy: 0.5323 - val_loss: 0.9837 - val_accuracy: 0.5199\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9837 - val_accuracy: 0.5177\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9727 - accuracy: 0.5328 - val_loss: 0.9839 - val_accuracy: 0.5296\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9726 - accuracy: 0.5330 - val_loss: 0.9841 - val_accuracy: 0.5296\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9726 - accuracy: 0.5316 - val_loss: 0.9845 - val_accuracy: 0.5301\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9726 - accuracy: 0.5322 - val_loss: 0.9837 - val_accuracy: 0.5283\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9725 - accuracy: 0.5315 - val_loss: 0.9837 - val_accuracy: 0.5296\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 551us/step - loss: 0.9726 - accuracy: 0.5318 - val_loss: 0.9842 - val_accuracy: 0.5150\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 556us/step - loss: 0.9726 - accuracy: 0.5323 - val_loss: 0.9836 - val_accuracy: 0.5239\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9723 - accuracy: 0.5326 - val_loss: 0.9850 - val_accuracy: 0.5159\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9725 - accuracy: 0.5318 - val_loss: 0.9841 - val_accuracy: 0.5292\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9726 - accuracy: 0.5320 - val_loss: 0.9838 - val_accuracy: 0.5195\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9725 - accuracy: 0.5323 - val_loss: 0.9843 - val_accuracy: 0.5296\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9726 - accuracy: 0.5314 - val_loss: 0.9842 - val_accuracy: 0.5177\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9725 - accuracy: 0.5323 - val_loss: 0.9836 - val_accuracy: 0.5235\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9727 - accuracy: 0.5331 - val_loss: 0.9836 - val_accuracy: 0.5190\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9724 - accuracy: 0.5331 - val_loss: 0.9838 - val_accuracy: 0.5195\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 510us/step - loss: 0.9726 - accuracy: 0.5324 - val_loss: 0.9845 - val_accuracy: 0.5150\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9725 - accuracy: 0.5321 - val_loss: 0.9842 - val_accuracy: 0.5177\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9724 - accuracy: 0.5328 - val_loss: 0.9837 - val_accuracy: 0.5199\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9726 - accuracy: 0.5324 - val_loss: 0.9843 - val_accuracy: 0.5150\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9726 - accuracy: 0.5323 - val_loss: 0.9835 - val_accuracy: 0.5226\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 549us/step - loss: 0.9725 - accuracy: 0.5316 - val_loss: 0.9839 - val_accuracy: 0.5186\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9726 - accuracy: 0.5327 - val_loss: 0.9838 - val_accuracy: 0.5195\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9725 - accuracy: 0.5322 - val_loss: 0.9843 - val_accuracy: 0.5150\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9726 - accuracy: 0.5326 - val_loss: 0.9835 - val_accuracy: 0.5204\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 549us/step - loss: 0.9727 - accuracy: 0.5315 - val_loss: 0.9837 - val_accuracy: 0.5177\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9724 - accuracy: 0.5311 - val_loss: 0.9842 - val_accuracy: 0.5292\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9724 - accuracy: 0.5320 - val_loss: 0.9838 - val_accuracy: 0.5181\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9724 - accuracy: 0.5330 - val_loss: 0.9835 - val_accuracy: 0.5274\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9837 - val_accuracy: 0.5177\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9725 - accuracy: 0.5324 - val_loss: 0.9838 - val_accuracy: 0.5279\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9726 - accuracy: 0.5331 - val_loss: 0.9851 - val_accuracy: 0.5296\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9725 - accuracy: 0.5314 - val_loss: 0.9839 - val_accuracy: 0.5177\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9727 - accuracy: 0.5325 - val_loss: 0.9839 - val_accuracy: 0.5177\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9727 - accuracy: 0.5321 - val_loss: 0.9837 - val_accuracy: 0.5305\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9725 - accuracy: 0.5313 - val_loss: 0.9837 - val_accuracy: 0.5296\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9726 - accuracy: 0.5316 - val_loss: 0.9837 - val_accuracy: 0.5173\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9725 - accuracy: 0.5321 - val_loss: 0.9840 - val_accuracy: 0.5177\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9724 - accuracy: 0.5324 - val_loss: 0.9849 - val_accuracy: 0.5150\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9725 - accuracy: 0.5312 - val_loss: 0.9836 - val_accuracy: 0.5173\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9726 - accuracy: 0.5326 - val_loss: 0.9836 - val_accuracy: 0.5283\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9725 - accuracy: 0.5321 - val_loss: 0.9843 - val_accuracy: 0.5283\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 557us/step - loss: 0.9726 - accuracy: 0.5330 - val_loss: 0.9838 - val_accuracy: 0.5195\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 570us/step - loss: 0.9727 - accuracy: 0.5316 - val_loss: 0.9834 - val_accuracy: 0.5279\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 576us/step - loss: 0.9723 - accuracy: 0.5318 - val_loss: 0.9848 - val_accuracy: 0.5296\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9724 - accuracy: 0.5323 - val_loss: 0.9836 - val_accuracy: 0.5168\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9726 - accuracy: 0.5325 - val_loss: 0.9836 - val_accuracy: 0.5186\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9723 - accuracy: 0.5331 - val_loss: 0.9843 - val_accuracy: 0.5292\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 551us/step - loss: 0.9724 - accuracy: 0.5319 - val_loss: 0.9835 - val_accuracy: 0.5195\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 565us/step - loss: 0.9725 - accuracy: 0.5322 - val_loss: 0.9837 - val_accuracy: 0.5195\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9726 - accuracy: 0.5315 - val_loss: 0.9835 - val_accuracy: 0.5195\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9725 - accuracy: 0.5320 - val_loss: 0.9839 - val_accuracy: 0.5177\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9725 - accuracy: 0.5319 - val_loss: 0.9834 - val_accuracy: 0.5235\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9726 - accuracy: 0.5320 - val_loss: 0.9836 - val_accuracy: 0.5186\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 584us/step - loss: 0.9724 - accuracy: 0.5316 - val_loss: 0.9835 - val_accuracy: 0.5292\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9725 - accuracy: 0.5311 - val_loss: 0.9835 - val_accuracy: 0.5204\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9727 - accuracy: 0.5323 - val_loss: 0.9833 - val_accuracy: 0.5235\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9724 - accuracy: 0.5330 - val_loss: 0.9835 - val_accuracy: 0.5296\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9725 - accuracy: 0.5329 - val_loss: 0.9838 - val_accuracy: 0.5279\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9725 - accuracy: 0.5317 - val_loss: 0.9835 - val_accuracy: 0.5226\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9726 - accuracy: 0.5310 - val_loss: 0.9833 - val_accuracy: 0.5217\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9725 - accuracy: 0.5320 - val_loss: 0.9837 - val_accuracy: 0.5173\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9725 - accuracy: 0.5322 - val_loss: 0.9834 - val_accuracy: 0.5195\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9726 - accuracy: 0.5323 - val_loss: 0.9833 - val_accuracy: 0.5235\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9726 - accuracy: 0.5314 - val_loss: 0.9838 - val_accuracy: 0.5292\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9725 - accuracy: 0.5324 - val_loss: 0.9835 - val_accuracy: 0.5186\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 562us/step - loss: 0.9723 - accuracy: 0.5317 - val_loss: 0.9840 - val_accuracy: 0.5177\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9726 - accuracy: 0.5318 - val_loss: 0.9834 - val_accuracy: 0.5235\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9724 - accuracy: 0.5323 - val_loss: 0.9834 - val_accuracy: 0.5186\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9726 - accuracy: 0.5326 - val_loss: 0.9833 - val_accuracy: 0.5217\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9725 - accuracy: 0.5318 - val_loss: 0.9834 - val_accuracy: 0.5235\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9725 - accuracy: 0.5326 - val_loss: 0.9835 - val_accuracy: 0.5186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9725 - accuracy: 0.5323 - val_loss: 0.9836 - val_accuracy: 0.5195\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9724 - accuracy: 0.5336 - val_loss: 0.9835 - val_accuracy: 0.5292\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9725 - accuracy: 0.5311 - val_loss: 0.9839 - val_accuracy: 0.5186\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9726 - accuracy: 0.5325 - val_loss: 0.9836 - val_accuracy: 0.5288\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9726 - accuracy: 0.5324 - val_loss: 0.9834 - val_accuracy: 0.5186\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9722 - accuracy: 0.5324 - val_loss: 0.9859 - val_accuracy: 0.5133\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9726 - accuracy: 0.5321 - val_loss: 0.9840 - val_accuracy: 0.5181\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9725 - accuracy: 0.5321 - val_loss: 0.9835 - val_accuracy: 0.5186\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9725 - accuracy: 0.5317 - val_loss: 0.9835 - val_accuracy: 0.5190\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9725 - accuracy: 0.5325 - val_loss: 0.9842 - val_accuracy: 0.5150\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9725 - accuracy: 0.5317 - val_loss: 0.9833 - val_accuracy: 0.5195\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9726 - accuracy: 0.5314 - val_loss: 0.9833 - val_accuracy: 0.5217\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9725 - accuracy: 0.5312 - val_loss: 0.9833 - val_accuracy: 0.5279\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9724 - accuracy: 0.5318 - val_loss: 0.9844 - val_accuracy: 0.5195\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9726 - accuracy: 0.5321 - val_loss: 0.9835 - val_accuracy: 0.5186\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9723 - accuracy: 0.5323 - val_loss: 0.9846 - val_accuracy: 0.5296\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9725 - accuracy: 0.5323 - val_loss: 0.9838 - val_accuracy: 0.5296\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9726 - accuracy: 0.5319 - val_loss: 0.9843 - val_accuracy: 0.5150\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9725 - accuracy: 0.5325 - val_loss: 0.9840 - val_accuracy: 0.5283\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 568us/step - loss: 0.9725 - accuracy: 0.5312 - val_loss: 0.9832 - val_accuracy: 0.5204\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 563us/step - loss: 0.9725 - accuracy: 0.5314 - val_loss: 0.9835 - val_accuracy: 0.5173\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9724 - accuracy: 0.5333 - val_loss: 0.9836 - val_accuracy: 0.5283\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9725 - accuracy: 0.5319 - val_loss: 0.9835 - val_accuracy: 0.5195\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9724 - accuracy: 0.5319 - val_loss: 0.9835 - val_accuracy: 0.5288\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9722 - accuracy: 0.5312 - val_loss: 0.9843 - val_accuracy: 0.5283\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9725 - accuracy: 0.5324 - val_loss: 0.9833 - val_accuracy: 0.5279\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9725 - accuracy: 0.5322 - val_loss: 0.9835 - val_accuracy: 0.5186\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9724 - accuracy: 0.5331 - val_loss: 0.9833 - val_accuracy: 0.5199\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9724 - accuracy: 0.5323 - val_loss: 0.9833 - val_accuracy: 0.5279\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9725 - accuracy: 0.5322 - val_loss: 0.9838 - val_accuracy: 0.5279\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9725 - accuracy: 0.5320 - val_loss: 0.9832 - val_accuracy: 0.5199\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9725 - accuracy: 0.5326 - val_loss: 0.9836 - val_accuracy: 0.5226\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 349us/step - loss: 0.9722 - accuracy: 0.5327\n",
      "Accuracy : 0.5327070355415344\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9836 - accuracy: 0.5226\n",
      "Accuracy : 0.5225663781166077\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "588/636 [==========================>...] - ETA: 0s - loss: 1.0611 - accuracy: 0.4589WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "636/636 [==============================] - 0s 663us/step - loss: 1.0590 - accuracy: 0.4590 - val_loss: 1.0318 - val_accuracy: 0.4593\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 1.0172 - accuracy: 0.4982 - val_loss: 0.9949 - val_accuracy: 0.5350\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9925 - accuracy: 0.5307 - val_loss: 0.9831 - val_accuracy: 0.5376\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9865 - accuracy: 0.5289 - val_loss: 0.9815 - val_accuracy: 0.5358\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9846 - accuracy: 0.5297 - val_loss: 0.9805 - val_accuracy: 0.5323\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9830 - accuracy: 0.5298 - val_loss: 0.9784 - val_accuracy: 0.5363\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9813 - accuracy: 0.5295 - val_loss: 0.9777 - val_accuracy: 0.5327\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9797 - accuracy: 0.5292 - val_loss: 0.9765 - val_accuracy: 0.5376\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9787 - accuracy: 0.5305 - val_loss: 0.9772 - val_accuracy: 0.5372\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9779 - accuracy: 0.5318 - val_loss: 0.9752 - val_accuracy: 0.5367\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9771 - accuracy: 0.5306 - val_loss: 0.9754 - val_accuracy: 0.5367\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9769 - accuracy: 0.5306 - val_loss: 0.9753 - val_accuracy: 0.5367\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9764 - accuracy: 0.5298 - val_loss: 0.9755 - val_accuracy: 0.5372\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9761 - accuracy: 0.5298 - val_loss: 0.9750 - val_accuracy: 0.5372\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9747 - val_accuracy: 0.5367\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9754 - accuracy: 0.5312 - val_loss: 0.9748 - val_accuracy: 0.5372\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9753 - accuracy: 0.5297 - val_loss: 0.9744 - val_accuracy: 0.5372\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9752 - accuracy: 0.5307 - val_loss: 0.9748 - val_accuracy: 0.5354\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9750 - val_accuracy: 0.5372\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9748 - accuracy: 0.5313 - val_loss: 0.9749 - val_accuracy: 0.5372\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 510us/step - loss: 0.9748 - accuracy: 0.5291 - val_loss: 0.9750 - val_accuracy: 0.5372\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9747 - accuracy: 0.5302 - val_loss: 0.9756 - val_accuracy: 0.5341\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9747 - accuracy: 0.5297 - val_loss: 0.9743 - val_accuracy: 0.5363\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9745 - accuracy: 0.5299 - val_loss: 0.9746 - val_accuracy: 0.5367\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9748 - val_accuracy: 0.5367\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9753 - val_accuracy: 0.5350\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9745 - accuracy: 0.5294 - val_loss: 0.9745 - val_accuracy: 0.5372\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9744 - accuracy: 0.5298 - val_loss: 0.9748 - val_accuracy: 0.5350\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9743 - accuracy: 0.5299 - val_loss: 0.9759 - val_accuracy: 0.5345\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9745 - accuracy: 0.5299 - val_loss: 0.9750 - val_accuracy: 0.5363\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9742 - accuracy: 0.5301 - val_loss: 0.9743 - val_accuracy: 0.5363\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9743 - accuracy: 0.5300 - val_loss: 0.9749 - val_accuracy: 0.5372\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9742 - accuracy: 0.5301 - val_loss: 0.9752 - val_accuracy: 0.5332\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 554us/step - loss: 0.9742 - accuracy: 0.5303 - val_loss: 0.9744 - val_accuracy: 0.5367\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9742 - accuracy: 0.5299 - val_loss: 0.9749 - val_accuracy: 0.5336\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9742 - accuracy: 0.5294 - val_loss: 0.9749 - val_accuracy: 0.5345\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9742 - accuracy: 0.5299 - val_loss: 0.9744 - val_accuracy: 0.5363\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9741 - accuracy: 0.5300 - val_loss: 0.9751 - val_accuracy: 0.5372\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9743 - accuracy: 0.5297 - val_loss: 0.9742 - val_accuracy: 0.5367\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9741 - accuracy: 0.5301 - val_loss: 0.9741 - val_accuracy: 0.5372\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9740 - accuracy: 0.5306 - val_loss: 0.9748 - val_accuracy: 0.5372\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9742 - accuracy: 0.5299 - val_loss: 0.9746 - val_accuracy: 0.5363\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9743 - accuracy: 0.5294 - val_loss: 0.9745 - val_accuracy: 0.5367\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9742 - accuracy: 0.5313 - val_loss: 0.9744 - val_accuracy: 0.5367\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9739 - accuracy: 0.5301 - val_loss: 0.9751 - val_accuracy: 0.5341\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9741 - accuracy: 0.5300 - val_loss: 0.9750 - val_accuracy: 0.5363\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9740 - accuracy: 0.5301 - val_loss: 0.9744 - val_accuracy: 0.5363\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9740 - accuracy: 0.5303 - val_loss: 0.9750 - val_accuracy: 0.5372\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9740 - accuracy: 0.5295 - val_loss: 0.9741 - val_accuracy: 0.5363\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9740 - accuracy: 0.5307 - val_loss: 0.9739 - val_accuracy: 0.5372\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9741 - accuracy: 0.5301 - val_loss: 0.9744 - val_accuracy: 0.5341\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9739 - accuracy: 0.5296 - val_loss: 0.9745 - val_accuracy: 0.5372\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9740 - accuracy: 0.5300 - val_loss: 0.9739 - val_accuracy: 0.5363\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9740 - accuracy: 0.5301 - val_loss: 0.9743 - val_accuracy: 0.5367\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9739 - accuracy: 0.5297 - val_loss: 0.9742 - val_accuracy: 0.5372\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9738 - accuracy: 0.5314 - val_loss: 0.9745 - val_accuracy: 0.5341\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9740 - accuracy: 0.5301 - val_loss: 0.9742 - val_accuracy: 0.5363\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9739 - accuracy: 0.5297 - val_loss: 0.9743 - val_accuracy: 0.5376\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9738 - accuracy: 0.5294 - val_loss: 0.9742 - val_accuracy: 0.5363\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9739 - accuracy: 0.5301 - val_loss: 0.9755 - val_accuracy: 0.5367\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9738 - accuracy: 0.5295 - val_loss: 0.9737 - val_accuracy: 0.5363\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9738 - accuracy: 0.5298 - val_loss: 0.9747 - val_accuracy: 0.5367\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9740 - accuracy: 0.5308 - val_loss: 0.9740 - val_accuracy: 0.5372\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9739 - accuracy: 0.5297 - val_loss: 0.9740 - val_accuracy: 0.5367\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9743 - val_accuracy: 0.5372\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 0.9743 - val_accuracy: 0.5367\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9738 - accuracy: 0.5296 - val_loss: 0.9755 - val_accuracy: 0.5327\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9739 - accuracy: 0.5305 - val_loss: 0.9736 - val_accuracy: 0.5363\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9739 - accuracy: 0.5303 - val_loss: 0.9734 - val_accuracy: 0.5372\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9739 - accuracy: 0.5299 - val_loss: 0.9745 - val_accuracy: 0.5363\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9739 - accuracy: 0.5309 - val_loss: 0.9747 - val_accuracy: 0.5367\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9738 - accuracy: 0.5299 - val_loss: 0.9742 - val_accuracy: 0.5372\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9739 - val_accuracy: 0.5363\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9740 - accuracy: 0.5293 - val_loss: 0.9740 - val_accuracy: 0.5363\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9739 - accuracy: 0.5300 - val_loss: 0.9742 - val_accuracy: 0.5367\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9738 - accuracy: 0.5299 - val_loss: 0.9744 - val_accuracy: 0.5358\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 500us/step - loss: 0.9738 - accuracy: 0.5300 - val_loss: 0.9738 - val_accuracy: 0.5367\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9738 - accuracy: 0.5302 - val_loss: 0.9740 - val_accuracy: 0.5345\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9739 - accuracy: 0.5305 - val_loss: 0.9739 - val_accuracy: 0.5367\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9736 - accuracy: 0.5306 - val_loss: 0.9749 - val_accuracy: 0.5358\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9740 - accuracy: 0.5302 - val_loss: 0.9744 - val_accuracy: 0.5372\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9737 - accuracy: 0.5298 - val_loss: 0.9733 - val_accuracy: 0.5363\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 0.9736 - val_accuracy: 0.5372\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9735 - accuracy: 0.5298 - val_loss: 0.9752 - val_accuracy: 0.5363\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9738 - accuracy: 0.5310 - val_loss: 0.9737 - val_accuracy: 0.5367\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9738 - val_accuracy: 0.5372\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9739 - accuracy: 0.5306 - val_loss: 0.9733 - val_accuracy: 0.5367\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9738 - accuracy: 0.5309 - val_loss: 0.9740 - val_accuracy: 0.5372\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 0.9745 - val_accuracy: 0.5363\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9736 - accuracy: 0.5303 - val_loss: 0.9741 - val_accuracy: 0.5367\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 0.9735 - val_accuracy: 0.5367\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9738 - accuracy: 0.5301 - val_loss: 0.9741 - val_accuracy: 0.5372\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9737 - accuracy: 0.5306 - val_loss: 0.9741 - val_accuracy: 0.5367\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9737 - accuracy: 0.5306 - val_loss: 0.9740 - val_accuracy: 0.5372\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9732 - val_accuracy: 0.5367\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9737 - accuracy: 0.5311 - val_loss: 0.9746 - val_accuracy: 0.5367\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9737 - accuracy: 0.5305 - val_loss: 0.9745 - val_accuracy: 0.5336\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 0.9735 - val_accuracy: 0.5367\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9736 - accuracy: 0.5310 - val_loss: 0.9735 - val_accuracy: 0.5363\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9735 - accuracy: 0.5300 - val_loss: 0.9738 - val_accuracy: 0.5363\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 0.9737 - val_accuracy: 0.5372\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9737 - accuracy: 0.5304 - val_loss: 0.9740 - val_accuracy: 0.5372\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9737 - accuracy: 0.5301 - val_loss: 0.9738 - val_accuracy: 0.5367\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9736 - accuracy: 0.5294 - val_loss: 0.9737 - val_accuracy: 0.5363\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9738 - accuracy: 0.5294 - val_loss: 0.9741 - val_accuracy: 0.5367\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9736 - accuracy: 0.5305 - val_loss: 0.9740 - val_accuracy: 0.5372\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9737 - accuracy: 0.5295 - val_loss: 0.9737 - val_accuracy: 0.5363\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9738 - val_accuracy: 0.5358\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9737 - accuracy: 0.5305 - val_loss: 0.9735 - val_accuracy: 0.5363\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9737 - accuracy: 0.5303 - val_loss: 0.9732 - val_accuracy: 0.5367\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9733 - accuracy: 0.5297 - val_loss: 0.9740 - val_accuracy: 0.5372\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9736 - accuracy: 0.5305 - val_loss: 0.9734 - val_accuracy: 0.5376\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9737 - accuracy: 0.5304 - val_loss: 0.9738 - val_accuracy: 0.5363\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9737 - accuracy: 0.5302 - val_loss: 0.9738 - val_accuracy: 0.5363\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9736 - accuracy: 0.5298 - val_loss: 0.9762 - val_accuracy: 0.5314\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9730 - val_accuracy: 0.5363\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9737 - accuracy: 0.5304 - val_loss: 0.9735 - val_accuracy: 0.5372\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9729 - val_accuracy: 0.5341\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9737 - accuracy: 0.5286 - val_loss: 0.9734 - val_accuracy: 0.5363\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9736 - accuracy: 0.5303 - val_loss: 0.9740 - val_accuracy: 0.5372\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9737 - accuracy: 0.5299 - val_loss: 0.9735 - val_accuracy: 0.5367\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9737 - accuracy: 0.5306 - val_loss: 0.9732 - val_accuracy: 0.5372\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9734 - accuracy: 0.5301 - val_loss: 0.9741 - val_accuracy: 0.5372\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9734 - val_accuracy: 0.5367\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9735 - accuracy: 0.5308 - val_loss: 0.9728 - val_accuracy: 0.5367\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9738 - accuracy: 0.5300 - val_loss: 0.9743 - val_accuracy: 0.5367\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9736 - val_accuracy: 0.5372\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9735 - accuracy: 0.5300 - val_loss: 0.9746 - val_accuracy: 0.5367\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9736 - accuracy: 0.5309 - val_loss: 0.9734 - val_accuracy: 0.5363\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9736 - accuracy: 0.5304 - val_loss: 0.9736 - val_accuracy: 0.5327\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9736 - accuracy: 0.5294 - val_loss: 0.9733 - val_accuracy: 0.5372\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9738 - accuracy: 0.5303 - val_loss: 0.9733 - val_accuracy: 0.5367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 563us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9737 - val_accuracy: 0.5367\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5299 - val_loss: 0.9741 - val_accuracy: 0.5367\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9736 - accuracy: 0.5299 - val_loss: 0.9734 - val_accuracy: 0.5367\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9739 - val_accuracy: 0.5363\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9737 - val_accuracy: 0.5367\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9737 - accuracy: 0.5298 - val_loss: 0.9739 - val_accuracy: 0.5376\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9738 - accuracy: 0.5302 - val_loss: 0.9743 - val_accuracy: 0.5376\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9735 - accuracy: 0.5302 - val_loss: 0.9737 - val_accuracy: 0.5376\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9736 - accuracy: 0.5305 - val_loss: 0.9732 - val_accuracy: 0.5341\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9738 - accuracy: 0.5297 - val_loss: 0.9735 - val_accuracy: 0.5363\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9736 - accuracy: 0.5304 - val_loss: 0.9734 - val_accuracy: 0.5363\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9737 - val_accuracy: 0.5367\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9735 - accuracy: 0.5309 - val_loss: 0.9739 - val_accuracy: 0.5341\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9735 - accuracy: 0.5303 - val_loss: 0.9735 - val_accuracy: 0.5363\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9738 - accuracy: 0.5302 - val_loss: 0.9735 - val_accuracy: 0.5367\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9735 - accuracy: 0.5308 - val_loss: 0.9738 - val_accuracy: 0.5372\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9737 - accuracy: 0.5304 - val_loss: 0.9751 - val_accuracy: 0.5367\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9737 - accuracy: 0.5306 - val_loss: 0.9738 - val_accuracy: 0.5363\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9736 - accuracy: 0.5305 - val_loss: 0.9734 - val_accuracy: 0.5350\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9736 - accuracy: 0.5306 - val_loss: 0.9746 - val_accuracy: 0.5336\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9737 - accuracy: 0.5306 - val_loss: 0.9733 - val_accuracy: 0.5358\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9736 - accuracy: 0.5310 - val_loss: 0.9737 - val_accuracy: 0.5363\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9735 - accuracy: 0.5304 - val_loss: 0.9732 - val_accuracy: 0.5363\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9735 - accuracy: 0.5300 - val_loss: 0.9742 - val_accuracy: 0.5372\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9737 - accuracy: 0.5304 - val_loss: 0.9731 - val_accuracy: 0.5363\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5302 - val_loss: 0.9740 - val_accuracy: 0.5367\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9736 - accuracy: 0.5302 - val_loss: 0.9736 - val_accuracy: 0.5367\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9738 - accuracy: 0.5299 - val_loss: 0.9742 - val_accuracy: 0.5363\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9734 - accuracy: 0.5316 - val_loss: 0.9740 - val_accuracy: 0.5367\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9737 - accuracy: 0.5301 - val_loss: 0.9729 - val_accuracy: 0.5367\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9740 - val_accuracy: 0.5363\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9735 - accuracy: 0.5297 - val_loss: 0.9747 - val_accuracy: 0.5341\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9731 - val_accuracy: 0.5367\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9734 - accuracy: 0.5297 - val_loss: 0.9753 - val_accuracy: 0.5314\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9737 - accuracy: 0.5302 - val_loss: 0.9732 - val_accuracy: 0.5372\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9734 - accuracy: 0.5312 - val_loss: 0.9751 - val_accuracy: 0.5372\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9737 - accuracy: 0.5303 - val_loss: 0.9747 - val_accuracy: 0.5341\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9736 - accuracy: 0.5310 - val_loss: 0.9739 - val_accuracy: 0.5363\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9736 - accuracy: 0.5303 - val_loss: 0.9731 - val_accuracy: 0.5367\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9745 - val_accuracy: 0.5372\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9733 - accuracy: 0.5310 - val_loss: 0.9736 - val_accuracy: 0.5358\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9736 - accuracy: 0.5298 - val_loss: 0.9735 - val_accuracy: 0.5367\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9736 - accuracy: 0.5303 - val_loss: 0.9733 - val_accuracy: 0.5372\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9735 - accuracy: 0.5304 - val_loss: 0.9732 - val_accuracy: 0.5367\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 0.9738 - val_accuracy: 0.5372\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9735 - accuracy: 0.5313 - val_loss: 0.9735 - val_accuracy: 0.5327\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9736 - accuracy: 0.5297 - val_loss: 0.9733 - val_accuracy: 0.5363\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9736 - accuracy: 0.5310 - val_loss: 0.9733 - val_accuracy: 0.5363\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9736 - accuracy: 0.5299 - val_loss: 0.9727 - val_accuracy: 0.5358\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9736 - accuracy: 0.5299 - val_loss: 0.9732 - val_accuracy: 0.5367\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9737 - accuracy: 0.5298 - val_loss: 0.9739 - val_accuracy: 0.5372\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9737 - val_accuracy: 0.5367\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9734 - accuracy: 0.5303 - val_loss: 0.9743 - val_accuracy: 0.5372\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9736 - accuracy: 0.5307 - val_loss: 0.9728 - val_accuracy: 0.5372\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9728 - val_accuracy: 0.5363\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 0.9728 - val_accuracy: 0.5372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9731 - val_accuracy: 0.5367\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9735 - accuracy: 0.5298 - val_loss: 0.9751 - val_accuracy: 0.5327\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9741 - val_accuracy: 0.5367\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9746 - val_accuracy: 0.5363\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9743 - val_accuracy: 0.5367\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9734 - accuracy: 0.5309 - val_loss: 0.9746 - val_accuracy: 0.5367\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9736 - accuracy: 0.5304 - val_loss: 0.9738 - val_accuracy: 0.5363\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9736 - accuracy: 0.5307 - val_loss: 0.9739 - val_accuracy: 0.5372\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9733 - val_accuracy: 0.5367\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9730 - val_accuracy: 0.5341\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9733 - accuracy: 0.5303 - val_loss: 0.9744 - val_accuracy: 0.5336\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9735 - accuracy: 0.5300 - val_loss: 0.9733 - val_accuracy: 0.5363\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 342us/step - loss: 0.9730 - accuracy: 0.5306\n",
      "Accuracy : 0.5306413769721985\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9733 - accuracy: 0.5363\n",
      "Accuracy : 0.5362831950187683\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 630us/step - loss: 1.0448 - accuracy: 0.4591 - val_loss: 1.0353 - val_accuracy: 0.4595\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 1.0039 - accuracy: 0.5175 - val_loss: 1.0116 - val_accuracy: 0.5215\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9857 - accuracy: 0.5304 - val_loss: 1.0065 - val_accuracy: 0.5166\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9815 - accuracy: 0.5304 - val_loss: 1.0040 - val_accuracy: 0.5237\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9786 - accuracy: 0.5314 - val_loss: 1.0027 - val_accuracy: 0.5224\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9765 - accuracy: 0.5312 - val_loss: 1.0027 - val_accuracy: 0.5219\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9752 - accuracy: 0.5305 - val_loss: 1.0017 - val_accuracy: 0.5224\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9741 - accuracy: 0.5322 - val_loss: 1.0010 - val_accuracy: 0.5228\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9734 - accuracy: 0.5325 - val_loss: 1.0016 - val_accuracy: 0.5215\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9730 - accuracy: 0.5326 - val_loss: 1.0012 - val_accuracy: 0.5206\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9725 - accuracy: 0.5314 - val_loss: 1.0016 - val_accuracy: 0.5219\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9724 - accuracy: 0.5321 - val_loss: 1.0011 - val_accuracy: 0.5206\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 469us/step - loss: 0.9721 - accuracy: 0.5321 - val_loss: 1.0011 - val_accuracy: 0.5201\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9719 - accuracy: 0.5316 - val_loss: 1.0016 - val_accuracy: 0.5219\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9718 - accuracy: 0.5313 - val_loss: 1.0010 - val_accuracy: 0.5228\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9718 - accuracy: 0.5327 - val_loss: 1.0014 - val_accuracy: 0.5206\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9715 - accuracy: 0.5321 - val_loss: 1.0007 - val_accuracy: 0.5201\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9714 - accuracy: 0.5324 - val_loss: 1.0026 - val_accuracy: 0.5201\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9715 - accuracy: 0.5309 - val_loss: 1.0019 - val_accuracy: 0.5219\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9715 - accuracy: 0.5320 - val_loss: 1.0028 - val_accuracy: 0.5175\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9714 - accuracy: 0.5308 - val_loss: 1.0007 - val_accuracy: 0.5206\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9713 - accuracy: 0.5322 - val_loss: 1.0008 - val_accuracy: 0.5206\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9712 - accuracy: 0.5317 - val_loss: 1.0016 - val_accuracy: 0.5228\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9713 - accuracy: 0.5313 - val_loss: 1.0013 - val_accuracy: 0.5219\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9712 - accuracy: 0.5315 - val_loss: 1.0014 - val_accuracy: 0.5224\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9712 - accuracy: 0.5316 - val_loss: 1.0013 - val_accuracy: 0.5206\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9712 - accuracy: 0.5304 - val_loss: 1.0020 - val_accuracy: 0.5224\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9710 - accuracy: 0.5328 - val_loss: 1.0037 - val_accuracy: 0.5170\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9713 - accuracy: 0.5325 - val_loss: 1.0016 - val_accuracy: 0.5206\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 1.0010 - val_accuracy: 0.5206\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 557us/step - loss: 0.9710 - accuracy: 0.5316 - val_loss: 1.0006 - val_accuracy: 0.5206\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9713 - accuracy: 0.5306 - val_loss: 1.0021 - val_accuracy: 0.5201\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9710 - accuracy: 0.5321 - val_loss: 1.0016 - val_accuracy: 0.5228\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9712 - accuracy: 0.5316 - val_loss: 1.0020 - val_accuracy: 0.5197\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9712 - accuracy: 0.5318 - val_loss: 1.0014 - val_accuracy: 0.5219\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9710 - accuracy: 0.5311 - val_loss: 1.0008 - val_accuracy: 0.5215\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9708 - accuracy: 0.5317 - val_loss: 1.0010 - val_accuracy: 0.5224\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9709 - accuracy: 0.5319 - val_loss: 1.0010 - val_accuracy: 0.5206\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9710 - accuracy: 0.5311 - val_loss: 1.0013 - val_accuracy: 0.5232\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9710 - accuracy: 0.5327 - val_loss: 1.0016 - val_accuracy: 0.5215\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9709 - accuracy: 0.5309 - val_loss: 1.0021 - val_accuracy: 0.5219\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9707 - accuracy: 0.5306 - val_loss: 1.0013 - val_accuracy: 0.5224\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 486us/step - loss: 0.9710 - accuracy: 0.5321 - val_loss: 1.0011 - val_accuracy: 0.5206\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9709 - accuracy: 0.5298 - val_loss: 1.0004 - val_accuracy: 0.5219\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9711 - accuracy: 0.5320 - val_loss: 1.0015 - val_accuracy: 0.5197\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9708 - accuracy: 0.5322 - val_loss: 1.0015 - val_accuracy: 0.5228\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9709 - accuracy: 0.5319 - val_loss: 1.0010 - val_accuracy: 0.5224\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9711 - accuracy: 0.5311 - val_loss: 1.0015 - val_accuracy: 0.5206\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9706 - accuracy: 0.5304 - val_loss: 1.0017 - val_accuracy: 0.5210\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9709 - accuracy: 0.5311 - val_loss: 1.0026 - val_accuracy: 0.5206\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9709 - accuracy: 0.5313 - val_loss: 1.0012 - val_accuracy: 0.5224\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9712 - accuracy: 0.5313 - val_loss: 1.0014 - val_accuracy: 0.5215\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9709 - accuracy: 0.5309 - val_loss: 1.0010 - val_accuracy: 0.5206\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9708 - accuracy: 0.5305 - val_loss: 1.0018 - val_accuracy: 0.5206\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9709 - accuracy: 0.5315 - val_loss: 1.0015 - val_accuracy: 0.5215\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9708 - accuracy: 0.5317 - val_loss: 1.0036 - val_accuracy: 0.5170\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9708 - accuracy: 0.5322 - val_loss: 1.0021 - val_accuracy: 0.5197\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9709 - accuracy: 0.5324 - val_loss: 1.0019 - val_accuracy: 0.5224\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9708 - accuracy: 0.5306 - val_loss: 1.0010 - val_accuracy: 0.5215\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9709 - accuracy: 0.5319 - val_loss: 1.0013 - val_accuracy: 0.5224\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9708 - accuracy: 0.5323 - val_loss: 1.0014 - val_accuracy: 0.5215\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9709 - accuracy: 0.5333 - val_loss: 1.0018 - val_accuracy: 0.5224\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9709 - accuracy: 0.5303 - val_loss: 1.0010 - val_accuracy: 0.5224\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9707 - accuracy: 0.5332 - val_loss: 1.0017 - val_accuracy: 0.5206\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9707 - accuracy: 0.5319 - val_loss: 1.0011 - val_accuracy: 0.5206\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9708 - accuracy: 0.5313 - val_loss: 1.0031 - val_accuracy: 0.5197\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9706 - accuracy: 0.5316 - val_loss: 1.0009 - val_accuracy: 0.5206\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9708 - accuracy: 0.5325 - val_loss: 1.0006 - val_accuracy: 0.5206\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9707 - accuracy: 0.5322 - val_loss: 1.0013 - val_accuracy: 0.5224\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9707 - accuracy: 0.5321 - val_loss: 1.0028 - val_accuracy: 0.5206\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9707 - accuracy: 0.5328 - val_loss: 1.0009 - val_accuracy: 0.5224\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9707 - accuracy: 0.5328 - val_loss: 1.0021 - val_accuracy: 0.5215\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9706 - accuracy: 0.5328 - val_loss: 1.0015 - val_accuracy: 0.5224\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9708 - accuracy: 0.5316 - val_loss: 1.0011 - val_accuracy: 0.5219\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9707 - accuracy: 0.5310 - val_loss: 1.0017 - val_accuracy: 0.5197\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9708 - accuracy: 0.5320 - val_loss: 1.0020 - val_accuracy: 0.5197\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9708 - accuracy: 0.5322 - val_loss: 1.0015 - val_accuracy: 0.5206\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9708 - accuracy: 0.5310 - val_loss: 1.0012 - val_accuracy: 0.5206\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9707 - accuracy: 0.5323 - val_loss: 1.0020 - val_accuracy: 0.5224\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9705 - accuracy: 0.5312 - val_loss: 1.0034 - val_accuracy: 0.5197\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9707 - accuracy: 0.5329 - val_loss: 1.0025 - val_accuracy: 0.5188\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 481us/step - loss: 0.9709 - accuracy: 0.5318 - val_loss: 1.0011 - val_accuracy: 0.5224\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9705 - accuracy: 0.5320 - val_loss: 1.0012 - val_accuracy: 0.5206\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9706 - accuracy: 0.5326 - val_loss: 1.0023 - val_accuracy: 0.5219\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9706 - accuracy: 0.5325 - val_loss: 1.0018 - val_accuracy: 0.5228\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9708 - accuracy: 0.5313 - val_loss: 1.0013 - val_accuracy: 0.5206\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9708 - accuracy: 0.5317 - val_loss: 1.0011 - val_accuracy: 0.5228\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9706 - accuracy: 0.5332 - val_loss: 1.0029 - val_accuracy: 0.5206\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9706 - accuracy: 0.5321 - val_loss: 1.0017 - val_accuracy: 0.5215\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9708 - accuracy: 0.5313 - val_loss: 1.0022 - val_accuracy: 0.5228\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9706 - accuracy: 0.5329 - val_loss: 1.0020 - val_accuracy: 0.5224\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9708 - accuracy: 0.5318 - val_loss: 1.0014 - val_accuracy: 0.5224\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9706 - accuracy: 0.5322 - val_loss: 1.0029 - val_accuracy: 0.5206\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9707 - accuracy: 0.5317 - val_loss: 1.0020 - val_accuracy: 0.5197\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9707 - accuracy: 0.5309 - val_loss: 1.0009 - val_accuracy: 0.5215\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9706 - accuracy: 0.5319 - val_loss: 1.0015 - val_accuracy: 0.5206\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9705 - accuracy: 0.5326 - val_loss: 1.0012 - val_accuracy: 0.5215\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9706 - accuracy: 0.5322 - val_loss: 1.0036 - val_accuracy: 0.5197\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 486us/step - loss: 0.9710 - accuracy: 0.5320 - val_loss: 1.0016 - val_accuracy: 0.5210\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9705 - accuracy: 0.5310 - val_loss: 1.0020 - val_accuracy: 0.5219\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9707 - accuracy: 0.5313 - val_loss: 1.0013 - val_accuracy: 0.5215\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9709 - accuracy: 0.5325 - val_loss: 1.0020 - val_accuracy: 0.5206\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9706 - accuracy: 0.5331 - val_loss: 1.0022 - val_accuracy: 0.5210\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9706 - accuracy: 0.5311 - val_loss: 1.0012 - val_accuracy: 0.5224\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9704 - accuracy: 0.5321 - val_loss: 1.0007 - val_accuracy: 0.5224\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9707 - accuracy: 0.5329 - val_loss: 1.0011 - val_accuracy: 0.5224\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9708 - accuracy: 0.5322 - val_loss: 1.0009 - val_accuracy: 0.5210\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9706 - accuracy: 0.5322 - val_loss: 1.0017 - val_accuracy: 0.5197\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9707 - accuracy: 0.5323 - val_loss: 1.0011 - val_accuracy: 0.5206\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9707 - accuracy: 0.5322 - val_loss: 1.0016 - val_accuracy: 0.5224\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9707 - accuracy: 0.5329 - val_loss: 1.0009 - val_accuracy: 0.5224\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9707 - accuracy: 0.5315 - val_loss: 1.0017 - val_accuracy: 0.5224\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9707 - accuracy: 0.5324 - val_loss: 1.0009 - val_accuracy: 0.5224\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9707 - accuracy: 0.5314 - val_loss: 1.0018 - val_accuracy: 0.5224\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9708 - accuracy: 0.5314 - val_loss: 1.0016 - val_accuracy: 0.5219\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9704 - accuracy: 0.5323 - val_loss: 1.0016 - val_accuracy: 0.5206\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9706 - accuracy: 0.5318 - val_loss: 1.0017 - val_accuracy: 0.5224\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9705 - accuracy: 0.5314 - val_loss: 1.0014 - val_accuracy: 0.5224\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9706 - accuracy: 0.5322 - val_loss: 1.0009 - val_accuracy: 0.5206\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9705 - accuracy: 0.5323 - val_loss: 1.0026 - val_accuracy: 0.5197\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9706 - accuracy: 0.5324 - val_loss: 1.0015 - val_accuracy: 0.5224\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 542us/step - loss: 0.9705 - accuracy: 0.5319 - val_loss: 1.0015 - val_accuracy: 0.5215\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9705 - accuracy: 0.5319 - val_loss: 1.0021 - val_accuracy: 0.5206\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9705 - accuracy: 0.5330 - val_loss: 1.0028 - val_accuracy: 0.5219\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9705 - accuracy: 0.5321 - val_loss: 1.0007 - val_accuracy: 0.5219\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9708 - accuracy: 0.5322 - val_loss: 1.0021 - val_accuracy: 0.5206\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9707 - accuracy: 0.5321 - val_loss: 1.0017 - val_accuracy: 0.5206\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9709 - accuracy: 0.5324 - val_loss: 1.0008 - val_accuracy: 0.5206\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9704 - accuracy: 0.5323 - val_loss: 1.0011 - val_accuracy: 0.5215\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9705 - accuracy: 0.5325 - val_loss: 1.0012 - val_accuracy: 0.5228\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9706 - accuracy: 0.5325 - val_loss: 1.0027 - val_accuracy: 0.5206\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9706 - accuracy: 0.5310 - val_loss: 1.0008 - val_accuracy: 0.5224\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9706 - accuracy: 0.5324 - val_loss: 1.0012 - val_accuracy: 0.5215\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9706 - accuracy: 0.5320 - val_loss: 1.0026 - val_accuracy: 0.5197\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9706 - accuracy: 0.5329 - val_loss: 1.0019 - val_accuracy: 0.5224\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9706 - accuracy: 0.5311 - val_loss: 1.0025 - val_accuracy: 0.5197\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9706 - accuracy: 0.5323 - val_loss: 1.0022 - val_accuracy: 0.5219\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9707 - accuracy: 0.5314 - val_loss: 1.0007 - val_accuracy: 0.5206\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9705 - accuracy: 0.5313 - val_loss: 1.0011 - val_accuracy: 0.5206\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9707 - accuracy: 0.5317 - val_loss: 1.0006 - val_accuracy: 0.5224\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9705 - accuracy: 0.5331 - val_loss: 1.0014 - val_accuracy: 0.5215\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9703 - accuracy: 0.5322 - val_loss: 1.0009 - val_accuracy: 0.5206\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9704 - accuracy: 0.5317 - val_loss: 1.0017 - val_accuracy: 0.5206\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9706 - accuracy: 0.5330 - val_loss: 1.0017 - val_accuracy: 0.5206\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9706 - accuracy: 0.5324 - val_loss: 1.0021 - val_accuracy: 0.5206\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9706 - accuracy: 0.5318 - val_loss: 1.0028 - val_accuracy: 0.5193\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9704 - accuracy: 0.5315 - val_loss: 1.0004 - val_accuracy: 0.5228\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9705 - accuracy: 0.5315 - val_loss: 1.0042 - val_accuracy: 0.5170\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9705 - accuracy: 0.5325 - val_loss: 1.0010 - val_accuracy: 0.5206\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9704 - accuracy: 0.5330 - val_loss: 1.0012 - val_accuracy: 0.5224\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9705 - accuracy: 0.5322 - val_loss: 1.0015 - val_accuracy: 0.5224\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9706 - accuracy: 0.5321 - val_loss: 1.0006 - val_accuracy: 0.5224\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9704 - accuracy: 0.5313 - val_loss: 1.0017 - val_accuracy: 0.5206\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9706 - accuracy: 0.5322 - val_loss: 1.0011 - val_accuracy: 0.5206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9707 - accuracy: 0.5335 - val_loss: 1.0016 - val_accuracy: 0.5206\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9706 - accuracy: 0.5320 - val_loss: 1.0016 - val_accuracy: 0.5224\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9703 - accuracy: 0.5317 - val_loss: 1.0016 - val_accuracy: 0.5206\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9705 - accuracy: 0.5314 - val_loss: 1.0013 - val_accuracy: 0.5224\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9703 - accuracy: 0.5319 - val_loss: 1.0015 - val_accuracy: 0.5224\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9704 - accuracy: 0.5319 - val_loss: 1.0009 - val_accuracy: 0.5224\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9706 - accuracy: 0.5324 - val_loss: 1.0023 - val_accuracy: 0.5193\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9706 - accuracy: 0.5314 - val_loss: 1.0016 - val_accuracy: 0.5206\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9704 - accuracy: 0.5318 - val_loss: 1.0015 - val_accuracy: 0.5206\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9700 - accuracy: 0.5324 - val_loss: 1.0026 - val_accuracy: 0.5224\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9704 - accuracy: 0.5326 - val_loss: 1.0014 - val_accuracy: 0.5224\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9705 - accuracy: 0.5317 - val_loss: 1.0015 - val_accuracy: 0.5224\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9705 - accuracy: 0.5320 - val_loss: 1.0008 - val_accuracy: 0.5215\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9704 - accuracy: 0.5324 - val_loss: 1.0030 - val_accuracy: 0.5224\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9704 - accuracy: 0.5324 - val_loss: 1.0013 - val_accuracy: 0.5219\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9704 - accuracy: 0.5317 - val_loss: 1.0006 - val_accuracy: 0.5224\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9705 - accuracy: 0.5325 - val_loss: 1.0009 - val_accuracy: 0.5206\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9705 - accuracy: 0.5314 - val_loss: 1.0010 - val_accuracy: 0.5206\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9703 - accuracy: 0.5325 - val_loss: 1.0022 - val_accuracy: 0.5206\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9706 - accuracy: 0.5320 - val_loss: 1.0010 - val_accuracy: 0.5206\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9704 - accuracy: 0.5318 - val_loss: 1.0014 - val_accuracy: 0.5224\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9705 - accuracy: 0.5326 - val_loss: 1.0018 - val_accuracy: 0.5206\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9707 - accuracy: 0.5325 - val_loss: 1.0006 - val_accuracy: 0.5210\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9705 - accuracy: 0.5320 - val_loss: 1.0007 - val_accuracy: 0.5206\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9706 - accuracy: 0.5325 - val_loss: 1.0015 - val_accuracy: 0.5224\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9704 - accuracy: 0.5329 - val_loss: 1.0003 - val_accuracy: 0.5215\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 556us/step - loss: 0.9704 - accuracy: 0.5316 - val_loss: 1.0015 - val_accuracy: 0.5206\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9704 - accuracy: 0.5327 - val_loss: 1.0005 - val_accuracy: 0.5219\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9703 - accuracy: 0.5301 - val_loss: 1.0006 - val_accuracy: 0.5215\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9703 - accuracy: 0.5315 - val_loss: 1.0012 - val_accuracy: 0.5219\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9705 - accuracy: 0.5317 - val_loss: 1.0010 - val_accuracy: 0.5219\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9705 - accuracy: 0.5322 - val_loss: 1.0006 - val_accuracy: 0.5219\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9703 - accuracy: 0.5314 - val_loss: 1.0023 - val_accuracy: 0.5197\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9705 - accuracy: 0.5330 - val_loss: 1.0011 - val_accuracy: 0.5210\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9705 - accuracy: 0.5331 - val_loss: 1.0020 - val_accuracy: 0.5201\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9707 - accuracy: 0.5319 - val_loss: 1.0017 - val_accuracy: 0.5210\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9704 - accuracy: 0.5324 - val_loss: 1.0007 - val_accuracy: 0.5228\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9706 - accuracy: 0.5329 - val_loss: 1.0008 - val_accuracy: 0.5224\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9707 - accuracy: 0.5321 - val_loss: 1.0014 - val_accuracy: 0.5224\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9706 - accuracy: 0.5322 - val_loss: 1.0006 - val_accuracy: 0.5210\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9702 - accuracy: 0.5311 - val_loss: 1.0015 - val_accuracy: 0.5228\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9703 - accuracy: 0.5316 - val_loss: 1.0010 - val_accuracy: 0.5241\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9706 - accuracy: 0.5321 - val_loss: 1.0015 - val_accuracy: 0.5219\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9704 - accuracy: 0.5326 - val_loss: 1.0014 - val_accuracy: 0.5210\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9705 - accuracy: 0.5317 - val_loss: 1.0010 - val_accuracy: 0.5224\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9703 - accuracy: 0.5323 - val_loss: 1.0017 - val_accuracy: 0.5206\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 409us/step - loss: 0.9703 - accuracy: 0.5322\n",
      "Accuracy : 0.5321890711784363\n",
      "\n",
      "Test split:\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "71/71 - 0s - loss: 1.0017 - accuracy: 0.5206\n",
      "Accuracy : 0.5205843448638916\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 663us/step - loss: 1.0494 - accuracy: 0.4499 - val_loss: 1.0243 - val_accuracy: 0.4807\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9954 - accuracy: 0.5283 - val_loss: 1.0094 - val_accuracy: 0.5104\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9842 - accuracy: 0.5319 - val_loss: 1.0113 - val_accuracy: 0.5135\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9819 - accuracy: 0.5327 - val_loss: 1.0084 - val_accuracy: 0.5113\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9799 - accuracy: 0.5317 - val_loss: 1.0067 - val_accuracy: 0.5108\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9784 - accuracy: 0.5332 - val_loss: 1.0061 - val_accuracy: 0.5091\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9770 - accuracy: 0.5338 - val_loss: 1.0062 - val_accuracy: 0.5135\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 506us/step - loss: 0.9762 - accuracy: 0.5332 - val_loss: 1.0053 - val_accuracy: 0.5126\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9755 - accuracy: 0.5324 - val_loss: 1.0064 - val_accuracy: 0.5126\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9746 - accuracy: 0.5333 - val_loss: 1.0048 - val_accuracy: 0.5091\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9741 - accuracy: 0.5333 - val_loss: 1.0052 - val_accuracy: 0.5139\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9738 - accuracy: 0.5332 - val_loss: 1.0047 - val_accuracy: 0.5131\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9731 - accuracy: 0.5337 - val_loss: 1.0053 - val_accuracy: 0.5131\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9730 - accuracy: 0.5328 - val_loss: 1.0057 - val_accuracy: 0.5122\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9729 - accuracy: 0.5332 - val_loss: 1.0050 - val_accuracy: 0.5122\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9728 - accuracy: 0.5332 - val_loss: 1.0047 - val_accuracy: 0.5122\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9723 - accuracy: 0.5341 - val_loss: 1.0042 - val_accuracy: 0.5139\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9724 - accuracy: 0.5330 - val_loss: 1.0045 - val_accuracy: 0.5131\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9722 - accuracy: 0.5329 - val_loss: 1.0041 - val_accuracy: 0.5122\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9722 - accuracy: 0.5323 - val_loss: 1.0047 - val_accuracy: 0.5131\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9720 - accuracy: 0.5337 - val_loss: 1.0041 - val_accuracy: 0.5126\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9719 - accuracy: 0.5327 - val_loss: 1.0046 - val_accuracy: 0.5122\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9719 - accuracy: 0.5327 - val_loss: 1.0047 - val_accuracy: 0.5113\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9717 - accuracy: 0.5330 - val_loss: 1.0042 - val_accuracy: 0.5131\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9717 - accuracy: 0.5322 - val_loss: 1.0040 - val_accuracy: 0.5122\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9717 - accuracy: 0.5325 - val_loss: 1.0057 - val_accuracy: 0.5117\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9716 - accuracy: 0.5324 - val_loss: 1.0057 - val_accuracy: 0.5113\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9718 - accuracy: 0.5326 - val_loss: 1.0039 - val_accuracy: 0.5122\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9715 - accuracy: 0.5330 - val_loss: 1.0042 - val_accuracy: 0.5117\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9715 - accuracy: 0.5319 - val_loss: 1.0037 - val_accuracy: 0.5104\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9715 - accuracy: 0.5329 - val_loss: 1.0038 - val_accuracy: 0.5131\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9713 - accuracy: 0.5328 - val_loss: 1.0061 - val_accuracy: 0.5135\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9715 - accuracy: 0.5310 - val_loss: 1.0045 - val_accuracy: 0.5104\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9712 - accuracy: 0.5327 - val_loss: 1.0049 - val_accuracy: 0.5108\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9715 - accuracy: 0.5323 - val_loss: 1.0038 - val_accuracy: 0.5104\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9714 - accuracy: 0.5327 - val_loss: 1.0036 - val_accuracy: 0.5126\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9714 - accuracy: 0.5325 - val_loss: 1.0037 - val_accuracy: 0.5131\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9712 - accuracy: 0.5326 - val_loss: 1.0038 - val_accuracy: 0.5108\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9712 - accuracy: 0.5321 - val_loss: 1.0035 - val_accuracy: 0.5117\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9712 - accuracy: 0.5339 - val_loss: 1.0040 - val_accuracy: 0.5126\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9712 - accuracy: 0.5331 - val_loss: 1.0042 - val_accuracy: 0.5122\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9713 - accuracy: 0.5326 - val_loss: 1.0036 - val_accuracy: 0.5108\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9712 - accuracy: 0.5323 - val_loss: 1.0039 - val_accuracy: 0.5122\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9710 - accuracy: 0.5327 - val_loss: 1.0041 - val_accuracy: 0.5126\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9711 - accuracy: 0.5328 - val_loss: 1.0043 - val_accuracy: 0.5108\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9713 - accuracy: 0.5323 - val_loss: 1.0039 - val_accuracy: 0.5104\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9709 - accuracy: 0.5337 - val_loss: 1.0034 - val_accuracy: 0.5104\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9710 - accuracy: 0.5329 - val_loss: 1.0040 - val_accuracy: 0.5113\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9712 - accuracy: 0.5334 - val_loss: 1.0037 - val_accuracy: 0.5131\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9712 - accuracy: 0.5326 - val_loss: 1.0038 - val_accuracy: 0.5100\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9710 - accuracy: 0.5319 - val_loss: 1.0030 - val_accuracy: 0.5108\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9707 - accuracy: 0.5328 - val_loss: 1.0044 - val_accuracy: 0.5104\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9711 - accuracy: 0.5331 - val_loss: 1.0037 - val_accuracy: 0.5131\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9710 - accuracy: 0.5324 - val_loss: 1.0032 - val_accuracy: 0.5122\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9710 - accuracy: 0.5332 - val_loss: 1.0041 - val_accuracy: 0.5113\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9708 - accuracy: 0.5331 - val_loss: 1.0046 - val_accuracy: 0.5113\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9709 - accuracy: 0.5327 - val_loss: 1.0041 - val_accuracy: 0.5122\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9709 - accuracy: 0.5322 - val_loss: 1.0032 - val_accuracy: 0.5108\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9709 - accuracy: 0.5334 - val_loss: 1.0042 - val_accuracy: 0.5108\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9709 - accuracy: 0.5323 - val_loss: 1.0032 - val_accuracy: 0.5108\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9709 - accuracy: 0.5324 - val_loss: 1.0038 - val_accuracy: 0.5122\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9709 - accuracy: 0.5327 - val_loss: 1.0036 - val_accuracy: 0.5104\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9706 - accuracy: 0.5332 - val_loss: 1.0038 - val_accuracy: 0.5100\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 489us/step - loss: 0.9709 - accuracy: 0.5328 - val_loss: 1.0041 - val_accuracy: 0.5108\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9709 - accuracy: 0.5334 - val_loss: 1.0053 - val_accuracy: 0.5113\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9709 - accuracy: 0.5331 - val_loss: 1.0031 - val_accuracy: 0.5117\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9709 - accuracy: 0.5336 - val_loss: 1.0030 - val_accuracy: 0.5113\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9707 - accuracy: 0.5338 - val_loss: 1.0029 - val_accuracy: 0.5113\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9708 - accuracy: 0.5326 - val_loss: 1.0044 - val_accuracy: 0.5104\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9709 - accuracy: 0.5330 - val_loss: 1.0029 - val_accuracy: 0.5104\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9708 - accuracy: 0.5321 - val_loss: 1.0036 - val_accuracy: 0.5122\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9709 - accuracy: 0.5328 - val_loss: 1.0029 - val_accuracy: 0.5104\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9706 - accuracy: 0.5326 - val_loss: 1.0028 - val_accuracy: 0.5131\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9706 - accuracy: 0.5331 - val_loss: 1.0035 - val_accuracy: 0.5108\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9708 - accuracy: 0.5333 - val_loss: 1.0037 - val_accuracy: 0.5104\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9709 - accuracy: 0.5330 - val_loss: 1.0032 - val_accuracy: 0.5113\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9708 - accuracy: 0.5326 - val_loss: 1.0030 - val_accuracy: 0.5104\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9707 - accuracy: 0.5328 - val_loss: 1.0031 - val_accuracy: 0.5122\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9709 - accuracy: 0.5325 - val_loss: 1.0029 - val_accuracy: 0.5108\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9708 - accuracy: 0.5334 - val_loss: 1.0029 - val_accuracy: 0.5108\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9707 - accuracy: 0.5320 - val_loss: 1.0029 - val_accuracy: 0.5108\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9707 - accuracy: 0.5326 - val_loss: 1.0029 - val_accuracy: 0.5104\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9706 - accuracy: 0.5323 - val_loss: 1.0043 - val_accuracy: 0.5108\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9708 - accuracy: 0.5326 - val_loss: 1.0030 - val_accuracy: 0.5104\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9707 - accuracy: 0.5334 - val_loss: 1.0030 - val_accuracy: 0.5126\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9706 - accuracy: 0.5326 - val_loss: 1.0037 - val_accuracy: 0.5113\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9705 - accuracy: 0.5332 - val_loss: 1.0050 - val_accuracy: 0.5113\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9706 - accuracy: 0.5326 - val_loss: 1.0031 - val_accuracy: 0.5104\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9706 - accuracy: 0.5330 - val_loss: 1.0028 - val_accuracy: 0.5104\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9707 - accuracy: 0.5324 - val_loss: 1.0032 - val_accuracy: 0.5100\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9708 - accuracy: 0.5317 - val_loss: 1.0032 - val_accuracy: 0.5126\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9708 - accuracy: 0.5328 - val_loss: 1.0029 - val_accuracy: 0.5104\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9706 - accuracy: 0.5335 - val_loss: 1.0027 - val_accuracy: 0.5117\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9708 - accuracy: 0.5322 - val_loss: 1.0026 - val_accuracy: 0.5104\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9707 - accuracy: 0.5331 - val_loss: 1.0033 - val_accuracy: 0.5122\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9707 - accuracy: 0.5327 - val_loss: 1.0032 - val_accuracy: 0.5108\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9708 - accuracy: 0.5322 - val_loss: 1.0025 - val_accuracy: 0.5104\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9705 - accuracy: 0.5333 - val_loss: 1.0036 - val_accuracy: 0.5126\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9707 - accuracy: 0.5327 - val_loss: 1.0035 - val_accuracy: 0.5100\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9707 - accuracy: 0.5331 - val_loss: 1.0028 - val_accuracy: 0.5100\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9707 - accuracy: 0.5337 - val_loss: 1.0032 - val_accuracy: 0.5126\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9706 - accuracy: 0.5332 - val_loss: 1.0028 - val_accuracy: 0.5104\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9705 - accuracy: 0.5335 - val_loss: 1.0045 - val_accuracy: 0.5108\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9706 - accuracy: 0.5326 - val_loss: 1.0035 - val_accuracy: 0.5104\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9705 - accuracy: 0.5332 - val_loss: 1.0036 - val_accuracy: 0.5108\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9705 - accuracy: 0.5327 - val_loss: 1.0033 - val_accuracy: 0.5108\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9707 - accuracy: 0.5340 - val_loss: 1.0030 - val_accuracy: 0.5108\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9706 - accuracy: 0.5321 - val_loss: 1.0025 - val_accuracy: 0.5113\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9706 - accuracy: 0.5321 - val_loss: 1.0026 - val_accuracy: 0.5113\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9706 - accuracy: 0.5338 - val_loss: 1.0034 - val_accuracy: 0.5104\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9706 - accuracy: 0.5335 - val_loss: 1.0044 - val_accuracy: 0.5108\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9705 - accuracy: 0.5327 - val_loss: 1.0033 - val_accuracy: 0.5100\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9705 - accuracy: 0.5335 - val_loss: 1.0030 - val_accuracy: 0.5108\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9706 - accuracy: 0.5324 - val_loss: 1.0036 - val_accuracy: 0.5100\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9706 - accuracy: 0.5337 - val_loss: 1.0027 - val_accuracy: 0.5100\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9706 - accuracy: 0.5332 - val_loss: 1.0026 - val_accuracy: 0.5104\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9705 - accuracy: 0.5331 - val_loss: 1.0036 - val_accuracy: 0.5108\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9705 - accuracy: 0.5332 - val_loss: 1.0033 - val_accuracy: 0.5122\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9705 - accuracy: 0.5331 - val_loss: 1.0034 - val_accuracy: 0.5091\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 510us/step - loss: 0.9705 - accuracy: 0.5324 - val_loss: 1.0023 - val_accuracy: 0.5100\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9706 - accuracy: 0.5328 - val_loss: 1.0030 - val_accuracy: 0.5100\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9705 - accuracy: 0.5330 - val_loss: 1.0029 - val_accuracy: 0.5108\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9706 - accuracy: 0.5324 - val_loss: 1.0030 - val_accuracy: 0.5126\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9705 - accuracy: 0.5335 - val_loss: 1.0026 - val_accuracy: 0.5126\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9705 - accuracy: 0.5331 - val_loss: 1.0025 - val_accuracy: 0.5104\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9705 - accuracy: 0.5323 - val_loss: 1.0032 - val_accuracy: 0.5108\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9705 - accuracy: 0.5326 - val_loss: 1.0036 - val_accuracy: 0.5108\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9706 - accuracy: 0.5331 - val_loss: 1.0030 - val_accuracy: 0.5108\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9704 - accuracy: 0.5325 - val_loss: 1.0034 - val_accuracy: 0.5060\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9706 - accuracy: 0.5328 - val_loss: 1.0022 - val_accuracy: 0.5113\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9706 - accuracy: 0.5338 - val_loss: 1.0029 - val_accuracy: 0.5100\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9706 - accuracy: 0.5329 - val_loss: 1.0025 - val_accuracy: 0.5131\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9706 - accuracy: 0.5327 - val_loss: 1.0031 - val_accuracy: 0.5108\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9705 - accuracy: 0.5338 - val_loss: 1.0028 - val_accuracy: 0.5113\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9705 - accuracy: 0.5332 - val_loss: 1.0046 - val_accuracy: 0.5108\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9706 - accuracy: 0.5327 - val_loss: 1.0028 - val_accuracy: 0.5108\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9706 - accuracy: 0.5336 - val_loss: 1.0029 - val_accuracy: 0.5126\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9705 - accuracy: 0.5338 - val_loss: 1.0021 - val_accuracy: 0.5108\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9704 - accuracy: 0.5328 - val_loss: 1.0038 - val_accuracy: 0.5108\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9704 - accuracy: 0.5334 - val_loss: 1.0021 - val_accuracy: 0.5126\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9705 - accuracy: 0.5323 - val_loss: 1.0030 - val_accuracy: 0.5104\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9705 - accuracy: 0.5327 - val_loss: 1.0025 - val_accuracy: 0.5126\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9706 - accuracy: 0.5336 - val_loss: 1.0023 - val_accuracy: 0.5104\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9706 - accuracy: 0.5336 - val_loss: 1.0026 - val_accuracy: 0.5126\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9705 - accuracy: 0.5323 - val_loss: 1.0039 - val_accuracy: 0.5100\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9704 - accuracy: 0.5323 - val_loss: 1.0034 - val_accuracy: 0.5113\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9705 - accuracy: 0.5325 - val_loss: 1.0033 - val_accuracy: 0.5100\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9706 - accuracy: 0.5328 - val_loss: 1.0024 - val_accuracy: 0.5108\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9705 - accuracy: 0.5323 - val_loss: 1.0021 - val_accuracy: 0.5104\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9705 - accuracy: 0.5333 - val_loss: 1.0020 - val_accuracy: 0.5104\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9707 - accuracy: 0.5331 - val_loss: 1.0031 - val_accuracy: 0.5113\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9704 - accuracy: 0.5340 - val_loss: 1.0036 - val_accuracy: 0.5100\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9706 - accuracy: 0.5324 - val_loss: 1.0030 - val_accuracy: 0.5104\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9705 - accuracy: 0.5324 - val_loss: 1.0024 - val_accuracy: 0.5113\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9706 - accuracy: 0.5326 - val_loss: 1.0024 - val_accuracy: 0.5108\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9705 - accuracy: 0.5329 - val_loss: 1.0023 - val_accuracy: 0.5104\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9705 - accuracy: 0.5327 - val_loss: 1.0020 - val_accuracy: 0.5104\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9705 - accuracy: 0.5332 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9705 - accuracy: 0.5322 - val_loss: 1.0029 - val_accuracy: 0.5108\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9706 - accuracy: 0.5327 - val_loss: 1.0021 - val_accuracy: 0.5108\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9704 - accuracy: 0.5339 - val_loss: 1.0021 - val_accuracy: 0.5126\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9705 - accuracy: 0.5339 - val_loss: 1.0026 - val_accuracy: 0.5126\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9705 - accuracy: 0.5327 - val_loss: 1.0029 - val_accuracy: 0.5100\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 571us/step - loss: 0.9705 - accuracy: 0.5325 - val_loss: 1.0022 - val_accuracy: 0.5104\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9705 - accuracy: 0.5323 - val_loss: 1.0029 - val_accuracy: 0.5108\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9704 - accuracy: 0.5329 - val_loss: 1.0030 - val_accuracy: 0.5131\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 625us/step - loss: 0.9703 - accuracy: 0.5329 - val_loss: 1.0020 - val_accuracy: 0.5126\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 559us/step - loss: 0.9707 - accuracy: 0.5333 - val_loss: 1.0025 - val_accuracy: 0.5126\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9704 - accuracy: 0.5331 - val_loss: 1.0022 - val_accuracy: 0.5104\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9704 - accuracy: 0.5333 - val_loss: 1.0038 - val_accuracy: 0.5108\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9706 - accuracy: 0.5333 - val_loss: 1.0023 - val_accuracy: 0.5104\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9704 - accuracy: 0.5320 - val_loss: 1.0029 - val_accuracy: 0.5108\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9705 - accuracy: 0.5330 - val_loss: 1.0024 - val_accuracy: 0.5117\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9705 - accuracy: 0.5329 - val_loss: 1.0022 - val_accuracy: 0.5113\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9704 - accuracy: 0.5330 - val_loss: 1.0030 - val_accuracy: 0.5108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9704 - accuracy: 0.5329 - val_loss: 1.0032 - val_accuracy: 0.5108\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9704 - accuracy: 0.5330 - val_loss: 1.0024 - val_accuracy: 0.5117\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 481us/step - loss: 0.9706 - accuracy: 0.5336 - val_loss: 1.0026 - val_accuracy: 0.5104\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9703 - accuracy: 0.5323 - val_loss: 1.0031 - val_accuracy: 0.5082\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9701 - accuracy: 0.5323 - val_loss: 1.0020 - val_accuracy: 0.5104\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9705 - accuracy: 0.5338 - val_loss: 1.0023 - val_accuracy: 0.5108\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9703 - accuracy: 0.5335 - val_loss: 1.0035 - val_accuracy: 0.5108\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 0.9705 - accuracy: 0.5320 - val_loss: 1.0024 - val_accuracy: 0.5113\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 548us/step - loss: 0.9705 - accuracy: 0.5336 - val_loss: 1.0023 - val_accuracy: 0.5100\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9707 - accuracy: 0.5332 - val_loss: 1.0024 - val_accuracy: 0.5108\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9704 - accuracy: 0.5325 - val_loss: 1.0023 - val_accuracy: 0.5113\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9707 - accuracy: 0.5333 - val_loss: 1.0018 - val_accuracy: 0.5113\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9705 - accuracy: 0.5333 - val_loss: 1.0021 - val_accuracy: 0.5104\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9705 - accuracy: 0.5327 - val_loss: 1.0019 - val_accuracy: 0.5108\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9704 - accuracy: 0.5336 - val_loss: 1.0027 - val_accuracy: 0.5126\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9705 - accuracy: 0.5327 - val_loss: 1.0026 - val_accuracy: 0.5131\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9705 - accuracy: 0.5326 - val_loss: 1.0018 - val_accuracy: 0.5108\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9706 - accuracy: 0.5325 - val_loss: 1.0022 - val_accuracy: 0.5131\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9704 - accuracy: 0.5328 - val_loss: 1.0024 - val_accuracy: 0.5108\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9704 - accuracy: 0.5323 - val_loss: 1.0021 - val_accuracy: 0.5108\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 538us/step - loss: 0.9703 - accuracy: 0.5334 - val_loss: 1.0021 - val_accuracy: 0.5104\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9702 - accuracy: 0.5333 - val_loss: 1.0040 - val_accuracy: 0.5100\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9704 - accuracy: 0.5324 - val_loss: 1.0031 - val_accuracy: 0.5122\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9704 - accuracy: 0.5332 - val_loss: 1.0017 - val_accuracy: 0.5104\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9705 - accuracy: 0.5328 - val_loss: 1.0019 - val_accuracy: 0.5104\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 425us/step - loss: 0.9701 - accuracy: 0.5335\n",
      "Accuracy : 0.5335169434547424\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0019 - accuracy: 0.5104\n",
      "Accuracy : 0.5104028582572937\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 765us/step - loss: 1.0431 - accuracy: 0.4591 - val_loss: 1.0284 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 541us/step - loss: 1.0058 - accuracy: 0.5177 - val_loss: 1.0027 - val_accuracy: 0.5268\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9879 - accuracy: 0.5314 - val_loss: 0.9974 - val_accuracy: 0.5193\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9842 - accuracy: 0.5302 - val_loss: 0.9960 - val_accuracy: 0.5117\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9821 - accuracy: 0.5316 - val_loss: 0.9939 - val_accuracy: 0.5219\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9805 - accuracy: 0.5312 - val_loss: 0.9930 - val_accuracy: 0.5206\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9792 - accuracy: 0.5315 - val_loss: 0.9916 - val_accuracy: 0.5188\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9780 - accuracy: 0.5320 - val_loss: 0.9906 - val_accuracy: 0.5219\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9773 - accuracy: 0.5315 - val_loss: 0.9901 - val_accuracy: 0.5224\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9764 - accuracy: 0.5320 - val_loss: 0.9899 - val_accuracy: 0.5224\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9762 - accuracy: 0.5315 - val_loss: 0.9890 - val_accuracy: 0.5281\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9755 - accuracy: 0.5309 - val_loss: 0.9893 - val_accuracy: 0.5215\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9751 - accuracy: 0.5311 - val_loss: 0.9884 - val_accuracy: 0.5224\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9748 - accuracy: 0.5320 - val_loss: 0.9883 - val_accuracy: 0.5232\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9745 - accuracy: 0.5313 - val_loss: 0.9884 - val_accuracy: 0.5224\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9741 - accuracy: 0.5307 - val_loss: 0.9881 - val_accuracy: 0.5241\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9741 - accuracy: 0.5326 - val_loss: 0.9881 - val_accuracy: 0.5277\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9740 - accuracy: 0.5316 - val_loss: 0.9879 - val_accuracy: 0.5272\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9739 - accuracy: 0.5311 - val_loss: 0.9883 - val_accuracy: 0.5228\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9738 - accuracy: 0.5314 - val_loss: 0.9883 - val_accuracy: 0.5228\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9735 - accuracy: 0.5322 - val_loss: 0.9885 - val_accuracy: 0.5228\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9880 - val_accuracy: 0.5224\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9878 - val_accuracy: 0.5294\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9736 - accuracy: 0.5316 - val_loss: 0.9875 - val_accuracy: 0.5263\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9734 - accuracy: 0.5318 - val_loss: 0.9878 - val_accuracy: 0.5281\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9732 - accuracy: 0.5307 - val_loss: 0.9875 - val_accuracy: 0.5263\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9730 - accuracy: 0.5316 - val_loss: 0.9885 - val_accuracy: 0.5224\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9875 - val_accuracy: 0.5277\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9730 - accuracy: 0.5324 - val_loss: 0.9880 - val_accuracy: 0.5241\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 519us/step - loss: 0.9732 - accuracy: 0.5318 - val_loss: 0.9878 - val_accuracy: 0.5224\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9732 - accuracy: 0.5304 - val_loss: 0.9875 - val_accuracy: 0.5246\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9730 - accuracy: 0.5317 - val_loss: 0.9877 - val_accuracy: 0.5268\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9732 - accuracy: 0.5316 - val_loss: 0.9876 - val_accuracy: 0.5294\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9731 - accuracy: 0.5321 - val_loss: 0.9871 - val_accuracy: 0.5268\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9728 - accuracy: 0.5310 - val_loss: 0.9876 - val_accuracy: 0.5241\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9732 - accuracy: 0.5316 - val_loss: 0.9876 - val_accuracy: 0.5263\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9727 - accuracy: 0.5309 - val_loss: 0.9882 - val_accuracy: 0.5228\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9728 - accuracy: 0.5304 - val_loss: 0.9872 - val_accuracy: 0.5241\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9730 - accuracy: 0.5310 - val_loss: 0.9875 - val_accuracy: 0.5241\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9729 - accuracy: 0.5309 - val_loss: 0.9881 - val_accuracy: 0.5228\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9729 - accuracy: 0.5312 - val_loss: 0.9877 - val_accuracy: 0.5281\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9727 - accuracy: 0.5314 - val_loss: 0.9873 - val_accuracy: 0.5241\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9872 - val_accuracy: 0.5255\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9729 - accuracy: 0.5317 - val_loss: 0.9870 - val_accuracy: 0.5268\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9729 - accuracy: 0.5315 - val_loss: 0.9871 - val_accuracy: 0.5277\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9729 - accuracy: 0.5307 - val_loss: 0.9869 - val_accuracy: 0.5286\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9726 - accuracy: 0.5311 - val_loss: 0.9873 - val_accuracy: 0.5259\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9726 - accuracy: 0.5314 - val_loss: 0.9871 - val_accuracy: 0.5277\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 0.9873 - val_accuracy: 0.5263\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9727 - accuracy: 0.5317 - val_loss: 0.9870 - val_accuracy: 0.5241\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9728 - accuracy: 0.5317 - val_loss: 0.9870 - val_accuracy: 0.5281\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9727 - accuracy: 0.5306 - val_loss: 0.9870 - val_accuracy: 0.5263\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9727 - accuracy: 0.5313 - val_loss: 0.9869 - val_accuracy: 0.5263\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9727 - accuracy: 0.5311 - val_loss: 0.9867 - val_accuracy: 0.5281\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9726 - accuracy: 0.5311 - val_loss: 0.9871 - val_accuracy: 0.5246\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9726 - accuracy: 0.5311 - val_loss: 0.9872 - val_accuracy: 0.5286\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9727 - accuracy: 0.5315 - val_loss: 0.9871 - val_accuracy: 0.5277\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9724 - accuracy: 0.5314 - val_loss: 0.9870 - val_accuracy: 0.5277\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9723 - accuracy: 0.5303 - val_loss: 0.9902 - val_accuracy: 0.5193\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9726 - accuracy: 0.5320 - val_loss: 0.9869 - val_accuracy: 0.5277\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9725 - accuracy: 0.5307 - val_loss: 0.9869 - val_accuracy: 0.5237\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9726 - accuracy: 0.5315 - val_loss: 0.9865 - val_accuracy: 0.5268\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9725 - accuracy: 0.5312 - val_loss: 0.9870 - val_accuracy: 0.5237\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9725 - accuracy: 0.5316 - val_loss: 0.9869 - val_accuracy: 0.5263\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9726 - accuracy: 0.5307 - val_loss: 0.9868 - val_accuracy: 0.5259\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9726 - accuracy: 0.5321 - val_loss: 0.9871 - val_accuracy: 0.5228\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9723 - accuracy: 0.5322 - val_loss: 0.9870 - val_accuracy: 0.5237\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9724 - accuracy: 0.5314 - val_loss: 0.9873 - val_accuracy: 0.5286\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 539us/step - loss: 0.9725 - accuracy: 0.5323 - val_loss: 0.9872 - val_accuracy: 0.5237\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9724 - accuracy: 0.5312 - val_loss: 0.9871 - val_accuracy: 0.5246\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9724 - accuracy: 0.5315 - val_loss: 0.9869 - val_accuracy: 0.5281\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9723 - accuracy: 0.5327 - val_loss: 0.9871 - val_accuracy: 0.5259\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9724 - accuracy: 0.5310 - val_loss: 0.9871 - val_accuracy: 0.5241\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9725 - accuracy: 0.5318 - val_loss: 0.9871 - val_accuracy: 0.5232\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9725 - accuracy: 0.5306 - val_loss: 0.9867 - val_accuracy: 0.5255\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9722 - accuracy: 0.5315 - val_loss: 0.9870 - val_accuracy: 0.5281\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9724 - accuracy: 0.5321 - val_loss: 0.9872 - val_accuracy: 0.5255\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9723 - accuracy: 0.5315 - val_loss: 0.9868 - val_accuracy: 0.5286\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9723 - accuracy: 0.5309 - val_loss: 0.9881 - val_accuracy: 0.5259\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9725 - accuracy: 0.5315 - val_loss: 0.9873 - val_accuracy: 0.5277\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9723 - accuracy: 0.5314 - val_loss: 0.9871 - val_accuracy: 0.5281\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 0.9894 - val_accuracy: 0.5166\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9723 - accuracy: 0.5330 - val_loss: 0.9865 - val_accuracy: 0.5281\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9725 - accuracy: 0.5316 - val_loss: 0.9867 - val_accuracy: 0.5246\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9724 - accuracy: 0.5313 - val_loss: 0.9865 - val_accuracy: 0.5241\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 509us/step - loss: 0.9723 - accuracy: 0.5314 - val_loss: 0.9864 - val_accuracy: 0.5259\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9722 - accuracy: 0.5316 - val_loss: 0.9872 - val_accuracy: 0.5281\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9722 - accuracy: 0.5314 - val_loss: 0.9871 - val_accuracy: 0.5281\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9721 - accuracy: 0.5314 - val_loss: 0.9874 - val_accuracy: 0.5281\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9722 - accuracy: 0.5310 - val_loss: 0.9871 - val_accuracy: 0.5281\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9723 - accuracy: 0.5320 - val_loss: 0.9867 - val_accuracy: 0.5286\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9723 - accuracy: 0.5313 - val_loss: 0.9871 - val_accuracy: 0.5272\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9722 - accuracy: 0.5321 - val_loss: 0.9867 - val_accuracy: 0.5241\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9723 - accuracy: 0.5317 - val_loss: 0.9870 - val_accuracy: 0.5232\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 534us/step - loss: 0.9723 - accuracy: 0.5311 - val_loss: 0.9868 - val_accuracy: 0.5241\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9723 - accuracy: 0.5322 - val_loss: 0.9872 - val_accuracy: 0.5228\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9723 - accuracy: 0.5309 - val_loss: 0.9870 - val_accuracy: 0.5286\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9721 - accuracy: 0.5328 - val_loss: 0.9888 - val_accuracy: 0.5224\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9723 - accuracy: 0.5306 - val_loss: 0.9869 - val_accuracy: 0.5241\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9723 - accuracy: 0.5322 - val_loss: 0.9867 - val_accuracy: 0.5241\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9720 - accuracy: 0.5307 - val_loss: 0.9868 - val_accuracy: 0.5281\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9722 - accuracy: 0.5312 - val_loss: 0.9866 - val_accuracy: 0.5272\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9724 - accuracy: 0.5317 - val_loss: 0.9868 - val_accuracy: 0.5286\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9721 - accuracy: 0.5310 - val_loss: 0.9868 - val_accuracy: 0.5277\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 535us/step - loss: 0.9721 - accuracy: 0.5313 - val_loss: 0.9873 - val_accuracy: 0.5228\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9721 - accuracy: 0.5323 - val_loss: 0.9875 - val_accuracy: 0.5277\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9723 - accuracy: 0.5319 - val_loss: 0.9866 - val_accuracy: 0.5268\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9721 - accuracy: 0.5311 - val_loss: 0.9867 - val_accuracy: 0.5268\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 0.9870 - val_accuracy: 0.5286\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9865 - val_accuracy: 0.5268\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9722 - accuracy: 0.5326 - val_loss: 0.9866 - val_accuracy: 0.5246\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9720 - accuracy: 0.5306 - val_loss: 0.9866 - val_accuracy: 0.5246\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9721 - accuracy: 0.5311 - val_loss: 0.9875 - val_accuracy: 0.5228\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9721 - accuracy: 0.5319 - val_loss: 0.9871 - val_accuracy: 0.5250\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 537us/step - loss: 0.9722 - accuracy: 0.5318 - val_loss: 0.9868 - val_accuracy: 0.5250\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9865 - val_accuracy: 0.5241\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9865 - val_accuracy: 0.5259\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9721 - accuracy: 0.5319 - val_loss: 0.9876 - val_accuracy: 0.5277\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9722 - accuracy: 0.5312 - val_loss: 0.9865 - val_accuracy: 0.5268\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 570us/step - loss: 0.9721 - accuracy: 0.5321 - val_loss: 0.9870 - val_accuracy: 0.5281\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9722 - accuracy: 0.5312 - val_loss: 0.9871 - val_accuracy: 0.5232\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9722 - accuracy: 0.5325 - val_loss: 0.9868 - val_accuracy: 0.5286\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9723 - accuracy: 0.5321 - val_loss: 0.9866 - val_accuracy: 0.5277\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9719 - accuracy: 0.5325 - val_loss: 0.9872 - val_accuracy: 0.5268\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9722 - accuracy: 0.5320 - val_loss: 0.9880 - val_accuracy: 0.5250\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9717 - accuracy: 0.5315 - val_loss: 0.9867 - val_accuracy: 0.5259\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9722 - accuracy: 0.5322 - val_loss: 0.9869 - val_accuracy: 0.5281\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9870 - val_accuracy: 0.5281\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9721 - accuracy: 0.5319 - val_loss: 0.9869 - val_accuracy: 0.5228\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9720 - accuracy: 0.5303 - val_loss: 0.9868 - val_accuracy: 0.5246\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9722 - accuracy: 0.5317 - val_loss: 0.9875 - val_accuracy: 0.5241\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9722 - accuracy: 0.5301 - val_loss: 0.9867 - val_accuracy: 0.5241\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9720 - accuracy: 0.5317 - val_loss: 0.9871 - val_accuracy: 0.5241\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9722 - accuracy: 0.5324 - val_loss: 0.9868 - val_accuracy: 0.5268\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9719 - accuracy: 0.5322 - val_loss: 0.9865 - val_accuracy: 0.5272\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9720 - accuracy: 0.5315 - val_loss: 0.9866 - val_accuracy: 0.5268\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9722 - accuracy: 0.5321 - val_loss: 0.9870 - val_accuracy: 0.5272\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9719 - accuracy: 0.5320 - val_loss: 0.9872 - val_accuracy: 0.5228\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9720 - accuracy: 0.5311 - val_loss: 0.9874 - val_accuracy: 0.5286\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9718 - accuracy: 0.5322 - val_loss: 0.9879 - val_accuracy: 0.5215\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9720 - accuracy: 0.5313 - val_loss: 0.9867 - val_accuracy: 0.5286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9720 - accuracy: 0.5329 - val_loss: 0.9866 - val_accuracy: 0.5268\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9719 - accuracy: 0.5321 - val_loss: 0.9876 - val_accuracy: 0.5241\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9718 - accuracy: 0.5317 - val_loss: 0.9880 - val_accuracy: 0.5263\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9720 - accuracy: 0.5311 - val_loss: 0.9877 - val_accuracy: 0.5286\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9720 - accuracy: 0.5319 - val_loss: 0.9867 - val_accuracy: 0.5263\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9721 - accuracy: 0.5318 - val_loss: 0.9868 - val_accuracy: 0.5277\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9721 - accuracy: 0.5311 - val_loss: 0.9869 - val_accuracy: 0.5286\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9720 - accuracy: 0.5315 - val_loss: 0.9866 - val_accuracy: 0.5232\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9720 - accuracy: 0.5312 - val_loss: 0.9865 - val_accuracy: 0.5263\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9719 - accuracy: 0.5308 - val_loss: 0.9870 - val_accuracy: 0.5246\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9720 - accuracy: 0.5315 - val_loss: 0.9866 - val_accuracy: 0.5277\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9720 - accuracy: 0.5313 - val_loss: 0.9872 - val_accuracy: 0.5281\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9720 - accuracy: 0.5316 - val_loss: 0.9868 - val_accuracy: 0.5263\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9719 - accuracy: 0.5319 - val_loss: 0.9868 - val_accuracy: 0.5281\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9720 - accuracy: 0.5317 - val_loss: 0.9867 - val_accuracy: 0.5263\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9719 - accuracy: 0.5315 - val_loss: 0.9872 - val_accuracy: 0.5286\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9719 - accuracy: 0.5312 - val_loss: 0.9873 - val_accuracy: 0.5241\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9720 - accuracy: 0.5324 - val_loss: 0.9868 - val_accuracy: 0.5241\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9718 - accuracy: 0.5311 - val_loss: 0.9872 - val_accuracy: 0.5246\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 481us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9866 - val_accuracy: 0.5286\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9719 - accuracy: 0.5323 - val_loss: 0.9878 - val_accuracy: 0.5272\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9717 - accuracy: 0.5313 - val_loss: 0.9875 - val_accuracy: 0.5286\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9718 - accuracy: 0.5316 - val_loss: 0.9872 - val_accuracy: 0.5219\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9721 - accuracy: 0.5322 - val_loss: 0.9870 - val_accuracy: 0.5263\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9720 - accuracy: 0.5319 - val_loss: 0.9871 - val_accuracy: 0.5286\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - ETA: 0s - loss: 0.9717 - accuracy: 0.53 - 0s 479us/step - loss: 0.9719 - accuracy: 0.5326 - val_loss: 0.9870 - val_accuracy: 0.5286\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9719 - accuracy: 0.5320 - val_loss: 0.9872 - val_accuracy: 0.5277\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9720 - accuracy: 0.5305 - val_loss: 0.9875 - val_accuracy: 0.5215\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9718 - accuracy: 0.5304 - val_loss: 0.9869 - val_accuracy: 0.5281\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9718 - accuracy: 0.5310 - val_loss: 0.9878 - val_accuracy: 0.5215\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9716 - accuracy: 0.5318 - val_loss: 0.9868 - val_accuracy: 0.5281\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 0.9878 - val_accuracy: 0.5281\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 517us/step - loss: 0.9719 - accuracy: 0.5314 - val_loss: 0.9869 - val_accuracy: 0.5277\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9718 - accuracy: 0.5322 - val_loss: 0.9868 - val_accuracy: 0.5286\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9719 - accuracy: 0.5318 - val_loss: 0.9871 - val_accuracy: 0.5241\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9717 - accuracy: 0.5325 - val_loss: 0.9880 - val_accuracy: 0.5272\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9718 - accuracy: 0.5319 - val_loss: 0.9872 - val_accuracy: 0.5250\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9718 - accuracy: 0.5314 - val_loss: 0.9869 - val_accuracy: 0.5277\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9719 - accuracy: 0.5318 - val_loss: 0.9870 - val_accuracy: 0.5241\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9717 - accuracy: 0.5315 - val_loss: 0.9877 - val_accuracy: 0.5246\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9718 - accuracy: 0.5317 - val_loss: 0.9871 - val_accuracy: 0.5241\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9717 - accuracy: 0.5316 - val_loss: 0.9875 - val_accuracy: 0.5286\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9717 - accuracy: 0.5310 - val_loss: 0.9874 - val_accuracy: 0.5232\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9719 - accuracy: 0.5318 - val_loss: 0.9869 - val_accuracy: 0.5250\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9719 - accuracy: 0.5314 - val_loss: 0.9871 - val_accuracy: 0.5263\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9716 - accuracy: 0.5322 - val_loss: 0.9879 - val_accuracy: 0.5241\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9718 - accuracy: 0.5317 - val_loss: 0.9874 - val_accuracy: 0.5232\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9718 - accuracy: 0.5312 - val_loss: 0.9870 - val_accuracy: 0.5277\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9718 - accuracy: 0.5310 - val_loss: 0.9875 - val_accuracy: 0.5277\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9719 - accuracy: 0.5321 - val_loss: 0.9877 - val_accuracy: 0.5228\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9717 - accuracy: 0.5311 - val_loss: 0.9876 - val_accuracy: 0.5241\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 481us/step - loss: 0.9717 - accuracy: 0.5320 - val_loss: 0.9882 - val_accuracy: 0.5277\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9718 - accuracy: 0.5313 - val_loss: 0.9875 - val_accuracy: 0.5232\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9719 - accuracy: 0.5321 - val_loss: 0.9878 - val_accuracy: 0.5263\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9718 - accuracy: 0.5319 - val_loss: 0.9876 - val_accuracy: 0.5290\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 483us/step - loss: 0.9717 - accuracy: 0.5319 - val_loss: 0.9872 - val_accuracy: 0.5250\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9716 - accuracy: 0.5325 - val_loss: 0.9872 - val_accuracy: 0.5286\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9717 - accuracy: 0.5313 - val_loss: 0.9874 - val_accuracy: 0.5241\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 467us/step - loss: 0.9720 - accuracy: 0.5318 - val_loss: 0.9873 - val_accuracy: 0.5286\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 342us/step - loss: 0.9713 - accuracy: 0.5312\n",
      "Accuracy : 0.531205415725708\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9873 - accuracy: 0.5286\n",
      "Accuracy : 0.5285524725914001\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 654us/step - loss: 1.0588 - accuracy: 0.4491 - val_loss: 1.0376 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 1.0240 - accuracy: 0.4913 - val_loss: 1.0050 - val_accuracy: 0.5370\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9999 - accuracy: 0.5276 - val_loss: 0.9865 - val_accuracy: 0.5405\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9892 - accuracy: 0.5284 - val_loss: 0.9806 - val_accuracy: 0.5387\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9849 - accuracy: 0.5283 - val_loss: 0.9774 - val_accuracy: 0.5392\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9823 - accuracy: 0.5290 - val_loss: 0.9758 - val_accuracy: 0.5418\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9805 - accuracy: 0.5300 - val_loss: 0.9742 - val_accuracy: 0.5409\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9732 - val_accuracy: 0.5396\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9783 - accuracy: 0.5294 - val_loss: 0.9724 - val_accuracy: 0.5405\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9777 - accuracy: 0.5308 - val_loss: 0.9720 - val_accuracy: 0.5405\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9772 - accuracy: 0.5295 - val_loss: 0.9714 - val_accuracy: 0.5387\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9767 - accuracy: 0.5300 - val_loss: 0.9717 - val_accuracy: 0.5387\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9765 - accuracy: 0.5304 - val_loss: 0.9709 - val_accuracy: 0.5392\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9763 - accuracy: 0.5305 - val_loss: 0.9709 - val_accuracy: 0.5383\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9762 - accuracy: 0.5292 - val_loss: 0.9708 - val_accuracy: 0.5409\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9760 - accuracy: 0.5307 - val_loss: 0.9704 - val_accuracy: 0.5387\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9759 - accuracy: 0.5307 - val_loss: 0.9701 - val_accuracy: 0.5401\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9701 - val_accuracy: 0.5401\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9759 - accuracy: 0.5299 - val_loss: 0.9700 - val_accuracy: 0.5396\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9757 - accuracy: 0.5300 - val_loss: 0.9703 - val_accuracy: 0.5392\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9701 - val_accuracy: 0.5401\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9757 - accuracy: 0.5302 - val_loss: 0.9700 - val_accuracy: 0.5405\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9699 - val_accuracy: 0.5401\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 0.9700 - val_accuracy: 0.5383\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9756 - accuracy: 0.5297 - val_loss: 0.9702 - val_accuracy: 0.5387\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9754 - accuracy: 0.5286 - val_loss: 0.9700 - val_accuracy: 0.5387\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9697 - val_accuracy: 0.5392\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9754 - accuracy: 0.5299 - val_loss: 0.9704 - val_accuracy: 0.5392\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 465us/step - loss: 0.9754 - accuracy: 0.5293 - val_loss: 0.9696 - val_accuracy: 0.5392\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9696 - val_accuracy: 0.5392\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9753 - accuracy: 0.5304 - val_loss: 0.9697 - val_accuracy: 0.5387\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9696 - val_accuracy: 0.5392\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9702 - val_accuracy: 0.5387\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9754 - accuracy: 0.5293 - val_loss: 0.9699 - val_accuracy: 0.5383\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9754 - accuracy: 0.5299 - val_loss: 0.9699 - val_accuracy: 0.5396\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9701 - val_accuracy: 0.5396\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9749 - accuracy: 0.5296 - val_loss: 0.9703 - val_accuracy: 0.5396\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9753 - accuracy: 0.5292 - val_loss: 0.9697 - val_accuracy: 0.5392\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9698 - val_accuracy: 0.5387\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9752 - accuracy: 0.5297 - val_loss: 0.9709 - val_accuracy: 0.5387\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 509us/step - loss: 0.9752 - accuracy: 0.5297 - val_loss: 0.9698 - val_accuracy: 0.5383\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9751 - accuracy: 0.5280 - val_loss: 0.9698 - val_accuracy: 0.5396\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9694 - val_accuracy: 0.5401\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9752 - accuracy: 0.5298 - val_loss: 0.9694 - val_accuracy: 0.5405\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9751 - accuracy: 0.5290 - val_loss: 0.9693 - val_accuracy: 0.5396\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9749 - accuracy: 0.5304 - val_loss: 0.9697 - val_accuracy: 0.5409\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9750 - accuracy: 0.5306 - val_loss: 0.9696 - val_accuracy: 0.5387\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9748 - accuracy: 0.5300 - val_loss: 0.9701 - val_accuracy: 0.5401\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9751 - accuracy: 0.5305 - val_loss: 0.9695 - val_accuracy: 0.5401\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9750 - accuracy: 0.5290 - val_loss: 0.9696 - val_accuracy: 0.5387\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 469us/step - loss: 0.9751 - accuracy: 0.5293 - val_loss: 0.9693 - val_accuracy: 0.5396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9751 - accuracy: 0.5305 - val_loss: 0.9695 - val_accuracy: 0.5383\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9750 - accuracy: 0.5293 - val_loss: 0.9697 - val_accuracy: 0.5387\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9752 - accuracy: 0.5294 - val_loss: 0.9695 - val_accuracy: 0.5396\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9750 - accuracy: 0.5307 - val_loss: 0.9700 - val_accuracy: 0.5396\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9749 - accuracy: 0.5300 - val_loss: 0.9696 - val_accuracy: 0.5392\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9749 - accuracy: 0.5299 - val_loss: 0.9697 - val_accuracy: 0.5392\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9693 - val_accuracy: 0.5396\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9748 - accuracy: 0.5298 - val_loss: 0.9697 - val_accuracy: 0.5414\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9750 - accuracy: 0.5308 - val_loss: 0.9693 - val_accuracy: 0.5387\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9747 - accuracy: 0.5302 - val_loss: 0.9700 - val_accuracy: 0.5396\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9748 - accuracy: 0.5304 - val_loss: 0.9694 - val_accuracy: 0.5387\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9749 - accuracy: 0.5296 - val_loss: 0.9691 - val_accuracy: 0.5392\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9748 - accuracy: 0.5294 - val_loss: 0.9693 - val_accuracy: 0.5387\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9746 - accuracy: 0.5303 - val_loss: 0.9700 - val_accuracy: 0.5396\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9691 - val_accuracy: 0.5396\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9747 - accuracy: 0.5305 - val_loss: 0.9699 - val_accuracy: 0.5392\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9747 - accuracy: 0.5307 - val_loss: 0.9695 - val_accuracy: 0.5396\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9748 - accuracy: 0.5304 - val_loss: 0.9696 - val_accuracy: 0.5392\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9747 - accuracy: 0.5293 - val_loss: 0.9696 - val_accuracy: 0.5396\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9747 - accuracy: 0.5303 - val_loss: 0.9691 - val_accuracy: 0.5387\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9747 - accuracy: 0.5297 - val_loss: 0.9690 - val_accuracy: 0.5392\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9747 - accuracy: 0.5295 - val_loss: 0.9691 - val_accuracy: 0.5392\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9744 - accuracy: 0.5307 - val_loss: 0.9707 - val_accuracy: 0.5392\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 536us/step - loss: 0.9745 - accuracy: 0.5293 - val_loss: 0.9694 - val_accuracy: 0.5378\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9695 - val_accuracy: 0.5383\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9746 - accuracy: 0.5296 - val_loss: 0.9694 - val_accuracy: 0.5387\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9745 - accuracy: 0.5297 - val_loss: 0.9691 - val_accuracy: 0.5392\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9745 - accuracy: 0.5299 - val_loss: 0.9697 - val_accuracy: 0.5396\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9747 - accuracy: 0.5296 - val_loss: 0.9704 - val_accuracy: 0.5396\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9747 - accuracy: 0.5292 - val_loss: 0.9691 - val_accuracy: 0.5392\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9746 - accuracy: 0.5298 - val_loss: 0.9693 - val_accuracy: 0.5401\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 465us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9696 - val_accuracy: 0.5383\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9690 - val_accuracy: 0.5387\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9745 - accuracy: 0.5297 - val_loss: 0.9696 - val_accuracy: 0.5405\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9746 - accuracy: 0.5300 - val_loss: 0.9694 - val_accuracy: 0.5392\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9744 - accuracy: 0.5306 - val_loss: 0.9693 - val_accuracy: 0.5392\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9744 - accuracy: 0.5293 - val_loss: 0.9699 - val_accuracy: 0.5392\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9691 - val_accuracy: 0.5387\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9745 - accuracy: 0.5295 - val_loss: 0.9691 - val_accuracy: 0.5392\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9743 - accuracy: 0.5297 - val_loss: 0.9694 - val_accuracy: 0.5387\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9746 - accuracy: 0.5295 - val_loss: 0.9693 - val_accuracy: 0.5396\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9747 - accuracy: 0.5303 - val_loss: 0.9691 - val_accuracy: 0.5392\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9745 - accuracy: 0.5301 - val_loss: 0.9697 - val_accuracy: 0.5392\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 467us/step - loss: 0.9746 - accuracy: 0.5298 - val_loss: 0.9690 - val_accuracy: 0.5392\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9745 - accuracy: 0.5296 - val_loss: 0.9698 - val_accuracy: 0.5378\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9744 - accuracy: 0.5294 - val_loss: 0.9688 - val_accuracy: 0.5392\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9744 - accuracy: 0.5296 - val_loss: 0.9690 - val_accuracy: 0.5396\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 532us/step - loss: 0.9745 - accuracy: 0.5312 - val_loss: 0.9692 - val_accuracy: 0.5392\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9744 - accuracy: 0.5293 - val_loss: 0.9691 - val_accuracy: 0.5401\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9745 - accuracy: 0.5290 - val_loss: 0.9695 - val_accuracy: 0.5383\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9745 - accuracy: 0.5300 - val_loss: 0.9692 - val_accuracy: 0.5401\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9743 - accuracy: 0.5289 - val_loss: 0.9691 - val_accuracy: 0.5378\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9744 - accuracy: 0.5298 - val_loss: 0.9694 - val_accuracy: 0.5392\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9743 - accuracy: 0.5303 - val_loss: 0.9692 - val_accuracy: 0.5392\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9745 - accuracy: 0.5298 - val_loss: 0.9692 - val_accuracy: 0.5392\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9745 - accuracy: 0.5295 - val_loss: 0.9691 - val_accuracy: 0.5383\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 482us/step - loss: 0.9744 - accuracy: 0.5300 - val_loss: 0.9696 - val_accuracy: 0.5387\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9745 - accuracy: 0.5302 - val_loss: 0.9690 - val_accuracy: 0.5383\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9742 - accuracy: 0.5297 - val_loss: 0.9695 - val_accuracy: 0.5396\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9745 - accuracy: 0.5303 - val_loss: 0.9693 - val_accuracy: 0.5396\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9743 - accuracy: 0.5308 - val_loss: 0.9694 - val_accuracy: 0.5392\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9744 - accuracy: 0.5283 - val_loss: 0.9692 - val_accuracy: 0.5378\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9743 - accuracy: 0.5293 - val_loss: 0.9688 - val_accuracy: 0.5396\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9745 - accuracy: 0.5298 - val_loss: 0.9690 - val_accuracy: 0.5392\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9744 - accuracy: 0.5295 - val_loss: 0.9689 - val_accuracy: 0.5392\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9743 - accuracy: 0.5295 - val_loss: 0.9688 - val_accuracy: 0.5396\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 529us/step - loss: 0.9744 - accuracy: 0.5303 - val_loss: 0.9689 - val_accuracy: 0.5392\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5307 - val_loss: 0.9693 - val_accuracy: 0.5378\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9744 - accuracy: 0.5302 - val_loss: 0.9691 - val_accuracy: 0.5392\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9744 - accuracy: 0.5304 - val_loss: 0.9689 - val_accuracy: 0.5392\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9743 - accuracy: 0.5301 - val_loss: 0.9692 - val_accuracy: 0.5383\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9744 - accuracy: 0.5302 - val_loss: 0.9691 - val_accuracy: 0.5378\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9743 - accuracy: 0.5305 - val_loss: 0.9695 - val_accuracy: 0.5378\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9743 - accuracy: 0.5300 - val_loss: 0.9695 - val_accuracy: 0.5387\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9743 - accuracy: 0.5286 - val_loss: 0.9693 - val_accuracy: 0.5392\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9742 - accuracy: 0.5299 - val_loss: 0.9694 - val_accuracy: 0.5392\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9744 - accuracy: 0.5309 - val_loss: 0.9688 - val_accuracy: 0.5392\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9691 - val_accuracy: 0.5383\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9743 - accuracy: 0.5292 - val_loss: 0.9693 - val_accuracy: 0.5392\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9744 - accuracy: 0.5309 - val_loss: 0.9693 - val_accuracy: 0.5387\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9742 - accuracy: 0.5310 - val_loss: 0.9691 - val_accuracy: 0.5383\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9743 - accuracy: 0.5304 - val_loss: 0.9689 - val_accuracy: 0.5378\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9743 - accuracy: 0.5306 - val_loss: 0.9692 - val_accuracy: 0.5383\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9743 - accuracy: 0.5306 - val_loss: 0.9693 - val_accuracy: 0.5392\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9743 - accuracy: 0.5300 - val_loss: 0.9691 - val_accuracy: 0.5392\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9742 - accuracy: 0.5301 - val_loss: 0.9690 - val_accuracy: 0.5387\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9743 - accuracy: 0.5299 - val_loss: 0.9690 - val_accuracy: 0.5383\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9743 - accuracy: 0.5294 - val_loss: 0.9693 - val_accuracy: 0.5383\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9743 - accuracy: 0.5312 - val_loss: 0.9693 - val_accuracy: 0.5383\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9743 - accuracy: 0.5300 - val_loss: 0.9691 - val_accuracy: 0.5378\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9742 - accuracy: 0.5291 - val_loss: 0.9690 - val_accuracy: 0.5396\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9743 - accuracy: 0.5301 - val_loss: 0.9691 - val_accuracy: 0.5401\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9743 - accuracy: 0.5296 - val_loss: 0.9692 - val_accuracy: 0.5383\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9741 - accuracy: 0.5303 - val_loss: 0.9699 - val_accuracy: 0.5383\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 0.9688 - val_accuracy: 0.5383\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9742 - accuracy: 0.5307 - val_loss: 0.9691 - val_accuracy: 0.5383\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9741 - accuracy: 0.5301 - val_loss: 0.9689 - val_accuracy: 0.5378\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9743 - accuracy: 0.5286 - val_loss: 0.9689 - val_accuracy: 0.5396\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9744 - accuracy: 0.5310 - val_loss: 0.9692 - val_accuracy: 0.5401\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9744 - accuracy: 0.5300 - val_loss: 0.9689 - val_accuracy: 0.5383\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9742 - accuracy: 0.5303 - val_loss: 0.9699 - val_accuracy: 0.5387\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9741 - accuracy: 0.5300 - val_loss: 0.9715 - val_accuracy: 0.5409\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9743 - accuracy: 0.5297 - val_loss: 0.9689 - val_accuracy: 0.5378\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9692 - val_accuracy: 0.5383\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9743 - accuracy: 0.5307 - val_loss: 0.9695 - val_accuracy: 0.5378\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9741 - accuracy: 0.5292 - val_loss: 0.9690 - val_accuracy: 0.5383\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9739 - accuracy: 0.5293 - val_loss: 0.9696 - val_accuracy: 0.5387\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9742 - accuracy: 0.5311 - val_loss: 0.9688 - val_accuracy: 0.5383\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9742 - accuracy: 0.5291 - val_loss: 0.9690 - val_accuracy: 0.5383\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9691 - val_accuracy: 0.5383\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9742 - accuracy: 0.5305 - val_loss: 0.9688 - val_accuracy: 0.5396\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9742 - accuracy: 0.5302 - val_loss: 0.9692 - val_accuracy: 0.5396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9742 - accuracy: 0.5297 - val_loss: 0.9691 - val_accuracy: 0.5383\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9744 - accuracy: 0.5298 - val_loss: 0.9689 - val_accuracy: 0.5378\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9742 - accuracy: 0.5297 - val_loss: 0.9690 - val_accuracy: 0.5383\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9743 - accuracy: 0.5304 - val_loss: 0.9693 - val_accuracy: 0.5392\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9742 - accuracy: 0.5300 - val_loss: 0.9687 - val_accuracy: 0.5396\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9741 - accuracy: 0.5298 - val_loss: 0.9691 - val_accuracy: 0.5378\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9741 - accuracy: 0.5305 - val_loss: 0.9687 - val_accuracy: 0.5392\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9742 - accuracy: 0.5292 - val_loss: 0.9690 - val_accuracy: 0.5383\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9741 - accuracy: 0.5308 - val_loss: 0.9695 - val_accuracy: 0.5414\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9741 - accuracy: 0.5298 - val_loss: 0.9694 - val_accuracy: 0.5378\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9742 - accuracy: 0.5305 - val_loss: 0.9689 - val_accuracy: 0.5378\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 557us/step - loss: 0.9742 - accuracy: 0.5311 - val_loss: 0.9690 - val_accuracy: 0.5383\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 531us/step - loss: 0.9740 - accuracy: 0.5299 - val_loss: 0.9691 - val_accuracy: 0.5383\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9741 - accuracy: 0.5304 - val_loss: 0.9690 - val_accuracy: 0.5392\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9742 - accuracy: 0.5297 - val_loss: 0.9689 - val_accuracy: 0.5370\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9740 - accuracy: 0.5311 - val_loss: 0.9695 - val_accuracy: 0.5374\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9740 - accuracy: 0.5305 - val_loss: 0.9692 - val_accuracy: 0.5378\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9742 - accuracy: 0.5312 - val_loss: 0.9688 - val_accuracy: 0.5378\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9742 - accuracy: 0.5292 - val_loss: 0.9690 - val_accuracy: 0.5374\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9740 - accuracy: 0.5302 - val_loss: 0.9695 - val_accuracy: 0.5387\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9742 - accuracy: 0.5294 - val_loss: 0.9691 - val_accuracy: 0.5383\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9742 - accuracy: 0.5301 - val_loss: 0.9692 - val_accuracy: 0.5383\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9741 - accuracy: 0.5303 - val_loss: 0.9690 - val_accuracy: 0.5387\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9741 - accuracy: 0.5305 - val_loss: 0.9695 - val_accuracy: 0.5392\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 526us/step - loss: 0.9743 - accuracy: 0.5289 - val_loss: 0.9692 - val_accuracy: 0.5378\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9740 - accuracy: 0.5311 - val_loss: 0.9690 - val_accuracy: 0.5383\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9739 - accuracy: 0.5287 - val_loss: 0.9691 - val_accuracy: 0.5374\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9742 - accuracy: 0.5305 - val_loss: 0.9689 - val_accuracy: 0.5370\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9740 - accuracy: 0.5314 - val_loss: 0.9693 - val_accuracy: 0.5378\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9742 - accuracy: 0.5295 - val_loss: 0.9690 - val_accuracy: 0.5378\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9740 - accuracy: 0.5297 - val_loss: 0.9697 - val_accuracy: 0.5370\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9741 - accuracy: 0.5288 - val_loss: 0.9689 - val_accuracy: 0.5392\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9741 - accuracy: 0.5302 - val_loss: 0.9688 - val_accuracy: 0.5405\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9738 - accuracy: 0.5295 - val_loss: 0.9693 - val_accuracy: 0.5378\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9742 - accuracy: 0.5301 - val_loss: 0.9691 - val_accuracy: 0.5405\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9741 - accuracy: 0.5296 - val_loss: 0.9690 - val_accuracy: 0.5378\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9739 - accuracy: 0.5302 - val_loss: 0.9688 - val_accuracy: 0.5365\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 351us/step - loss: 0.9737 - accuracy: 0.5307\n",
      "Accuracy : 0.5307136178016663\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9688 - accuracy: 0.5365\n",
      "Accuracy : 0.5365206003189087\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 658us/step - loss: 1.0697 - accuracy: 0.4288 - val_loss: 1.0448 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 1.0357 - accuracy: 0.4595 - val_loss: 1.0130 - val_accuracy: 0.4834\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 1.0038 - accuracy: 0.5243 - val_loss: 0.9772 - val_accuracy: 0.5423\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9898 - accuracy: 0.5296 - val_loss: 0.9712 - val_accuracy: 0.5423\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9873 - accuracy: 0.5279 - val_loss: 0.9695 - val_accuracy: 0.5418\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9855 - accuracy: 0.5292 - val_loss: 0.9699 - val_accuracy: 0.5396\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9838 - accuracy: 0.5293 - val_loss: 0.9670 - val_accuracy: 0.5414\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9821 - accuracy: 0.5299 - val_loss: 0.9669 - val_accuracy: 0.5387\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9811 - accuracy: 0.5299 - val_loss: 0.9656 - val_accuracy: 0.5374\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9800 - accuracy: 0.5308 - val_loss: 0.9633 - val_accuracy: 0.5414\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9791 - accuracy: 0.5290 - val_loss: 0.9627 - val_accuracy: 0.5414\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9784 - accuracy: 0.5309 - val_loss: 0.9631 - val_accuracy: 0.5396\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9781 - accuracy: 0.5301 - val_loss: 0.9630 - val_accuracy: 0.5378\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 546us/step - loss: 0.9776 - accuracy: 0.5287 - val_loss: 0.9619 - val_accuracy: 0.5423\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 563us/step - loss: 0.9777 - accuracy: 0.5304 - val_loss: 0.9613 - val_accuracy: 0.5392\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9613 - val_accuracy: 0.5387\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 533us/step - loss: 0.9770 - accuracy: 0.5304 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 514us/step - loss: 0.9770 - accuracy: 0.5302 - val_loss: 0.9608 - val_accuracy: 0.5396\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9767 - accuracy: 0.5302 - val_loss: 0.9608 - val_accuracy: 0.5396\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9765 - accuracy: 0.5296 - val_loss: 0.9606 - val_accuracy: 0.5396\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9764 - accuracy: 0.5304 - val_loss: 0.9607 - val_accuracy: 0.5414\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9765 - accuracy: 0.5293 - val_loss: 0.9609 - val_accuracy: 0.5378\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9763 - accuracy: 0.5306 - val_loss: 0.9631 - val_accuracy: 0.5383\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9764 - accuracy: 0.5284 - val_loss: 0.9625 - val_accuracy: 0.5392\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9763 - accuracy: 0.5291 - val_loss: 0.9605 - val_accuracy: 0.5396\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9760 - accuracy: 0.5308 - val_loss: 0.9604 - val_accuracy: 0.5396\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 545us/step - loss: 0.9762 - accuracy: 0.5296 - val_loss: 0.9607 - val_accuracy: 0.5378\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9604 - val_accuracy: 0.5414\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 560us/step - loss: 0.9759 - accuracy: 0.5296 - val_loss: 0.9612 - val_accuracy: 0.5361\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9761 - accuracy: 0.5293 - val_loss: 0.9621 - val_accuracy: 0.5378\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9760 - accuracy: 0.5286 - val_loss: 0.9613 - val_accuracy: 0.5387\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9759 - accuracy: 0.5285 - val_loss: 0.9610 - val_accuracy: 0.5396\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9762 - accuracy: 0.5297 - val_loss: 0.9610 - val_accuracy: 0.5396\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 0.9603 - val_accuracy: 0.5387\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9760 - accuracy: 0.5291 - val_loss: 0.9629 - val_accuracy: 0.5378\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9759 - accuracy: 0.5305 - val_loss: 0.9604 - val_accuracy: 0.5414\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9758 - accuracy: 0.5294 - val_loss: 0.9613 - val_accuracy: 0.5387\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9758 - accuracy: 0.5289 - val_loss: 0.9614 - val_accuracy: 0.5378\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 581us/step - loss: 0.9759 - accuracy: 0.5290 - val_loss: 0.9624 - val_accuracy: 0.5387\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 567us/step - loss: 0.9759 - accuracy: 0.5290 - val_loss: 0.9605 - val_accuracy: 0.5396\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9760 - accuracy: 0.5292 - val_loss: 0.9605 - val_accuracy: 0.5387\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9758 - accuracy: 0.5290 - val_loss: 0.9625 - val_accuracy: 0.5374\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9757 - accuracy: 0.5288 - val_loss: 0.9602 - val_accuracy: 0.5387\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9757 - accuracy: 0.5292 - val_loss: 0.9607 - val_accuracy: 0.5387\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9757 - accuracy: 0.5285 - val_loss: 0.9607 - val_accuracy: 0.5383\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9756 - accuracy: 0.5286 - val_loss: 0.9619 - val_accuracy: 0.5378\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9756 - accuracy: 0.5285 - val_loss: 0.9605 - val_accuracy: 0.5387\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9755 - accuracy: 0.5300 - val_loss: 0.9604 - val_accuracy: 0.5409\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9603 - val_accuracy: 0.5396\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9603 - val_accuracy: 0.5396\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9756 - accuracy: 0.5304 - val_loss: 0.9625 - val_accuracy: 0.5374\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9754 - accuracy: 0.5292 - val_loss: 0.9613 - val_accuracy: 0.5374\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9758 - accuracy: 0.5287 - val_loss: 0.9629 - val_accuracy: 0.5383\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9757 - accuracy: 0.5286 - val_loss: 0.9611 - val_accuracy: 0.5361\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 0.9615 - val_accuracy: 0.5361\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9601 - val_accuracy: 0.5414\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9755 - accuracy: 0.5297 - val_loss: 0.9611 - val_accuracy: 0.5370\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9618 - val_accuracy: 0.5383\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9756 - accuracy: 0.5286 - val_loss: 0.9608 - val_accuracy: 0.5370\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9755 - accuracy: 0.5289 - val_loss: 0.9615 - val_accuracy: 0.5378\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9756 - accuracy: 0.5295 - val_loss: 0.9612 - val_accuracy: 0.5365\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9758 - accuracy: 0.5295 - val_loss: 0.9609 - val_accuracy: 0.5361\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9604 - val_accuracy: 0.5392\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 543us/step - loss: 0.9753 - accuracy: 0.5289 - val_loss: 0.9618 - val_accuracy: 0.5365\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9755 - accuracy: 0.5291 - val_loss: 0.9602 - val_accuracy: 0.5409\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9755 - accuracy: 0.5287 - val_loss: 0.9604 - val_accuracy: 0.5414\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9755 - accuracy: 0.5292 - val_loss: 0.9600 - val_accuracy: 0.5392\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9604 - val_accuracy: 0.5414\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9753 - accuracy: 0.5287 - val_loss: 0.9636 - val_accuracy: 0.5365\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9754 - accuracy: 0.5290 - val_loss: 0.9610 - val_accuracy: 0.5374\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9754 - accuracy: 0.5279 - val_loss: 0.9603 - val_accuracy: 0.5383\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9756 - accuracy: 0.5292 - val_loss: 0.9615 - val_accuracy: 0.5365\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9605 - val_accuracy: 0.5392\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 493us/step - loss: 0.9755 - accuracy: 0.5294 - val_loss: 0.9609 - val_accuracy: 0.5365\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9608 - val_accuracy: 0.5414\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9755 - accuracy: 0.5295 - val_loss: 0.9606 - val_accuracy: 0.5392\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9753 - accuracy: 0.5288 - val_loss: 0.9603 - val_accuracy: 0.5387\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9755 - accuracy: 0.5295 - val_loss: 0.9603 - val_accuracy: 0.5387\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9753 - accuracy: 0.5293 - val_loss: 0.9646 - val_accuracy: 0.5392\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9755 - accuracy: 0.5288 - val_loss: 0.9602 - val_accuracy: 0.5392\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9756 - accuracy: 0.5305 - val_loss: 0.9600 - val_accuracy: 0.5387\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9754 - accuracy: 0.5293 - val_loss: 0.9600 - val_accuracy: 0.5405\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9753 - accuracy: 0.5296 - val_loss: 0.9602 - val_accuracy: 0.5387\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9605 - val_accuracy: 0.5387\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9602 - val_accuracy: 0.5409\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9755 - accuracy: 0.5290 - val_loss: 0.9601 - val_accuracy: 0.5409\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9617 - val_accuracy: 0.5374\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9603 - val_accuracy: 0.5392\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9754 - accuracy: 0.5289 - val_loss: 0.9600 - val_accuracy: 0.5387\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9754 - accuracy: 0.5302 - val_loss: 0.9600 - val_accuracy: 0.5409\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9754 - accuracy: 0.5294 - val_loss: 0.9636 - val_accuracy: 0.5387\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9752 - accuracy: 0.5292 - val_loss: 0.9622 - val_accuracy: 0.5401\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9755 - accuracy: 0.5296 - val_loss: 0.9603 - val_accuracy: 0.5387\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9754 - accuracy: 0.5305 - val_loss: 0.9605 - val_accuracy: 0.5387\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9752 - accuracy: 0.5302 - val_loss: 0.9607 - val_accuracy: 0.5409\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9611 - val_accuracy: 0.5401\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9753 - accuracy: 0.5297 - val_loss: 0.9608 - val_accuracy: 0.5387\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9609 - val_accuracy: 0.5387\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9601 - val_accuracy: 0.5392\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9754 - accuracy: 0.5297 - val_loss: 0.9604 - val_accuracy: 0.5392\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9754 - accuracy: 0.5293 - val_loss: 0.9607 - val_accuracy: 0.5392\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9754 - accuracy: 0.5292 - val_loss: 0.9604 - val_accuracy: 0.5414\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9751 - accuracy: 0.5296 - val_loss: 0.9614 - val_accuracy: 0.5392\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9752 - accuracy: 0.5297 - val_loss: 0.9642 - val_accuracy: 0.5374\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9753 - accuracy: 0.5288 - val_loss: 0.9629 - val_accuracy: 0.5383\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9754 - accuracy: 0.5296 - val_loss: 0.9612 - val_accuracy: 0.5387\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9606 - val_accuracy: 0.5401\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9753 - accuracy: 0.5304 - val_loss: 0.9600 - val_accuracy: 0.5387\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9754 - accuracy: 0.5291 - val_loss: 0.9622 - val_accuracy: 0.5365\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 518us/step - loss: 0.9753 - accuracy: 0.5293 - val_loss: 0.9605 - val_accuracy: 0.5392\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9755 - accuracy: 0.5302 - val_loss: 0.9606 - val_accuracy: 0.5392\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9620 - val_accuracy: 0.5396\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9755 - accuracy: 0.5296 - val_loss: 0.9614 - val_accuracy: 0.5365\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9753 - accuracy: 0.5301 - val_loss: 0.9609 - val_accuracy: 0.5392\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9755 - accuracy: 0.5300 - val_loss: 0.9616 - val_accuracy: 0.5370\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9752 - accuracy: 0.5297 - val_loss: 0.9601 - val_accuracy: 0.5414\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9754 - accuracy: 0.5299 - val_loss: 0.9606 - val_accuracy: 0.5383\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9754 - accuracy: 0.5294 - val_loss: 0.9606 - val_accuracy: 0.5387\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9754 - accuracy: 0.5299 - val_loss: 0.9600 - val_accuracy: 0.5409\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9752 - accuracy: 0.5291 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9754 - accuracy: 0.5302 - val_loss: 0.9604 - val_accuracy: 0.5392\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9750 - accuracy: 0.5306 - val_loss: 0.9609 - val_accuracy: 0.5370\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9754 - accuracy: 0.5306 - val_loss: 0.9610 - val_accuracy: 0.5392\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9753 - accuracy: 0.5298 - val_loss: 0.9612 - val_accuracy: 0.5374\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9631 - val_accuracy: 0.5387\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9605 - val_accuracy: 0.5383\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9601 - val_accuracy: 0.5392\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9753 - accuracy: 0.5292 - val_loss: 0.9607 - val_accuracy: 0.5392\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9754 - accuracy: 0.5289 - val_loss: 0.9604 - val_accuracy: 0.5414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9751 - accuracy: 0.5296 - val_loss: 0.9619 - val_accuracy: 0.5387\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9754 - accuracy: 0.5291 - val_loss: 0.9611 - val_accuracy: 0.5392\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9753 - accuracy: 0.5294 - val_loss: 0.9606 - val_accuracy: 0.5409\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9752 - accuracy: 0.5285 - val_loss: 0.9603 - val_accuracy: 0.5414\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9613 - val_accuracy: 0.5374\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9614 - val_accuracy: 0.5365\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9753 - accuracy: 0.5296 - val_loss: 0.9608 - val_accuracy: 0.5387\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9751 - accuracy: 0.5296 - val_loss: 0.9603 - val_accuracy: 0.5401\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9608 - val_accuracy: 0.5365\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9753 - accuracy: 0.5296 - val_loss: 0.9608 - val_accuracy: 0.5401\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9751 - accuracy: 0.5289 - val_loss: 0.9599 - val_accuracy: 0.5405\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9751 - accuracy: 0.5282 - val_loss: 0.9632 - val_accuracy: 0.5383\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9754 - accuracy: 0.5292 - val_loss: 0.9607 - val_accuracy: 0.5396\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9751 - accuracy: 0.5296 - val_loss: 0.9601 - val_accuracy: 0.5392\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9607 - val_accuracy: 0.5392\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9753 - accuracy: 0.5289 - val_loss: 0.9602 - val_accuracy: 0.5414\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9752 - accuracy: 0.5307 - val_loss: 0.9626 - val_accuracy: 0.5365\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9751 - accuracy: 0.5298 - val_loss: 0.9607 - val_accuracy: 0.5365\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9751 - accuracy: 0.5291 - val_loss: 0.9607 - val_accuracy: 0.5365\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9751 - accuracy: 0.5307 - val_loss: 0.9624 - val_accuracy: 0.5374\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9753 - accuracy: 0.5296 - val_loss: 0.9601 - val_accuracy: 0.5414\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9751 - accuracy: 0.5290 - val_loss: 0.9606 - val_accuracy: 0.5387\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9603 - val_accuracy: 0.5387\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9752 - accuracy: 0.5294 - val_loss: 0.9604 - val_accuracy: 0.5387\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9751 - accuracy: 0.5299 - val_loss: 0.9607 - val_accuracy: 0.5396\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9752 - accuracy: 0.5293 - val_loss: 0.9627 - val_accuracy: 0.5370\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9751 - accuracy: 0.5305 - val_loss: 0.9623 - val_accuracy: 0.5365\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9752 - accuracy: 0.5300 - val_loss: 0.9627 - val_accuracy: 0.5365\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9749 - accuracy: 0.5304 - val_loss: 0.9608 - val_accuracy: 0.5392\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9751 - accuracy: 0.5290 - val_loss: 0.9618 - val_accuracy: 0.5387\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9606 - val_accuracy: 0.5387\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9609 - val_accuracy: 0.5370\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9752 - accuracy: 0.5300 - val_loss: 0.9608 - val_accuracy: 0.5387\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9752 - accuracy: 0.5302 - val_loss: 0.9600 - val_accuracy: 0.5409\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9749 - accuracy: 0.5292 - val_loss: 0.9610 - val_accuracy: 0.5361\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9749 - accuracy: 0.5294 - val_loss: 0.9604 - val_accuracy: 0.5392\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9752 - accuracy: 0.5306 - val_loss: 0.9604 - val_accuracy: 0.5392\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9605 - val_accuracy: 0.5387\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9749 - accuracy: 0.5296 - val_loss: 0.9613 - val_accuracy: 0.5370\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9750 - accuracy: 0.5299 - val_loss: 0.9611 - val_accuracy: 0.5392\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9609 - val_accuracy: 0.5387\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9603 - val_accuracy: 0.5387\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9750 - accuracy: 0.5304 - val_loss: 0.9609 - val_accuracy: 0.5392\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9750 - accuracy: 0.5291 - val_loss: 0.9616 - val_accuracy: 0.5365\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9752 - accuracy: 0.5285 - val_loss: 0.9603 - val_accuracy: 0.5414\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9752 - accuracy: 0.5287 - val_loss: 0.9600 - val_accuracy: 0.5414\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9750 - accuracy: 0.5291 - val_loss: 0.9629 - val_accuracy: 0.5374\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9624 - val_accuracy: 0.5374\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9753 - accuracy: 0.5287 - val_loss: 0.9605 - val_accuracy: 0.5392\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9751 - accuracy: 0.5297 - val_loss: 0.9624 - val_accuracy: 0.5387\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9750 - accuracy: 0.5284 - val_loss: 0.9610 - val_accuracy: 0.5387\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9751 - accuracy: 0.5306 - val_loss: 0.9612 - val_accuracy: 0.5396\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9605 - val_accuracy: 0.5387\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9600 - val_accuracy: 0.5392\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9752 - accuracy: 0.5298 - val_loss: 0.9608 - val_accuracy: 0.5374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9752 - accuracy: 0.5294 - val_loss: 0.9615 - val_accuracy: 0.5361\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5304 - val_loss: 0.9615 - val_accuracy: 0.5370\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9752 - accuracy: 0.5300 - val_loss: 0.9612 - val_accuracy: 0.5392\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9749 - accuracy: 0.5298 - val_loss: 0.9652 - val_accuracy: 0.5387\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9751 - accuracy: 0.5289 - val_loss: 0.9607 - val_accuracy: 0.5387\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9751 - accuracy: 0.5303 - val_loss: 0.9604 - val_accuracy: 0.5414\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9752 - accuracy: 0.5291 - val_loss: 0.9606 - val_accuracy: 0.5392\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9751 - accuracy: 0.5297 - val_loss: 0.9621 - val_accuracy: 0.5387\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9753 - accuracy: 0.5293 - val_loss: 0.9619 - val_accuracy: 0.5356\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9751 - accuracy: 0.5302 - val_loss: 0.9607 - val_accuracy: 0.5387\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9752 - accuracy: 0.5298 - val_loss: 0.9613 - val_accuracy: 0.5361\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9752 - accuracy: 0.5290 - val_loss: 0.9607 - val_accuracy: 0.5387\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9750 - accuracy: 0.5294 - val_loss: 0.9600 - val_accuracy: 0.5409\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9750 - accuracy: 0.5288 - val_loss: 0.9611 - val_accuracy: 0.5387\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9750 - accuracy: 0.5288 - val_loss: 0.9610 - val_accuracy: 0.5392\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 343us/step - loss: 0.9745 - accuracy: 0.5300\n",
      "Accuracy : 0.530025064945221\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9610 - accuracy: 0.5392\n",
      "Accuracy : 0.5391766428947449\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 647us/step - loss: 1.0714 - accuracy: 0.4253 - val_loss: 1.0382 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 1.0305 - accuracy: 0.4675 - val_loss: 1.0063 - val_accuracy: 0.5325\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 1.0067 - accuracy: 0.5227 - val_loss: 0.9778 - val_accuracy: 0.5489\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9919 - accuracy: 0.5295 - val_loss: 0.9637 - val_accuracy: 0.5440\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9875 - accuracy: 0.5285 - val_loss: 0.9582 - val_accuracy: 0.5454\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9852 - accuracy: 0.5287 - val_loss: 0.9545 - val_accuracy: 0.5454\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9837 - accuracy: 0.5295 - val_loss: 0.9518 - val_accuracy: 0.5449\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9829 - accuracy: 0.5290 - val_loss: 0.9499 - val_accuracy: 0.5471\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9822 - accuracy: 0.5302 - val_loss: 0.9482 - val_accuracy: 0.5471\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9817 - accuracy: 0.5291 - val_loss: 0.9462 - val_accuracy: 0.5516\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9813 - accuracy: 0.5291 - val_loss: 0.9458 - val_accuracy: 0.5440\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9809 - accuracy: 0.5295 - val_loss: 0.9450 - val_accuracy: 0.5440\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9807 - accuracy: 0.5288 - val_loss: 0.9445 - val_accuracy: 0.5458\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9805 - accuracy: 0.5294 - val_loss: 0.9430 - val_accuracy: 0.5489\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9803 - accuracy: 0.5302 - val_loss: 0.9433 - val_accuracy: 0.5467\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9800 - accuracy: 0.5288 - val_loss: 0.9422 - val_accuracy: 0.5498\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9799 - accuracy: 0.5281 - val_loss: 0.9416 - val_accuracy: 0.5458\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9797 - accuracy: 0.5289 - val_loss: 0.9414 - val_accuracy: 0.5502\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9796 - accuracy: 0.5298 - val_loss: 0.9419 - val_accuracy: 0.5458\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9794 - accuracy: 0.5294 - val_loss: 0.9408 - val_accuracy: 0.5467\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9795 - accuracy: 0.5288 - val_loss: 0.9413 - val_accuracy: 0.5440\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9794 - accuracy: 0.5291 - val_loss: 0.9406 - val_accuracy: 0.5516\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9793 - accuracy: 0.5290 - val_loss: 0.9411 - val_accuracy: 0.5458\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9400 - val_accuracy: 0.5511\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9791 - accuracy: 0.5283 - val_loss: 0.9401 - val_accuracy: 0.5525\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9790 - accuracy: 0.5288 - val_loss: 0.9398 - val_accuracy: 0.5485\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9789 - accuracy: 0.5299 - val_loss: 0.9399 - val_accuracy: 0.5511\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9789 - accuracy: 0.5292 - val_loss: 0.9397 - val_accuracy: 0.5489\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9789 - accuracy: 0.5285 - val_loss: 0.9391 - val_accuracy: 0.5471\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9788 - accuracy: 0.5280 - val_loss: 0.9394 - val_accuracy: 0.5502\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9789 - accuracy: 0.5289 - val_loss: 0.9391 - val_accuracy: 0.5463\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9787 - accuracy: 0.5275 - val_loss: 0.9394 - val_accuracy: 0.5489\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9788 - accuracy: 0.5292 - val_loss: 0.9385 - val_accuracy: 0.5485\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9788 - accuracy: 0.5284 - val_loss: 0.9384 - val_accuracy: 0.5480\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9786 - accuracy: 0.5277 - val_loss: 0.9390 - val_accuracy: 0.5485\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9787 - accuracy: 0.5286 - val_loss: 0.9383 - val_accuracy: 0.5463\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9787 - accuracy: 0.5292 - val_loss: 0.9390 - val_accuracy: 0.5489\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9786 - accuracy: 0.5288 - val_loss: 0.9385 - val_accuracy: 0.5489\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9787 - accuracy: 0.5289 - val_loss: 0.9380 - val_accuracy: 0.5485\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 496us/step - loss: 0.9786 - accuracy: 0.5280 - val_loss: 0.9388 - val_accuracy: 0.5516\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9786 - accuracy: 0.5286 - val_loss: 0.9393 - val_accuracy: 0.5467\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9787 - accuracy: 0.5292 - val_loss: 0.9386 - val_accuracy: 0.5454\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9785 - accuracy: 0.5283 - val_loss: 0.9397 - val_accuracy: 0.5458\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9784 - accuracy: 0.5296 - val_loss: 0.9385 - val_accuracy: 0.5485\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9783 - accuracy: 0.5279 - val_loss: 0.9380 - val_accuracy: 0.5454\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9782 - accuracy: 0.5296 - val_loss: 0.9395 - val_accuracy: 0.5449\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9786 - accuracy: 0.5297 - val_loss: 0.9381 - val_accuracy: 0.5485\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9781 - accuracy: 0.5275 - val_loss: 0.9393 - val_accuracy: 0.5538\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9784 - accuracy: 0.5285 - val_loss: 0.9395 - val_accuracy: 0.5458\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9782 - accuracy: 0.5282 - val_loss: 0.9399 - val_accuracy: 0.5449\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9783 - accuracy: 0.5292 - val_loss: 0.9392 - val_accuracy: 0.5494\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9784 - accuracy: 0.5283 - val_loss: 0.9387 - val_accuracy: 0.5520\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9782 - accuracy: 0.5276 - val_loss: 0.9393 - val_accuracy: 0.5485\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9782 - accuracy: 0.5300 - val_loss: 0.9385 - val_accuracy: 0.5489\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9786 - accuracy: 0.5288 - val_loss: 0.9383 - val_accuracy: 0.5476\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9783 - accuracy: 0.5272 - val_loss: 0.9382 - val_accuracy: 0.5494\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9782 - accuracy: 0.5287 - val_loss: 0.9388 - val_accuracy: 0.5511\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9781 - accuracy: 0.5276 - val_loss: 0.9389 - val_accuracy: 0.5542\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9782 - accuracy: 0.5291 - val_loss: 0.9386 - val_accuracy: 0.5529\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9782 - accuracy: 0.5291 - val_loss: 0.9381 - val_accuracy: 0.5440\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9779 - accuracy: 0.5290 - val_loss: 0.9383 - val_accuracy: 0.5454\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9782 - accuracy: 0.5290 - val_loss: 0.9377 - val_accuracy: 0.5432\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 512us/step - loss: 0.9780 - accuracy: 0.5292 - val_loss: 0.9376 - val_accuracy: 0.5480\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9781 - accuracy: 0.5288 - val_loss: 0.9387 - val_accuracy: 0.5516\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9779 - accuracy: 0.5297 - val_loss: 0.9398 - val_accuracy: 0.5458\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9781 - accuracy: 0.5292 - val_loss: 0.9396 - val_accuracy: 0.5463\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9780 - accuracy: 0.5288 - val_loss: 0.9381 - val_accuracy: 0.5489\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9781 - accuracy: 0.5295 - val_loss: 0.9392 - val_accuracy: 0.5533\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9781 - accuracy: 0.5286 - val_loss: 0.9381 - val_accuracy: 0.5494\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9779 - accuracy: 0.5288 - val_loss: 0.9377 - val_accuracy: 0.5467\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9780 - accuracy: 0.5289 - val_loss: 0.9389 - val_accuracy: 0.5516\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9781 - accuracy: 0.5288 - val_loss: 0.9378 - val_accuracy: 0.5516\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9779 - accuracy: 0.5287 - val_loss: 0.9376 - val_accuracy: 0.5445\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9781 - accuracy: 0.5273 - val_loss: 0.9391 - val_accuracy: 0.5533\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9780 - accuracy: 0.5301 - val_loss: 0.9383 - val_accuracy: 0.5449\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9781 - accuracy: 0.5285 - val_loss: 0.9377 - val_accuracy: 0.5498\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9778 - accuracy: 0.5297 - val_loss: 0.9382 - val_accuracy: 0.5502\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9778 - accuracy: 0.5286 - val_loss: 0.9393 - val_accuracy: 0.5454\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9779 - accuracy: 0.5281 - val_loss: 0.9392 - val_accuracy: 0.5454\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 514us/step - loss: 0.9780 - accuracy: 0.5291 - val_loss: 0.9379 - val_accuracy: 0.5494\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9780 - accuracy: 0.5280 - val_loss: 0.9381 - val_accuracy: 0.5471\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9777 - accuracy: 0.5288 - val_loss: 0.9385 - val_accuracy: 0.5432\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9778 - accuracy: 0.5285 - val_loss: 0.9395 - val_accuracy: 0.5463\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9780 - accuracy: 0.5295 - val_loss: 0.9386 - val_accuracy: 0.5502\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9780 - accuracy: 0.5282 - val_loss: 0.9387 - val_accuracy: 0.5494\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9780 - accuracy: 0.5297 - val_loss: 0.9382 - val_accuracy: 0.5454\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9776 - accuracy: 0.5285 - val_loss: 0.9391 - val_accuracy: 0.5520\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9778 - accuracy: 0.5288 - val_loss: 0.9389 - val_accuracy: 0.5458\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9777 - accuracy: 0.5282 - val_loss: 0.9416 - val_accuracy: 0.5423\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9778 - accuracy: 0.5291 - val_loss: 0.9390 - val_accuracy: 0.5480\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9778 - accuracy: 0.5299 - val_loss: 0.9401 - val_accuracy: 0.5458\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9778 - accuracy: 0.5293 - val_loss: 0.9383 - val_accuracy: 0.5516\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9779 - accuracy: 0.5289 - val_loss: 0.9387 - val_accuracy: 0.5525\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9775 - accuracy: 0.5288 - val_loss: 0.9399 - val_accuracy: 0.5463\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9778 - accuracy: 0.5292 - val_loss: 0.9395 - val_accuracy: 0.5449\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 496us/step - loss: 0.9778 - accuracy: 0.5286 - val_loss: 0.9391 - val_accuracy: 0.5529\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9776 - accuracy: 0.5293 - val_loss: 0.9375 - val_accuracy: 0.5525\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9778 - accuracy: 0.5289 - val_loss: 0.9391 - val_accuracy: 0.5525\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9779 - accuracy: 0.5283 - val_loss: 0.9390 - val_accuracy: 0.5494\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9776 - accuracy: 0.5294 - val_loss: 0.9377 - val_accuracy: 0.5507\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9777 - accuracy: 0.5289 - val_loss: 0.9393 - val_accuracy: 0.5511\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9775 - accuracy: 0.5295 - val_loss: 0.9398 - val_accuracy: 0.5458\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9776 - accuracy: 0.5283 - val_loss: 0.9380 - val_accuracy: 0.5480\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9778 - accuracy: 0.5292 - val_loss: 0.9409 - val_accuracy: 0.5445\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9777 - accuracy: 0.5289 - val_loss: 0.9383 - val_accuracy: 0.5511\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9778 - accuracy: 0.5292 - val_loss: 0.9389 - val_accuracy: 0.5494\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9775 - accuracy: 0.5306 - val_loss: 0.9391 - val_accuracy: 0.5427\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9778 - accuracy: 0.5283 - val_loss: 0.9384 - val_accuracy: 0.5436\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9776 - accuracy: 0.5303 - val_loss: 0.9417 - val_accuracy: 0.5463\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 516us/step - loss: 0.9777 - accuracy: 0.5293 - val_loss: 0.9378 - val_accuracy: 0.5511\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 530us/step - loss: 0.9778 - accuracy: 0.5288 - val_loss: 0.9405 - val_accuracy: 0.5449\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9778 - accuracy: 0.5296 - val_loss: 0.9393 - val_accuracy: 0.5525\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 515us/step - loss: 0.9777 - accuracy: 0.5282 - val_loss: 0.9385 - val_accuracy: 0.5494\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9778 - accuracy: 0.5287 - val_loss: 0.9382 - val_accuracy: 0.5498\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9776 - accuracy: 0.5294 - val_loss: 0.9419 - val_accuracy: 0.5463\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9778 - accuracy: 0.5288 - val_loss: 0.9381 - val_accuracy: 0.5489\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9776 - accuracy: 0.5287 - val_loss: 0.9388 - val_accuracy: 0.5494\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9775 - accuracy: 0.5286 - val_loss: 0.9393 - val_accuracy: 0.5454\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9778 - accuracy: 0.5285 - val_loss: 0.9395 - val_accuracy: 0.5529\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 467us/step - loss: 0.9778 - accuracy: 0.5287 - val_loss: 0.9392 - val_accuracy: 0.5529\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9775 - accuracy: 0.5284 - val_loss: 0.9383 - val_accuracy: 0.5511\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9777 - accuracy: 0.5293 - val_loss: 0.9405 - val_accuracy: 0.5463\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9774 - accuracy: 0.5289 - val_loss: 0.9377 - val_accuracy: 0.5489\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9775 - accuracy: 0.5294 - val_loss: 0.9406 - val_accuracy: 0.5480\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9776 - accuracy: 0.5288 - val_loss: 0.9385 - val_accuracy: 0.5529\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9775 - accuracy: 0.5284 - val_loss: 0.9402 - val_accuracy: 0.5463\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9776 - accuracy: 0.5283 - val_loss: 0.9390 - val_accuracy: 0.5511\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 510us/step - loss: 0.9776 - accuracy: 0.5283 - val_loss: 0.9385 - val_accuracy: 0.5529\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9776 - accuracy: 0.5292 - val_loss: 0.9393 - val_accuracy: 0.5454\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9775 - accuracy: 0.5286 - val_loss: 0.9398 - val_accuracy: 0.5445\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9777 - accuracy: 0.5297 - val_loss: 0.9386 - val_accuracy: 0.5511\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9395 - val_accuracy: 0.5476\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 469us/step - loss: 0.9776 - accuracy: 0.5285 - val_loss: 0.9397 - val_accuracy: 0.5463\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9775 - accuracy: 0.5299 - val_loss: 0.9402 - val_accuracy: 0.5525\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9776 - accuracy: 0.5297 - val_loss: 0.9384 - val_accuracy: 0.5432\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 508us/step - loss: 0.9776 - accuracy: 0.5287 - val_loss: 0.9401 - val_accuracy: 0.5511\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9775 - accuracy: 0.5286 - val_loss: 0.9397 - val_accuracy: 0.5525\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9777 - accuracy: 0.5293 - val_loss: 0.9384 - val_accuracy: 0.5511\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9777 - accuracy: 0.5283 - val_loss: 0.9392 - val_accuracy: 0.5458\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 0.9381 - val_accuracy: 0.5494\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9776 - accuracy: 0.5290 - val_loss: 0.9407 - val_accuracy: 0.5458\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9775 - accuracy: 0.5286 - val_loss: 0.9401 - val_accuracy: 0.5449\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9775 - accuracy: 0.5300 - val_loss: 0.9389 - val_accuracy: 0.5511\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9776 - accuracy: 0.5295 - val_loss: 0.9401 - val_accuracy: 0.5525\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9777 - accuracy: 0.5290 - val_loss: 0.9388 - val_accuracy: 0.5525\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9775 - accuracy: 0.5294 - val_loss: 0.9384 - val_accuracy: 0.5489\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9775 - accuracy: 0.5290 - val_loss: 0.9425 - val_accuracy: 0.5440\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 0.9400 - val_accuracy: 0.5463\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9775 - accuracy: 0.5282 - val_loss: 0.9395 - val_accuracy: 0.5449\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9777 - accuracy: 0.5285 - val_loss: 0.9384 - val_accuracy: 0.5489\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9772 - accuracy: 0.5285 - val_loss: 0.9415 - val_accuracy: 0.5463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 464us/step - loss: 0.9775 - accuracy: 0.5291 - val_loss: 0.9390 - val_accuracy: 0.5525\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9773 - accuracy: 0.5288 - val_loss: 0.9388 - val_accuracy: 0.5529\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9774 - accuracy: 0.5290 - val_loss: 0.9399 - val_accuracy: 0.5516\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9774 - accuracy: 0.5290 - val_loss: 0.9397 - val_accuracy: 0.5458\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9774 - accuracy: 0.5291 - val_loss: 0.9383 - val_accuracy: 0.5507\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9774 - accuracy: 0.5295 - val_loss: 0.9404 - val_accuracy: 0.5463\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9774 - accuracy: 0.5285 - val_loss: 0.9413 - val_accuracy: 0.5436\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9776 - accuracy: 0.5294 - val_loss: 0.9396 - val_accuracy: 0.5454\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 468us/step - loss: 0.9775 - accuracy: 0.5298 - val_loss: 0.9405 - val_accuracy: 0.5529\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9775 - accuracy: 0.5290 - val_loss: 0.9387 - val_accuracy: 0.5516\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 466us/step - loss: 0.9776 - accuracy: 0.5292 - val_loss: 0.9397 - val_accuracy: 0.5516\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 470us/step - loss: 0.9775 - accuracy: 0.5288 - val_loss: 0.9386 - val_accuracy: 0.5529\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9775 - accuracy: 0.5279 - val_loss: 0.9381 - val_accuracy: 0.5494\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9773 - accuracy: 0.5286 - val_loss: 0.9400 - val_accuracy: 0.5449\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9776 - accuracy: 0.5293 - val_loss: 0.9382 - val_accuracy: 0.5458\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9775 - accuracy: 0.5281 - val_loss: 0.9429 - val_accuracy: 0.5445\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9775 - accuracy: 0.5279 - val_loss: 0.9396 - val_accuracy: 0.5449\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9773 - accuracy: 0.5290 - val_loss: 0.9393 - val_accuracy: 0.5436\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9775 - accuracy: 0.5291 - val_loss: 0.9386 - val_accuracy: 0.5485\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 485us/step - loss: 0.9775 - accuracy: 0.5286 - val_loss: 0.9384 - val_accuracy: 0.5480\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 465us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9414 - val_accuracy: 0.5440\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9394 - val_accuracy: 0.5529\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9775 - accuracy: 0.5294 - val_loss: 0.9400 - val_accuracy: 0.5520\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9774 - accuracy: 0.5282 - val_loss: 0.9398 - val_accuracy: 0.5463\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9776 - accuracy: 0.5294 - val_loss: 0.9401 - val_accuracy: 0.5511\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9774 - accuracy: 0.5283 - val_loss: 0.9391 - val_accuracy: 0.5511\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9774 - accuracy: 0.5287 - val_loss: 0.9395 - val_accuracy: 0.5471\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9774 - accuracy: 0.5291 - val_loss: 0.9392 - val_accuracy: 0.5449\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9773 - accuracy: 0.5290 - val_loss: 0.9405 - val_accuracy: 0.5480\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9776 - accuracy: 0.5286 - val_loss: 0.9393 - val_accuracy: 0.5525\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9774 - accuracy: 0.5296 - val_loss: 0.9423 - val_accuracy: 0.5405\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9774 - accuracy: 0.5288 - val_loss: 0.9389 - val_accuracy: 0.5432\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9776 - accuracy: 0.5292 - val_loss: 0.9395 - val_accuracy: 0.5511\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9775 - accuracy: 0.5296 - val_loss: 0.9399 - val_accuracy: 0.5525\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 468us/step - loss: 0.9775 - accuracy: 0.5292 - val_loss: 0.9414 - val_accuracy: 0.5454\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9775 - accuracy: 0.5285 - val_loss: 0.9396 - val_accuracy: 0.5525\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 465us/step - loss: 0.9775 - accuracy: 0.5275 - val_loss: 0.9442 - val_accuracy: 0.5458\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9774 - accuracy: 0.5298 - val_loss: 0.9392 - val_accuracy: 0.5525\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9776 - accuracy: 0.5284 - val_loss: 0.9395 - val_accuracy: 0.5502\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9775 - accuracy: 0.5290 - val_loss: 0.9388 - val_accuracy: 0.5529\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9773 - accuracy: 0.5285 - val_loss: 0.9385 - val_accuracy: 0.5445\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9775 - accuracy: 0.5296 - val_loss: 0.9402 - val_accuracy: 0.5463\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9773 - accuracy: 0.5297 - val_loss: 0.9403 - val_accuracy: 0.5480\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9775 - accuracy: 0.5289 - val_loss: 0.9393 - val_accuracy: 0.5533\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 466us/step - loss: 0.9774 - accuracy: 0.5297 - val_loss: 0.9395 - val_accuracy: 0.5511\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9433 - val_accuracy: 0.5414\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9775 - accuracy: 0.5284 - val_loss: 0.9402 - val_accuracy: 0.5476\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9772 - accuracy: 0.5294 - val_loss: 0.9390 - val_accuracy: 0.5480\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9775 - accuracy: 0.5284 - val_loss: 0.9402 - val_accuracy: 0.5525\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 339us/step - loss: 0.9771 - accuracy: 0.5281\n",
      "Accuracy : 0.5280578136444092\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9402 - accuracy: 0.5525\n",
      "Accuracy : 0.5524568557739258\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 654us/step - loss: 1.0447 - accuracy: 0.4591 - val_loss: 1.0261 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 1.0125 - accuracy: 0.4869 - val_loss: 1.0025 - val_accuracy: 0.5197\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9971 - accuracy: 0.5307 - val_loss: 0.9921 - val_accuracy: 0.5294\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9909 - accuracy: 0.5295 - val_loss: 0.9893 - val_accuracy: 0.5286\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9875 - accuracy: 0.5286 - val_loss: 0.9848 - val_accuracy: 0.5259\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 502us/step - loss: 0.9845 - accuracy: 0.5304 - val_loss: 0.9823 - val_accuracy: 0.5263\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9824 - accuracy: 0.5306 - val_loss: 0.9796 - val_accuracy: 0.5272\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9805 - accuracy: 0.5314 - val_loss: 0.9780 - val_accuracy: 0.5277\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9791 - accuracy: 0.5308 - val_loss: 0.9767 - val_accuracy: 0.5272\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9780 - accuracy: 0.5311 - val_loss: 0.9785 - val_accuracy: 0.5246\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9772 - accuracy: 0.5315 - val_loss: 0.9755 - val_accuracy: 0.5286\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9765 - accuracy: 0.5316 - val_loss: 0.9757 - val_accuracy: 0.5299\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9760 - accuracy: 0.5312 - val_loss: 0.9749 - val_accuracy: 0.5272\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9757 - accuracy: 0.5314 - val_loss: 0.9756 - val_accuracy: 0.5290\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9754 - accuracy: 0.5318 - val_loss: 0.9752 - val_accuracy: 0.5277\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 465us/step - loss: 0.9751 - accuracy: 0.5318 - val_loss: 0.9748 - val_accuracy: 0.5299\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9751 - accuracy: 0.5318 - val_loss: 0.9756 - val_accuracy: 0.5281\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9750 - accuracy: 0.5319 - val_loss: 0.9752 - val_accuracy: 0.5277\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 468us/step - loss: 0.9747 - accuracy: 0.5322 - val_loss: 0.9741 - val_accuracy: 0.5281\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9747 - accuracy: 0.5306 - val_loss: 0.9737 - val_accuracy: 0.5290\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9744 - accuracy: 0.5315 - val_loss: 0.9760 - val_accuracy: 0.5290\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9746 - accuracy: 0.5310 - val_loss: 0.9734 - val_accuracy: 0.5272\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9747 - accuracy: 0.5310 - val_loss: 0.9738 - val_accuracy: 0.5290\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9746 - accuracy: 0.5303 - val_loss: 0.9745 - val_accuracy: 0.5299\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9744 - accuracy: 0.5321 - val_loss: 0.9737 - val_accuracy: 0.5290\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9746 - accuracy: 0.5316 - val_loss: 0.9741 - val_accuracy: 0.5286\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 0.9740 - val_accuracy: 0.5281\n",
      "Epoch 28/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9744 - accuracy: 0.5315 - val_loss: 0.9734 - val_accuracy: 0.5290\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9745 - accuracy: 0.5312 - val_loss: 0.9731 - val_accuracy: 0.5290\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9744 - accuracy: 0.5304 - val_loss: 0.9739 - val_accuracy: 0.5290\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9744 - accuracy: 0.5311 - val_loss: 0.9737 - val_accuracy: 0.5272\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9742 - accuracy: 0.5319 - val_loss: 0.9735 - val_accuracy: 0.5290\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9743 - accuracy: 0.5311 - val_loss: 0.9740 - val_accuracy: 0.5286\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9743 - accuracy: 0.5324 - val_loss: 0.9739 - val_accuracy: 0.5286\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 466us/step - loss: 0.9744 - accuracy: 0.5317 - val_loss: 0.9743 - val_accuracy: 0.5281\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9743 - accuracy: 0.5321 - val_loss: 0.9731 - val_accuracy: 0.5290\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 513us/step - loss: 0.9742 - accuracy: 0.5313 - val_loss: 0.9737 - val_accuracy: 0.5286\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9741 - accuracy: 0.5313 - val_loss: 0.9736 - val_accuracy: 0.5281\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9740 - accuracy: 0.5322 - val_loss: 0.9739 - val_accuracy: 0.5272\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9741 - accuracy: 0.5320 - val_loss: 0.9733 - val_accuracy: 0.5281\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9742 - accuracy: 0.5314 - val_loss: 0.9749 - val_accuracy: 0.5272\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9741 - accuracy: 0.5316 - val_loss: 0.9730 - val_accuracy: 0.5272\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9741 - accuracy: 0.5311 - val_loss: 0.9732 - val_accuracy: 0.5272\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 465us/step - loss: 0.9741 - accuracy: 0.5316 - val_loss: 0.9728 - val_accuracy: 0.5290\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9741 - accuracy: 0.5315 - val_loss: 0.9736 - val_accuracy: 0.5277\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9741 - accuracy: 0.5313 - val_loss: 0.9728 - val_accuracy: 0.5272\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 0.9729 - val_accuracy: 0.5281\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 0.9741 - val_accuracy: 0.5281\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9741 - accuracy: 0.5317 - val_loss: 0.9733 - val_accuracy: 0.5272\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9740 - accuracy: 0.5315 - val_loss: 0.9746 - val_accuracy: 0.5281\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 481us/step - loss: 0.9742 - accuracy: 0.5309 - val_loss: 0.9733 - val_accuracy: 0.5272\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9741 - accuracy: 0.5309 - val_loss: 0.9728 - val_accuracy: 0.5290\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9739 - accuracy: 0.5303 - val_loss: 0.9729 - val_accuracy: 0.5286\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9739 - accuracy: 0.5310 - val_loss: 0.9729 - val_accuracy: 0.5272\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9740 - accuracy: 0.5315 - val_loss: 0.9729 - val_accuracy: 0.5294\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9740 - accuracy: 0.5304 - val_loss: 0.9744 - val_accuracy: 0.5294\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9739 - accuracy: 0.5306 - val_loss: 0.9743 - val_accuracy: 0.5286\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 465us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9739 - val_accuracy: 0.5272\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9739 - accuracy: 0.5315 - val_loss: 0.9738 - val_accuracy: 0.5281\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9739 - accuracy: 0.5313 - val_loss: 0.9744 - val_accuracy: 0.5281\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9738 - accuracy: 0.5313 - val_loss: 0.9735 - val_accuracy: 0.5272\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 478us/step - loss: 0.9739 - accuracy: 0.5307 - val_loss: 0.9733 - val_accuracy: 0.5272\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9739 - accuracy: 0.5322 - val_loss: 0.9735 - val_accuracy: 0.5272\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9739 - accuracy: 0.5326 - val_loss: 0.9732 - val_accuracy: 0.5272\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9739 - accuracy: 0.5315 - val_loss: 0.9740 - val_accuracy: 0.5290\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9739 - accuracy: 0.5315 - val_loss: 0.9733 - val_accuracy: 0.5286\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 469us/step - loss: 0.9735 - accuracy: 0.5326 - val_loss: 0.9728 - val_accuracy: 0.5286\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9738 - accuracy: 0.5318 - val_loss: 0.9734 - val_accuracy: 0.5286\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 468us/step - loss: 0.9738 - accuracy: 0.5322 - val_loss: 0.9743 - val_accuracy: 0.5294\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9738 - accuracy: 0.5318 - val_loss: 0.9738 - val_accuracy: 0.5286\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9746 - val_accuracy: 0.5281\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9737 - accuracy: 0.5305 - val_loss: 0.9746 - val_accuracy: 0.5290\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 0.9728 - val_accuracy: 0.5294\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 466us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9727 - val_accuracy: 0.5259\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9741 - accuracy: 0.5309 - val_loss: 0.9730 - val_accuracy: 0.5272\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 0.9736 - val_accuracy: 0.5286\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 0.9731 - val_accuracy: 0.5277\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9732 - val_accuracy: 0.5272\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9737 - accuracy: 0.5319 - val_loss: 0.9738 - val_accuracy: 0.5281\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9737 - accuracy: 0.5317 - val_loss: 0.9730 - val_accuracy: 0.5281\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9737 - accuracy: 0.5318 - val_loss: 0.9726 - val_accuracy: 0.5294\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 0.9733 - val_accuracy: 0.5272\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9737 - accuracy: 0.5316 - val_loss: 0.9745 - val_accuracy: 0.5290\n",
      "Epoch 84/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9738 - accuracy: 0.5315 - val_loss: 0.9730 - val_accuracy: 0.5281\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9738 - accuracy: 0.5320 - val_loss: 0.9727 - val_accuracy: 0.5281\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9739 - accuracy: 0.5313 - val_loss: 0.9731 - val_accuracy: 0.5290\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9738 - accuracy: 0.5322 - val_loss: 0.9739 - val_accuracy: 0.5272\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9739 - accuracy: 0.5312 - val_loss: 0.9727 - val_accuracy: 0.5281\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 468us/step - loss: 0.9737 - accuracy: 0.5309 - val_loss: 0.9726 - val_accuracy: 0.5272\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5313 - val_loss: 0.9724 - val_accuracy: 0.5290\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9735 - val_accuracy: 0.5286\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 0.9729 - val_accuracy: 0.5294\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9737 - accuracy: 0.5314 - val_loss: 0.9725 - val_accuracy: 0.5294\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9737 - accuracy: 0.5305 - val_loss: 0.9733 - val_accuracy: 0.5286\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9732 - val_accuracy: 0.5281\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9735 - accuracy: 0.5308 - val_loss: 0.9744 - val_accuracy: 0.5294\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9738 - accuracy: 0.5307 - val_loss: 0.9731 - val_accuracy: 0.5272\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 469us/step - loss: 0.9736 - accuracy: 0.5319 - val_loss: 0.9756 - val_accuracy: 0.5272\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 0.9728 - val_accuracy: 0.5277\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9737 - accuracy: 0.5323 - val_loss: 0.9739 - val_accuracy: 0.5290\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5320 - val_loss: 0.9728 - val_accuracy: 0.5263\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 0.9732 - val_accuracy: 0.5272\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9737 - accuracy: 0.5316 - val_loss: 0.9735 - val_accuracy: 0.5281\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9738 - accuracy: 0.5307 - val_loss: 0.9729 - val_accuracy: 0.5286\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9744 - val_accuracy: 0.5272\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 0.9728 - val_accuracy: 0.5272\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 0.9746 - val_accuracy: 0.5281\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9737 - accuracy: 0.5325 - val_loss: 0.9734 - val_accuracy: 0.5303\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 468us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9727 - val_accuracy: 0.5272\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9734 - val_accuracy: 0.5281\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9731 - val_accuracy: 0.5281\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5319 - val_loss: 0.9732 - val_accuracy: 0.5281\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9733 - accuracy: 0.5319 - val_loss: 0.9737 - val_accuracy: 0.5290\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9737 - accuracy: 0.5309 - val_loss: 0.9732 - val_accuracy: 0.5281\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9735 - accuracy: 0.5320 - val_loss: 0.9742 - val_accuracy: 0.5294\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 467us/step - loss: 0.9737 - accuracy: 0.5311 - val_loss: 0.9729 - val_accuracy: 0.5294\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 540us/step - loss: 0.9737 - accuracy: 0.5311 - val_loss: 0.9732 - val_accuracy: 0.5272\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 497us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 0.9735 - val_accuracy: 0.5290\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9726 - val_accuracy: 0.5272\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 0.9740 - val_accuracy: 0.5281\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9737 - accuracy: 0.5309 - val_loss: 0.9733 - val_accuracy: 0.5290\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9736 - accuracy: 0.5306 - val_loss: 0.9742 - val_accuracy: 0.5290\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9737 - accuracy: 0.5307 - val_loss: 0.9741 - val_accuracy: 0.5290\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9725 - val_accuracy: 0.5294\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9738 - accuracy: 0.5314 - val_loss: 0.9730 - val_accuracy: 0.5290\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9734 - accuracy: 0.5313 - val_loss: 0.9727 - val_accuracy: 0.5281\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9735 - accuracy: 0.5322 - val_loss: 0.9728 - val_accuracy: 0.5281\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9736 - accuracy: 0.5318 - val_loss: 0.9727 - val_accuracy: 0.5272\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 466us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 0.9729 - val_accuracy: 0.5277\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9736 - accuracy: 0.5323 - val_loss: 0.9725 - val_accuracy: 0.5294\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9735 - accuracy: 0.5322 - val_loss: 0.9733 - val_accuracy: 0.5286\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9728 - val_accuracy: 0.5294\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 487us/step - loss: 0.9735 - accuracy: 0.5321 - val_loss: 0.9741 - val_accuracy: 0.5303\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9736 - accuracy: 0.5321 - val_loss: 0.9729 - val_accuracy: 0.5259\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9736 - accuracy: 0.5322 - val_loss: 0.9733 - val_accuracy: 0.5277\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9736 - accuracy: 0.5323 - val_loss: 0.9728 - val_accuracy: 0.5272\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 470us/step - loss: 0.9735 - accuracy: 0.5316 - val_loss: 0.9735 - val_accuracy: 0.5290\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9735 - val_accuracy: 0.5290\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 466us/step - loss: 0.9736 - accuracy: 0.5332 - val_loss: 0.9730 - val_accuracy: 0.5272\n",
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9729 - val_accuracy: 0.5272\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9735 - accuracy: 0.5309 - val_loss: 0.9746 - val_accuracy: 0.5255\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9735 - accuracy: 0.5313 - val_loss: 0.9727 - val_accuracy: 0.5272\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9728 - val_accuracy: 0.5281\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 466us/step - loss: 0.9736 - accuracy: 0.5310 - val_loss: 0.9726 - val_accuracy: 0.5272\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9735 - accuracy: 0.5318 - val_loss: 0.9749 - val_accuracy: 0.5303\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 0.9731 - val_accuracy: 0.5277\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9727 - val_accuracy: 0.5272\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 470us/step - loss: 0.9735 - accuracy: 0.5319 - val_loss: 0.9729 - val_accuracy: 0.5272\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9736 - accuracy: 0.5309 - val_loss: 0.9733 - val_accuracy: 0.5281\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9746 - val_accuracy: 0.5303\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9735 - accuracy: 0.5319 - val_loss: 0.9752 - val_accuracy: 0.5246\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 0.9727 - val_accuracy: 0.5294\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9738 - accuracy: 0.5310 - val_loss: 0.9734 - val_accuracy: 0.5281\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9738 - val_accuracy: 0.5308\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9735 - accuracy: 0.5320 - val_loss: 0.9729 - val_accuracy: 0.5299\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9730 - val_accuracy: 0.5272\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9734 - accuracy: 0.5308 - val_loss: 0.9730 - val_accuracy: 0.5255\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9734 - accuracy: 0.5315 - val_loss: 0.9746 - val_accuracy: 0.5303\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9734 - accuracy: 0.5315 - val_loss: 0.9725 - val_accuracy: 0.5290\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9736 - accuracy: 0.5323 - val_loss: 0.9742 - val_accuracy: 0.5281\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9735 - accuracy: 0.5303 - val_loss: 0.9730 - val_accuracy: 0.5290\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9738 - accuracy: 0.5307 - val_loss: 0.9731 - val_accuracy: 0.5281\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9736 - accuracy: 0.5306 - val_loss: 0.9729 - val_accuracy: 0.5272\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9734 - accuracy: 0.5314 - val_loss: 0.9727 - val_accuracy: 0.5286\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9736 - accuracy: 0.5326 - val_loss: 0.9734 - val_accuracy: 0.5290\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5317 - val_loss: 0.9728 - val_accuracy: 0.5290\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 468us/step - loss: 0.9736 - accuracy: 0.5324 - val_loss: 0.9729 - val_accuracy: 0.5290\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9735 - accuracy: 0.5319 - val_loss: 0.9738 - val_accuracy: 0.5308\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9732 - val_accuracy: 0.5290\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9737 - accuracy: 0.5317 - val_loss: 0.9729 - val_accuracy: 0.5286\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9735 - accuracy: 0.5311 - val_loss: 0.9724 - val_accuracy: 0.5281\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9737 - accuracy: 0.5314 - val_loss: 0.9729 - val_accuracy: 0.5294\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9736 - accuracy: 0.5304 - val_loss: 0.9730 - val_accuracy: 0.5272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9736 - accuracy: 0.5313 - val_loss: 0.9726 - val_accuracy: 0.5290\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9736 - accuracy: 0.5316 - val_loss: 0.9733 - val_accuracy: 0.5272\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9736 - accuracy: 0.5317 - val_loss: 0.9754 - val_accuracy: 0.5294\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9733 - accuracy: 0.5310 - val_loss: 0.9725 - val_accuracy: 0.5259\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 0.9727 - val_accuracy: 0.5290\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9736 - accuracy: 0.5313 - val_loss: 0.9739 - val_accuracy: 0.5277\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9736 - accuracy: 0.5317 - val_loss: 0.9736 - val_accuracy: 0.5290\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9739 - val_accuracy: 0.5308\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9735 - accuracy: 0.5321 - val_loss: 0.9744 - val_accuracy: 0.5303\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9737 - accuracy: 0.5318 - val_loss: 0.9733 - val_accuracy: 0.5272\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9731 - val_accuracy: 0.5277\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 466us/step - loss: 0.9735 - accuracy: 0.5308 - val_loss: 0.9728 - val_accuracy: 0.5272\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9737 - accuracy: 0.5314 - val_loss: 0.9731 - val_accuracy: 0.5272\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9736 - accuracy: 0.5319 - val_loss: 0.9737 - val_accuracy: 0.5290\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9735 - accuracy: 0.5316 - val_loss: 0.9733 - val_accuracy: 0.5308\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9737 - accuracy: 0.5315 - val_loss: 0.9727 - val_accuracy: 0.5272\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9735 - accuracy: 0.5312 - val_loss: 0.9739 - val_accuracy: 0.5290\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9735 - accuracy: 0.5316 - val_loss: 0.9740 - val_accuracy: 0.5281\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9737 - accuracy: 0.5312 - val_loss: 0.9735 - val_accuracy: 0.5281\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9736 - accuracy: 0.5316 - val_loss: 0.9731 - val_accuracy: 0.5272\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9736 - accuracy: 0.5320 - val_loss: 0.9733 - val_accuracy: 0.5277\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9729 - val_accuracy: 0.5281\n",
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 474us/step - loss: 0.9735 - accuracy: 0.5315 - val_loss: 0.9735 - val_accuracy: 0.5272\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9737 - accuracy: 0.5322 - val_loss: 0.9730 - val_accuracy: 0.5272\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9735 - accuracy: 0.5325 - val_loss: 0.9731 - val_accuracy: 0.5294\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9736 - accuracy: 0.5308 - val_loss: 0.9727 - val_accuracy: 0.5272\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9734 - accuracy: 0.5315 - val_loss: 0.9745 - val_accuracy: 0.5290\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 339us/step - loss: 0.9739 - accuracy: 0.5322\n",
      "Accuracy : 0.5321890711784363\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9745 - accuracy: 0.5290\n",
      "Accuracy : 0.528995156288147\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      "636/636 [==============================] - 0s 623us/step - loss: 1.0710 - accuracy: 0.4379 - val_loss: 1.0538 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 1.0410 - accuracy: 0.4657 - val_loss: 1.0143 - val_accuracy: 0.5228\n",
      "Epoch 3/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 1.0019 - accuracy: 0.5263 - val_loss: 0.9809 - val_accuracy: 0.5378\n",
      "Epoch 4/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9878 - accuracy: 0.5303 - val_loss: 0.9724 - val_accuracy: 0.5334\n",
      "Epoch 5/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9847 - accuracy: 0.5301 - val_loss: 0.9685 - val_accuracy: 0.5330\n",
      "Epoch 6/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9829 - accuracy: 0.5300 - val_loss: 0.9660 - val_accuracy: 0.5378\n",
      "Epoch 7/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9818 - accuracy: 0.5289 - val_loss: 0.9652 - val_accuracy: 0.5383\n",
      "Epoch 8/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9808 - accuracy: 0.5306 - val_loss: 0.9619 - val_accuracy: 0.5356\n",
      "Epoch 9/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9800 - accuracy: 0.5295 - val_loss: 0.9602 - val_accuracy: 0.5334\n",
      "Epoch 10/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9797 - accuracy: 0.5296 - val_loss: 0.9593 - val_accuracy: 0.5378\n",
      "Epoch 11/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9789 - accuracy: 0.5302 - val_loss: 0.9583 - val_accuracy: 0.5325\n",
      "Epoch 12/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9786 - accuracy: 0.5302 - val_loss: 0.9573 - val_accuracy: 0.5374\n",
      "Epoch 13/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9784 - accuracy: 0.5312 - val_loss: 0.9571 - val_accuracy: 0.5383\n",
      "Epoch 14/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9782 - accuracy: 0.5327 - val_loss: 0.9560 - val_accuracy: 0.5347\n",
      "Epoch 15/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9778 - accuracy: 0.5301 - val_loss: 0.9556 - val_accuracy: 0.5330\n",
      "Epoch 16/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9781 - accuracy: 0.5314 - val_loss: 0.9559 - val_accuracy: 0.5361\n",
      "Epoch 17/200\n",
      "636/636 [==============================] - 0s 547us/step - loss: 0.9777 - accuracy: 0.5300 - val_loss: 0.9557 - val_accuracy: 0.5374\n",
      "Epoch 18/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9776 - accuracy: 0.5297 - val_loss: 0.9546 - val_accuracy: 0.5370\n",
      "Epoch 19/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9777 - accuracy: 0.5300 - val_loss: 0.9544 - val_accuracy: 0.5370\n",
      "Epoch 20/200\n",
      "636/636 [==============================] - 0s 483us/step - loss: 0.9773 - accuracy: 0.5292 - val_loss: 0.9547 - val_accuracy: 0.5383\n",
      "Epoch 21/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9774 - accuracy: 0.5297 - val_loss: 0.9546 - val_accuracy: 0.5387\n",
      "Epoch 22/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9774 - accuracy: 0.5297 - val_loss: 0.9537 - val_accuracy: 0.5370\n",
      "Epoch 23/200\n",
      "636/636 [==============================] - 0s 486us/step - loss: 0.9774 - accuracy: 0.5294 - val_loss: 0.9533 - val_accuracy: 0.5374\n",
      "Epoch 24/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9773 - accuracy: 0.5295 - val_loss: 0.9534 - val_accuracy: 0.5370\n",
      "Epoch 25/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9773 - accuracy: 0.5303 - val_loss: 0.9533 - val_accuracy: 0.5383\n",
      "Epoch 26/200\n",
      "636/636 [==============================] - 0s 520us/step - loss: 0.9771 - accuracy: 0.5308 - val_loss: 0.9531 - val_accuracy: 0.5370\n",
      "Epoch 27/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9771 - accuracy: 0.5305 - val_loss: 0.9529 - val_accuracy: 0.5370\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 470us/step - loss: 0.9770 - accuracy: 0.5290 - val_loss: 0.9531 - val_accuracy: 0.5374\n",
      "Epoch 29/200\n",
      "636/636 [==============================] - 0s 525us/step - loss: 0.9770 - accuracy: 0.5300 - val_loss: 0.9559 - val_accuracy: 0.5347\n",
      "Epoch 30/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9772 - accuracy: 0.5297 - val_loss: 0.9531 - val_accuracy: 0.5383\n",
      "Epoch 31/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9771 - accuracy: 0.5305 - val_loss: 0.9526 - val_accuracy: 0.5378\n",
      "Epoch 32/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9771 - accuracy: 0.5293 - val_loss: 0.9528 - val_accuracy: 0.5383\n",
      "Epoch 33/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9770 - accuracy: 0.5299 - val_loss: 0.9528 - val_accuracy: 0.5352\n",
      "Epoch 34/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9772 - accuracy: 0.5304 - val_loss: 0.9524 - val_accuracy: 0.5374\n",
      "Epoch 35/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9771 - accuracy: 0.5305 - val_loss: 0.9525 - val_accuracy: 0.5356\n",
      "Epoch 36/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9770 - accuracy: 0.5293 - val_loss: 0.9528 - val_accuracy: 0.5387\n",
      "Epoch 37/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9768 - accuracy: 0.5296 - val_loss: 0.9526 - val_accuracy: 0.5383\n",
      "Epoch 38/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9770 - accuracy: 0.5296 - val_loss: 0.9522 - val_accuracy: 0.5370\n",
      "Epoch 39/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9767 - accuracy: 0.5298 - val_loss: 0.9527 - val_accuracy: 0.5383\n",
      "Epoch 40/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9768 - accuracy: 0.5295 - val_loss: 0.9521 - val_accuracy: 0.5352\n",
      "Epoch 41/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9770 - accuracy: 0.5294 - val_loss: 0.9525 - val_accuracy: 0.5370\n",
      "Epoch 42/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9768 - accuracy: 0.5296 - val_loss: 0.9522 - val_accuracy: 0.5352\n",
      "Epoch 43/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9768 - accuracy: 0.5302 - val_loss: 0.9532 - val_accuracy: 0.5347\n",
      "Epoch 44/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9770 - accuracy: 0.5287 - val_loss: 0.9528 - val_accuracy: 0.5383\n",
      "Epoch 45/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9523 - val_accuracy: 0.5387\n",
      "Epoch 46/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9769 - accuracy: 0.5292 - val_loss: 0.9523 - val_accuracy: 0.5387\n",
      "Epoch 47/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9767 - accuracy: 0.5291 - val_loss: 0.9521 - val_accuracy: 0.5387\n",
      "Epoch 48/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9766 - accuracy: 0.5295 - val_loss: 0.9517 - val_accuracy: 0.5378\n",
      "Epoch 49/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9768 - accuracy: 0.5294 - val_loss: 0.9526 - val_accuracy: 0.5383\n",
      "Epoch 50/200\n",
      "636/636 [==============================] - 0s 467us/step - loss: 0.9767 - accuracy: 0.5317 - val_loss: 0.9520 - val_accuracy: 0.5378\n",
      "Epoch 51/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9767 - accuracy: 0.5305 - val_loss: 0.9520 - val_accuracy: 0.5378\n",
      "Epoch 52/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9766 - accuracy: 0.5304 - val_loss: 0.9522 - val_accuracy: 0.5383\n",
      "Epoch 53/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9766 - accuracy: 0.5307 - val_loss: 0.9526 - val_accuracy: 0.5387\n",
      "Epoch 54/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9767 - accuracy: 0.5294 - val_loss: 0.9521 - val_accuracy: 0.5383\n",
      "Epoch 55/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9767 - accuracy: 0.5298 - val_loss: 0.9516 - val_accuracy: 0.5374\n",
      "Epoch 56/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9767 - accuracy: 0.5307 - val_loss: 0.9520 - val_accuracy: 0.5361\n",
      "Epoch 57/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9768 - accuracy: 0.5302 - val_loss: 0.9527 - val_accuracy: 0.5374\n",
      "Epoch 58/200\n",
      "636/636 [==============================] - 0s 507us/step - loss: 0.9767 - accuracy: 0.5308 - val_loss: 0.9538 - val_accuracy: 0.5343\n",
      "Epoch 59/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9767 - accuracy: 0.5302 - val_loss: 0.9520 - val_accuracy: 0.5383\n",
      "Epoch 60/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9766 - accuracy: 0.5294 - val_loss: 0.9517 - val_accuracy: 0.5383\n",
      "Epoch 61/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9516 - val_accuracy: 0.5352\n",
      "Epoch 62/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9765 - accuracy: 0.5306 - val_loss: 0.9515 - val_accuracy: 0.5374\n",
      "Epoch 63/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9767 - accuracy: 0.5298 - val_loss: 0.9534 - val_accuracy: 0.5347\n",
      "Epoch 64/200\n",
      "636/636 [==============================] - 0s 484us/step - loss: 0.9767 - accuracy: 0.5292 - val_loss: 0.9527 - val_accuracy: 0.5370\n",
      "Epoch 65/200\n",
      "636/636 [==============================] - 0s 495us/step - loss: 0.9766 - accuracy: 0.5299 - val_loss: 0.9521 - val_accuracy: 0.5370\n",
      "Epoch 66/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9764 - accuracy: 0.5312 - val_loss: 0.9514 - val_accuracy: 0.5352\n",
      "Epoch 67/200\n",
      "636/636 [==============================] - 0s 528us/step - loss: 0.9765 - accuracy: 0.5298 - val_loss: 0.9522 - val_accuracy: 0.5374\n",
      "Epoch 68/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9765 - accuracy: 0.5305 - val_loss: 0.9526 - val_accuracy: 0.5356\n",
      "Epoch 69/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9766 - accuracy: 0.5292 - val_loss: 0.9517 - val_accuracy: 0.5378\n",
      "Epoch 70/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9765 - accuracy: 0.5292 - val_loss: 0.9535 - val_accuracy: 0.5347\n",
      "Epoch 71/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9764 - accuracy: 0.5302 - val_loss: 0.9518 - val_accuracy: 0.5325\n",
      "Epoch 72/200\n",
      "636/636 [==============================] - 0s 522us/step - loss: 0.9765 - accuracy: 0.5302 - val_loss: 0.9519 - val_accuracy: 0.5370\n",
      "Epoch 73/200\n",
      "636/636 [==============================] - 0s 482us/step - loss: 0.9764 - accuracy: 0.5306 - val_loss: 0.9526 - val_accuracy: 0.5383\n",
      "Epoch 74/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9766 - accuracy: 0.5297 - val_loss: 0.9515 - val_accuracy: 0.5374\n",
      "Epoch 75/200\n",
      "636/636 [==============================] - 0s 473us/step - loss: 0.9765 - accuracy: 0.5291 - val_loss: 0.9514 - val_accuracy: 0.5356\n",
      "Epoch 76/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9765 - accuracy: 0.5301 - val_loss: 0.9511 - val_accuracy: 0.5378\n",
      "Epoch 77/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9763 - accuracy: 0.5304 - val_loss: 0.9513 - val_accuracy: 0.5378\n",
      "Epoch 78/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9767 - accuracy: 0.5301 - val_loss: 0.9537 - val_accuracy: 0.5361\n",
      "Epoch 79/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9764 - accuracy: 0.5300 - val_loss: 0.9514 - val_accuracy: 0.5334\n",
      "Epoch 80/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9763 - accuracy: 0.5296 - val_loss: 0.9512 - val_accuracy: 0.5370\n",
      "Epoch 81/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9763 - accuracy: 0.5308 - val_loss: 0.9519 - val_accuracy: 0.5374\n",
      "Epoch 82/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9763 - accuracy: 0.5302 - val_loss: 0.9515 - val_accuracy: 0.5383\n",
      "Epoch 83/200\n",
      "636/636 [==============================] - 0s 506us/step - loss: 0.9765 - accuracy: 0.5302 - val_loss: 0.9511 - val_accuracy: 0.5374\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636/636 [==============================] - 0s 495us/step - loss: 0.9764 - accuracy: 0.5302 - val_loss: 0.9516 - val_accuracy: 0.5370\n",
      "Epoch 85/200\n",
      "636/636 [==============================] - 0s 470us/step - loss: 0.9764 - accuracy: 0.5308 - val_loss: 0.9512 - val_accuracy: 0.5383\n",
      "Epoch 86/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9764 - accuracy: 0.5290 - val_loss: 0.9530 - val_accuracy: 0.5374\n",
      "Epoch 87/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9520 - val_accuracy: 0.5383\n",
      "Epoch 88/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9509 - val_accuracy: 0.5352\n",
      "Epoch 89/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9513 - val_accuracy: 0.5378\n",
      "Epoch 90/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9509 - val_accuracy: 0.5374\n",
      "Epoch 91/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9763 - accuracy: 0.5303 - val_loss: 0.9513 - val_accuracy: 0.5383\n",
      "Epoch 92/200\n",
      "636/636 [==============================] - 0s 524us/step - loss: 0.9765 - accuracy: 0.5301 - val_loss: 0.9544 - val_accuracy: 0.5343\n",
      "Epoch 93/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9516 - val_accuracy: 0.5374\n",
      "Epoch 94/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9764 - accuracy: 0.5298 - val_loss: 0.9512 - val_accuracy: 0.5374\n",
      "Epoch 95/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9763 - accuracy: 0.5297 - val_loss: 0.9519 - val_accuracy: 0.5383\n",
      "Epoch 96/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9764 - accuracy: 0.5291 - val_loss: 0.9519 - val_accuracy: 0.5317\n",
      "Epoch 97/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9763 - accuracy: 0.5284 - val_loss: 0.9515 - val_accuracy: 0.5370\n",
      "Epoch 98/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9763 - accuracy: 0.5300 - val_loss: 0.9511 - val_accuracy: 0.5378\n",
      "Epoch 99/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9763 - accuracy: 0.5306 - val_loss: 0.9522 - val_accuracy: 0.5374\n",
      "Epoch 100/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9763 - accuracy: 0.5312 - val_loss: 0.9516 - val_accuracy: 0.5365\n",
      "Epoch 101/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9762 - accuracy: 0.5290 - val_loss: 0.9536 - val_accuracy: 0.5347\n",
      "Epoch 102/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9761 - accuracy: 0.5302 - val_loss: 0.9520 - val_accuracy: 0.5383\n",
      "Epoch 103/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9763 - accuracy: 0.5304 - val_loss: 0.9506 - val_accuracy: 0.5378\n",
      "Epoch 104/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9763 - accuracy: 0.5301 - val_loss: 0.9506 - val_accuracy: 0.5383\n",
      "Epoch 105/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9764 - accuracy: 0.5302 - val_loss: 0.9509 - val_accuracy: 0.5370\n",
      "Epoch 106/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9763 - accuracy: 0.5304 - val_loss: 0.9519 - val_accuracy: 0.5374\n",
      "Epoch 107/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9765 - accuracy: 0.5302 - val_loss: 0.9515 - val_accuracy: 0.5374\n",
      "Epoch 108/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9763 - accuracy: 0.5304 - val_loss: 0.9519 - val_accuracy: 0.5383\n",
      "Epoch 109/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9762 - accuracy: 0.5298 - val_loss: 0.9514 - val_accuracy: 0.5343\n",
      "Epoch 110/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9763 - accuracy: 0.5307 - val_loss: 0.9534 - val_accuracy: 0.5374\n",
      "Epoch 111/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9763 - accuracy: 0.5300 - val_loss: 0.9508 - val_accuracy: 0.5378\n",
      "Epoch 112/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9763 - accuracy: 0.5302 - val_loss: 0.9512 - val_accuracy: 0.5361\n",
      "Epoch 113/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9762 - accuracy: 0.5314 - val_loss: 0.9514 - val_accuracy: 0.5383\n",
      "Epoch 114/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9762 - accuracy: 0.5306 - val_loss: 0.9508 - val_accuracy: 0.5352\n",
      "Epoch 115/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9763 - accuracy: 0.5305 - val_loss: 0.9516 - val_accuracy: 0.5387\n",
      "Epoch 116/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9763 - accuracy: 0.5301 - val_loss: 0.9514 - val_accuracy: 0.5383\n",
      "Epoch 117/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9762 - accuracy: 0.5299 - val_loss: 0.9510 - val_accuracy: 0.5374\n",
      "Epoch 118/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9762 - accuracy: 0.5302 - val_loss: 0.9512 - val_accuracy: 0.5374\n",
      "Epoch 119/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9762 - accuracy: 0.5298 - val_loss: 0.9522 - val_accuracy: 0.5356\n",
      "Epoch 120/200\n",
      "636/636 [==============================] - 0s 493us/step - loss: 0.9761 - accuracy: 0.5311 - val_loss: 0.9506 - val_accuracy: 0.5356\n",
      "Epoch 121/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9761 - accuracy: 0.5302 - val_loss: 0.9517 - val_accuracy: 0.5383\n",
      "Epoch 122/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9764 - accuracy: 0.5301 - val_loss: 0.9509 - val_accuracy: 0.5374\n",
      "Epoch 123/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9761 - accuracy: 0.5303 - val_loss: 0.9535 - val_accuracy: 0.5347\n",
      "Epoch 124/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9763 - accuracy: 0.5294 - val_loss: 0.9521 - val_accuracy: 0.5387\n",
      "Epoch 125/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9506 - val_accuracy: 0.5356\n",
      "Epoch 126/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9762 - accuracy: 0.5295 - val_loss: 0.9512 - val_accuracy: 0.5378\n",
      "Epoch 127/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9760 - accuracy: 0.5295 - val_loss: 0.9510 - val_accuracy: 0.5370\n",
      "Epoch 128/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9763 - accuracy: 0.5308 - val_loss: 0.9516 - val_accuracy: 0.5387\n",
      "Epoch 129/200\n",
      "636/636 [==============================] - 0s 519us/step - loss: 0.9762 - accuracy: 0.5316 - val_loss: 0.9511 - val_accuracy: 0.5387\n",
      "Epoch 130/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9760 - accuracy: 0.5293 - val_loss: 0.9514 - val_accuracy: 0.5347\n",
      "Epoch 131/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9761 - accuracy: 0.5303 - val_loss: 0.9523 - val_accuracy: 0.5361\n",
      "Epoch 132/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9761 - accuracy: 0.5303 - val_loss: 0.9514 - val_accuracy: 0.5383\n",
      "Epoch 133/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9761 - accuracy: 0.5300 - val_loss: 0.9512 - val_accuracy: 0.5378\n",
      "Epoch 134/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9763 - accuracy: 0.5300 - val_loss: 0.9504 - val_accuracy: 0.5361\n",
      "Epoch 135/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9761 - accuracy: 0.5302 - val_loss: 0.9513 - val_accuracy: 0.5383\n",
      "Epoch 136/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9762 - accuracy: 0.5299 - val_loss: 0.9507 - val_accuracy: 0.5378\n",
      "Epoch 137/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9762 - accuracy: 0.5308 - val_loss: 0.9509 - val_accuracy: 0.5383\n",
      "Epoch 138/200\n",
      "636/636 [==============================] - 0s 503us/step - loss: 0.9761 - accuracy: 0.5297 - val_loss: 0.9519 - val_accuracy: 0.5383\n",
      "Epoch 139/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9763 - accuracy: 0.5309 - val_loss: 0.9506 - val_accuracy: 0.5356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9761 - accuracy: 0.5297 - val_loss: 0.9510 - val_accuracy: 0.5383\n",
      "Epoch 141/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9521 - val_accuracy: 0.5356\n",
      "Epoch 142/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9761 - accuracy: 0.5308 - val_loss: 0.9512 - val_accuracy: 0.5374\n",
      "Epoch 143/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9761 - accuracy: 0.5306 - val_loss: 0.9508 - val_accuracy: 0.5370\n",
      "Epoch 144/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9761 - accuracy: 0.5300 - val_loss: 0.9510 - val_accuracy: 0.5378\n",
      "Epoch 145/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9760 - accuracy: 0.5311 - val_loss: 0.9503 - val_accuracy: 0.5370\n",
      "Epoch 146/200\n",
      "636/636 [==============================] - 0s 500us/step - loss: 0.9760 - accuracy: 0.5301 - val_loss: 0.9511 - val_accuracy: 0.5378\n",
      "Epoch 147/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9759 - accuracy: 0.5307 - val_loss: 0.9508 - val_accuracy: 0.5352\n",
      "Epoch 148/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9761 - accuracy: 0.5308 - val_loss: 0.9517 - val_accuracy: 0.5383\n",
      "Epoch 149/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9760 - accuracy: 0.5317 - val_loss: 0.9510 - val_accuracy: 0.5378\n",
      "Epoch 150/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9759 - accuracy: 0.5309 - val_loss: 0.9505 - val_accuracy: 0.5378\n",
      "Epoch 151/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9760 - accuracy: 0.5301 - val_loss: 0.9511 - val_accuracy: 0.5383\n",
      "Epoch 152/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9761 - accuracy: 0.5296 - val_loss: 0.9508 - val_accuracy: 0.5370\n",
      "Epoch 153/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9760 - accuracy: 0.5298 - val_loss: 0.9509 - val_accuracy: 0.5378\n",
      "Epoch 154/200\n",
      "636/636 [==============================] - 0s 492us/step - loss: 0.9760 - accuracy: 0.5300 - val_loss: 0.9512 - val_accuracy: 0.5374\n",
      "Epoch 155/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9760 - accuracy: 0.5304 - val_loss: 0.9512 - val_accuracy: 0.5370\n",
      "Epoch 156/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9760 - accuracy: 0.5293 - val_loss: 0.9504 - val_accuracy: 0.5378\n",
      "Epoch 157/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9761 - accuracy: 0.5300 - val_loss: 0.9506 - val_accuracy: 0.5378\n",
      "Epoch 158/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9761 - accuracy: 0.5302 - val_loss: 0.9511 - val_accuracy: 0.5374\n",
      "Epoch 159/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9760 - accuracy: 0.5287 - val_loss: 0.9507 - val_accuracy: 0.5370\n",
      "Epoch 160/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9759 - accuracy: 0.5307 - val_loss: 0.9517 - val_accuracy: 0.5378\n",
      "Epoch 161/200\n",
      "636/636 [==============================] - 0s 494us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9510 - val_accuracy: 0.5330\n",
      "Epoch 162/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9760 - accuracy: 0.5303 - val_loss: 0.9507 - val_accuracy: 0.5387\n",
      "Epoch 163/200\n",
      "636/636 [==============================] - 0s 502us/step - loss: 0.9760 - accuracy: 0.5309 - val_loss: 0.9508 - val_accuracy: 0.5378\n",
      "Epoch 164/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9759 - accuracy: 0.5304 - val_loss: 0.9505 - val_accuracy: 0.5365\n",
      "Epoch 165/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9759 - accuracy: 0.5298 - val_loss: 0.9512 - val_accuracy: 0.5352\n",
      "Epoch 166/200\n",
      "636/636 [==============================] - 0s 477us/step - loss: 0.9760 - accuracy: 0.5301 - val_loss: 0.9514 - val_accuracy: 0.5374\n",
      "Epoch 167/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9759 - accuracy: 0.5308 - val_loss: 0.9522 - val_accuracy: 0.5361\n",
      "Epoch 168/200\n",
      "636/636 [==============================] - 0s 523us/step - loss: 0.9761 - accuracy: 0.5306 - val_loss: 0.9506 - val_accuracy: 0.5361\n",
      "Epoch 169/200\n",
      "636/636 [==============================] - 0s 527us/step - loss: 0.9759 - accuracy: 0.5305 - val_loss: 0.9525 - val_accuracy: 0.5383\n",
      "Epoch 170/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9760 - accuracy: 0.5311 - val_loss: 0.9512 - val_accuracy: 0.5387\n",
      "Epoch 171/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9759 - accuracy: 0.5311 - val_loss: 0.9504 - val_accuracy: 0.5378\n",
      "Epoch 172/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9760 - accuracy: 0.5307 - val_loss: 0.9513 - val_accuracy: 0.5378\n",
      "Epoch 173/200\n",
      "636/636 [==============================] - 0s 476us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9507 - val_accuracy: 0.5374\n",
      "Epoch 174/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9761 - accuracy: 0.5298 - val_loss: 0.9517 - val_accuracy: 0.5374\n",
      "Epoch 175/200\n",
      "636/636 [==============================] - 0s 488us/step - loss: 0.9759 - accuracy: 0.5305 - val_loss: 0.9507 - val_accuracy: 0.5378\n",
      "Epoch 176/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9760 - accuracy: 0.5308 - val_loss: 0.9514 - val_accuracy: 0.5383\n",
      "Epoch 177/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9759 - accuracy: 0.5303 - val_loss: 0.9514 - val_accuracy: 0.5365\n",
      "Epoch 178/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9758 - accuracy: 0.5302 - val_loss: 0.9513 - val_accuracy: 0.5370\n",
      "Epoch 179/200\n",
      "636/636 [==============================] - 0s 478us/step - loss: 0.9759 - accuracy: 0.5309 - val_loss: 0.9507 - val_accuracy: 0.5383\n",
      "Epoch 180/200\n",
      "636/636 [==============================] - 0s 498us/step - loss: 0.9760 - accuracy: 0.5295 - val_loss: 0.9506 - val_accuracy: 0.5352\n",
      "Epoch 181/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9761 - accuracy: 0.5305 - val_loss: 0.9502 - val_accuracy: 0.5370\n",
      "Epoch 182/200\n",
      "636/636 [==============================] - 0s 491us/step - loss: 0.9758 - accuracy: 0.5307 - val_loss: 0.9516 - val_accuracy: 0.5387\n",
      "Epoch 183/200\n",
      "636/636 [==============================] - 0s 511us/step - loss: 0.9760 - accuracy: 0.5299 - val_loss: 0.9509 - val_accuracy: 0.5370\n",
      "Epoch 184/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9760 - accuracy: 0.5289 - val_loss: 0.9509 - val_accuracy: 0.5356\n",
      "Epoch 185/200\n",
      "636/636 [==============================] - 0s 501us/step - loss: 0.9758 - accuracy: 0.5308 - val_loss: 0.9530 - val_accuracy: 0.5383\n",
      "Epoch 186/200\n",
      "636/636 [==============================] - 0s 499us/step - loss: 0.9759 - accuracy: 0.5313 - val_loss: 0.9511 - val_accuracy: 0.5370\n",
      "Epoch 187/200\n",
      "636/636 [==============================] - 0s 490us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9506 - val_accuracy: 0.5378\n",
      "Epoch 188/200\n",
      "636/636 [==============================] - 0s 504us/step - loss: 0.9758 - accuracy: 0.5304 - val_loss: 0.9504 - val_accuracy: 0.5352\n",
      "Epoch 189/200\n",
      "636/636 [==============================] - 0s 480us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9509 - val_accuracy: 0.5347\n",
      "Epoch 190/200\n",
      "636/636 [==============================] - 0s 496us/step - loss: 0.9758 - accuracy: 0.5311 - val_loss: 0.9521 - val_accuracy: 0.5387\n",
      "Epoch 191/200\n",
      "636/636 [==============================] - 0s 465us/step - loss: 0.9757 - accuracy: 0.5297 - val_loss: 0.9507 - val_accuracy: 0.5352\n",
      "Epoch 192/200\n",
      "636/636 [==============================] - 0s 471us/step - loss: 0.9760 - accuracy: 0.5309 - val_loss: 0.9508 - val_accuracy: 0.5356\n",
      "Epoch 193/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9758 - accuracy: 0.5304 - val_loss: 0.9504 - val_accuracy: 0.5370\n",
      "Epoch 194/200\n",
      "636/636 [==============================] - 0s 521us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9501 - val_accuracy: 0.5378\n",
      "Epoch 195/200\n",
      "636/636 [==============================] - 0s 472us/step - loss: 0.9760 - accuracy: 0.5299 - val_loss: 0.9509 - val_accuracy: 0.5378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/200\n",
      "636/636 [==============================] - 0s 475us/step - loss: 0.9759 - accuracy: 0.5310 - val_loss: 0.9506 - val_accuracy: 0.5378\n",
      "Epoch 197/200\n",
      "636/636 [==============================] - 0s 497us/step - loss: 0.9759 - accuracy: 0.5303 - val_loss: 0.9505 - val_accuracy: 0.5374\n",
      "Epoch 198/200\n",
      "636/636 [==============================] - 0s 479us/step - loss: 0.9759 - accuracy: 0.5308 - val_loss: 0.9507 - val_accuracy: 0.5365\n",
      "Epoch 199/200\n",
      "636/636 [==============================] - 0s 489us/step - loss: 0.9758 - accuracy: 0.5294 - val_loss: 0.9508 - val_accuracy: 0.5325\n",
      "Epoch 200/200\n",
      "636/636 [==============================] - 0s 505us/step - loss: 0.9759 - accuracy: 0.5306 - val_loss: 0.9514 - val_accuracy: 0.5374\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 313us/step - loss: 0.9756 - accuracy: 0.5300\n",
      "Accuracy : 0.530025064945221\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9514 - accuracy: 0.5374\n",
      "Accuracy : 0.5374059081077576\n",
      "\n",
      "The final train accuracy is:0.5311270475387573 \n",
      "\n",
      "The final test accuracy is:0.5312944412231445 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"LB.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data = np.array(df.iloc[:,0:3])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "    \n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "    \n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (3,1)),\n",
    "        keras.layers.Dense(5,activation='sigmoid'),\n",
    "        keras.layers.Dense(5,activation='sigmoid'),\n",
    "        keras.layers.Dense(3,activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dynamic-steering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dying-comparative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acoustic-drill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-metro",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
