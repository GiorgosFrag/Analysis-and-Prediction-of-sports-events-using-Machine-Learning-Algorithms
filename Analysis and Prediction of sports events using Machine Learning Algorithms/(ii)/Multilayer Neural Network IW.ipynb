{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "mediterranean-length",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1.0975 - accuracy: 0.3217 - val_loss: 1.0818 - val_accuracy: 0.4588\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 723us/step - loss: 1.0712 - accuracy: 0.4591 - val_loss: 1.0637 - val_accuracy: 0.4588\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 1.0582 - accuracy: 0.4591 - val_loss: 1.0550 - val_accuracy: 0.4588\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 616us/step - loss: 1.0504 - accuracy: 0.4591 - val_loss: 1.0482 - val_accuracy: 0.4588\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 711us/step - loss: 1.0426 - accuracy: 0.4591 - val_loss: 1.0403 - val_accuracy: 0.4588\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 1.0335 - accuracy: 0.4594 - val_loss: 1.0310 - val_accuracy: 0.4655\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 594us/step - loss: 1.0233 - accuracy: 0.4988 - val_loss: 1.0211 - val_accuracy: 0.5159\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 746us/step - loss: 1.0126 - accuracy: 0.5215 - val_loss: 1.0116 - val_accuracy: 0.5173\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 1.0035 - accuracy: 0.5265 - val_loss: 1.0045 - val_accuracy: 0.5226\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 730us/step - loss: 0.9968 - accuracy: 0.5305 - val_loss: 0.9997 - val_accuracy: 0.5235\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9923 - accuracy: 0.5308 - val_loss: 0.9965 - val_accuracy: 0.5283\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 662us/step - loss: 0.9893 - accuracy: 0.5300 - val_loss: 0.9947 - val_accuracy: 0.5261\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 591us/step - loss: 0.9873 - accuracy: 0.5301 - val_loss: 0.9932 - val_accuracy: 0.5261\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 768us/step - loss: 0.9858 - accuracy: 0.5300 - val_loss: 0.9920 - val_accuracy: 0.5305\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9847 - accuracy: 0.5309 - val_loss: 0.9912 - val_accuracy: 0.5296\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 658us/step - loss: 0.9835 - accuracy: 0.5300 - val_loss: 0.9902 - val_accuracy: 0.5288\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9828 - accuracy: 0.5302 - val_loss: 0.9894 - val_accuracy: 0.5270\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 741us/step - loss: 0.9819 - accuracy: 0.5299 - val_loss: 0.9888 - val_accuracy: 0.5270\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9813 - accuracy: 0.5300 - val_loss: 0.9883 - val_accuracy: 0.5261\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 652us/step - loss: 0.9807 - accuracy: 0.5302 - val_loss: 0.9879 - val_accuracy: 0.5296\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 602us/step - loss: 0.9804 - accuracy: 0.5299 - val_loss: 0.9875 - val_accuracy: 0.5301\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 735us/step - loss: 0.9799 - accuracy: 0.5296 - val_loss: 0.9873 - val_accuracy: 0.5283\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9795 - accuracy: 0.5312 - val_loss: 0.9867 - val_accuracy: 0.5305\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9791 - accuracy: 0.5307 - val_loss: 0.9866 - val_accuracy: 0.5261\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 632us/step - loss: 0.9789 - accuracy: 0.5303 - val_loss: 0.9862 - val_accuracy: 0.5305\n",
      "Epoch 26/200\n",
      "92/92 [==============================] - 0s 748us/step - loss: 0.9785 - accuracy: 0.5311 - val_loss: 0.9859 - val_accuracy: 0.5296\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9782 - accuracy: 0.5311 - val_loss: 0.9857 - val_accuracy: 0.5283\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 687us/step - loss: 0.9780 - accuracy: 0.5304 - val_loss: 0.9855 - val_accuracy: 0.5305\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 676us/step - loss: 0.9777 - accuracy: 0.5308 - val_loss: 0.9854 - val_accuracy: 0.5261\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 610us/step - loss: 0.9777 - accuracy: 0.5299 - val_loss: 0.9850 - val_accuracy: 0.5305\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 729us/step - loss: 0.9773 - accuracy: 0.5305 - val_loss: 0.9850 - val_accuracy: 0.5296\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9772 - accuracy: 0.5314 - val_loss: 0.9847 - val_accuracy: 0.5292\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9769 - accuracy: 0.5300 - val_loss: 0.9844 - val_accuracy: 0.5283\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9768 - accuracy: 0.5297 - val_loss: 0.9845 - val_accuracy: 0.5257\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9767 - accuracy: 0.5292 - val_loss: 0.9845 - val_accuracy: 0.5261\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 685us/step - loss: 0.9766 - accuracy: 0.5301 - val_loss: 0.9841 - val_accuracy: 0.5292\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 696us/step - loss: 0.9763 - accuracy: 0.5303 - val_loss: 0.9839 - val_accuracy: 0.5292\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 685us/step - loss: 0.9762 - accuracy: 0.5312 - val_loss: 0.9837 - val_accuracy: 0.5301\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 677us/step - loss: 0.9760 - accuracy: 0.5311 - val_loss: 0.9839 - val_accuracy: 0.5230\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9760 - accuracy: 0.5310 - val_loss: 0.9836 - val_accuracy: 0.5257\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 696us/step - loss: 0.9758 - accuracy: 0.5300 - val_loss: 0.9835 - val_accuracy: 0.5270\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9757 - accuracy: 0.5308 - val_loss: 0.9836 - val_accuracy: 0.5292\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9755 - accuracy: 0.5300 - val_loss: 0.9840 - val_accuracy: 0.5226\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 619us/step - loss: 0.9756 - accuracy: 0.5312 - val_loss: 0.9832 - val_accuracy: 0.5292\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 708us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9835 - val_accuracy: 0.5230\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9830 - val_accuracy: 0.5296\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9752 - accuracy: 0.5305 - val_loss: 0.9830 - val_accuracy: 0.5283\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9751 - accuracy: 0.5306 - val_loss: 0.9830 - val_accuracy: 0.5239\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9750 - accuracy: 0.5311 - val_loss: 0.9832 - val_accuracy: 0.5292\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9752 - accuracy: 0.5310 - val_loss: 0.9829 - val_accuracy: 0.5235\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 601us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9829 - val_accuracy: 0.5230\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 682us/step - loss: 0.9751 - accuracy: 0.5314 - val_loss: 0.9829 - val_accuracy: 0.5230\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9749 - accuracy: 0.5317 - val_loss: 0.9827 - val_accuracy: 0.5243\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 659us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 0.9827 - val_accuracy: 0.5239\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9748 - accuracy: 0.5300 - val_loss: 0.9826 - val_accuracy: 0.5296\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9744 - accuracy: 0.5305 - val_loss: 0.9836 - val_accuracy: 0.5261\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9749 - accuracy: 0.5305 - val_loss: 0.9825 - val_accuracy: 0.5261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9746 - accuracy: 0.5313 - val_loss: 0.9826 - val_accuracy: 0.5292\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9745 - accuracy: 0.5312 - val_loss: 0.9825 - val_accuracy: 0.5261\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 859us/step - loss: 0.9745 - accuracy: 0.5315 - val_loss: 0.9828 - val_accuracy: 0.5292\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 729us/step - loss: 0.9746 - accuracy: 0.5315 - val_loss: 0.9824 - val_accuracy: 0.5288\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 685us/step - loss: 0.9744 - accuracy: 0.5317 - val_loss: 0.9825 - val_accuracy: 0.5283\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 680us/step - loss: 0.9745 - accuracy: 0.5309 - val_loss: 0.9824 - val_accuracy: 0.5243\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 672us/step - loss: 0.9744 - accuracy: 0.5305 - val_loss: 0.9824 - val_accuracy: 0.5239\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 599us/step - loss: 0.9743 - accuracy: 0.5312 - val_loss: 0.9823 - val_accuracy: 0.5235\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 788us/step - loss: 0.9743 - accuracy: 0.5307 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9742 - accuracy: 0.5321 - val_loss: 0.9823 - val_accuracy: 0.5239\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 730us/step - loss: 0.9741 - accuracy: 0.5314 - val_loss: 0.9828 - val_accuracy: 0.5292\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 676us/step - loss: 0.9742 - accuracy: 0.5306 - val_loss: 0.9825 - val_accuracy: 0.5226\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 661us/step - loss: 0.9743 - accuracy: 0.5308 - val_loss: 0.9824 - val_accuracy: 0.5243\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9742 - accuracy: 0.5311 - val_loss: 0.9823 - val_accuracy: 0.5235\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 736us/step - loss: 0.9742 - accuracy: 0.5311 - val_loss: 0.9822 - val_accuracy: 0.5239\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9742 - accuracy: 0.5310 - val_loss: 0.9824 - val_accuracy: 0.5283\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 654us/step - loss: 0.9741 - accuracy: 0.5308 - val_loss: 0.9824 - val_accuracy: 0.5283\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 708us/step - loss: 0.9741 - accuracy: 0.5316 - val_loss: 0.9822 - val_accuracy: 0.5296\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9740 - accuracy: 0.5316 - val_loss: 0.9822 - val_accuracy: 0.5239\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 659us/step - loss: 0.9740 - accuracy: 0.5301 - val_loss: 0.9821 - val_accuracy: 0.5248\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 637us/step - loss: 0.9741 - accuracy: 0.5312 - val_loss: 0.9821 - val_accuracy: 0.5239\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9740 - accuracy: 0.5308 - val_loss: 0.9821 - val_accuracy: 0.5235\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9740 - accuracy: 0.5312 - val_loss: 0.9822 - val_accuracy: 0.5239\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 654us/step - loss: 0.9739 - accuracy: 0.5313 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 681us/step - loss: 0.9738 - accuracy: 0.5309 - val_loss: 0.9823 - val_accuracy: 0.5283\n",
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 679us/step - loss: 0.9740 - accuracy: 0.5313 - val_loss: 0.9821 - val_accuracy: 0.5292\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 672us/step - loss: 0.9739 - accuracy: 0.5307 - val_loss: 0.9821 - val_accuracy: 0.5239\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 673us/step - loss: 0.9740 - accuracy: 0.5320 - val_loss: 0.9822 - val_accuracy: 0.5279\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9740 - accuracy: 0.5314 - val_loss: 0.9823 - val_accuracy: 0.5226\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9739 - accuracy: 0.5312 - val_loss: 0.9821 - val_accuracy: 0.5235\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9738 - accuracy: 0.5318 - val_loss: 0.9821 - val_accuracy: 0.5239\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 685us/step - loss: 0.9739 - accuracy: 0.5312 - val_loss: 0.9822 - val_accuracy: 0.5288\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 696us/step - loss: 0.9738 - accuracy: 0.5299 - val_loss: 0.9822 - val_accuracy: 0.5288\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 690us/step - loss: 0.9738 - accuracy: 0.5314 - val_loss: 0.9822 - val_accuracy: 0.5283\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9738 - accuracy: 0.5310 - val_loss: 0.9824 - val_accuracy: 0.5230\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9739 - accuracy: 0.5303 - val_loss: 0.9820 - val_accuracy: 0.5235\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 618us/step - loss: 0.9739 - accuracy: 0.5312 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 765us/step - loss: 0.9738 - accuracy: 0.5309 - val_loss: 0.9821 - val_accuracy: 0.5288\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 640us/step - loss: 0.9737 - accuracy: 0.5297 - val_loss: 0.9821 - val_accuracy: 0.5288\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 656us/step - loss: 0.9738 - accuracy: 0.5312 - val_loss: 0.9821 - val_accuracy: 0.5288\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 0.9821 - val_accuracy: 0.5288\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9737 - accuracy: 0.5314 - val_loss: 0.9821 - val_accuracy: 0.5239\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 518us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 0.9820 - val_accuracy: 0.5230\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 577us/step - loss: 0.9738 - accuracy: 0.5302 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 657us/step - loss: 0.9737 - accuracy: 0.5302 - val_loss: 0.9820 - val_accuracy: 0.5235\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 0.9738 - accuracy: 0.5310 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 676us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 618us/step - loss: 0.9737 - accuracy: 0.5310 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 669us/step - loss: 0.9737 - accuracy: 0.5302 - val_loss: 0.9820 - val_accuracy: 0.5279\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 603us/step - loss: 0.9737 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 708us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9821 - val_accuracy: 0.5235\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9737 - accuracy: 0.5306 - val_loss: 0.9824 - val_accuracy: 0.5226\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 738us/step - loss: 0.9737 - accuracy: 0.5296 - val_loss: 0.9820 - val_accuracy: 0.5230\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 579us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 0.9820 - val_accuracy: 0.5279\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 732us/step - loss: 0.9736 - accuracy: 0.5301 - val_loss: 0.9820 - val_accuracy: 0.5243\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9737 - accuracy: 0.5294 - val_loss: 0.9820 - val_accuracy: 0.5283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 685us/step - loss: 0.9736 - accuracy: 0.5296 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9820 - val_accuracy: 0.5243\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9819 - val_accuracy: 0.5239\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9736 - accuracy: 0.5315 - val_loss: 0.9820 - val_accuracy: 0.5243\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9736 - accuracy: 0.5311 - val_loss: 0.9822 - val_accuracy: 0.5283\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9735 - accuracy: 0.5311 - val_loss: 0.9823 - val_accuracy: 0.5283\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9736 - accuracy: 0.5318 - val_loss: 0.9819 - val_accuracy: 0.5239\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9735 - accuracy: 0.5314 - val_loss: 0.9820 - val_accuracy: 0.5288\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9735 - accuracy: 0.5305 - val_loss: 0.9822 - val_accuracy: 0.5283\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 599us/step - loss: 0.9736 - accuracy: 0.5297 - val_loss: 0.9821 - val_accuracy: 0.5230\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 654us/step - loss: 0.9736 - accuracy: 0.5309 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 773us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9819 - val_accuracy: 0.5239\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 680us/step - loss: 0.9735 - accuracy: 0.5311 - val_loss: 0.9820 - val_accuracy: 0.5230\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 551us/step - loss: 0.9736 - accuracy: 0.5312 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 722us/step - loss: 0.9735 - accuracy: 0.5308 - val_loss: 0.9823 - val_accuracy: 0.5283\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 611us/step - loss: 0.9736 - accuracy: 0.5306 - val_loss: 0.9819 - val_accuracy: 0.5239\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 721us/step - loss: 0.9735 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5243\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 624us/step - loss: 0.9734 - accuracy: 0.5313 - val_loss: 0.9821 - val_accuracy: 0.5283\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9736 - accuracy: 0.5307 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 685us/step - loss: 0.9734 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5248\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9735 - accuracy: 0.5313 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9735 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9734 - accuracy: 0.5307 - val_loss: 0.9820 - val_accuracy: 0.5288\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9735 - accuracy: 0.5317 - val_loss: 0.9819 - val_accuracy: 0.5239\n",
      "Epoch 139/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9735 - accuracy: 0.5308 - val_loss: 0.9822 - val_accuracy: 0.5230\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9735 - accuracy: 0.5310 - val_loss: 0.9819 - val_accuracy: 0.5239\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 696us/step - loss: 0.9735 - accuracy: 0.5303 - val_loss: 0.9819 - val_accuracy: 0.5239\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 644us/step - loss: 0.9735 - accuracy: 0.5306 - val_loss: 0.9820 - val_accuracy: 0.5230\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9734 - accuracy: 0.5311 - val_loss: 0.9821 - val_accuracy: 0.5283\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9734 - accuracy: 0.5307 - val_loss: 0.9820 - val_accuracy: 0.5235\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9734 - accuracy: 0.5312 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9734 - accuracy: 0.5299 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9734 - accuracy: 0.5305 - val_loss: 0.9820 - val_accuracy: 0.5283\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9734 - accuracy: 0.5312 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 662us/step - loss: 0.9734 - accuracy: 0.5311 - val_loss: 0.9821 - val_accuracy: 0.5239\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 601us/step - loss: 0.9734 - accuracy: 0.5311 - val_loss: 0.9820 - val_accuracy: 0.5283\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 702us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 686us/step - loss: 0.9734 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5248\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9734 - accuracy: 0.5296 - val_loss: 0.9821 - val_accuracy: 0.5239\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9734 - accuracy: 0.5307 - val_loss: 0.9822 - val_accuracy: 0.5226\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9821 - val_accuracy: 0.5226\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 546us/step - loss: 0.9734 - accuracy: 0.5312 - val_loss: 0.9820 - val_accuracy: 0.5230\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 661us/step - loss: 0.9734 - accuracy: 0.5308 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 898us/step - loss: 0.9734 - accuracy: 0.5321 - val_loss: 0.9821 - val_accuracy: 0.5230\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.9733 - accuracy: 0.5322 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 751us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 870us/step - loss: 0.9734 - accuracy: 0.5309 - val_loss: 0.9819 - val_accuracy: 0.5239\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 718us/step - loss: 0.9734 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5230\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 794us/step - loss: 0.9733 - accuracy: 0.5308 - val_loss: 0.9821 - val_accuracy: 0.5283\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 762us/step - loss: 0.9734 - accuracy: 0.5308 - val_loss: 0.9820 - val_accuracy: 0.5230\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 772us/step - loss: 0.9735 - accuracy: 0.5302 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 740us/step - loss: 0.9734 - accuracy: 0.5308 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5283\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9733 - accuracy: 0.5299 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 672us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9823 - val_accuracy: 0.5288\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 651us/step - loss: 0.9733 - accuracy: 0.5297 - val_loss: 0.9819 - val_accuracy: 0.5239\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 660us/step - loss: 0.9734 - accuracy: 0.5303 - val_loss: 0.9820 - val_accuracy: 0.5283\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 678us/step - loss: 0.9733 - accuracy: 0.5313 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 685us/step - loss: 0.9735 - accuracy: 0.5306 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9734 - accuracy: 0.5319 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9732 - accuracy: 0.5305 - val_loss: 0.9826 - val_accuracy: 0.5226\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9735 - accuracy: 0.5297 - val_loss: 0.9820 - val_accuracy: 0.5248\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9734 - accuracy: 0.5315 - val_loss: 0.9820 - val_accuracy: 0.5248\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9735 - accuracy: 0.5312 - val_loss: 0.9821 - val_accuracy: 0.5283\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9732 - accuracy: 0.5316 - val_loss: 0.9823 - val_accuracy: 0.5230\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 685us/step - loss: 0.9732 - accuracy: 0.5306 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 676us/step - loss: 0.9733 - accuracy: 0.5307 - val_loss: 0.9820 - val_accuracy: 0.5283\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 685us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 0.9821 - val_accuracy: 0.5283\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 533us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 692us/step - loss: 0.9732 - accuracy: 0.5312 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 622us/step - loss: 0.9733 - accuracy: 0.5311 - val_loss: 0.9820 - val_accuracy: 0.5283\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 580us/step - loss: 0.9732 - accuracy: 0.5306 - val_loss: 0.9821 - val_accuracy: 0.5230\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 698us/step - loss: 0.9734 - accuracy: 0.5315 - val_loss: 0.9821 - val_accuracy: 0.5239\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 678us/step - loss: 0.9734 - accuracy: 0.5306 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 568us/step - loss: 0.9732 - accuracy: 0.5308 - val_loss: 0.9821 - val_accuracy: 0.5230\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 697us/step - loss: 0.9732 - accuracy: 0.5305 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9733 - accuracy: 0.5307 - val_loss: 0.9820 - val_accuracy: 0.5243\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 568us/step - loss: 0.9732 - accuracy: 0.5318 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 688us/step - loss: 0.9732 - accuracy: 0.5309 - val_loss: 0.9821 - val_accuracy: 0.5270\n",
      "Epoch 195/200\n",
      "92/92 [==============================] - 0s 624us/step - loss: 0.9733 - accuracy: 0.5302 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 660us/step - loss: 0.9733 - accuracy: 0.5309 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 605us/step - loss: 0.9733 - accuracy: 0.5305 - val_loss: 0.9822 - val_accuracy: 0.5243\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 549us/step - loss: 0.9732 - accuracy: 0.5316 - val_loss: 0.9820 - val_accuracy: 0.5239\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 675us/step - loss: 0.9732 - accuracy: 0.5311 - val_loss: 0.9820 - val_accuracy: 0.5230\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 750us/step - loss: 0.9734 - accuracy: 0.5303 - val_loss: 0.9821 - val_accuracy: 0.5230\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 368us/step - loss: 0.9732 - accuracy: 0.5307\n",
      "Accuracy : 0.5306905508041382\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9821 - accuracy: 0.5230\n",
      "Accuracy : 0.5230088233947754\n",
      "Fold #2\n",
      "Epoch 1/200\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1.0638 - accuracy: 0.4590 - val_loss: 1.0544 - val_accuracy: 0.4593\n",
      "Epoch 2/200\n",
      "92/92 [==============================] - 0s 633us/step - loss: 1.0503 - accuracy: 0.4590 - val_loss: 1.0426 - val_accuracy: 0.4593\n",
      "Epoch 3/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 1.0397 - accuracy: 0.4590 - val_loss: 1.0307 - val_accuracy: 0.4593\n",
      "Epoch 4/200\n",
      "92/92 [==============================] - 0s 703us/step - loss: 1.0280 - accuracy: 0.4590 - val_loss: 1.0173 - val_accuracy: 0.4593\n",
      "Epoch 5/200\n",
      "92/92 [==============================] - 0s 748us/step - loss: 1.0155 - accuracy: 0.4976 - val_loss: 1.0041 - val_accuracy: 0.5221\n",
      "Epoch 6/200\n",
      "92/92 [==============================] - 0s 511us/step - loss: 1.0043 - accuracy: 0.5246 - val_loss: 0.9938 - val_accuracy: 0.5288\n",
      "Epoch 7/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9967 - accuracy: 0.5287 - val_loss: 0.9872 - val_accuracy: 0.5385\n",
      "Epoch 8/200\n",
      "92/92 [==============================] - 0s 634us/step - loss: 0.9921 - accuracy: 0.5290 - val_loss: 0.9835 - val_accuracy: 0.5363\n",
      "Epoch 9/200\n",
      "92/92 [==============================] - 0s 623us/step - loss: 0.9894 - accuracy: 0.5285 - val_loss: 0.9815 - val_accuracy: 0.5358\n",
      "Epoch 10/200\n",
      "92/92 [==============================] - 0s 772us/step - loss: 0.9878 - accuracy: 0.5278 - val_loss: 0.9802 - val_accuracy: 0.5363\n",
      "Epoch 11/200\n",
      "92/92 [==============================] - 0s 487us/step - loss: 0.9866 - accuracy: 0.5278 - val_loss: 0.9792 - val_accuracy: 0.5363\n",
      "Epoch 12/200\n",
      "92/92 [==============================] - 0s 576us/step - loss: 0.9855 - accuracy: 0.5274 - val_loss: 0.9783 - val_accuracy: 0.5358\n",
      "Epoch 13/200\n",
      "92/92 [==============================] - 0s 618us/step - loss: 0.9846 - accuracy: 0.5289 - val_loss: 0.9777 - val_accuracy: 0.5327\n",
      "Epoch 14/200\n",
      "92/92 [==============================] - 0s 637us/step - loss: 0.9837 - accuracy: 0.5288 - val_loss: 0.9772 - val_accuracy: 0.5332\n",
      "Epoch 15/200\n",
      "92/92 [==============================] - 0s 686us/step - loss: 0.9829 - accuracy: 0.5286 - val_loss: 0.9770 - val_accuracy: 0.5332\n",
      "Epoch 16/200\n",
      "92/92 [==============================] - 0s 775us/step - loss: 0.9824 - accuracy: 0.5283 - val_loss: 0.9762 - val_accuracy: 0.5372\n",
      "Epoch 17/200\n",
      "92/92 [==============================] - 0s 805us/step - loss: 0.9817 - accuracy: 0.5303 - val_loss: 0.9757 - val_accuracy: 0.5354\n",
      "Epoch 18/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9811 - accuracy: 0.5294 - val_loss: 0.9754 - val_accuracy: 0.5358\n",
      "Epoch 19/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9805 - accuracy: 0.5299 - val_loss: 0.9751 - val_accuracy: 0.5358\n",
      "Epoch 20/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9802 - accuracy: 0.5298 - val_loss: 0.9747 - val_accuracy: 0.5354\n",
      "Epoch 21/200\n",
      "92/92 [==============================] - 0s 772us/step - loss: 0.9796 - accuracy: 0.5297 - val_loss: 0.9743 - val_accuracy: 0.5372\n",
      "Epoch 22/200\n",
      "92/92 [==============================] - 0s 751us/step - loss: 0.9792 - accuracy: 0.5301 - val_loss: 0.9740 - val_accuracy: 0.5381\n",
      "Epoch 23/200\n",
      "92/92 [==============================] - 0s 718us/step - loss: 0.9788 - accuracy: 0.5301 - val_loss: 0.9738 - val_accuracy: 0.5367\n",
      "Epoch 24/200\n",
      "92/92 [==============================] - 0s 664us/step - loss: 0.9785 - accuracy: 0.5303 - val_loss: 0.9737 - val_accuracy: 0.5385\n",
      "Epoch 25/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9783 - accuracy: 0.5289 - val_loss: 0.9735 - val_accuracy: 0.5385\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 642us/step - loss: 0.9780 - accuracy: 0.5297 - val_loss: 0.9733 - val_accuracy: 0.5385\n",
      "Epoch 27/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9777 - accuracy: 0.5297 - val_loss: 0.9733 - val_accuracy: 0.5385\n",
      "Epoch 28/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9776 - accuracy: 0.5301 - val_loss: 0.9732 - val_accuracy: 0.5367\n",
      "Epoch 29/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9774 - accuracy: 0.5300 - val_loss: 0.9732 - val_accuracy: 0.5385\n",
      "Epoch 30/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9772 - accuracy: 0.5292 - val_loss: 0.9729 - val_accuracy: 0.5367\n",
      "Epoch 31/200\n",
      "92/92 [==============================] - 0s 631us/step - loss: 0.9770 - accuracy: 0.5289 - val_loss: 0.9730 - val_accuracy: 0.5358\n",
      "Epoch 32/200\n",
      "92/92 [==============================] - 0s 539us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9729 - val_accuracy: 0.5385\n",
      "Epoch 33/200\n",
      "92/92 [==============================] - 0s 739us/step - loss: 0.9769 - accuracy: 0.5302 - val_loss: 0.9729 - val_accuracy: 0.5381\n",
      "Epoch 34/200\n",
      "92/92 [==============================] - 0s 642us/step - loss: 0.9766 - accuracy: 0.5305 - val_loss: 0.9726 - val_accuracy: 0.5372\n",
      "Epoch 35/200\n",
      "92/92 [==============================] - 0s 521us/step - loss: 0.9766 - accuracy: 0.5295 - val_loss: 0.9727 - val_accuracy: 0.5372\n",
      "Epoch 36/200\n",
      "92/92 [==============================] - 0s 782us/step - loss: 0.9765 - accuracy: 0.5288 - val_loss: 0.9727 - val_accuracy: 0.5385\n",
      "Epoch 37/200\n",
      "92/92 [==============================] - 0s 568us/step - loss: 0.9764 - accuracy: 0.5301 - val_loss: 0.9727 - val_accuracy: 0.5385\n",
      "Epoch 38/200\n",
      "92/92 [==============================] - 0s 648us/step - loss: 0.9764 - accuracy: 0.5304 - val_loss: 0.9725 - val_accuracy: 0.5372\n",
      "Epoch 39/200\n",
      "92/92 [==============================] - 0s 747us/step - loss: 0.9763 - accuracy: 0.5301 - val_loss: 0.9724 - val_accuracy: 0.5372\n",
      "Epoch 40/200\n",
      "92/92 [==============================] - 0s 611us/step - loss: 0.9762 - accuracy: 0.5292 - val_loss: 0.9726 - val_accuracy: 0.5372\n",
      "Epoch 41/200\n",
      "92/92 [==============================] - 0s 648us/step - loss: 0.9762 - accuracy: 0.5291 - val_loss: 0.9725 - val_accuracy: 0.5372\n",
      "Epoch 42/200\n",
      "92/92 [==============================] - 0s 752us/step - loss: 0.9762 - accuracy: 0.5295 - val_loss: 0.9725 - val_accuracy: 0.5376\n",
      "Epoch 43/200\n",
      "92/92 [==============================] - 0s 492us/step - loss: 0.9760 - accuracy: 0.5292 - val_loss: 0.9724 - val_accuracy: 0.5372\n",
      "Epoch 44/200\n",
      "92/92 [==============================] - 0s 746us/step - loss: 0.9759 - accuracy: 0.5296 - val_loss: 0.9724 - val_accuracy: 0.5367\n",
      "Epoch 45/200\n",
      "92/92 [==============================] - 0s 669us/step - loss: 0.9760 - accuracy: 0.5302 - val_loss: 0.9723 - val_accuracy: 0.5358\n",
      "Epoch 46/200\n",
      "92/92 [==============================] - 0s 590us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9724 - val_accuracy: 0.5358\n",
      "Epoch 47/200\n",
      "92/92 [==============================] - 0s 674us/step - loss: 0.9758 - accuracy: 0.5297 - val_loss: 0.9724 - val_accuracy: 0.5367\n",
      "Epoch 48/200\n",
      "92/92 [==============================] - 0s 593us/step - loss: 0.9758 - accuracy: 0.5298 - val_loss: 0.9725 - val_accuracy: 0.5385\n",
      "Epoch 49/200\n",
      "92/92 [==============================] - 0s 737us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 0.9726 - val_accuracy: 0.5381\n",
      "Epoch 50/200\n",
      "92/92 [==============================] - 0s 618us/step - loss: 0.9757 - accuracy: 0.5294 - val_loss: 0.9722 - val_accuracy: 0.5372\n",
      "Epoch 51/200\n",
      "92/92 [==============================] - 0s 640us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 0.9723 - val_accuracy: 0.5367\n",
      "Epoch 52/200\n",
      "92/92 [==============================] - 0s 713us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 0.9721 - val_accuracy: 0.5372\n",
      "Epoch 53/200\n",
      "92/92 [==============================] - 0s 602us/step - loss: 0.9757 - accuracy: 0.5288 - val_loss: 0.9726 - val_accuracy: 0.5381\n",
      "Epoch 54/200\n",
      "92/92 [==============================] - 0s 691us/step - loss: 0.9757 - accuracy: 0.5290 - val_loss: 0.9724 - val_accuracy: 0.5385\n",
      "Epoch 55/200\n",
      "92/92 [==============================] - 0s 660us/step - loss: 0.9757 - accuracy: 0.5293 - val_loss: 0.9722 - val_accuracy: 0.5372\n",
      "Epoch 56/200\n",
      "92/92 [==============================] - 0s 652us/step - loss: 0.9756 - accuracy: 0.5303 - val_loss: 0.9723 - val_accuracy: 0.5376\n",
      "Epoch 57/200\n",
      "92/92 [==============================] - 0s 547us/step - loss: 0.9756 - accuracy: 0.5294 - val_loss: 0.9722 - val_accuracy: 0.5367\n",
      "Epoch 58/200\n",
      "92/92 [==============================] - 0s 661us/step - loss: 0.9756 - accuracy: 0.5292 - val_loss: 0.9725 - val_accuracy: 0.5381\n",
      "Epoch 59/200\n",
      "92/92 [==============================] - 0s 623us/step - loss: 0.9756 - accuracy: 0.5297 - val_loss: 0.9722 - val_accuracy: 0.5376\n",
      "Epoch 60/200\n",
      "92/92 [==============================] - 0s 772us/step - loss: 0.9755 - accuracy: 0.5295 - val_loss: 0.9720 - val_accuracy: 0.5372\n",
      "Epoch 61/200\n",
      "92/92 [==============================] - 0s 590us/step - loss: 0.9755 - accuracy: 0.5300 - val_loss: 0.9722 - val_accuracy: 0.5354\n",
      "Epoch 62/200\n",
      "92/92 [==============================] - 0s 608us/step - loss: 0.9754 - accuracy: 0.5300 - val_loss: 0.9720 - val_accuracy: 0.5358\n",
      "Epoch 63/200\n",
      "92/92 [==============================] - 0s 658us/step - loss: 0.9754 - accuracy: 0.5301 - val_loss: 0.9722 - val_accuracy: 0.5372\n",
      "Epoch 64/200\n",
      "92/92 [==============================] - 0s 621us/step - loss: 0.9755 - accuracy: 0.5296 - val_loss: 0.9722 - val_accuracy: 0.5376\n",
      "Epoch 65/200\n",
      "92/92 [==============================] - 0s 784us/step - loss: 0.9753 - accuracy: 0.5294 - val_loss: 0.9720 - val_accuracy: 0.5372\n",
      "Epoch 66/200\n",
      "92/92 [==============================] - 0s 593us/step - loss: 0.9754 - accuracy: 0.5294 - val_loss: 0.9722 - val_accuracy: 0.5367\n",
      "Epoch 67/200\n",
      "92/92 [==============================] - 0s 708us/step - loss: 0.9754 - accuracy: 0.5294 - val_loss: 0.9719 - val_accuracy: 0.5358\n",
      "Epoch 68/200\n",
      "92/92 [==============================] - 0s 542us/step - loss: 0.9754 - accuracy: 0.5292 - val_loss: 0.9720 - val_accuracy: 0.5372\n",
      "Epoch 69/200\n",
      "92/92 [==============================] - 0s 755us/step - loss: 0.9753 - accuracy: 0.5290 - val_loss: 0.9720 - val_accuracy: 0.5372\n",
      "Epoch 70/200\n",
      "92/92 [==============================] - 0s 588us/step - loss: 0.9753 - accuracy: 0.5286 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 71/200\n",
      "92/92 [==============================] - 0s 602us/step - loss: 0.9753 - accuracy: 0.5290 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 72/200\n",
      "92/92 [==============================] - 0s 747us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9720 - val_accuracy: 0.5376\n",
      "Epoch 73/200\n",
      "92/92 [==============================] - 0s 678us/step - loss: 0.9753 - accuracy: 0.5299 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 74/200\n",
      "92/92 [==============================] - 0s 638us/step - loss: 0.9752 - accuracy: 0.5297 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 75/200\n",
      "92/92 [==============================] - 0s 669us/step - loss: 0.9752 - accuracy: 0.5303 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 76/200\n",
      "92/92 [==============================] - 0s 732us/step - loss: 0.9752 - accuracy: 0.5298 - val_loss: 0.9720 - val_accuracy: 0.5367\n",
      "Epoch 77/200\n",
      "92/92 [==============================] - 0s 522us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9720 - val_accuracy: 0.5372\n",
      "Epoch 78/200\n",
      "92/92 [==============================] - 0s 788us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9722 - val_accuracy: 0.5358\n",
      "Epoch 79/200\n",
      "92/92 [==============================] - 0s 609us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9721 - val_accuracy: 0.5381\n",
      "Epoch 80/200\n",
      "92/92 [==============================] - 0s 623us/step - loss: 0.9753 - accuracy: 0.5291 - val_loss: 0.9719 - val_accuracy: 0.5358\n",
      "Epoch 81/200\n",
      "92/92 [==============================] - 0s 632us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9720 - val_accuracy: 0.5376\n",
      "Epoch 82/200\n",
      "92/92 [==============================] - 0s 578us/step - loss: 0.9752 - accuracy: 0.5295 - val_loss: 0.9720 - val_accuracy: 0.5381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "92/92 [==============================] - 0s 720us/step - loss: 0.9752 - accuracy: 0.5299 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 84/200\n",
      "92/92 [==============================] - 0s 709us/step - loss: 0.9753 - accuracy: 0.5291 - val_loss: 0.9719 - val_accuracy: 0.5358\n",
      "Epoch 85/200\n",
      "92/92 [==============================] - 0s 602us/step - loss: 0.9752 - accuracy: 0.5303 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 86/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9718 - val_accuracy: 0.5372\n",
      "Epoch 87/200\n",
      "92/92 [==============================] - 0s 715us/step - loss: 0.9751 - accuracy: 0.5298 - val_loss: 0.9719 - val_accuracy: 0.5376\n",
      "Epoch 88/200\n",
      "92/92 [==============================] - 0s 619us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9719 - val_accuracy: 0.5376\n",
      "Epoch 89/200\n",
      "92/92 [==============================] - 0s 679us/step - loss: 0.9751 - accuracy: 0.5297 - val_loss: 0.9718 - val_accuracy: 0.5372\n",
      "Epoch 90/200\n",
      "92/92 [==============================] - 0s 748us/step - loss: 0.9751 - accuracy: 0.5300 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 91/200\n",
      "92/92 [==============================] - 0s 604us/step - loss: 0.9751 - accuracy: 0.5295 - val_loss: 0.9718 - val_accuracy: 0.5372\n",
      "Epoch 92/200\n",
      "92/92 [==============================] - 0s 655us/step - loss: 0.9751 - accuracy: 0.5296 - val_loss: 0.9720 - val_accuracy: 0.5381\n",
      "Epoch 93/200\n",
      "92/92 [==============================] - 0s 626us/step - loss: 0.9751 - accuracy: 0.5291 - val_loss: 0.9718 - val_accuracy: 0.5367\n",
      "Epoch 94/200\n",
      "92/92 [==============================] - 0s 629us/step - loss: 0.9750 - accuracy: 0.5292 - val_loss: 0.9718 - val_accuracy: 0.5367\n",
      "Epoch 95/200\n",
      "92/92 [==============================] - 0s 580us/step - loss: 0.9751 - accuracy: 0.5292 - val_loss: 0.9718 - val_accuracy: 0.5367\n",
      "Epoch 96/200\n",
      "92/92 [==============================] - 0s 650us/step - loss: 0.9751 - accuracy: 0.5291 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 97/200\n",
      "92/92 [==============================] - 0s 608us/step - loss: 0.9750 - accuracy: 0.5294 - val_loss: 0.9723 - val_accuracy: 0.5381\n",
      "Epoch 98/200\n",
      "92/92 [==============================] - 0s 767us/step - loss: 0.9751 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 99/200\n",
      "92/92 [==============================] - 0s 649us/step - loss: 0.9750 - accuracy: 0.5291 - val_loss: 0.9718 - val_accuracy: 0.5358\n",
      "Epoch 100/200\n",
      "92/92 [==============================] - 0s 628us/step - loss: 0.9750 - accuracy: 0.5303 - val_loss: 0.9720 - val_accuracy: 0.5381\n",
      "Epoch 101/200\n",
      "92/92 [==============================] - 0s 695us/step - loss: 0.9750 - accuracy: 0.5295 - val_loss: 0.9721 - val_accuracy: 0.5381\n",
      "Epoch 102/200\n",
      "92/92 [==============================] - 0s 710us/step - loss: 0.9752 - accuracy: 0.5293 - val_loss: 0.9719 - val_accuracy: 0.5381\n",
      "Epoch 103/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9749 - accuracy: 0.5286 - val_loss: 0.9720 - val_accuracy: 0.5358\n",
      "Epoch 104/200\n",
      "92/92 [==============================] - 0s 811us/step - loss: 0.9751 - accuracy: 0.5304 - val_loss: 0.9718 - val_accuracy: 0.5367\n",
      "Epoch 105/200\n",
      "92/92 [==============================] - 0s 607us/step - loss: 0.9750 - accuracy: 0.5301 - val_loss: 0.9718 - val_accuracy: 0.5372\n",
      "Epoch 106/200\n",
      "92/92 [==============================] - 0s 734us/step - loss: 0.9750 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 107/200\n",
      "92/92 [==============================] - 0s 537us/step - loss: 0.9750 - accuracy: 0.5298 - val_loss: 0.9719 - val_accuracy: 0.5367\n",
      "Epoch 108/200\n",
      "92/92 [==============================] - 0s 782us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9718 - val_accuracy: 0.5372\n",
      "Epoch 109/200\n",
      "92/92 [==============================] - 0s 581us/step - loss: 0.9749 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 110/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9750 - accuracy: 0.5292 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 111/200\n",
      "92/92 [==============================] - 0s 701us/step - loss: 0.9750 - accuracy: 0.5303 - val_loss: 0.9718 - val_accuracy: 0.5381\n",
      "Epoch 112/200\n",
      "92/92 [==============================] - 0s 602us/step - loss: 0.9749 - accuracy: 0.5298 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 113/200\n",
      "92/92 [==============================] - 0s 619us/step - loss: 0.9750 - accuracy: 0.5303 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 114/200\n",
      "92/92 [==============================] - 0s 614us/step - loss: 0.9748 - accuracy: 0.5293 - val_loss: 0.9719 - val_accuracy: 0.5376\n",
      "Epoch 115/200\n",
      "92/92 [==============================] - 0s 579us/step - loss: 0.9751 - accuracy: 0.5306 - val_loss: 0.9718 - val_accuracy: 0.5367\n",
      "Epoch 116/200\n",
      "92/92 [==============================] - 0s 680us/step - loss: 0.9749 - accuracy: 0.5288 - val_loss: 0.9720 - val_accuracy: 0.5385\n",
      "Epoch 117/200\n",
      "92/92 [==============================] - 0s 614us/step - loss: 0.9749 - accuracy: 0.5290 - val_loss: 0.9719 - val_accuracy: 0.5381\n",
      "Epoch 118/200\n",
      "92/92 [==============================] - 0s 641us/step - loss: 0.9749 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5358\n",
      "Epoch 119/200\n",
      "92/92 [==============================] - 0s 749us/step - loss: 0.9749 - accuracy: 0.5289 - val_loss: 0.9717 - val_accuracy: 0.5367\n",
      "Epoch 120/200\n",
      "92/92 [==============================] - 0s 589us/step - loss: 0.9749 - accuracy: 0.5294 - val_loss: 0.9721 - val_accuracy: 0.5385\n",
      "Epoch 121/200\n",
      "92/92 [==============================] - 0s 669us/step - loss: 0.9750 - accuracy: 0.5296 - val_loss: 0.9719 - val_accuracy: 0.5381\n",
      "Epoch 122/200\n",
      "92/92 [==============================] - 0s 540us/step - loss: 0.9748 - accuracy: 0.5300 - val_loss: 0.9718 - val_accuracy: 0.5367\n",
      "Epoch 123/200\n",
      "92/92 [==============================] - 0s 662us/step - loss: 0.9749 - accuracy: 0.5293 - val_loss: 0.9718 - val_accuracy: 0.5381\n",
      "Epoch 124/200\n",
      "92/92 [==============================] - 0s 676us/step - loss: 0.9749 - accuracy: 0.5296 - val_loss: 0.9720 - val_accuracy: 0.5385\n",
      "Epoch 125/200\n",
      "92/92 [==============================] - 0s 696us/step - loss: 0.9749 - accuracy: 0.5302 - val_loss: 0.9717 - val_accuracy: 0.5367\n",
      "Epoch 126/200\n",
      "92/92 [==============================] - 0s 621us/step - loss: 0.9749 - accuracy: 0.5295 - val_loss: 0.9719 - val_accuracy: 0.5381\n",
      "Epoch 127/200\n",
      "92/92 [==============================] - 0s 698us/step - loss: 0.9748 - accuracy: 0.5311 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 128/200\n",
      "92/92 [==============================] - 0s 670us/step - loss: 0.9749 - accuracy: 0.5297 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 129/200\n",
      "92/92 [==============================] - 0s 630us/step - loss: 0.9749 - accuracy: 0.5286 - val_loss: 0.9718 - val_accuracy: 0.5389\n",
      "Epoch 130/200\n",
      "92/92 [==============================] - 0s 777us/step - loss: 0.9748 - accuracy: 0.5302 - val_loss: 0.9717 - val_accuracy: 0.5367\n",
      "Epoch 131/200\n",
      "92/92 [==============================] - 0s 563us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9717 - val_accuracy: 0.5367\n",
      "Epoch 132/200\n",
      "92/92 [==============================] - 0s 617us/step - loss: 0.9748 - accuracy: 0.5303 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 133/200\n",
      "92/92 [==============================] - 0s 647us/step - loss: 0.9748 - accuracy: 0.5297 - val_loss: 0.9720 - val_accuracy: 0.5367\n",
      "Epoch 134/200\n",
      "92/92 [==============================] - 0s 624us/step - loss: 0.9749 - accuracy: 0.5292 - val_loss: 0.9718 - val_accuracy: 0.5367\n",
      "Epoch 135/200\n",
      "92/92 [==============================] - 0s 677us/step - loss: 0.9748 - accuracy: 0.5292 - val_loss: 0.9718 - val_accuracy: 0.5381\n",
      "Epoch 136/200\n",
      "92/92 [==============================] - 0s 697us/step - loss: 0.9748 - accuracy: 0.5298 - val_loss: 0.9719 - val_accuracy: 0.5358\n",
      "Epoch 137/200\n",
      "92/92 [==============================] - 0s 622us/step - loss: 0.9748 - accuracy: 0.5285 - val_loss: 0.9721 - val_accuracy: 0.5385\n",
      "Epoch 138/200\n",
      "92/92 [==============================] - 0s 657us/step - loss: 0.9749 - accuracy: 0.5296 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 798us/step - loss: 0.9748 - accuracy: 0.5300 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 140/200\n",
      "92/92 [==============================] - 0s 558us/step - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 141/200\n",
      "92/92 [==============================] - 0s 662us/step - loss: 0.9748 - accuracy: 0.5299 - val_loss: 0.9717 - val_accuracy: 0.5376\n",
      "Epoch 142/200\n",
      "92/92 [==============================] - 0s 694us/step - loss: 0.9748 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 143/200\n",
      "92/92 [==============================] - 0s 603us/step - loss: 0.9748 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5376\n",
      "Epoch 144/200\n",
      "92/92 [==============================] - 0s 653us/step - loss: 0.9748 - accuracy: 0.5297 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 145/200\n",
      "92/92 [==============================] - 0s 706us/step - loss: 0.9748 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 146/200\n",
      "92/92 [==============================] - 0s 602us/step - loss: 0.9748 - accuracy: 0.5298 - val_loss: 0.9720 - val_accuracy: 0.5381\n",
      "Epoch 147/200\n",
      "92/92 [==============================] - 0s 694us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9719 - val_accuracy: 0.5358\n",
      "Epoch 148/200\n",
      "92/92 [==============================] - 0s 766us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 149/200\n",
      "92/92 [==============================] - 0s 467us/step - loss: 0.9747 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5376\n",
      "Epoch 150/200\n",
      "92/92 [==============================] - 0s 555us/step - loss: 0.9748 - accuracy: 0.5296 - val_loss: 0.9716 - val_accuracy: 0.5376\n",
      "Epoch 151/200\n",
      "92/92 [==============================] - 0s 701us/step - loss: 0.9748 - accuracy: 0.5306 - val_loss: 0.9718 - val_accuracy: 0.5367\n",
      "Epoch 152/200\n",
      "92/92 [==============================] - 0s 581us/step - loss: 0.9748 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5367\n",
      "Epoch 153/200\n",
      "92/92 [==============================] - 0s 682us/step - loss: 0.9747 - accuracy: 0.5291 - val_loss: 0.9719 - val_accuracy: 0.5367\n",
      "Epoch 154/200\n",
      "92/92 [==============================] - 0s 633us/step - loss: 0.9748 - accuracy: 0.5294 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 155/200\n",
      "92/92 [==============================] - 0s 690us/step - loss: 0.9748 - accuracy: 0.5301 - val_loss: 0.9719 - val_accuracy: 0.5376\n",
      "Epoch 156/200\n",
      "92/92 [==============================] - 0s 693us/step - loss: 0.9748 - accuracy: 0.5291 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 157/200\n",
      "92/92 [==============================] - 0s 679us/step - loss: 0.9747 - accuracy: 0.5297 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 158/200\n",
      "92/92 [==============================] - 0s 685us/step - loss: 0.9747 - accuracy: 0.5302 - val_loss: 0.9719 - val_accuracy: 0.5381\n",
      "Epoch 159/200\n",
      "92/92 [==============================] - 0s 632us/step - loss: 0.9747 - accuracy: 0.5311 - val_loss: 0.9719 - val_accuracy: 0.5372\n",
      "Epoch 160/200\n",
      "92/92 [==============================] - 0s 747us/step - loss: 0.9748 - accuracy: 0.5293 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 161/200\n",
      "92/92 [==============================] - 0s 614us/step - loss: 0.9748 - accuracy: 0.5305 - val_loss: 0.9717 - val_accuracy: 0.5358\n",
      "Epoch 162/200\n",
      "92/92 [==============================] - 0s 644us/step - loss: 0.9747 - accuracy: 0.5292 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 163/200\n",
      "92/92 [==============================] - 0s 674us/step - loss: 0.9747 - accuracy: 0.5297 - val_loss: 0.9717 - val_accuracy: 0.5367\n",
      "Epoch 164/200\n",
      "92/92 [==============================] - 0s 583us/step - loss: 0.9747 - accuracy: 0.5295 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 165/200\n",
      "92/92 [==============================] - 0s 615us/step - loss: 0.9747 - accuracy: 0.5293 - val_loss: 0.9717 - val_accuracy: 0.5367\n",
      "Epoch 166/200\n",
      "92/92 [==============================] - 0s 603us/step - loss: 0.9748 - accuracy: 0.5298 - val_loss: 0.9717 - val_accuracy: 0.5367\n",
      "Epoch 167/200\n",
      "92/92 [==============================] - 0s 618us/step - loss: 0.9748 - accuracy: 0.5293 - val_loss: 0.9718 - val_accuracy: 0.5381\n",
      "Epoch 168/200\n",
      "92/92 [==============================] - 0s 534us/step - loss: 0.9747 - accuracy: 0.5299 - val_loss: 0.9717 - val_accuracy: 0.5381\n",
      "Epoch 169/200\n",
      "92/92 [==============================] - 0s 620us/step - loss: 0.9747 - accuracy: 0.5299 - val_loss: 0.9718 - val_accuracy: 0.5381\n",
      "Epoch 170/200\n",
      "92/92 [==============================] - 0s 515us/step - loss: 0.9747 - accuracy: 0.5297 - val_loss: 0.9718 - val_accuracy: 0.5389\n",
      "Epoch 171/200\n",
      "92/92 [==============================] - 0s 696us/step - loss: 0.9747 - accuracy: 0.5290 - val_loss: 0.9716 - val_accuracy: 0.5367\n",
      "Epoch 172/200\n",
      "92/92 [==============================] - 0s 616us/step - loss: 0.9747 - accuracy: 0.5301 - val_loss: 0.9719 - val_accuracy: 0.5385\n",
      "Epoch 173/200\n",
      "92/92 [==============================] - 0s 556us/step - loss: 0.9747 - accuracy: 0.5295 - val_loss: 0.9720 - val_accuracy: 0.5381\n",
      "Epoch 174/200\n",
      "92/92 [==============================] - 0s 809us/step - loss: 0.9747 - accuracy: 0.5291 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 175/200\n",
      "92/92 [==============================] - 0s 552us/step - loss: 0.9748 - accuracy: 0.5291 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 176/200\n",
      "92/92 [==============================] - 0s 637us/step - loss: 0.9748 - accuracy: 0.5298 - val_loss: 0.9716 - val_accuracy: 0.5367\n",
      "Epoch 177/200\n",
      "92/92 [==============================] - 0s 622us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9717 - val_accuracy: 0.5381\n",
      "Epoch 178/200\n",
      "92/92 [==============================] - 0s 750us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9718 - val_accuracy: 0.5358\n",
      "Epoch 179/200\n",
      "92/92 [==============================] - 0s 571us/step - loss: 0.9746 - accuracy: 0.5292 - val_loss: 0.9715 - val_accuracy: 0.5372\n",
      "Epoch 180/200\n",
      "92/92 [==============================] - 0s 689us/step - loss: 0.9747 - accuracy: 0.5290 - val_loss: 0.9718 - val_accuracy: 0.5372\n",
      "Epoch 181/200\n",
      "92/92 [==============================] - 0s 623us/step - loss: 0.9746 - accuracy: 0.5290 - val_loss: 0.9717 - val_accuracy: 0.5381\n",
      "Epoch 182/200\n",
      "92/92 [==============================] - 0s 637us/step - loss: 0.9747 - accuracy: 0.5299 - val_loss: 0.9717 - val_accuracy: 0.5389\n",
      "Epoch 183/200\n",
      "92/92 [==============================] - 0s 766us/step - loss: 0.9746 - accuracy: 0.5296 - val_loss: 0.9718 - val_accuracy: 0.5358\n",
      "Epoch 184/200\n",
      "92/92 [==============================] - 0s 568us/step - loss: 0.9746 - accuracy: 0.5290 - val_loss: 0.9720 - val_accuracy: 0.5376\n",
      "Epoch 185/200\n",
      "92/92 [==============================] - 0s 659us/step - loss: 0.9747 - accuracy: 0.5303 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 186/200\n",
      "92/92 [==============================] - 0s 634us/step - loss: 0.9746 - accuracy: 0.5290 - val_loss: 0.9716 - val_accuracy: 0.5367\n",
      "Epoch 187/200\n",
      "92/92 [==============================] - 0s 635us/step - loss: 0.9746 - accuracy: 0.5299 - val_loss: 0.9717 - val_accuracy: 0.5389\n",
      "Epoch 188/200\n",
      "92/92 [==============================] - 0s 735us/step - loss: 0.9746 - accuracy: 0.5299 - val_loss: 0.9718 - val_accuracy: 0.5376\n",
      "Epoch 189/200\n",
      "92/92 [==============================] - 0s 671us/step - loss: 0.9747 - accuracy: 0.5291 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 190/200\n",
      "92/92 [==============================] - 0s 643us/step - loss: 0.9747 - accuracy: 0.5294 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 191/200\n",
      "92/92 [==============================] - 0s 704us/step - loss: 0.9747 - accuracy: 0.5299 - val_loss: 0.9717 - val_accuracy: 0.5367\n",
      "Epoch 192/200\n",
      "92/92 [==============================] - 0s 590us/step - loss: 0.9746 - accuracy: 0.5296 - val_loss: 0.9717 - val_accuracy: 0.5372\n",
      "Epoch 193/200\n",
      "92/92 [==============================] - 0s 487us/step - loss: 0.9747 - accuracy: 0.5286 - val_loss: 0.9720 - val_accuracy: 0.5381\n",
      "Epoch 194/200\n",
      "92/92 [==============================] - 0s 550us/step - loss: 0.9747 - accuracy: 0.5292 - val_loss: 0.9716 - val_accuracy: 0.5389\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 705us/step - loss: 0.9746 - accuracy: 0.5298 - val_loss: 0.9718 - val_accuracy: 0.5381\n",
      "Epoch 196/200\n",
      "92/92 [==============================] - 0s 603us/step - loss: 0.9747 - accuracy: 0.5284 - val_loss: 0.9718 - val_accuracy: 0.5389\n",
      "Epoch 197/200\n",
      "92/92 [==============================] - 0s 652us/step - loss: 0.9746 - accuracy: 0.5301 - val_loss: 0.9718 - val_accuracy: 0.5381\n",
      "Epoch 198/200\n",
      "92/92 [==============================] - 0s 627us/step - loss: 0.9747 - accuracy: 0.5294 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 199/200\n",
      "92/92 [==============================] - 0s 681us/step - loss: 0.9747 - accuracy: 0.5274 - val_loss: 0.9716 - val_accuracy: 0.5372\n",
      "Epoch 200/200\n",
      "92/92 [==============================] - 0s 697us/step - loss: 0.9746 - accuracy: 0.5299 - val_loss: 0.9717 - val_accuracy: 0.5381\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 359us/step - loss: 0.9746 - accuracy: 0.5294\n",
      "Accuracy : 0.529411792755127\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9717 - accuracy: 0.5381\n",
      "Accuracy : 0.5380530953407288\n",
      "Fold #3\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.1427 - accuracy: 0.2899 - val_loss: 1.0965 - val_accuracy: 0.3037\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 692us/step - loss: 1.0691 - accuracy: 0.4912 - val_loss: 1.0599 - val_accuracy: 0.4754\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 761us/step - loss: 1.0449 - accuracy: 0.4931 - val_loss: 1.0479 - val_accuracy: 0.4688\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 688us/step - loss: 1.0349 - accuracy: 0.4986 - val_loss: 1.0412 - val_accuracy: 0.4759\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 769us/step - loss: 1.0265 - accuracy: 0.5035 - val_loss: 1.0350 - val_accuracy: 0.4834\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 519us/step - loss: 1.0196 - accuracy: 0.5106 - val_loss: 1.0300 - val_accuracy: 0.4852\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 1.0136 - accuracy: 0.5221 - val_loss: 1.0254 - val_accuracy: 0.5082\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 1.0074 - accuracy: 0.5247 - val_loss: 1.0208 - val_accuracy: 0.5108\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 1.0018 - accuracy: 0.5253 - val_loss: 1.0168 - val_accuracy: 0.5144\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 751us/step - loss: 0.9976 - accuracy: 0.5262 - val_loss: 1.0138 - val_accuracy: 0.5193\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9935 - accuracy: 0.5288 - val_loss: 1.0111 - val_accuracy: 0.5246\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 766us/step - loss: 0.9904 - accuracy: 0.5298 - val_loss: 1.0092 - val_accuracy: 0.5268\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 749us/step - loss: 0.9882 - accuracy: 0.5320 - val_loss: 1.0078 - val_accuracy: 0.5224\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 670us/step - loss: 0.9865 - accuracy: 0.5312 - val_loss: 1.0069 - val_accuracy: 0.5206\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9849 - accuracy: 0.5313 - val_loss: 1.0060 - val_accuracy: 0.5188\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9840 - accuracy: 0.5323 - val_loss: 1.0057 - val_accuracy: 0.5188\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9831 - accuracy: 0.5319 - val_loss: 1.0053 - val_accuracy: 0.5197\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 557us/step - loss: 0.9824 - accuracy: 0.5318 - val_loss: 1.0050 - val_accuracy: 0.5188\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9824 - accuracy: 0.5304 - val_loss: 1.0050 - val_accuracy: 0.5201\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 790us/step - loss: 0.9818 - accuracy: 0.5315 - val_loss: 1.0048 - val_accuracy: 0.5188\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 682us/step - loss: 0.9813 - accuracy: 0.5302 - val_loss: 1.0045 - val_accuracy: 0.5188\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 609us/step - loss: 0.9808 - accuracy: 0.5320 - val_loss: 1.0044 - val_accuracy: 0.5175\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9805 - accuracy: 0.5312 - val_loss: 1.0042 - val_accuracy: 0.5193\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9803 - accuracy: 0.5321 - val_loss: 1.0040 - val_accuracy: 0.5193\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 750us/step - loss: 0.9799 - accuracy: 0.5313 - val_loss: 1.0039 - val_accuracy: 0.5188\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 840us/step - loss: 0.9797 - accuracy: 0.5309 - val_loss: 1.0037 - val_accuracy: 0.5193\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9793 - accuracy: 0.5316 - val_loss: 1.0036 - val_accuracy: 0.5193\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9790 - accuracy: 0.5324 - val_loss: 1.0036 - val_accuracy: 0.5193\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 672us/step - loss: 0.9789 - accuracy: 0.5313 - val_loss: 1.0034 - val_accuracy: 0.5193\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9785 - accuracy: 0.5309 - val_loss: 1.0033 - val_accuracy: 0.5193\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9781 - accuracy: 0.5319 - val_loss: 1.0032 - val_accuracy: 0.5188\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 703us/step - loss: 0.9780 - accuracy: 0.5317 - val_loss: 1.0031 - val_accuracy: 0.5175\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 741us/step - loss: 0.9776 - accuracy: 0.5319 - val_loss: 1.0030 - val_accuracy: 0.5188\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9774 - accuracy: 0.5316 - val_loss: 1.0029 - val_accuracy: 0.5188\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9772 - accuracy: 0.5320 - val_loss: 1.0030 - val_accuracy: 0.5206\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 547us/step - loss: 0.9770 - accuracy: 0.5318 - val_loss: 1.0029 - val_accuracy: 0.5179\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 558us/step - loss: 0.9767 - accuracy: 0.5322 - val_loss: 1.0029 - val_accuracy: 0.5206\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 827us/step - loss: 0.9765 - accuracy: 0.5317 - val_loss: 1.0026 - val_accuracy: 0.5188\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9766 - accuracy: 0.5312 - val_loss: 1.0026 - val_accuracy: 0.5206\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9762 - accuracy: 0.5321 - val_loss: 1.0025 - val_accuracy: 0.5188\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 788us/step - loss: 0.9759 - accuracy: 0.5312 - val_loss: 1.0025 - val_accuracy: 0.5201\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 0.9758 - accuracy: 0.5323 - val_loss: 1.0024 - val_accuracy: 0.5175\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9757 - accuracy: 0.5310 - val_loss: 1.0025 - val_accuracy: 0.5193\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 781us/step - loss: 0.9754 - accuracy: 0.5314 - val_loss: 1.0024 - val_accuracy: 0.5193\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9752 - accuracy: 0.5322 - val_loss: 1.0026 - val_accuracy: 0.5219\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 846us/step - loss: 0.9750 - accuracy: 0.5314 - val_loss: 1.0025 - val_accuracy: 0.5224\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9751 - accuracy: 0.5310 - val_loss: 1.0025 - val_accuracy: 0.5219\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 599us/step - loss: 0.9749 - accuracy: 0.5308 - val_loss: 1.0025 - val_accuracy: 0.5224\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9748 - accuracy: 0.5320 - val_loss: 1.0025 - val_accuracy: 0.5219\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 687us/step - loss: 0.9747 - accuracy: 0.5316 - val_loss: 1.0022 - val_accuracy: 0.5201\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9743 - accuracy: 0.5313 - val_loss: 1.0020 - val_accuracy: 0.5201\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 790us/step - loss: 0.9742 - accuracy: 0.5314 - val_loss: 1.0021 - val_accuracy: 0.5201\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9744 - accuracy: 0.5314 - val_loss: 1.0021 - val_accuracy: 0.5201\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 591us/step - loss: 0.9738 - accuracy: 0.5317 - val_loss: 1.0025 - val_accuracy: 0.5246\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9743 - accuracy: 0.5300 - val_loss: 1.0025 - val_accuracy: 0.5237\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 556us/step - loss: 0.9741 - accuracy: 0.5296 - val_loss: 1.0022 - val_accuracy: 0.5219\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 536us/step - loss: 0.9738 - accuracy: 0.5297 - val_loss: 1.0021 - val_accuracy: 0.5219\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 1.0022 - val_accuracy: 0.5259\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 664us/step - loss: 0.9736 - accuracy: 0.5313 - val_loss: 1.0021 - val_accuracy: 0.5219\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 795us/step - loss: 0.9736 - accuracy: 0.5299 - val_loss: 1.0021 - val_accuracy: 0.5259\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 639us/step - loss: 0.9734 - accuracy: 0.5315 - val_loss: 1.0019 - val_accuracy: 0.5201\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9733 - accuracy: 0.5315 - val_loss: 1.0023 - val_accuracy: 0.5259\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 830us/step - loss: 0.9734 - accuracy: 0.5316 - val_loss: 1.0021 - val_accuracy: 0.5259\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9731 - accuracy: 0.5313 - val_loss: 1.0018 - val_accuracy: 0.5201\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9731 - accuracy: 0.5308 - val_loss: 1.0021 - val_accuracy: 0.5246\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 685us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 1.0019 - val_accuracy: 0.5210\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 0.9729 - accuracy: 0.5322 - val_loss: 1.0020 - val_accuracy: 0.5215\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 638us/step - loss: 0.9728 - accuracy: 0.5313 - val_loss: 1.0019 - val_accuracy: 0.5215\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 664us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 1.0023 - val_accuracy: 0.5224\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9728 - accuracy: 0.5301 - val_loss: 1.0021 - val_accuracy: 0.5259\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9726 - accuracy: 0.5316 - val_loss: 1.0017 - val_accuracy: 0.5201\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9727 - accuracy: 0.5315 - val_loss: 1.0018 - val_accuracy: 0.5215\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 726us/step - loss: 0.9725 - accuracy: 0.5318 - val_loss: 1.0023 - val_accuracy: 0.5241\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 694us/step - loss: 0.9726 - accuracy: 0.5317 - val_loss: 1.0019 - val_accuracy: 0.5219\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9723 - accuracy: 0.5315 - val_loss: 1.0019 - val_accuracy: 0.5259\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 715us/step - loss: 0.9724 - accuracy: 0.5320 - val_loss: 1.0016 - val_accuracy: 0.5219\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9724 - accuracy: 0.5301 - val_loss: 1.0021 - val_accuracy: 0.5215\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 803us/step - loss: 0.9723 - accuracy: 0.5310 - val_loss: 1.0015 - val_accuracy: 0.5215\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9724 - accuracy: 0.5317 - val_loss: 1.0016 - val_accuracy: 0.5215\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 811us/step - loss: 0.9726 - accuracy: 0.5321 - val_loss: 1.0021 - val_accuracy: 0.5241\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9722 - accuracy: 0.5303 - val_loss: 1.0018 - val_accuracy: 0.5246\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9721 - accuracy: 0.5314 - val_loss: 1.0018 - val_accuracy: 0.5210\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 725us/step - loss: 0.9721 - accuracy: 0.5323 - val_loss: 1.0020 - val_accuracy: 0.5259\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 685us/step - loss: 0.9720 - accuracy: 0.5317 - val_loss: 1.0018 - val_accuracy: 0.5246\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9720 - accuracy: 0.5308 - val_loss: 1.0018 - val_accuracy: 0.5210\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9721 - accuracy: 0.5314 - val_loss: 1.0019 - val_accuracy: 0.5246\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 741us/step - loss: 0.9719 - accuracy: 0.5312 - val_loss: 1.0020 - val_accuracy: 0.5259\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 726us/step - loss: 0.9719 - accuracy: 0.5312 - val_loss: 1.0026 - val_accuracy: 0.5246\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9720 - accuracy: 0.5317 - val_loss: 1.0025 - val_accuracy: 0.5255\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 740us/step - loss: 0.9720 - accuracy: 0.5315 - val_loss: 1.0022 - val_accuracy: 0.5241\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 568us/step - loss: 0.9719 - accuracy: 0.5318 - val_loss: 1.0021 - val_accuracy: 0.5241\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9718 - accuracy: 0.5311 - val_loss: 1.0019 - val_accuracy: 0.5210\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 579us/step - loss: 0.9722 - accuracy: 0.5320 - val_loss: 1.0022 - val_accuracy: 0.5219\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 0.9718 - accuracy: 0.5307 - val_loss: 1.0021 - val_accuracy: 0.5210\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9717 - accuracy: 0.5312 - val_loss: 1.0021 - val_accuracy: 0.5255\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9717 - accuracy: 0.5307 - val_loss: 1.0024 - val_accuracy: 0.5228\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9717 - accuracy: 0.5315 - val_loss: 1.0022 - val_accuracy: 0.5246\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9716 - accuracy: 0.5308 - val_loss: 1.0019 - val_accuracy: 0.5206\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 682us/step - loss: 0.9717 - accuracy: 0.5310 - val_loss: 1.0022 - val_accuracy: 0.5246\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 800us/step - loss: 0.9716 - accuracy: 0.5308 - val_loss: 1.0020 - val_accuracy: 0.5250\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9718 - accuracy: 0.5316 - val_loss: 1.0017 - val_accuracy: 0.5210\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 665us/step - loss: 0.9715 - accuracy: 0.5309 - val_loss: 1.0018 - val_accuracy: 0.5210\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9718 - accuracy: 0.5302 - val_loss: 1.0020 - val_accuracy: 0.5241\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 665us/step - loss: 0.9717 - accuracy: 0.5309 - val_loss: 1.0020 - val_accuracy: 0.5241\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9717 - accuracy: 0.5305 - val_loss: 1.0022 - val_accuracy: 0.5224\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 557us/step - loss: 0.9715 - accuracy: 0.5312 - val_loss: 1.0022 - val_accuracy: 0.5255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9716 - accuracy: 0.5308 - val_loss: 1.0022 - val_accuracy: 0.5246\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 783us/step - loss: 0.9715 - accuracy: 0.5315 - val_loss: 1.0020 - val_accuracy: 0.5210\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 685us/step - loss: 0.9714 - accuracy: 0.5307 - val_loss: 1.0020 - val_accuracy: 0.5210\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9716 - accuracy: 0.5308 - val_loss: 1.0024 - val_accuracy: 0.5228\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 673us/step - loss: 0.9715 - accuracy: 0.5316 - val_loss: 1.0023 - val_accuracy: 0.5246\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 0.9714 - accuracy: 0.5310 - val_loss: 1.0020 - val_accuracy: 0.5210\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9715 - accuracy: 0.5310 - val_loss: 1.0021 - val_accuracy: 0.5250\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 618us/step - loss: 0.9715 - accuracy: 0.5299 - val_loss: 1.0021 - val_accuracy: 0.5250\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 740us/step - loss: 0.9714 - accuracy: 0.5305 - val_loss: 1.0021 - val_accuracy: 0.5215\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9716 - accuracy: 0.5310 - val_loss: 1.0023 - val_accuracy: 0.5215\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9716 - accuracy: 0.5315 - val_loss: 1.0022 - val_accuracy: 0.5246\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9715 - accuracy: 0.5323 - val_loss: 1.0023 - val_accuracy: 0.5255\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 637us/step - loss: 0.9714 - accuracy: 0.5304 - val_loss: 1.0022 - val_accuracy: 0.5241\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9714 - accuracy: 0.5312 - val_loss: 1.0023 - val_accuracy: 0.5237\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 830us/step - loss: 0.9715 - accuracy: 0.5308 - val_loss: 1.0021 - val_accuracy: 0.5241\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 552us/step - loss: 0.9714 - accuracy: 0.5309 - val_loss: 1.0020 - val_accuracy: 0.5210\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 790us/step - loss: 0.9714 - accuracy: 0.5321 - val_loss: 1.0018 - val_accuracy: 0.5241\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9714 - accuracy: 0.5310 - val_loss: 1.0018 - val_accuracy: 0.5241\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 816us/step - loss: 0.9714 - accuracy: 0.5316 - val_loss: 1.0018 - val_accuracy: 0.5255\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 525us/step - loss: 0.9717 - accuracy: 0.5316 - val_loss: 1.0020 - val_accuracy: 0.5232\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 568us/step - loss: 0.9714 - accuracy: 0.5301 - val_loss: 1.0020 - val_accuracy: 0.5228\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9716 - accuracy: 0.5304 - val_loss: 1.0021 - val_accuracy: 0.5241\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 0.9712 - accuracy: 0.5313 - val_loss: 1.0022 - val_accuracy: 0.5237\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9713 - accuracy: 0.5304 - val_loss: 1.0021 - val_accuracy: 0.5232\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 776us/step - loss: 0.9713 - accuracy: 0.5307 - val_loss: 1.0022 - val_accuracy: 0.5232\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9717 - accuracy: 0.5287 - val_loss: 1.0025 - val_accuracy: 0.5237\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9713 - accuracy: 0.5311 - val_loss: 1.0023 - val_accuracy: 0.5232\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9712 - accuracy: 0.5308 - val_loss: 1.0027 - val_accuracy: 0.5232\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 539us/step - loss: 0.9714 - accuracy: 0.5309 - val_loss: 1.0026 - val_accuracy: 0.5232\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 705us/step - loss: 0.9715 - accuracy: 0.5311 - val_loss: 1.0025 - val_accuracy: 0.5237\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 795us/step - loss: 0.9713 - accuracy: 0.5302 - val_loss: 1.0019 - val_accuracy: 0.5206\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 849us/step - loss: 0.9714 - accuracy: 0.5316 - val_loss: 1.0024 - val_accuracy: 0.5232\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9713 - accuracy: 0.5304 - val_loss: 1.0026 - val_accuracy: 0.5246\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 849us/step - loss: 0.9712 - accuracy: 0.5300 - val_loss: 1.0029 - val_accuracy: 0.5237\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 676us/step - loss: 0.9714 - accuracy: 0.5307 - val_loss: 1.0022 - val_accuracy: 0.5255\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 726us/step - loss: 0.9713 - accuracy: 0.5309 - val_loss: 1.0026 - val_accuracy: 0.5255\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 745us/step - loss: 0.9713 - accuracy: 0.5320 - val_loss: 1.0024 - val_accuracy: 0.5206\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9712 - accuracy: 0.5317 - val_loss: 1.0020 - val_accuracy: 0.5210\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 813us/step - loss: 0.9713 - accuracy: 0.5312 - val_loss: 1.0019 - val_accuracy: 0.5210\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9713 - accuracy: 0.5322 - val_loss: 1.0021 - val_accuracy: 0.5228\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 793us/step - loss: 0.9712 - accuracy: 0.5319 - val_loss: 1.0021 - val_accuracy: 0.5246\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9713 - accuracy: 0.5304 - val_loss: 1.0027 - val_accuracy: 0.5224\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 818us/step - loss: 0.9714 - accuracy: 0.5310 - val_loss: 1.0022 - val_accuracy: 0.5210\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9712 - accuracy: 0.5316 - val_loss: 1.0029 - val_accuracy: 0.5237\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9711 - accuracy: 0.5311 - val_loss: 1.0023 - val_accuracy: 0.5224\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 707us/step - loss: 0.9712 - accuracy: 0.5314 - val_loss: 1.0021 - val_accuracy: 0.5246\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9713 - accuracy: 0.5316 - val_loss: 1.0025 - val_accuracy: 0.5241\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 693us/step - loss: 0.9712 - accuracy: 0.5319 - val_loss: 1.0022 - val_accuracy: 0.5246\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9714 - accuracy: 0.5312 - val_loss: 1.0021 - val_accuracy: 0.5246\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 515us/step - loss: 0.9712 - accuracy: 0.5310 - val_loss: 1.0022 - val_accuracy: 0.5224\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 537us/step - loss: 0.9711 - accuracy: 0.5310 - val_loss: 1.0022 - val_accuracy: 0.5206\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9712 - accuracy: 0.5316 - val_loss: 1.0027 - val_accuracy: 0.5237\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9712 - accuracy: 0.5308 - val_loss: 1.0022 - val_accuracy: 0.5241\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9712 - accuracy: 0.5318 - val_loss: 1.0021 - val_accuracy: 0.5228\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 820us/step - loss: 0.9712 - accuracy: 0.5317 - val_loss: 1.0024 - val_accuracy: 0.5228\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 669us/step - loss: 0.9713 - accuracy: 0.5309 - val_loss: 1.0022 - val_accuracy: 0.5241\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 594us/step - loss: 0.9712 - accuracy: 0.5307 - val_loss: 1.0021 - val_accuracy: 0.5250\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 704us/step - loss: 0.9714 - accuracy: 0.5316 - val_loss: 1.0024 - val_accuracy: 0.5232\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 681us/step - loss: 0.9713 - accuracy: 0.5308 - val_loss: 1.0028 - val_accuracy: 0.5232\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9713 - accuracy: 0.5314 - val_loss: 1.0027 - val_accuracy: 0.5232\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 797us/step - loss: 0.9711 - accuracy: 0.5315 - val_loss: 1.0026 - val_accuracy: 0.5228\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9712 - accuracy: 0.5319 - val_loss: 1.0028 - val_accuracy: 0.5237\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9713 - accuracy: 0.5309 - val_loss: 1.0023 - val_accuracy: 0.5232\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 843us/step - loss: 0.9712 - accuracy: 0.5311 - val_loss: 1.0022 - val_accuracy: 0.5232\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 552us/step - loss: 0.9712 - accuracy: 0.5308 - val_loss: 1.0019 - val_accuracy: 0.5210\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 795us/step - loss: 0.9713 - accuracy: 0.5321 - val_loss: 1.0024 - val_accuracy: 0.5232\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9712 - accuracy: 0.5307 - val_loss: 1.0019 - val_accuracy: 0.5259\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9713 - accuracy: 0.5313 - val_loss: 1.0020 - val_accuracy: 0.5241\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9711 - accuracy: 0.5312 - val_loss: 1.0018 - val_accuracy: 0.5259\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 688us/step - loss: 0.9712 - accuracy: 0.5307 - val_loss: 1.0019 - val_accuracy: 0.5206\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9711 - accuracy: 0.5304 - val_loss: 1.0019 - val_accuracy: 0.5210\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 787us/step - loss: 0.9711 - accuracy: 0.5310 - val_loss: 1.0025 - val_accuracy: 0.5237\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9712 - accuracy: 0.5310 - val_loss: 1.0020 - val_accuracy: 0.5246\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9712 - accuracy: 0.5313 - val_loss: 1.0021 - val_accuracy: 0.5241\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9712 - accuracy: 0.5316 - val_loss: 1.0018 - val_accuracy: 0.5250\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 0.9711 - accuracy: 0.5313 - val_loss: 1.0017 - val_accuracy: 0.5241\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 552us/step - loss: 0.9711 - accuracy: 0.5301 - val_loss: 1.0018 - val_accuracy: 0.5232\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 746us/step - loss: 0.9712 - accuracy: 0.5310 - val_loss: 1.0016 - val_accuracy: 0.5210\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 752us/step - loss: 0.9713 - accuracy: 0.5308 - val_loss: 1.0021 - val_accuracy: 0.5237\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9713 - accuracy: 0.5311 - val_loss: 1.0018 - val_accuracy: 0.5232\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 839us/step - loss: 0.9711 - accuracy: 0.5306 - val_loss: 1.0019 - val_accuracy: 0.5232\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 543us/step - loss: 0.9714 - accuracy: 0.5308 - val_loss: 1.0024 - val_accuracy: 0.5206\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9712 - accuracy: 0.5306 - val_loss: 1.0017 - val_accuracy: 0.5232\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 774us/step - loss: 0.9710 - accuracy: 0.5310 - val_loss: 1.0015 - val_accuracy: 0.5210\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9711 - accuracy: 0.5308 - val_loss: 1.0016 - val_accuracy: 0.5241\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9711 - accuracy: 0.5307 - val_loss: 1.0018 - val_accuracy: 0.5246\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9713 - accuracy: 0.5314 - val_loss: 1.0020 - val_accuracy: 0.5232\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9711 - accuracy: 0.5306 - val_loss: 1.0027 - val_accuracy: 0.5237\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9712 - accuracy: 0.5310 - val_loss: 1.0026 - val_accuracy: 0.5232\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9711 - accuracy: 0.5307 - val_loss: 1.0020 - val_accuracy: 0.5224\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 590us/step - loss: 0.9712 - accuracy: 0.5311 - val_loss: 1.0020 - val_accuracy: 0.5210\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 649us/step - loss: 0.9710 - accuracy: 0.5313 - val_loss: 1.0020 - val_accuracy: 0.5237\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 693us/step - loss: 0.9710 - accuracy: 0.5314 - val_loss: 1.0021 - val_accuracy: 0.5232\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 0.9712 - accuracy: 0.5305 - val_loss: 1.0017 - val_accuracy: 0.5224\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 370us/step - loss: 0.9709 - accuracy: 0.5315\n",
      "Accuracy : 0.531500518321991\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0017 - accuracy: 0.5224\n",
      "Accuracy : 0.5223550200462341\n",
      "Fold #4\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0658 - accuracy: 0.4591 - val_loss: 1.0608 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 1.0559 - accuracy: 0.4591 - val_loss: 1.0556 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 1.0491 - accuracy: 0.4591 - val_loss: 1.0506 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 839us/step - loss: 1.0427 - accuracy: 0.4591 - val_loss: 1.0457 - val_accuracy: 0.4591\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 1.0358 - accuracy: 0.4591 - val_loss: 1.0395 - val_accuracy: 0.4591\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 660us/step - loss: 1.0222 - accuracy: 0.4687 - val_loss: 1.0266 - val_accuracy: 0.4799\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 1.0084 - accuracy: 0.5122 - val_loss: 1.0196 - val_accuracy: 0.4923\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9998 - accuracy: 0.5226 - val_loss: 1.0144 - val_accuracy: 0.5038\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9933 - accuracy: 0.5291 - val_loss: 1.0112 - val_accuracy: 0.5175\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 709us/step - loss: 0.9893 - accuracy: 0.5290 - val_loss: 1.0093 - val_accuracy: 0.5126\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 538us/step - loss: 0.9864 - accuracy: 0.5311 - val_loss: 1.0082 - val_accuracy: 0.5082\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 810us/step - loss: 0.9843 - accuracy: 0.5330 - val_loss: 1.0077 - val_accuracy: 0.5073\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9832 - accuracy: 0.5320 - val_loss: 1.0074 - val_accuracy: 0.5073\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9823 - accuracy: 0.5329 - val_loss: 1.0073 - val_accuracy: 0.5073\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 883us/step - loss: 0.9821 - accuracy: 0.5311 - val_loss: 1.0072 - val_accuracy: 0.5100\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9811 - accuracy: 0.5324 - val_loss: 1.0070 - val_accuracy: 0.5073\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9811 - accuracy: 0.5300 - val_loss: 1.0069 - val_accuracy: 0.5073\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 721us/step - loss: 0.9803 - accuracy: 0.5315 - val_loss: 1.0068 - val_accuracy: 0.5073\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9797 - accuracy: 0.5323 - val_loss: 1.0067 - val_accuracy: 0.5082\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9795 - accuracy: 0.5320 - val_loss: 1.0066 - val_accuracy: 0.5073\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9790 - accuracy: 0.5321 - val_loss: 1.0065 - val_accuracy: 0.5082\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9786 - accuracy: 0.5313 - val_loss: 1.0062 - val_accuracy: 0.5073\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9785 - accuracy: 0.5307 - val_loss: 1.0060 - val_accuracy: 0.5073\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9785 - accuracy: 0.5318 - val_loss: 1.0057 - val_accuracy: 0.5073\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9776 - accuracy: 0.5330 - val_loss: 1.0056 - val_accuracy: 0.5073\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9775 - accuracy: 0.5335 - val_loss: 1.0055 - val_accuracy: 0.5073\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 786us/step - loss: 0.9772 - accuracy: 0.5322 - val_loss: 1.0055 - val_accuracy: 0.5073\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 839us/step - loss: 0.9768 - accuracy: 0.5329 - val_loss: 1.0053 - val_accuracy: 0.5086\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9767 - accuracy: 0.5339 - val_loss: 1.0051 - val_accuracy: 0.5086\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 818us/step - loss: 0.9761 - accuracy: 0.5335 - val_loss: 1.0048 - val_accuracy: 0.5100\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 850us/step - loss: 0.9762 - accuracy: 0.5313 - val_loss: 1.0047 - val_accuracy: 0.5082\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9756 - accuracy: 0.5336 - val_loss: 1.0046 - val_accuracy: 0.5082\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9755 - accuracy: 0.5333 - val_loss: 1.0045 - val_accuracy: 0.5082\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 813us/step - loss: 0.9752 - accuracy: 0.5329 - val_loss: 1.0042 - val_accuracy: 0.5100\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 760us/step - loss: 0.9753 - accuracy: 0.5330 - val_loss: 1.0043 - val_accuracy: 0.5082\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9748 - accuracy: 0.5326 - val_loss: 1.0040 - val_accuracy: 0.5082\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 704us/step - loss: 0.9754 - accuracy: 0.5318 - val_loss: 1.0037 - val_accuracy: 0.5069\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9746 - accuracy: 0.5327 - val_loss: 1.0038 - val_accuracy: 0.5069\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9746 - accuracy: 0.5316 - val_loss: 1.0038 - val_accuracy: 0.5077\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9743 - accuracy: 0.5331 - val_loss: 1.0040 - val_accuracy: 0.5082\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9742 - accuracy: 0.5325 - val_loss: 1.0041 - val_accuracy: 0.5100\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9740 - accuracy: 0.5326 - val_loss: 1.0039 - val_accuracy: 0.5073\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 725us/step - loss: 0.9741 - accuracy: 0.5327 - val_loss: 1.0039 - val_accuracy: 0.5091\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9738 - accuracy: 0.5326 - val_loss: 1.0036 - val_accuracy: 0.5082\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9738 - accuracy: 0.5316 - val_loss: 1.0035 - val_accuracy: 0.5100\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9737 - accuracy: 0.5329 - val_loss: 1.0036 - val_accuracy: 0.5077\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 736us/step - loss: 0.9736 - accuracy: 0.5327 - val_loss: 1.0037 - val_accuracy: 0.5069\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 679us/step - loss: 0.9735 - accuracy: 0.5332 - val_loss: 1.0039 - val_accuracy: 0.5095\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9734 - accuracy: 0.5329 - val_loss: 1.0033 - val_accuracy: 0.5069\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 569us/step - loss: 0.9735 - accuracy: 0.5326 - val_loss: 1.0034 - val_accuracy: 0.5073\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 811us/step - loss: 0.9733 - accuracy: 0.5321 - val_loss: 1.0036 - val_accuracy: 0.5100\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9731 - accuracy: 0.5323 - val_loss: 1.0035 - val_accuracy: 0.5100\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9731 - accuracy: 0.5336 - val_loss: 1.0034 - val_accuracy: 0.5100\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9732 - accuracy: 0.5333 - val_loss: 1.0033 - val_accuracy: 0.5091\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9728 - accuracy: 0.5322 - val_loss: 1.0036 - val_accuracy: 0.5082\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9729 - accuracy: 0.5313 - val_loss: 1.0033 - val_accuracy: 0.5104\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9728 - accuracy: 0.5323 - val_loss: 1.0033 - val_accuracy: 0.5082\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9726 - accuracy: 0.5321 - val_loss: 1.0033 - val_accuracy: 0.5077\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 613us/step - loss: 0.9725 - accuracy: 0.5331 - val_loss: 1.0033 - val_accuracy: 0.5082\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9727 - accuracy: 0.5326 - val_loss: 1.0034 - val_accuracy: 0.5086\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9724 - accuracy: 0.5319 - val_loss: 1.0030 - val_accuracy: 0.5073\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9729 - accuracy: 0.5333 - val_loss: 1.0029 - val_accuracy: 0.5082\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9724 - accuracy: 0.5324 - val_loss: 1.0030 - val_accuracy: 0.5082\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9725 - accuracy: 0.5327 - val_loss: 1.0031 - val_accuracy: 0.5077\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9725 - accuracy: 0.5328 - val_loss: 1.0032 - val_accuracy: 0.5082\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9722 - accuracy: 0.5327 - val_loss: 1.0033 - val_accuracy: 0.5126\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9723 - accuracy: 0.5321 - val_loss: 1.0029 - val_accuracy: 0.5091\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9721 - accuracy: 0.5328 - val_loss: 1.0033 - val_accuracy: 0.5126\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9722 - accuracy: 0.5329 - val_loss: 1.0030 - val_accuracy: 0.5082\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 745us/step - loss: 0.9722 - accuracy: 0.5324 - val_loss: 1.0030 - val_accuracy: 0.5122\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9721 - accuracy: 0.5315 - val_loss: 1.0029 - val_accuracy: 0.5100\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 713us/step - loss: 0.9722 - accuracy: 0.5329 - val_loss: 1.0030 - val_accuracy: 0.5086\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9720 - accuracy: 0.5318 - val_loss: 1.0031 - val_accuracy: 0.5082\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9719 - accuracy: 0.5334 - val_loss: 1.0030 - val_accuracy: 0.5064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9725 - accuracy: 0.5316 - val_loss: 1.0029 - val_accuracy: 0.5126\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9719 - accuracy: 0.5314 - val_loss: 1.0031 - val_accuracy: 0.5139\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 733us/step - loss: 0.9721 - accuracy: 0.5311 - val_loss: 1.0034 - val_accuracy: 0.5139\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9721 - accuracy: 0.5313 - val_loss: 1.0028 - val_accuracy: 0.5126\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9718 - accuracy: 0.5328 - val_loss: 1.0030 - val_accuracy: 0.5122\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9719 - accuracy: 0.5316 - val_loss: 1.0029 - val_accuracy: 0.5082\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 733us/step - loss: 0.9719 - accuracy: 0.5321 - val_loss: 1.0031 - val_accuracy: 0.5122\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9719 - accuracy: 0.5317 - val_loss: 1.0031 - val_accuracy: 0.5144\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9719 - accuracy: 0.5323 - val_loss: 1.0030 - val_accuracy: 0.5126\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9718 - accuracy: 0.5318 - val_loss: 1.0027 - val_accuracy: 0.5073\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9716 - accuracy: 0.5332 - val_loss: 1.0029 - val_accuracy: 0.5122\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9717 - accuracy: 0.5328 - val_loss: 1.0031 - val_accuracy: 0.5122\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9717 - accuracy: 0.5315 - val_loss: 1.0028 - val_accuracy: 0.5126\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9718 - accuracy: 0.5322 - val_loss: 1.0027 - val_accuracy: 0.5126\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9716 - accuracy: 0.5324 - val_loss: 1.0030 - val_accuracy: 0.5131\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9718 - accuracy: 0.5315 - val_loss: 1.0031 - val_accuracy: 0.5144\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 786us/step - loss: 0.9718 - accuracy: 0.5323 - val_loss: 1.0033 - val_accuracy: 0.5139\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 829us/step - loss: 0.9718 - accuracy: 0.5313 - val_loss: 1.0028 - val_accuracy: 0.5082\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9717 - accuracy: 0.5317 - val_loss: 1.0029 - val_accuracy: 0.5086\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9719 - accuracy: 0.5325 - val_loss: 1.0029 - val_accuracy: 0.5073\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9718 - accuracy: 0.5328 - val_loss: 1.0028 - val_accuracy: 0.5091\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9717 - accuracy: 0.5330 - val_loss: 1.0028 - val_accuracy: 0.5095\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9715 - accuracy: 0.5324 - val_loss: 1.0029 - val_accuracy: 0.5082\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9717 - accuracy: 0.5327 - val_loss: 1.0029 - val_accuracy: 0.5122\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9717 - accuracy: 0.5309 - val_loss: 1.0024 - val_accuracy: 0.5113\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9719 - accuracy: 0.5311 - val_loss: 1.0024 - val_accuracy: 0.5126\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 0.9716 - accuracy: 0.5325 - val_loss: 1.0026 - val_accuracy: 0.5144\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9717 - accuracy: 0.5333 - val_loss: 1.0024 - val_accuracy: 0.5073\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9716 - accuracy: 0.5338 - val_loss: 1.0029 - val_accuracy: 0.5139\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 720us/step - loss: 0.9718 - accuracy: 0.5309 - val_loss: 1.0026 - val_accuracy: 0.5144\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 698us/step - loss: 0.9715 - accuracy: 0.5328 - val_loss: 1.0029 - val_accuracy: 0.5139\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9716 - accuracy: 0.5316 - val_loss: 1.0027 - val_accuracy: 0.5117\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 795us/step - loss: 0.9714 - accuracy: 0.5334 - val_loss: 1.0028 - val_accuracy: 0.5113\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 698us/step - loss: 0.9714 - accuracy: 0.5331 - val_loss: 1.0027 - val_accuracy: 0.5073\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 731us/step - loss: 0.9718 - accuracy: 0.5336 - val_loss: 1.0027 - val_accuracy: 0.5073\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9716 - accuracy: 0.5327 - val_loss: 1.0030 - val_accuracy: 0.5139\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9715 - accuracy: 0.5325 - val_loss: 1.0030 - val_accuracy: 0.5135\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9715 - accuracy: 0.5318 - val_loss: 1.0031 - val_accuracy: 0.5135\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9716 - accuracy: 0.5309 - val_loss: 1.0029 - val_accuracy: 0.5117\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 733us/step - loss: 0.9714 - accuracy: 0.5320 - val_loss: 1.0027 - val_accuracy: 0.5073\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9716 - accuracy: 0.5324 - val_loss: 1.0028 - val_accuracy: 0.5113\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9714 - accuracy: 0.5307 - val_loss: 1.0026 - val_accuracy: 0.5122\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9716 - accuracy: 0.5298 - val_loss: 1.0024 - val_accuracy: 0.5113\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9717 - accuracy: 0.5324 - val_loss: 1.0028 - val_accuracy: 0.5162\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9715 - accuracy: 0.5312 - val_loss: 1.0029 - val_accuracy: 0.5139\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9715 - accuracy: 0.5309 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 733us/step - loss: 0.9715 - accuracy: 0.5312 - val_loss: 1.0029 - val_accuracy: 0.5131\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9714 - accuracy: 0.5322 - val_loss: 1.0027 - val_accuracy: 0.5113\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 672us/step - loss: 0.9714 - accuracy: 0.5306 - val_loss: 1.0025 - val_accuracy: 0.5117\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9714 - accuracy: 0.5309 - val_loss: 1.0028 - val_accuracy: 0.5073\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9716 - accuracy: 0.5328 - val_loss: 1.0030 - val_accuracy: 0.5135\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 829us/step - loss: 0.9713 - accuracy: 0.5324 - val_loss: 1.0028 - val_accuracy: 0.5117\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 561us/step - loss: 0.9715 - accuracy: 0.5313 - val_loss: 1.0028 - val_accuracy: 0.5135\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 771us/step - loss: 0.9714 - accuracy: 0.5319 - val_loss: 1.0032 - val_accuracy: 0.5157\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 754us/step - loss: 0.9714 - accuracy: 0.5326 - val_loss: 1.0028 - val_accuracy: 0.5113\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9713 - accuracy: 0.5331 - val_loss: 1.0030 - val_accuracy: 0.5131\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 765us/step - loss: 0.9715 - accuracy: 0.5315 - val_loss: 1.0030 - val_accuracy: 0.5113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 718us/step - loss: 0.9714 - accuracy: 0.5322 - val_loss: 1.0030 - val_accuracy: 0.5069\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9718 - accuracy: 0.5323 - val_loss: 1.0027 - val_accuracy: 0.5113\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9714 - accuracy: 0.5313 - val_loss: 1.0024 - val_accuracy: 0.5113\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 817us/step - loss: 0.9714 - accuracy: 0.5314 - val_loss: 1.0022 - val_accuracy: 0.5117\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 544us/step - loss: 0.9713 - accuracy: 0.5322 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 0.9715 - accuracy: 0.5310 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 847us/step - loss: 0.9713 - accuracy: 0.5314 - val_loss: 1.0025 - val_accuracy: 0.5082\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 543us/step - loss: 0.9721 - accuracy: 0.5331 - val_loss: 1.0024 - val_accuracy: 0.5157\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 0.9715 - accuracy: 0.5309 - val_loss: 1.0025 - val_accuracy: 0.5131\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 782us/step - loss: 0.9713 - accuracy: 0.5315 - val_loss: 1.0025 - val_accuracy: 0.5113\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9713 - accuracy: 0.5332 - val_loss: 1.0029 - val_accuracy: 0.5131\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 0.9714 - accuracy: 0.5324 - val_loss: 1.0028 - val_accuracy: 0.5131\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9714 - accuracy: 0.5320 - val_loss: 1.0028 - val_accuracy: 0.5113\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 515us/step - loss: 0.9715 - accuracy: 0.5321 - val_loss: 1.0027 - val_accuracy: 0.5117\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 726us/step - loss: 0.9712 - accuracy: 0.5331 - val_loss: 1.0030 - val_accuracy: 0.5131\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 549us/step - loss: 0.9715 - accuracy: 0.5314 - val_loss: 1.0026 - val_accuracy: 0.5095\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 694us/step - loss: 0.9714 - accuracy: 0.5325 - val_loss: 1.0025 - val_accuracy: 0.5073\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 850us/step - loss: 0.9716 - accuracy: 0.5333 - val_loss: 1.0024 - val_accuracy: 0.5113\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 548us/step - loss: 0.9714 - accuracy: 0.5332 - val_loss: 1.0027 - val_accuracy: 0.5135\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 758us/step - loss: 0.9719 - accuracy: 0.5312 - val_loss: 1.0026 - val_accuracy: 0.5135\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 791us/step - loss: 0.9713 - accuracy: 0.5313 - val_loss: 1.0026 - val_accuracy: 0.5135\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 561us/step - loss: 0.9714 - accuracy: 0.5318 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 830us/step - loss: 0.9714 - accuracy: 0.5327 - val_loss: 1.0025 - val_accuracy: 0.5117\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9712 - accuracy: 0.5326 - val_loss: 1.0031 - val_accuracy: 0.5162\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9715 - accuracy: 0.5316 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 769us/step - loss: 0.9713 - accuracy: 0.5334 - val_loss: 1.0028 - val_accuracy: 0.5131\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 756us/step - loss: 0.9713 - accuracy: 0.5329 - val_loss: 1.0025 - val_accuracy: 0.5117\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 604us/step - loss: 0.9713 - accuracy: 0.5321 - val_loss: 1.0027 - val_accuracy: 0.5117\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 794us/step - loss: 0.9714 - accuracy: 0.5327 - val_loss: 1.0025 - val_accuracy: 0.5117\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9714 - accuracy: 0.5325 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 818us/step - loss: 0.9713 - accuracy: 0.5331 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9712 - accuracy: 0.5327 - val_loss: 1.0027 - val_accuracy: 0.5113\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 777us/step - loss: 0.9713 - accuracy: 0.5314 - val_loss: 1.0025 - val_accuracy: 0.5082\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9715 - accuracy: 0.5331 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 750us/step - loss: 0.9713 - accuracy: 0.5313 - val_loss: 1.0026 - val_accuracy: 0.5086\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9714 - accuracy: 0.5325 - val_loss: 1.0025 - val_accuracy: 0.5117\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 807us/step - loss: 0.9713 - accuracy: 0.5322 - val_loss: 1.0025 - val_accuracy: 0.5117\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 782us/step - loss: 0.9713 - accuracy: 0.5323 - val_loss: 1.0026 - val_accuracy: 0.5073\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9713 - accuracy: 0.5325 - val_loss: 1.0028 - val_accuracy: 0.5122\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 774us/step - loss: 0.9713 - accuracy: 0.5327 - val_loss: 1.0027 - val_accuracy: 0.5117\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 762us/step - loss: 0.9712 - accuracy: 0.5339 - val_loss: 1.0027 - val_accuracy: 0.5117\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9714 - accuracy: 0.5333 - val_loss: 1.0026 - val_accuracy: 0.5073\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 768us/step - loss: 0.9712 - accuracy: 0.5320 - val_loss: 1.0027 - val_accuracy: 0.5131\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 746us/step - loss: 0.9712 - accuracy: 0.5323 - val_loss: 1.0028 - val_accuracy: 0.5113\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 615us/step - loss: 0.9712 - accuracy: 0.5327 - val_loss: 1.0027 - val_accuracy: 0.5117\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9713 - accuracy: 0.5326 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 786us/step - loss: 0.9712 - accuracy: 0.5325 - val_loss: 1.0029 - val_accuracy: 0.5131\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9712 - accuracy: 0.5321 - val_loss: 1.0027 - val_accuracy: 0.5117\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 803us/step - loss: 0.9712 - accuracy: 0.5322 - val_loss: 1.0028 - val_accuracy: 0.5091\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 817us/step - loss: 0.9713 - accuracy: 0.5329 - val_loss: 1.0027 - val_accuracy: 0.5082\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9717 - accuracy: 0.5322 - val_loss: 1.0024 - val_accuracy: 0.5117\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 762us/step - loss: 0.9713 - accuracy: 0.5324 - val_loss: 1.0026 - val_accuracy: 0.5122\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 848us/step - loss: 0.9713 - accuracy: 0.5322 - val_loss: 1.0027 - val_accuracy: 0.5117\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 541us/step - loss: 0.9715 - accuracy: 0.5328 - val_loss: 1.0025 - val_accuracy: 0.5073\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9712 - accuracy: 0.5311 - val_loss: 1.0024 - val_accuracy: 0.5135\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 821us/step - loss: 0.9713 - accuracy: 0.5322 - val_loss: 1.0026 - val_accuracy: 0.5113\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 700us/step - loss: 0.9713 - accuracy: 0.5322 - val_loss: 1.0028 - val_accuracy: 0.5131\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9714 - accuracy: 0.5311 - val_loss: 1.0026 - val_accuracy: 0.5131\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9712 - accuracy: 0.5317 - val_loss: 1.0027 - val_accuracy: 0.5113\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9712 - accuracy: 0.5324 - val_loss: 1.0025 - val_accuracy: 0.5117\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9712 - accuracy: 0.5334 - val_loss: 1.0025 - val_accuracy: 0.5113\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 708us/step - loss: 0.9714 - accuracy: 0.5315 - val_loss: 1.0025 - val_accuracy: 0.5073\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9714 - accuracy: 0.5330 - val_loss: 1.0023 - val_accuracy: 0.5113\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9712 - accuracy: 0.5329 - val_loss: 1.0025 - val_accuracy: 0.5117\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9712 - accuracy: 0.5317 - val_loss: 1.0028 - val_accuracy: 0.5131\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 724us/step - loss: 0.9712 - accuracy: 0.5312 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9712 - accuracy: 0.5321 - val_loss: 1.0027 - val_accuracy: 0.5117\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9711 - accuracy: 0.5311 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9712 - accuracy: 0.5331 - val_loss: 1.0026 - val_accuracy: 0.5117\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 383us/step - loss: 0.9710 - accuracy: 0.5332\n",
      "Accuracy : 0.5332218408584595\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 1.0026 - accuracy: 0.5117\n",
      "Accuracy : 0.5117308497428894\n",
      "Fold #5\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0777 - accuracy: 0.4217 - val_loss: 1.0671 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 817us/step - loss: 1.0610 - accuracy: 0.4591 - val_loss: 1.0575 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 1.0521 - accuracy: 0.4591 - val_loss: 1.0492 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 1.0435 - accuracy: 0.4591 - val_loss: 1.0418 - val_accuracy: 0.4591\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 1.0341 - accuracy: 0.4591 - val_loss: 1.0330 - val_accuracy: 0.4591\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 1.0241 - accuracy: 0.4810 - val_loss: 1.0241 - val_accuracy: 0.4998\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 1.0143 - accuracy: 0.5145 - val_loss: 1.0161 - val_accuracy: 0.5166\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 1.0059 - accuracy: 0.5222 - val_loss: 1.0099 - val_accuracy: 0.5201\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9990 - accuracy: 0.5276 - val_loss: 1.0050 - val_accuracy: 0.5246\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9936 - accuracy: 0.5300 - val_loss: 1.0014 - val_accuracy: 0.5277\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9900 - accuracy: 0.5306 - val_loss: 0.9993 - val_accuracy: 0.5263\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9879 - accuracy: 0.5313 - val_loss: 0.9979 - val_accuracy: 0.5224\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9858 - accuracy: 0.5316 - val_loss: 0.9968 - val_accuracy: 0.5224\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9848 - accuracy: 0.5317 - val_loss: 0.9963 - val_accuracy: 0.5246\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9844 - accuracy: 0.5304 - val_loss: 0.9959 - val_accuracy: 0.5193\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9836 - accuracy: 0.5284 - val_loss: 0.9954 - val_accuracy: 0.5193\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9828 - accuracy: 0.5312 - val_loss: 0.9951 - val_accuracy: 0.5184\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9821 - accuracy: 0.5298 - val_loss: 0.9947 - val_accuracy: 0.5184\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 532us/step - loss: 0.9819 - accuracy: 0.5312 - val_loss: 0.9943 - val_accuracy: 0.5184\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 733us/step - loss: 0.9812 - accuracy: 0.5311 - val_loss: 0.9940 - val_accuracy: 0.5188\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 825us/step - loss: 0.9808 - accuracy: 0.5305 - val_loss: 0.9937 - val_accuracy: 0.5188\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9804 - accuracy: 0.5311 - val_loss: 0.9934 - val_accuracy: 0.5206\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9803 - accuracy: 0.5301 - val_loss: 0.9932 - val_accuracy: 0.5197\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 813us/step - loss: 0.9802 - accuracy: 0.5312 - val_loss: 0.9930 - val_accuracy: 0.5228\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 587us/step - loss: 0.9796 - accuracy: 0.5308 - val_loss: 0.9927 - val_accuracy: 0.5197\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 728us/step - loss: 0.9792 - accuracy: 0.5310 - val_loss: 0.9925 - val_accuracy: 0.5188\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 749us/step - loss: 0.9787 - accuracy: 0.5310 - val_loss: 0.9924 - val_accuracy: 0.5232\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9786 - accuracy: 0.5311 - val_loss: 0.9921 - val_accuracy: 0.5206\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9784 - accuracy: 0.5307 - val_loss: 0.9919 - val_accuracy: 0.5224\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9780 - accuracy: 0.5315 - val_loss: 0.9916 - val_accuracy: 0.5219\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 744us/step - loss: 0.9779 - accuracy: 0.5315 - val_loss: 0.9913 - val_accuracy: 0.5224\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9777 - accuracy: 0.5313 - val_loss: 0.9914 - val_accuracy: 0.5206\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9776 - accuracy: 0.5307 - val_loss: 0.9912 - val_accuracy: 0.5206\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 510us/step - loss: 0.9773 - accuracy: 0.5313 - val_loss: 0.9910 - val_accuracy: 0.5250\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9773 - accuracy: 0.5308 - val_loss: 0.9908 - val_accuracy: 0.5263\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 814us/step - loss: 0.9768 - accuracy: 0.5315 - val_loss: 0.9908 - val_accuracy: 0.5250\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9769 - accuracy: 0.5321 - val_loss: 0.9908 - val_accuracy: 0.5210\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9765 - accuracy: 0.5312 - val_loss: 0.9906 - val_accuracy: 0.5241\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9766 - accuracy: 0.5318 - val_loss: 0.9904 - val_accuracy: 0.5228\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9764 - accuracy: 0.5307 - val_loss: 0.9903 - val_accuracy: 0.5263\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9760 - accuracy: 0.5314 - val_loss: 0.9903 - val_accuracy: 0.5241\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9757 - accuracy: 0.5316 - val_loss: 0.9902 - val_accuracy: 0.5228\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 678us/step - loss: 0.9757 - accuracy: 0.5309 - val_loss: 0.9902 - val_accuracy: 0.5250\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9756 - accuracy: 0.5318 - val_loss: 0.9900 - val_accuracy: 0.5250\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9755 - accuracy: 0.5313 - val_loss: 0.9898 - val_accuracy: 0.5250\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9756 - accuracy: 0.5311 - val_loss: 0.9896 - val_accuracy: 0.5255\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9897 - val_accuracy: 0.5259\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 762us/step - loss: 0.9751 - accuracy: 0.5316 - val_loss: 0.9900 - val_accuracy: 0.5210\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9894 - val_accuracy: 0.5241\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 719us/step - loss: 0.9749 - accuracy: 0.5314 - val_loss: 0.9893 - val_accuracy: 0.5219\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 742us/step - loss: 0.9749 - accuracy: 0.5309 - val_loss: 0.9893 - val_accuracy: 0.5241\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9749 - accuracy: 0.5313 - val_loss: 0.9893 - val_accuracy: 0.5259\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 752us/step - loss: 0.9746 - accuracy: 0.5316 - val_loss: 0.9894 - val_accuracy: 0.5263\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 699us/step - loss: 0.9746 - accuracy: 0.5319 - val_loss: 0.9893 - val_accuracy: 0.5259\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9748 - accuracy: 0.5300 - val_loss: 0.9891 - val_accuracy: 0.5237\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 705us/step - loss: 0.9744 - accuracy: 0.5317 - val_loss: 0.9892 - val_accuracy: 0.5263\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9744 - accuracy: 0.5307 - val_loss: 0.9892 - val_accuracy: 0.5268\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9744 - accuracy: 0.5313 - val_loss: 0.9892 - val_accuracy: 0.5272\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9742 - accuracy: 0.5310 - val_loss: 0.9891 - val_accuracy: 0.5250\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 708us/step - loss: 0.9743 - accuracy: 0.5308 - val_loss: 0.9890 - val_accuracy: 0.5219\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 747us/step - loss: 0.9741 - accuracy: 0.5312 - val_loss: 0.9891 - val_accuracy: 0.5277\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9742 - accuracy: 0.5308 - val_loss: 0.9890 - val_accuracy: 0.5250\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9741 - accuracy: 0.5318 - val_loss: 0.9891 - val_accuracy: 0.5241\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9740 - accuracy: 0.5309 - val_loss: 0.9890 - val_accuracy: 0.5215\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9740 - accuracy: 0.5308 - val_loss: 0.9890 - val_accuracy: 0.5255\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9737 - accuracy: 0.5308 - val_loss: 0.9888 - val_accuracy: 0.5250\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9738 - accuracy: 0.5314 - val_loss: 0.9889 - val_accuracy: 0.5250\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9738 - accuracy: 0.5314 - val_loss: 0.9888 - val_accuracy: 0.5255\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 801us/step - loss: 0.9738 - accuracy: 0.5313 - val_loss: 0.9888 - val_accuracy: 0.5259\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9738 - accuracy: 0.5310 - val_loss: 0.9890 - val_accuracy: 0.5263\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 704us/step - loss: 0.9741 - accuracy: 0.5315 - val_loss: 0.9886 - val_accuracy: 0.5250\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 0.9741 - accuracy: 0.5303 - val_loss: 0.9886 - val_accuracy: 0.5250\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 788us/step - loss: 0.9740 - accuracy: 0.5304 - val_loss: 0.9886 - val_accuracy: 0.5277\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9737 - accuracy: 0.5302 - val_loss: 0.9887 - val_accuracy: 0.5250\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9735 - accuracy: 0.5311 - val_loss: 0.9887 - val_accuracy: 0.5268\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9735 - accuracy: 0.5307 - val_loss: 0.9888 - val_accuracy: 0.5255\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9737 - accuracy: 0.5314 - val_loss: 0.9887 - val_accuracy: 0.5224\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 676us/step - loss: 0.9736 - accuracy: 0.5314 - val_loss: 0.9889 - val_accuracy: 0.5250\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9742 - accuracy: 0.5295 - val_loss: 0.9890 - val_accuracy: 0.5263\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9735 - accuracy: 0.5312 - val_loss: 0.9888 - val_accuracy: 0.5228\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9734 - accuracy: 0.5306 - val_loss: 0.9887 - val_accuracy: 0.5272\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9734 - accuracy: 0.5301 - val_loss: 0.9886 - val_accuracy: 0.5268\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9736 - accuracy: 0.5305 - val_loss: 0.9885 - val_accuracy: 0.5268\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9735 - accuracy: 0.5313 - val_loss: 0.9885 - val_accuracy: 0.5277\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9734 - accuracy: 0.5308 - val_loss: 0.9886 - val_accuracy: 0.5228\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9733 - accuracy: 0.5301 - val_loss: 0.9885 - val_accuracy: 0.5255\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9732 - accuracy: 0.5312 - val_loss: 0.9889 - val_accuracy: 0.5263\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9737 - accuracy: 0.5319 - val_loss: 0.9885 - val_accuracy: 0.5277\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 733us/step - loss: 0.9733 - accuracy: 0.5307 - val_loss: 0.9886 - val_accuracy: 0.5255\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9736 - accuracy: 0.5328 - val_loss: 0.9886 - val_accuracy: 0.5228\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9733 - accuracy: 0.5311 - val_loss: 0.9886 - val_accuracy: 0.5277\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9731 - accuracy: 0.5312 - val_loss: 0.9885 - val_accuracy: 0.5277\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9736 - accuracy: 0.5302 - val_loss: 0.9885 - val_accuracy: 0.5263\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9733 - accuracy: 0.5306 - val_loss: 0.9884 - val_accuracy: 0.5255\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9731 - accuracy: 0.5318 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9734 - accuracy: 0.5292 - val_loss: 0.9884 - val_accuracy: 0.5272\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 737us/step - loss: 0.9734 - accuracy: 0.5298 - val_loss: 0.9885 - val_accuracy: 0.5259\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9733 - accuracy: 0.5299 - val_loss: 0.9885 - val_accuracy: 0.5228\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9731 - accuracy: 0.5302 - val_loss: 0.9884 - val_accuracy: 0.5277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 730us/step - loss: 0.9729 - accuracy: 0.5297 - val_loss: 0.9885 - val_accuracy: 0.5255\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9731 - accuracy: 0.5307 - val_loss: 0.9885 - val_accuracy: 0.5255\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9733 - accuracy: 0.5308 - val_loss: 0.9886 - val_accuracy: 0.5228\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 755us/step - loss: 0.9735 - accuracy: 0.5314 - val_loss: 0.9884 - val_accuracy: 0.5246\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 731us/step - loss: 0.9731 - accuracy: 0.5302 - val_loss: 0.9883 - val_accuracy: 0.5277\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 770us/step - loss: 0.9732 - accuracy: 0.5313 - val_loss: 0.9883 - val_accuracy: 0.5215\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 883us/step - loss: 0.9733 - accuracy: 0.5312 - val_loss: 0.9883 - val_accuracy: 0.5281\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 773us/step - loss: 0.9731 - accuracy: 0.5311 - val_loss: 0.9886 - val_accuracy: 0.5268\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9732 - accuracy: 0.5303 - val_loss: 0.9885 - val_accuracy: 0.5263\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9734 - accuracy: 0.5286 - val_loss: 0.9884 - val_accuracy: 0.5272\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9731 - accuracy: 0.5310 - val_loss: 0.9884 - val_accuracy: 0.5228\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9731 - accuracy: 0.5314 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 757us/step - loss: 0.9730 - accuracy: 0.5308 - val_loss: 0.9885 - val_accuracy: 0.5215\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9732 - accuracy: 0.5295 - val_loss: 0.9884 - val_accuracy: 0.5281\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9730 - accuracy: 0.5305 - val_loss: 0.9885 - val_accuracy: 0.5272\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 709us/step - loss: 0.9729 - accuracy: 0.5312 - val_loss: 0.9887 - val_accuracy: 0.5237\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9733 - accuracy: 0.5307 - val_loss: 0.9885 - val_accuracy: 0.5281\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 756us/step - loss: 0.9731 - accuracy: 0.5304 - val_loss: 0.9884 - val_accuracy: 0.5281\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9730 - accuracy: 0.5305 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 766us/step - loss: 0.9729 - accuracy: 0.5310 - val_loss: 0.9887 - val_accuracy: 0.5237\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9730 - accuracy: 0.5315 - val_loss: 0.9885 - val_accuracy: 0.5277\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9731 - accuracy: 0.5317 - val_loss: 0.9885 - val_accuracy: 0.5232\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 696us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 0.9885 - val_accuracy: 0.5268\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9731 - accuracy: 0.5303 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 518us/step - loss: 0.9729 - accuracy: 0.5312 - val_loss: 0.9886 - val_accuracy: 0.5255\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 0.9886 - val_accuracy: 0.5263\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 728us/step - loss: 0.9731 - accuracy: 0.5302 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9730 - accuracy: 0.5316 - val_loss: 0.9885 - val_accuracy: 0.5281\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9730 - accuracy: 0.5307 - val_loss: 0.9884 - val_accuracy: 0.5281\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9729 - accuracy: 0.5302 - val_loss: 0.9886 - val_accuracy: 0.5255\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 548us/step - loss: 0.9733 - accuracy: 0.5311 - val_loss: 0.9884 - val_accuracy: 0.5268\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 812us/step - loss: 0.9729 - accuracy: 0.5294 - val_loss: 0.9884 - val_accuracy: 0.5281\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9731 - accuracy: 0.5305 - val_loss: 0.9884 - val_accuracy: 0.5268\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 803us/step - loss: 0.9729 - accuracy: 0.5298 - val_loss: 0.9884 - val_accuracy: 0.5281\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 555us/step - loss: 0.9728 - accuracy: 0.5306 - val_loss: 0.9885 - val_accuracy: 0.5250\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 0.9885 - val_accuracy: 0.5263\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9729 - accuracy: 0.5312 - val_loss: 0.9885 - val_accuracy: 0.5263\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9732 - accuracy: 0.5299 - val_loss: 0.9883 - val_accuracy: 0.5281\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9727 - accuracy: 0.5311 - val_loss: 0.9886 - val_accuracy: 0.5255\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9731 - accuracy: 0.5309 - val_loss: 0.9886 - val_accuracy: 0.5281\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 765us/step - loss: 0.9729 - accuracy: 0.5309 - val_loss: 0.9886 - val_accuracy: 0.5263\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 647us/step - loss: 0.9728 - accuracy: 0.5313 - val_loss: 0.9886 - val_accuracy: 0.5224\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 740us/step - loss: 0.9729 - accuracy: 0.5302 - val_loss: 0.9884 - val_accuracy: 0.5232\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 640us/step - loss: 0.9728 - accuracy: 0.5310 - val_loss: 0.9886 - val_accuracy: 0.5259\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 829us/step - loss: 0.9732 - accuracy: 0.5306 - val_loss: 0.9885 - val_accuracy: 0.5232\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9727 - accuracy: 0.5304 - val_loss: 0.9884 - val_accuracy: 0.5259\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 565us/step - loss: 0.9734 - accuracy: 0.5294 - val_loss: 0.9882 - val_accuracy: 0.5263\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9729 - accuracy: 0.5307 - val_loss: 0.9884 - val_accuracy: 0.5237\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 536us/step - loss: 0.9729 - accuracy: 0.5306 - val_loss: 0.9886 - val_accuracy: 0.5259\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 756us/step - loss: 0.9727 - accuracy: 0.5312 - val_loss: 0.9885 - val_accuracy: 0.5237\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 690us/step - loss: 0.9729 - accuracy: 0.5304 - val_loss: 0.9884 - val_accuracy: 0.5259\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 681us/step - loss: 0.9728 - accuracy: 0.5308 - val_loss: 0.9886 - val_accuracy: 0.5232\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 795us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 679us/step - loss: 0.9729 - accuracy: 0.5313 - val_loss: 0.9885 - val_accuracy: 0.5263\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 662us/step - loss: 0.9729 - accuracy: 0.5308 - val_loss: 0.9887 - val_accuracy: 0.5259\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 804us/step - loss: 0.9729 - accuracy: 0.5319 - val_loss: 0.9886 - val_accuracy: 0.5228\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 685us/step - loss: 0.9728 - accuracy: 0.5309 - val_loss: 0.9887 - val_accuracy: 0.5219\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9726 - accuracy: 0.5311 - val_loss: 0.9889 - val_accuracy: 0.5246\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 704us/step - loss: 0.9732 - accuracy: 0.5314 - val_loss: 0.9884 - val_accuracy: 0.5215\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9731 - accuracy: 0.5305 - val_loss: 0.9883 - val_accuracy: 0.5259\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9729 - accuracy: 0.5311 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 828us/step - loss: 0.9727 - accuracy: 0.5298 - val_loss: 0.9884 - val_accuracy: 0.5232\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9730 - accuracy: 0.5306 - val_loss: 0.9883 - val_accuracy: 0.5259\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 0.9884 - val_accuracy: 0.5232\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 812us/step - loss: 0.9729 - accuracy: 0.5305 - val_loss: 0.9884 - val_accuracy: 0.5215\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9727 - accuracy: 0.5306 - val_loss: 0.9885 - val_accuracy: 0.5259\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 574us/step - loss: 0.9729 - accuracy: 0.5301 - val_loss: 0.9886 - val_accuracy: 0.5232\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 514us/step - loss: 0.9728 - accuracy: 0.5309 - val_loss: 0.9885 - val_accuracy: 0.5277\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 0.9728 - accuracy: 0.5312 - val_loss: 0.9887 - val_accuracy: 0.5259\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 563us/step - loss: 0.9727 - accuracy: 0.5310 - val_loss: 0.9886 - val_accuracy: 0.5232\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9728 - accuracy: 0.5313 - val_loss: 0.9885 - val_accuracy: 0.5259\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 774us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 0.9885 - val_accuracy: 0.5263\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9727 - accuracy: 0.5305 - val_loss: 0.9887 - val_accuracy: 0.5255\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 650us/step - loss: 0.9728 - accuracy: 0.5310 - val_loss: 0.9887 - val_accuracy: 0.5228\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 0.9887 - val_accuracy: 0.5268\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9726 - accuracy: 0.5311 - val_loss: 0.9886 - val_accuracy: 0.5219\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9728 - accuracy: 0.5324 - val_loss: 0.9889 - val_accuracy: 0.5237\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 720us/step - loss: 0.9726 - accuracy: 0.5310 - val_loss: 0.9885 - val_accuracy: 0.5259\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 685us/step - loss: 0.9730 - accuracy: 0.5316 - val_loss: 0.9883 - val_accuracy: 0.5255\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 827us/step - loss: 0.9730 - accuracy: 0.5296 - val_loss: 0.9882 - val_accuracy: 0.5272\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9727 - accuracy: 0.5308 - val_loss: 0.9885 - val_accuracy: 0.5255\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9728 - accuracy: 0.5299 - val_loss: 0.9884 - val_accuracy: 0.5255\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9730 - accuracy: 0.5302 - val_loss: 0.9883 - val_accuracy: 0.5263\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 767us/step - loss: 0.9726 - accuracy: 0.5312 - val_loss: 0.9884 - val_accuracy: 0.5228\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 725us/step - loss: 0.9727 - accuracy: 0.5305 - val_loss: 0.9884 - val_accuracy: 0.5277\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 787us/step - loss: 0.9726 - accuracy: 0.5306 - val_loss: 0.9886 - val_accuracy: 0.5250\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9728 - accuracy: 0.5315 - val_loss: 0.9886 - val_accuracy: 0.5219\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9726 - accuracy: 0.5310 - val_loss: 0.9885 - val_accuracy: 0.5250\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9730 - accuracy: 0.5306 - val_loss: 0.9885 - val_accuracy: 0.5263\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9730 - accuracy: 0.5307 - val_loss: 0.9886 - val_accuracy: 0.5246\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 749us/step - loss: 0.9732 - accuracy: 0.5298 - val_loss: 0.9886 - val_accuracy: 0.5232\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9729 - accuracy: 0.5302 - val_loss: 0.9887 - val_accuracy: 0.5246\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 849us/step - loss: 0.9726 - accuracy: 0.5309 - val_loss: 0.9888 - val_accuracy: 0.5219\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 597us/step - loss: 0.9727 - accuracy: 0.5319 - val_loss: 0.9888 - val_accuracy: 0.5228\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 846us/step - loss: 0.9727 - accuracy: 0.5312 - val_loss: 0.9887 - val_accuracy: 0.5232\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9727 - accuracy: 0.5315 - val_loss: 0.9886 - val_accuracy: 0.5232\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9727 - accuracy: 0.5309 - val_loss: 0.9886 - val_accuracy: 0.5228\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9728 - accuracy: 0.5311 - val_loss: 0.9885 - val_accuracy: 0.5255\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 722us/step - loss: 0.9726 - accuracy: 0.5320 - val_loss: 0.9886 - val_accuracy: 0.5228\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9728 - accuracy: 0.5310 - val_loss: 0.9887 - val_accuracy: 0.5255\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 400us/step - loss: 0.9724 - accuracy: 0.5313\n",
      "Accuracy : 0.5312545895576477\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9887 - accuracy: 0.5255\n",
      "Accuracy : 0.5254537463188171\n",
      "Fold #6\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0992 - accuracy: 0.4591 - val_loss: 1.0776 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 1.0675 - accuracy: 0.4591 - val_loss: 1.0575 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 1.0515 - accuracy: 0.4591 - val_loss: 1.0424 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 1.0379 - accuracy: 0.4592 - val_loss: 1.0296 - val_accuracy: 0.4604\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 698us/step - loss: 1.0259 - accuracy: 0.4857 - val_loss: 1.0166 - val_accuracy: 0.5100\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 738us/step - loss: 1.0143 - accuracy: 0.5139 - val_loss: 1.0047 - val_accuracy: 0.5330\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 1.0040 - accuracy: 0.5224 - val_loss: 0.9951 - val_accuracy: 0.5378\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9969 - accuracy: 0.5283 - val_loss: 0.9888 - val_accuracy: 0.5432\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9925 - accuracy: 0.5284 - val_loss: 0.9856 - val_accuracy: 0.5365\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 704us/step - loss: 0.9892 - accuracy: 0.5285 - val_loss: 0.9829 - val_accuracy: 0.5343\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 519us/step - loss: 0.9876 - accuracy: 0.5287 - val_loss: 0.9806 - val_accuracy: 0.5365\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9861 - accuracy: 0.5288 - val_loss: 0.9797 - val_accuracy: 0.5352\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 830us/step - loss: 0.9853 - accuracy: 0.5298 - val_loss: 0.9795 - val_accuracy: 0.5365\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9852 - accuracy: 0.5264 - val_loss: 0.9786 - val_accuracy: 0.5343\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 562us/step - loss: 0.9846 - accuracy: 0.5299 - val_loss: 0.9784 - val_accuracy: 0.5343\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 548us/step - loss: 0.9840 - accuracy: 0.5289 - val_loss: 0.9779 - val_accuracy: 0.5352\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9837 - accuracy: 0.5292 - val_loss: 0.9780 - val_accuracy: 0.5365\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 0.9836 - accuracy: 0.5285 - val_loss: 0.9776 - val_accuracy: 0.5361\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 779us/step - loss: 0.9831 - accuracy: 0.5286 - val_loss: 0.9776 - val_accuracy: 0.5361\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9830 - accuracy: 0.5268 - val_loss: 0.9775 - val_accuracy: 0.5361\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9825 - accuracy: 0.5281 - val_loss: 0.9771 - val_accuracy: 0.5361\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 842us/step - loss: 0.9824 - accuracy: 0.5295 - val_loss: 0.9773 - val_accuracy: 0.5361\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9825 - accuracy: 0.5267 - val_loss: 0.9770 - val_accuracy: 0.5347\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 567us/step - loss: 0.9817 - accuracy: 0.5283 - val_loss: 0.9768 - val_accuracy: 0.5347\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9814 - accuracy: 0.5289 - val_loss: 0.9763 - val_accuracy: 0.5378\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 570us/step - loss: 0.9815 - accuracy: 0.5291 - val_loss: 0.9764 - val_accuracy: 0.5356\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 699us/step - loss: 0.9811 - accuracy: 0.5285 - val_loss: 0.9761 - val_accuracy: 0.5356\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 543us/step - loss: 0.9809 - accuracy: 0.5280 - val_loss: 0.9759 - val_accuracy: 0.5352\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 741us/step - loss: 0.9806 - accuracy: 0.5292 - val_loss: 0.9754 - val_accuracy: 0.5361\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 0.9805 - accuracy: 0.5290 - val_loss: 0.9753 - val_accuracy: 0.5361\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9799 - accuracy: 0.5295 - val_loss: 0.9750 - val_accuracy: 0.5356\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9799 - accuracy: 0.5302 - val_loss: 0.9747 - val_accuracy: 0.5396\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 713us/step - loss: 0.9797 - accuracy: 0.5297 - val_loss: 0.9748 - val_accuracy: 0.5361\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 0.9797 - accuracy: 0.5281 - val_loss: 0.9744 - val_accuracy: 0.5383\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 768us/step - loss: 0.9793 - accuracy: 0.5296 - val_loss: 0.9745 - val_accuracy: 0.5361\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 600us/step - loss: 0.9798 - accuracy: 0.5275 - val_loss: 0.9743 - val_accuracy: 0.5396\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 841us/step - loss: 0.9792 - accuracy: 0.5295 - val_loss: 0.9742 - val_accuracy: 0.5396\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 681us/step - loss: 0.9790 - accuracy: 0.5285 - val_loss: 0.9741 - val_accuracy: 0.5392\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9790 - accuracy: 0.5286 - val_loss: 0.9742 - val_accuracy: 0.5356\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 724us/step - loss: 0.9785 - accuracy: 0.5298 - val_loss: 0.9739 - val_accuracy: 0.5396\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 734us/step - loss: 0.9786 - accuracy: 0.5288 - val_loss: 0.9739 - val_accuracy: 0.5396\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 545us/step - loss: 0.9787 - accuracy: 0.5294 - val_loss: 0.9736 - val_accuracy: 0.5383\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 529us/step - loss: 0.9785 - accuracy: 0.5300 - val_loss: 0.9736 - val_accuracy: 0.5387\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 578us/step - loss: 0.9782 - accuracy: 0.5295 - val_loss: 0.9736 - val_accuracy: 0.5396\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 830us/step - loss: 0.9782 - accuracy: 0.5297 - val_loss: 0.9735 - val_accuracy: 0.5383\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9783 - accuracy: 0.5295 - val_loss: 0.9735 - val_accuracy: 0.5427\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9780 - accuracy: 0.5294 - val_loss: 0.9734 - val_accuracy: 0.5374\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 740us/step - loss: 0.9781 - accuracy: 0.5283 - val_loss: 0.9734 - val_accuracy: 0.5370\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9778 - accuracy: 0.5299 - val_loss: 0.9738 - val_accuracy: 0.5356\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 737us/step - loss: 0.9783 - accuracy: 0.5283 - val_loss: 0.9733 - val_accuracy: 0.5383\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9779 - accuracy: 0.5295 - val_loss: 0.9732 - val_accuracy: 0.5378\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 659us/step - loss: 0.9778 - accuracy: 0.5294 - val_loss: 0.9732 - val_accuracy: 0.5396\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9775 - accuracy: 0.5296 - val_loss: 0.9730 - val_accuracy: 0.5396\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9774 - accuracy: 0.5297 - val_loss: 0.9727 - val_accuracy: 0.5387\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 671us/step - loss: 0.9775 - accuracy: 0.5298 - val_loss: 0.9727 - val_accuracy: 0.5432\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 781us/step - loss: 0.9776 - accuracy: 0.5299 - val_loss: 0.9727 - val_accuracy: 0.5374\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9775 - accuracy: 0.5289 - val_loss: 0.9729 - val_accuracy: 0.5365\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9772 - accuracy: 0.5295 - val_loss: 0.9725 - val_accuracy: 0.5432\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9772 - accuracy: 0.5293 - val_loss: 0.9726 - val_accuracy: 0.5392\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9771 - accuracy: 0.5303 - val_loss: 0.9726 - val_accuracy: 0.5387\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9773 - accuracy: 0.5282 - val_loss: 0.9725 - val_accuracy: 0.5383\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9770 - accuracy: 0.5302 - val_loss: 0.9724 - val_accuracy: 0.5396\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9770 - accuracy: 0.5290 - val_loss: 0.9729 - val_accuracy: 0.5392\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9771 - accuracy: 0.5292 - val_loss: 0.9726 - val_accuracy: 0.5374\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9770 - accuracy: 0.5278 - val_loss: 0.9730 - val_accuracy: 0.5396\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9770 - accuracy: 0.5295 - val_loss: 0.9726 - val_accuracy: 0.5378\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9768 - accuracy: 0.5304 - val_loss: 0.9724 - val_accuracy: 0.5449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9770 - accuracy: 0.5296 - val_loss: 0.9726 - val_accuracy: 0.5378\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9769 - accuracy: 0.5300 - val_loss: 0.9723 - val_accuracy: 0.5405\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9770 - accuracy: 0.5288 - val_loss: 0.9721 - val_accuracy: 0.5423\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 541us/step - loss: 0.9768 - accuracy: 0.5286 - val_loss: 0.9720 - val_accuracy: 0.5387\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 865us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9722 - val_accuracy: 0.5383\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9767 - accuracy: 0.5283 - val_loss: 0.9720 - val_accuracy: 0.5405\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9768 - accuracy: 0.5282 - val_loss: 0.9720 - val_accuracy: 0.5432\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 792us/step - loss: 0.9766 - accuracy: 0.5293 - val_loss: 0.9722 - val_accuracy: 0.5383\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9767 - accuracy: 0.5277 - val_loss: 0.9719 - val_accuracy: 0.5387\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9719 - val_accuracy: 0.5387\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9719 - val_accuracy: 0.5423\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9765 - accuracy: 0.5292 - val_loss: 0.9719 - val_accuracy: 0.5378\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 736us/step - loss: 0.9764 - accuracy: 0.5303 - val_loss: 0.9718 - val_accuracy: 0.5387\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9764 - accuracy: 0.5298 - val_loss: 0.9717 - val_accuracy: 0.5405\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9762 - accuracy: 0.5300 - val_loss: 0.9717 - val_accuracy: 0.5409\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9717 - val_accuracy: 0.5423\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9763 - accuracy: 0.5306 - val_loss: 0.9714 - val_accuracy: 0.5423\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9716 - val_accuracy: 0.5383\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9762 - accuracy: 0.5300 - val_loss: 0.9715 - val_accuracy: 0.5418\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9766 - accuracy: 0.5282 - val_loss: 0.9716 - val_accuracy: 0.5440\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9768 - accuracy: 0.5285 - val_loss: 0.9716 - val_accuracy: 0.5423\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9762 - accuracy: 0.5287 - val_loss: 0.9717 - val_accuracy: 0.5378\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9761 - accuracy: 0.5290 - val_loss: 0.9718 - val_accuracy: 0.5387\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 777us/step - loss: 0.9762 - accuracy: 0.5295 - val_loss: 0.9715 - val_accuracy: 0.5418\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9762 - accuracy: 0.5288 - val_loss: 0.9716 - val_accuracy: 0.5414\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9763 - accuracy: 0.5287 - val_loss: 0.9715 - val_accuracy: 0.5423\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9762 - accuracy: 0.5288 - val_loss: 0.9716 - val_accuracy: 0.5405\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 817us/step - loss: 0.9762 - accuracy: 0.5286 - val_loss: 0.9719 - val_accuracy: 0.5423\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9759 - accuracy: 0.5285 - val_loss: 0.9714 - val_accuracy: 0.5423\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 742us/step - loss: 0.9761 - accuracy: 0.5285 - val_loss: 0.9714 - val_accuracy: 0.5423\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9761 - accuracy: 0.5292 - val_loss: 0.9714 - val_accuracy: 0.5423\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9761 - accuracy: 0.5293 - val_loss: 0.9716 - val_accuracy: 0.5383\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 738us/step - loss: 0.9768 - accuracy: 0.5291 - val_loss: 0.9717 - val_accuracy: 0.5423\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 643us/step - loss: 0.9759 - accuracy: 0.5301 - val_loss: 0.9717 - val_accuracy: 0.5387\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9762 - accuracy: 0.5301 - val_loss: 0.9714 - val_accuracy: 0.5423\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9759 - accuracy: 0.5286 - val_loss: 0.9715 - val_accuracy: 0.5423\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9760 - accuracy: 0.5290 - val_loss: 0.9715 - val_accuracy: 0.5383\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9759 - accuracy: 0.5288 - val_loss: 0.9713 - val_accuracy: 0.5432\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 670us/step - loss: 0.9758 - accuracy: 0.5285 - val_loss: 0.9718 - val_accuracy: 0.5387\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 757us/step - loss: 0.9763 - accuracy: 0.5292 - val_loss: 0.9712 - val_accuracy: 0.5423\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 715us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9713 - val_accuracy: 0.5383\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9710 - val_accuracy: 0.5405\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 698us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9711 - val_accuracy: 0.5423\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 790us/step - loss: 0.9758 - accuracy: 0.5287 - val_loss: 0.9711 - val_accuracy: 0.5383\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9760 - accuracy: 0.5301 - val_loss: 0.9712 - val_accuracy: 0.5409\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 822us/step - loss: 0.9759 - accuracy: 0.5290 - val_loss: 0.9712 - val_accuracy: 0.5423\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 671us/step - loss: 0.9757 - accuracy: 0.5282 - val_loss: 0.9711 - val_accuracy: 0.5423\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 0.9757 - accuracy: 0.5291 - val_loss: 0.9711 - val_accuracy: 0.5383\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 804us/step - loss: 0.9756 - accuracy: 0.5302 - val_loss: 0.9710 - val_accuracy: 0.5423\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9757 - accuracy: 0.5289 - val_loss: 0.9711 - val_accuracy: 0.5383\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 816us/step - loss: 0.9762 - accuracy: 0.5296 - val_loss: 0.9713 - val_accuracy: 0.5387\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 746us/step - loss: 0.9761 - accuracy: 0.5285 - val_loss: 0.9709 - val_accuracy: 0.5423\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9756 - accuracy: 0.5292 - val_loss: 0.9709 - val_accuracy: 0.5423\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9757 - accuracy: 0.5287 - val_loss: 0.9707 - val_accuracy: 0.5423\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 766us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 0.9710 - val_accuracy: 0.5392\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 734us/step - loss: 0.9760 - accuracy: 0.5299 - val_loss: 0.9709 - val_accuracy: 0.5423\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9758 - accuracy: 0.5286 - val_loss: 0.9712 - val_accuracy: 0.5387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 731us/step - loss: 0.9759 - accuracy: 0.5294 - val_loss: 0.9708 - val_accuracy: 0.5423\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 731us/step - loss: 0.9757 - accuracy: 0.5279 - val_loss: 0.9707 - val_accuracy: 0.5423\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 720us/step - loss: 0.9756 - accuracy: 0.5291 - val_loss: 0.9710 - val_accuracy: 0.5383\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9760 - accuracy: 0.5287 - val_loss: 0.9709 - val_accuracy: 0.5423\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 731us/step - loss: 0.9755 - accuracy: 0.5292 - val_loss: 0.9706 - val_accuracy: 0.5423\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 742us/step - loss: 0.9756 - accuracy: 0.5277 - val_loss: 0.9706 - val_accuracy: 0.5423\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9757 - accuracy: 0.5289 - val_loss: 0.9707 - val_accuracy: 0.5423\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 752us/step - loss: 0.9757 - accuracy: 0.5302 - val_loss: 0.9713 - val_accuracy: 0.5370\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 688us/step - loss: 0.9764 - accuracy: 0.5289 - val_loss: 0.9710 - val_accuracy: 0.5396\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9757 - accuracy: 0.5285 - val_loss: 0.9708 - val_accuracy: 0.5383\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 644us/step - loss: 0.9756 - accuracy: 0.5286 - val_loss: 0.9706 - val_accuracy: 0.5432\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9755 - accuracy: 0.5287 - val_loss: 0.9704 - val_accuracy: 0.5427\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 926us/step - loss: 0.9755 - accuracy: 0.5290 - val_loss: 0.9707 - val_accuracy: 0.5392\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9756 - accuracy: 0.5292 - val_loss: 0.9706 - val_accuracy: 0.5401\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 770us/step - loss: 0.9756 - accuracy: 0.5285 - val_loss: 0.9710 - val_accuracy: 0.5401\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 745us/step - loss: 0.9756 - accuracy: 0.5277 - val_loss: 0.9710 - val_accuracy: 0.5414\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 0.9755 - accuracy: 0.5285 - val_loss: 0.9709 - val_accuracy: 0.5423\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9757 - accuracy: 0.5300 - val_loss: 0.9706 - val_accuracy: 0.5401\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9756 - accuracy: 0.5287 - val_loss: 0.9705 - val_accuracy: 0.5409\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 704us/step - loss: 0.9756 - accuracy: 0.5289 - val_loss: 0.9705 - val_accuracy: 0.5409\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9708 - val_accuracy: 0.5392\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9755 - accuracy: 0.5284 - val_loss: 0.9709 - val_accuracy: 0.5418\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9757 - accuracy: 0.5287 - val_loss: 0.9706 - val_accuracy: 0.5423\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 715us/step - loss: 0.9755 - accuracy: 0.5290 - val_loss: 0.9706 - val_accuracy: 0.5423\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9707 - val_accuracy: 0.5409\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9754 - accuracy: 0.5284 - val_loss: 0.9705 - val_accuracy: 0.5432\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9755 - accuracy: 0.5285 - val_loss: 0.9704 - val_accuracy: 0.5423\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9758 - accuracy: 0.5289 - val_loss: 0.9706 - val_accuracy: 0.5401\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9755 - accuracy: 0.5294 - val_loss: 0.9706 - val_accuracy: 0.5418\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 0.9754 - accuracy: 0.5294 - val_loss: 0.9709 - val_accuracy: 0.5378\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9758 - accuracy: 0.5285 - val_loss: 0.9706 - val_accuracy: 0.5378\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9756 - accuracy: 0.5291 - val_loss: 0.9704 - val_accuracy: 0.5409\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9755 - accuracy: 0.5294 - val_loss: 0.9704 - val_accuracy: 0.5423\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 813us/step - loss: 0.9756 - accuracy: 0.5279 - val_loss: 0.9705 - val_accuracy: 0.5409\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 595us/step - loss: 0.9754 - accuracy: 0.5287 - val_loss: 0.9704 - val_accuracy: 0.5423\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 696us/step - loss: 0.9754 - accuracy: 0.5293 - val_loss: 0.9703 - val_accuracy: 0.5401\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 852us/step - loss: 0.9754 - accuracy: 0.5289 - val_loss: 0.9704 - val_accuracy: 0.5423\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9754 - accuracy: 0.5285 - val_loss: 0.9705 - val_accuracy: 0.5409\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9755 - accuracy: 0.5274 - val_loss: 0.9712 - val_accuracy: 0.5387\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9761 - accuracy: 0.5290 - val_loss: 0.9709 - val_accuracy: 0.5383\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 742us/step - loss: 0.9757 - accuracy: 0.5274 - val_loss: 0.9707 - val_accuracy: 0.5401\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 676us/step - loss: 0.9754 - accuracy: 0.5287 - val_loss: 0.9707 - val_accuracy: 0.5418\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 788us/step - loss: 0.9758 - accuracy: 0.5276 - val_loss: 0.9706 - val_accuracy: 0.5423\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 685us/step - loss: 0.9754 - accuracy: 0.5279 - val_loss: 0.9705 - val_accuracy: 0.5401\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 720us/step - loss: 0.9755 - accuracy: 0.5295 - val_loss: 0.9705 - val_accuracy: 0.5396\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9754 - accuracy: 0.5295 - val_loss: 0.9704 - val_accuracy: 0.5423\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 741us/step - loss: 0.9754 - accuracy: 0.5283 - val_loss: 0.9707 - val_accuracy: 0.5365\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 634us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 0.9709 - val_accuracy: 0.5370\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9753 - accuracy: 0.5287 - val_loss: 0.9704 - val_accuracy: 0.5432\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9754 - accuracy: 0.5298 - val_loss: 0.9704 - val_accuracy: 0.5423\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 557us/step - loss: 0.9753 - accuracy: 0.5286 - val_loss: 0.9705 - val_accuracy: 0.5423\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9754 - accuracy: 0.5288 - val_loss: 0.9707 - val_accuracy: 0.5383\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9758 - accuracy: 0.5293 - val_loss: 0.9704 - val_accuracy: 0.5423\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 766us/step - loss: 0.9754 - accuracy: 0.5285 - val_loss: 0.9707 - val_accuracy: 0.5392\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9756 - accuracy: 0.5300 - val_loss: 0.9703 - val_accuracy: 0.5423\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 648us/step - loss: 0.9753 - accuracy: 0.5289 - val_loss: 0.9702 - val_accuracy: 0.5418\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 596us/step - loss: 0.9755 - accuracy: 0.5287 - val_loss: 0.9705 - val_accuracy: 0.5418\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 627us/step - loss: 0.9753 - accuracy: 0.5289 - val_loss: 0.9702 - val_accuracy: 0.5423\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 538us/step - loss: 0.9753 - accuracy: 0.5288 - val_loss: 0.9702 - val_accuracy: 0.5423\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 767us/step - loss: 0.9753 - accuracy: 0.5296 - val_loss: 0.9702 - val_accuracy: 0.5401\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9753 - accuracy: 0.5280 - val_loss: 0.9704 - val_accuracy: 0.5396\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 766us/step - loss: 0.9755 - accuracy: 0.5292 - val_loss: 0.9702 - val_accuracy: 0.5418\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9752 - accuracy: 0.5296 - val_loss: 0.9703 - val_accuracy: 0.5374\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 685us/step - loss: 0.9753 - accuracy: 0.5281 - val_loss: 0.9701 - val_accuracy: 0.5423\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9754 - accuracy: 0.5283 - val_loss: 0.9702 - val_accuracy: 0.5418\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 715us/step - loss: 0.9752 - accuracy: 0.5289 - val_loss: 0.9705 - val_accuracy: 0.5356\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9753 - accuracy: 0.5305 - val_loss: 0.9702 - val_accuracy: 0.5423\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9753 - accuracy: 0.5294 - val_loss: 0.9701 - val_accuracy: 0.5418\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 749us/step - loss: 0.9752 - accuracy: 0.5301 - val_loss: 0.9699 - val_accuracy: 0.5423\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 698us/step - loss: 0.9753 - accuracy: 0.5294 - val_loss: 0.9699 - val_accuracy: 0.5418\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9754 - accuracy: 0.5288 - val_loss: 0.9699 - val_accuracy: 0.5427\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 646us/step - loss: 0.9753 - accuracy: 0.5292 - val_loss: 0.9700 - val_accuracy: 0.5405\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 636us/step - loss: 0.9753 - accuracy: 0.5290 - val_loss: 0.9702 - val_accuracy: 0.5409\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 608us/step - loss: 0.9754 - accuracy: 0.5300 - val_loss: 0.9701 - val_accuracy: 0.5409\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 850us/step - loss: 0.9752 - accuracy: 0.5292 - val_loss: 0.9704 - val_accuracy: 0.5365\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 729us/step - loss: 0.9752 - accuracy: 0.5285 - val_loss: 0.9707 - val_accuracy: 0.5401\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 354us/step - loss: 0.9750 - accuracy: 0.5294\n",
      "Accuracy : 0.5294349193572998\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9707 - accuracy: 0.5401\n",
      "Accuracy : 0.5400619506835938\n",
      "Fold #7\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0835 - accuracy: 0.3908 - val_loss: 1.0627 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 861us/step - loss: 1.0561 - accuracy: 0.4591 - val_loss: 1.0452 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 1.0430 - accuracy: 0.4591 - val_loss: 1.0335 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 630us/step - loss: 1.0343 - accuracy: 0.4591 - val_loss: 1.0236 - val_accuracy: 0.4591\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 1.0267 - accuracy: 0.4591 - val_loss: 1.0145 - val_accuracy: 0.4591\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 843us/step - loss: 1.0195 - accuracy: 0.4634 - val_loss: 1.0057 - val_accuracy: 0.4874\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 1.0130 - accuracy: 0.5024 - val_loss: 0.9980 - val_accuracy: 0.5206\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 1.0066 - accuracy: 0.5185 - val_loss: 0.9907 - val_accuracy: 0.5325\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 818us/step - loss: 1.0016 - accuracy: 0.5248 - val_loss: 0.9851 - val_accuracy: 0.5356\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 517us/step - loss: 0.9984 - accuracy: 0.5265 - val_loss: 0.9811 - val_accuracy: 0.5370\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 572us/step - loss: 0.9959 - accuracy: 0.5290 - val_loss: 0.9781 - val_accuracy: 0.5378\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 661us/step - loss: 0.9938 - accuracy: 0.5288 - val_loss: 0.9758 - val_accuracy: 0.5409\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 811us/step - loss: 0.9925 - accuracy: 0.5257 - val_loss: 0.9745 - val_accuracy: 0.5409\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 682us/step - loss: 0.9914 - accuracy: 0.5282 - val_loss: 0.9730 - val_accuracy: 0.5378\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9908 - accuracy: 0.5240 - val_loss: 0.9720 - val_accuracy: 0.5414\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 707us/step - loss: 0.9900 - accuracy: 0.5248 - val_loss: 0.9713 - val_accuracy: 0.5387\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 851us/step - loss: 0.9895 - accuracy: 0.5241 - val_loss: 0.9707 - val_accuracy: 0.5409\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9888 - accuracy: 0.5254 - val_loss: 0.9703 - val_accuracy: 0.5378\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 682us/step - loss: 0.9883 - accuracy: 0.5269 - val_loss: 0.9701 - val_accuracy: 0.5387\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9876 - accuracy: 0.5251 - val_loss: 0.9697 - val_accuracy: 0.5392\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 583us/step - loss: 0.9874 - accuracy: 0.5276 - val_loss: 0.9688 - val_accuracy: 0.5378\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9866 - accuracy: 0.5284 - val_loss: 0.9687 - val_accuracy: 0.5387\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9860 - accuracy: 0.5275 - val_loss: 0.9684 - val_accuracy: 0.5409\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 747us/step - loss: 0.9857 - accuracy: 0.5294 - val_loss: 0.9676 - val_accuracy: 0.5383\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9856 - accuracy: 0.5259 - val_loss: 0.9678 - val_accuracy: 0.5414\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 0.9847 - accuracy: 0.5288 - val_loss: 0.9676 - val_accuracy: 0.5423\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 773us/step - loss: 0.9844 - accuracy: 0.5298 - val_loss: 0.9671 - val_accuracy: 0.5414\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9841 - accuracy: 0.5297 - val_loss: 0.9671 - val_accuracy: 0.5414\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 626us/step - loss: 0.9837 - accuracy: 0.5280 - val_loss: 0.9664 - val_accuracy: 0.5414\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9833 - accuracy: 0.5289 - val_loss: 0.9662 - val_accuracy: 0.5418\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 629us/step - loss: 0.9831 - accuracy: 0.5304 - val_loss: 0.9659 - val_accuracy: 0.5418\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9827 - accuracy: 0.5289 - val_loss: 0.9659 - val_accuracy: 0.5414\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 809us/step - loss: 0.9826 - accuracy: 0.5301 - val_loss: 0.9659 - val_accuracy: 0.5370\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9822 - accuracy: 0.5305 - val_loss: 0.9653 - val_accuracy: 0.5423\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 821us/step - loss: 0.9821 - accuracy: 0.5286 - val_loss: 0.9649 - val_accuracy: 0.5418\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 725us/step - loss: 0.9817 - accuracy: 0.5298 - val_loss: 0.9650 - val_accuracy: 0.5414\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 584us/step - loss: 0.9815 - accuracy: 0.5283 - val_loss: 0.9649 - val_accuracy: 0.5414\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 770us/step - loss: 0.9813 - accuracy: 0.5299 - val_loss: 0.9645 - val_accuracy: 0.5418\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 754us/step - loss: 0.9810 - accuracy: 0.5297 - val_loss: 0.9642 - val_accuracy: 0.5418\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9808 - accuracy: 0.5297 - val_loss: 0.9643 - val_accuracy: 0.5378\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 653us/step - loss: 0.9806 - accuracy: 0.5302 - val_loss: 0.9638 - val_accuracy: 0.5418\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9804 - accuracy: 0.5302 - val_loss: 0.9641 - val_accuracy: 0.5378\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 799us/step - loss: 0.9802 - accuracy: 0.5304 - val_loss: 0.9636 - val_accuracy: 0.5414\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9806 - accuracy: 0.5285 - val_loss: 0.9637 - val_accuracy: 0.5409\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 656us/step - loss: 0.9800 - accuracy: 0.5290 - val_loss: 0.9638 - val_accuracy: 0.5378\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 628us/step - loss: 0.9798 - accuracy: 0.5300 - val_loss: 0.9636 - val_accuracy: 0.5378\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 754us/step - loss: 0.9796 - accuracy: 0.5298 - val_loss: 0.9635 - val_accuracy: 0.5392\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 658us/step - loss: 0.9794 - accuracy: 0.5298 - val_loss: 0.9633 - val_accuracy: 0.5374\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 851us/step - loss: 0.9793 - accuracy: 0.5303 - val_loss: 0.9633 - val_accuracy: 0.5378\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9792 - accuracy: 0.5292 - val_loss: 0.9628 - val_accuracy: 0.5414\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9790 - accuracy: 0.5302 - val_loss: 0.9627 - val_accuracy: 0.5378\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9789 - accuracy: 0.5298 - val_loss: 0.9630 - val_accuracy: 0.5370\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 676us/step - loss: 0.9788 - accuracy: 0.5296 - val_loss: 0.9627 - val_accuracy: 0.5374\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 782us/step - loss: 0.9787 - accuracy: 0.5296 - val_loss: 0.9626 - val_accuracy: 0.5392\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9786 - accuracy: 0.5301 - val_loss: 0.9626 - val_accuracy: 0.5374\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 808us/step - loss: 0.9782 - accuracy: 0.5303 - val_loss: 0.9627 - val_accuracy: 0.5374\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9781 - accuracy: 0.5300 - val_loss: 0.9625 - val_accuracy: 0.5378\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 737us/step - loss: 0.9782 - accuracy: 0.5292 - val_loss: 0.9625 - val_accuracy: 0.5378\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 806us/step - loss: 0.9782 - accuracy: 0.5296 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9778 - accuracy: 0.5294 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 742us/step - loss: 0.9779 - accuracy: 0.5292 - val_loss: 0.9626 - val_accuracy: 0.5361\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 804us/step - loss: 0.9779 - accuracy: 0.5296 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 665us/step - loss: 0.9776 - accuracy: 0.5291 - val_loss: 0.9621 - val_accuracy: 0.5396\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 854us/step - loss: 0.9782 - accuracy: 0.5292 - val_loss: 0.9627 - val_accuracy: 0.5370\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 633us/step - loss: 0.9775 - accuracy: 0.5300 - val_loss: 0.9623 - val_accuracy: 0.5361\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 713us/step - loss: 0.9773 - accuracy: 0.5291 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9776 - accuracy: 0.5284 - val_loss: 0.9622 - val_accuracy: 0.5383\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 801us/step - loss: 0.9777 - accuracy: 0.5303 - val_loss: 0.9627 - val_accuracy: 0.5370\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 745us/step - loss: 0.9772 - accuracy: 0.5301 - val_loss: 0.9624 - val_accuracy: 0.5365\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 589us/step - loss: 0.9771 - accuracy: 0.5303 - val_loss: 0.9623 - val_accuracy: 0.5365\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 794us/step - loss: 0.9771 - accuracy: 0.5299 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 767us/step - loss: 0.9771 - accuracy: 0.5299 - val_loss: 0.9624 - val_accuracy: 0.5361\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9771 - accuracy: 0.5290 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 789us/step - loss: 0.9769 - accuracy: 0.5298 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9770 - accuracy: 0.5299 - val_loss: 0.9620 - val_accuracy: 0.5365\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9769 - accuracy: 0.5299 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 738us/step - loss: 0.9771 - accuracy: 0.5301 - val_loss: 0.9622 - val_accuracy: 0.5361\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 735us/step - loss: 0.9768 - accuracy: 0.5301 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9769 - accuracy: 0.5302 - val_loss: 0.9620 - val_accuracy: 0.5365\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 696us/step - loss: 0.9768 - accuracy: 0.5298 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 601us/step - loss: 0.9769 - accuracy: 0.5304 - val_loss: 0.9623 - val_accuracy: 0.5370\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 847us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 685us/step - loss: 0.9773 - accuracy: 0.5297 - val_loss: 0.9626 - val_accuracy: 0.5370\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9767 - accuracy: 0.5295 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 830us/step - loss: 0.9767 - accuracy: 0.5284 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 511us/step - loss: 0.9765 - accuracy: 0.5303 - val_loss: 0.9621 - val_accuracy: 0.5370\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 602us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 815us/step - loss: 0.9765 - accuracy: 0.5301 - val_loss: 0.9624 - val_accuracy: 0.5361\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 544us/step - loss: 0.9766 - accuracy: 0.5299 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9764 - accuracy: 0.5289 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 804us/step - loss: 0.9765 - accuracy: 0.5305 - val_loss: 0.9620 - val_accuracy: 0.5365\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 580us/step - loss: 0.9764 - accuracy: 0.5301 - val_loss: 0.9622 - val_accuracy: 0.5365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 794us/step - loss: 0.9764 - accuracy: 0.5302 - val_loss: 0.9620 - val_accuracy: 0.5361\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 560us/step - loss: 0.9765 - accuracy: 0.5286 - val_loss: 0.9621 - val_accuracy: 0.5370\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 631us/step - loss: 0.9763 - accuracy: 0.5294 - val_loss: 0.9619 - val_accuracy: 0.5374\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 794us/step - loss: 0.9763 - accuracy: 0.5293 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 619us/step - loss: 0.9764 - accuracy: 0.5303 - val_loss: 0.9620 - val_accuracy: 0.5365\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 707us/step - loss: 0.9762 - accuracy: 0.5296 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 825us/step - loss: 0.9762 - accuracy: 0.5301 - val_loss: 0.9617 - val_accuracy: 0.5365\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 577us/step - loss: 0.9763 - accuracy: 0.5293 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 836us/step - loss: 0.9762 - accuracy: 0.5294 - val_loss: 0.9618 - val_accuracy: 0.5361\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9764 - accuracy: 0.5298 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 624us/step - loss: 0.9762 - accuracy: 0.5292 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9761 - accuracy: 0.5299 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 854us/step - loss: 0.9762 - accuracy: 0.5299 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 559us/step - loss: 0.9763 - accuracy: 0.5298 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 686us/step - loss: 0.9761 - accuracy: 0.5298 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9762 - accuracy: 0.5296 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 789us/step - loss: 0.9761 - accuracy: 0.5286 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 683us/step - loss: 0.9765 - accuracy: 0.5300 - val_loss: 0.9623 - val_accuracy: 0.5365\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 671us/step - loss: 0.9761 - accuracy: 0.5293 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 795us/step - loss: 0.9761 - accuracy: 0.5299 - val_loss: 0.9623 - val_accuracy: 0.5365\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9764 - accuracy: 0.5290 - val_loss: 0.9621 - val_accuracy: 0.5370\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9760 - accuracy: 0.5294 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 818us/step - loss: 0.9761 - accuracy: 0.5299 - val_loss: 0.9620 - val_accuracy: 0.5365\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9768 - accuracy: 0.5297 - val_loss: 0.9626 - val_accuracy: 0.5374\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 607us/step - loss: 0.9762 - accuracy: 0.5280 - val_loss: 0.9625 - val_accuracy: 0.5378\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9760 - accuracy: 0.5282 - val_loss: 0.9623 - val_accuracy: 0.5370\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9759 - accuracy: 0.5291 - val_loss: 0.9623 - val_accuracy: 0.5370\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 585us/step - loss: 0.9759 - accuracy: 0.5298 - val_loss: 0.9622 - val_accuracy: 0.5365\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 719us/step - loss: 0.9760 - accuracy: 0.5299 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 851us/step - loss: 0.9759 - accuracy: 0.5302 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 621us/step - loss: 0.9759 - accuracy: 0.5301 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 847us/step - loss: 0.9761 - accuracy: 0.5299 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 681us/step - loss: 0.9759 - accuracy: 0.5291 - val_loss: 0.9618 - val_accuracy: 0.5365\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 611us/step - loss: 0.9761 - accuracy: 0.5301 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 857us/step - loss: 0.9760 - accuracy: 0.5297 - val_loss: 0.9617 - val_accuracy: 0.5374\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 681us/step - loss: 0.9765 - accuracy: 0.5307 - val_loss: 0.9626 - val_accuracy: 0.5361\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9761 - accuracy: 0.5284 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 833us/step - loss: 0.9761 - accuracy: 0.5294 - val_loss: 0.9623 - val_accuracy: 0.5374\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 770us/step - loss: 0.9759 - accuracy: 0.5293 - val_loss: 0.9623 - val_accuracy: 0.5374\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9759 - accuracy: 0.5294 - val_loss: 0.9621 - val_accuracy: 0.5378\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 698us/step - loss: 0.9759 - accuracy: 0.5298 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 772us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9619 - val_accuracy: 0.5370\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 849us/step - loss: 0.9759 - accuracy: 0.5302 - val_loss: 0.9621 - val_accuracy: 0.5370\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9759 - accuracy: 0.5298 - val_loss: 0.9617 - val_accuracy: 0.5365\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 842us/step - loss: 0.9759 - accuracy: 0.5288 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 715us/step - loss: 0.9760 - accuracy: 0.5308 - val_loss: 0.9621 - val_accuracy: 0.5370\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 849us/step - loss: 0.9758 - accuracy: 0.5298 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 731us/step - loss: 0.9759 - accuracy: 0.5297 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 737us/step - loss: 0.9758 - accuracy: 0.5302 - val_loss: 0.9619 - val_accuracy: 0.5374\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9758 - accuracy: 0.5292 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 687us/step - loss: 0.9758 - accuracy: 0.5293 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 612us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9621 - val_accuracy: 0.5370\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9758 - accuracy: 0.5291 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 836us/step - loss: 0.9759 - accuracy: 0.5298 - val_loss: 0.9622 - val_accuracy: 0.5374\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 666us/step - loss: 0.9758 - accuracy: 0.5296 - val_loss: 0.9619 - val_accuracy: 0.5365\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9759 - accuracy: 0.5293 - val_loss: 0.9621 - val_accuracy: 0.5365\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9758 - accuracy: 0.5303 - val_loss: 0.9618 - val_accuracy: 0.5378\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9760 - accuracy: 0.5296 - val_loss: 0.9619 - val_accuracy: 0.5370\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9757 - accuracy: 0.5295 - val_loss: 0.9619 - val_accuracy: 0.5370\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 791us/step - loss: 0.9760 - accuracy: 0.5285 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 617us/step - loss: 0.9759 - accuracy: 0.5286 - val_loss: 0.9617 - val_accuracy: 0.5374\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 0.9617 - val_accuracy: 0.5374\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 849us/step - loss: 0.9757 - accuracy: 0.5291 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 833us/step - loss: 0.9756 - accuracy: 0.5292 - val_loss: 0.9619 - val_accuracy: 0.5370\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 548us/step - loss: 0.9757 - accuracy: 0.5296 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 767us/step - loss: 0.9759 - accuracy: 0.5294 - val_loss: 0.9617 - val_accuracy: 0.5365\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 787us/step - loss: 0.9758 - accuracy: 0.5296 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 561us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 771us/step - loss: 0.9758 - accuracy: 0.5288 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 776us/step - loss: 0.9758 - accuracy: 0.5290 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 766us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 729us/step - loss: 0.9758 - accuracy: 0.5300 - val_loss: 0.9617 - val_accuracy: 0.5387\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 594us/step - loss: 0.9756 - accuracy: 0.5299 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 801us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 787us/step - loss: 0.9758 - accuracy: 0.5288 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 623us/step - loss: 0.9758 - accuracy: 0.5301 - val_loss: 0.9621 - val_accuracy: 0.5370\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 620us/step - loss: 0.9759 - accuracy: 0.5298 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 881us/step - loss: 0.9758 - accuracy: 0.5305 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 760us/step - loss: 0.9757 - accuracy: 0.5292 - val_loss: 0.9619 - val_accuracy: 0.5374\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 738us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 767us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9619 - val_accuracy: 0.5374\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 749us/step - loss: 0.9758 - accuracy: 0.5297 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 744us/step - loss: 0.9756 - accuracy: 0.5290 - val_loss: 0.9616 - val_accuracy: 0.5392\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 737us/step - loss: 0.9758 - accuracy: 0.5296 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 713us/step - loss: 0.9757 - accuracy: 0.5303 - val_loss: 0.9616 - val_accuracy: 0.5365\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 818us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9617 - val_accuracy: 0.5374\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9757 - accuracy: 0.5297 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9758 - accuracy: 0.5293 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9757 - accuracy: 0.5297 - val_loss: 0.9619 - val_accuracy: 0.5374\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9758 - accuracy: 0.5298 - val_loss: 0.9622 - val_accuracy: 0.5370\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 797us/step - loss: 0.9757 - accuracy: 0.5286 - val_loss: 0.9618 - val_accuracy: 0.5365\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9619 - val_accuracy: 0.5370\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9758 - accuracy: 0.5303 - val_loss: 0.9624 - val_accuracy: 0.5370\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9757 - accuracy: 0.5293 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9759 - accuracy: 0.5288 - val_loss: 0.9617 - val_accuracy: 0.5370\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9758 - accuracy: 0.5299 - val_loss: 0.9616 - val_accuracy: 0.5374\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9756 - accuracy: 0.5301 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9756 - accuracy: 0.5298 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9757 - accuracy: 0.5293 - val_loss: 0.9620 - val_accuracy: 0.5374\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9757 - accuracy: 0.5292 - val_loss: 0.9620 - val_accuracy: 0.5370\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 703us/step - loss: 0.9757 - accuracy: 0.5300 - val_loss: 0.9621 - val_accuracy: 0.5374\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9757 - accuracy: 0.5298 - val_loss: 0.9618 - val_accuracy: 0.5378\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9758 - accuracy: 0.5298 - val_loss: 0.9618 - val_accuracy: 0.5370\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 401us/step - loss: 0.9754 - accuracy: 0.5300\n",
      "Accuracy : 0.5299758911132812\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9618 - accuracy: 0.5370\n",
      "Accuracy : 0.5369632840156555\n",
      "Fold #8\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0558 - accuracy: 0.4591 - val_loss: 1.0473 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 1.0489 - accuracy: 0.4591 - val_loss: 1.0415 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 1.0437 - accuracy: 0.4591 - val_loss: 1.0341 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 701us/step - loss: 1.0373 - accuracy: 0.4591 - val_loss: 1.0256 - val_accuracy: 0.4591\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 1.0301 - accuracy: 0.4625 - val_loss: 1.0156 - val_accuracy: 0.5241\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 1.0206 - accuracy: 0.5101 - val_loss: 1.0013 - val_accuracy: 0.5378\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 1.0097 - accuracy: 0.5220 - val_loss: 0.9881 - val_accuracy: 0.5405\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 1.0021 - accuracy: 0.5266 - val_loss: 0.9794 - val_accuracy: 0.5414\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9977 - accuracy: 0.5289 - val_loss: 0.9745 - val_accuracy: 0.5427\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9947 - accuracy: 0.5285 - val_loss: 0.9705 - val_accuracy: 0.5454\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 676us/step - loss: 0.9924 - accuracy: 0.5290 - val_loss: 0.9672 - val_accuracy: 0.5436\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9908 - accuracy: 0.5284 - val_loss: 0.9646 - val_accuracy: 0.5436\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9894 - accuracy: 0.5289 - val_loss: 0.9626 - val_accuracy: 0.5449\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9888 - accuracy: 0.5285 - val_loss: 0.9616 - val_accuracy: 0.5449\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9881 - accuracy: 0.5276 - val_loss: 0.9601 - val_accuracy: 0.5454\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9883 - accuracy: 0.5287 - val_loss: 0.9595 - val_accuracy: 0.5445\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9870 - accuracy: 0.5284 - val_loss: 0.9588 - val_accuracy: 0.5440\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 856us/step - loss: 0.9864 - accuracy: 0.5275 - val_loss: 0.9572 - val_accuracy: 0.5454\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 747us/step - loss: 0.9864 - accuracy: 0.5278 - val_loss: 0.9565 - val_accuracy: 0.5454\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9858 - accuracy: 0.5283 - val_loss: 0.9562 - val_accuracy: 0.5440\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 807us/step - loss: 0.9856 - accuracy: 0.5265 - val_loss: 0.9555 - val_accuracy: 0.5454\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9853 - accuracy: 0.5303 - val_loss: 0.9550 - val_accuracy: 0.5449\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 798us/step - loss: 0.9849 - accuracy: 0.5286 - val_loss: 0.9545 - val_accuracy: 0.5440\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 786us/step - loss: 0.9847 - accuracy: 0.5272 - val_loss: 0.9538 - val_accuracy: 0.5445\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9841 - accuracy: 0.5289 - val_loss: 0.9531 - val_accuracy: 0.5440\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 797us/step - loss: 0.9839 - accuracy: 0.5285 - val_loss: 0.9525 - val_accuracy: 0.5454\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9837 - accuracy: 0.5287 - val_loss: 0.9519 - val_accuracy: 0.5454\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9835 - accuracy: 0.5286 - val_loss: 0.9517 - val_accuracy: 0.5454\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9831 - accuracy: 0.5275 - val_loss: 0.9512 - val_accuracy: 0.5454\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 699us/step - loss: 0.9829 - accuracy: 0.5286 - val_loss: 0.9507 - val_accuracy: 0.5454\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9828 - accuracy: 0.5290 - val_loss: 0.9504 - val_accuracy: 0.5454\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 0.9826 - accuracy: 0.5295 - val_loss: 0.9505 - val_accuracy: 0.5454\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9826 - accuracy: 0.5284 - val_loss: 0.9500 - val_accuracy: 0.5449\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9821 - accuracy: 0.5288 - val_loss: 0.9500 - val_accuracy: 0.5449\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9828 - accuracy: 0.5273 - val_loss: 0.9492 - val_accuracy: 0.5454\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 688us/step - loss: 0.9818 - accuracy: 0.5292 - val_loss: 0.9487 - val_accuracy: 0.5454\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9818 - accuracy: 0.5280 - val_loss: 0.9486 - val_accuracy: 0.5440\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 593us/step - loss: 0.9816 - accuracy: 0.5291 - val_loss: 0.9480 - val_accuracy: 0.5440\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9815 - accuracy: 0.5287 - val_loss: 0.9478 - val_accuracy: 0.5440\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9814 - accuracy: 0.5292 - val_loss: 0.9474 - val_accuracy: 0.5440\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9814 - accuracy: 0.5284 - val_loss: 0.9473 - val_accuracy: 0.5436\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9812 - accuracy: 0.5285 - val_loss: 0.9471 - val_accuracy: 0.5440\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9814 - accuracy: 0.5289 - val_loss: 0.9469 - val_accuracy: 0.5440\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9810 - accuracy: 0.5289 - val_loss: 0.9466 - val_accuracy: 0.5440\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9810 - accuracy: 0.5296 - val_loss: 0.9463 - val_accuracy: 0.5440\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 734us/step - loss: 0.9809 - accuracy: 0.5291 - val_loss: 0.9460 - val_accuracy: 0.5440\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9808 - accuracy: 0.5292 - val_loss: 0.9457 - val_accuracy: 0.5405\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9807 - accuracy: 0.5279 - val_loss: 0.9457 - val_accuracy: 0.5440\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9806 - accuracy: 0.5287 - val_loss: 0.9456 - val_accuracy: 0.5440\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9803 - accuracy: 0.5291 - val_loss: 0.9456 - val_accuracy: 0.5463\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9802 - accuracy: 0.5287 - val_loss: 0.9451 - val_accuracy: 0.5440\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9807 - accuracy: 0.5283 - val_loss: 0.9451 - val_accuracy: 0.5427\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9802 - accuracy: 0.5295 - val_loss: 0.9447 - val_accuracy: 0.5418\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9800 - accuracy: 0.5290 - val_loss: 0.9446 - val_accuracy: 0.5423\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9799 - accuracy: 0.5291 - val_loss: 0.9447 - val_accuracy: 0.5440\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9800 - accuracy: 0.5287 - val_loss: 0.9454 - val_accuracy: 0.5440\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9800 - accuracy: 0.5286 - val_loss: 0.9446 - val_accuracy: 0.5432\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9799 - accuracy: 0.5295 - val_loss: 0.9445 - val_accuracy: 0.5427\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9799 - accuracy: 0.5288 - val_loss: 0.9442 - val_accuracy: 0.5405\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 841us/step - loss: 0.9798 - accuracy: 0.5285 - val_loss: 0.9444 - val_accuracy: 0.5440\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 744us/step - loss: 0.9797 - accuracy: 0.5297 - val_loss: 0.9442 - val_accuracy: 0.5440\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 786us/step - loss: 0.9797 - accuracy: 0.5288 - val_loss: 0.9437 - val_accuracy: 0.5423\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9799 - accuracy: 0.5286 - val_loss: 0.9442 - val_accuracy: 0.5440\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9797 - accuracy: 0.5299 - val_loss: 0.9441 - val_accuracy: 0.5440\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 711us/step - loss: 0.9799 - accuracy: 0.5287 - val_loss: 0.9437 - val_accuracy: 0.5427\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9797 - accuracy: 0.5288 - val_loss: 0.9438 - val_accuracy: 0.5423\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9795 - accuracy: 0.5286 - val_loss: 0.9437 - val_accuracy: 0.5423\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9794 - accuracy: 0.5292 - val_loss: 0.9435 - val_accuracy: 0.5427\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 704us/step - loss: 0.9794 - accuracy: 0.5291 - val_loss: 0.9432 - val_accuracy: 0.5427\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9795 - accuracy: 0.5291 - val_loss: 0.9430 - val_accuracy: 0.5405\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9794 - accuracy: 0.5291 - val_loss: 0.9431 - val_accuracy: 0.5427\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9794 - accuracy: 0.5295 - val_loss: 0.9427 - val_accuracy: 0.5427\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9796 - accuracy: 0.5273 - val_loss: 0.9429 - val_accuracy: 0.5427\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9794 - accuracy: 0.5287 - val_loss: 0.9428 - val_accuracy: 0.5405\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9792 - accuracy: 0.5295 - val_loss: 0.9426 - val_accuracy: 0.5405\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9793 - accuracy: 0.5273 - val_loss: 0.9430 - val_accuracy: 0.5427\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9794 - accuracy: 0.5301 - val_loss: 0.9429 - val_accuracy: 0.5427\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9427 - val_accuracy: 0.5427\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9791 - accuracy: 0.5291 - val_loss: 0.9429 - val_accuracy: 0.5427\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9791 - accuracy: 0.5291 - val_loss: 0.9427 - val_accuracy: 0.5405\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9791 - accuracy: 0.5274 - val_loss: 0.9430 - val_accuracy: 0.5405\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9789 - accuracy: 0.5292 - val_loss: 0.9425 - val_accuracy: 0.5418\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9791 - accuracy: 0.5287 - val_loss: 0.9423 - val_accuracy: 0.5423\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9791 - accuracy: 0.5279 - val_loss: 0.9424 - val_accuracy: 0.5432\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 709us/step - loss: 0.9791 - accuracy: 0.5289 - val_loss: 0.9426 - val_accuracy: 0.5405\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9791 - accuracy: 0.5286 - val_loss: 0.9425 - val_accuracy: 0.5405\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9792 - accuracy: 0.5290 - val_loss: 0.9424 - val_accuracy: 0.5405\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9789 - accuracy: 0.5290 - val_loss: 0.9421 - val_accuracy: 0.5405\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9790 - accuracy: 0.5284 - val_loss: 0.9424 - val_accuracy: 0.5427\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9792 - accuracy: 0.5289 - val_loss: 0.9418 - val_accuracy: 0.5423\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 703us/step - loss: 0.9788 - accuracy: 0.5293 - val_loss: 0.9415 - val_accuracy: 0.5427\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 738us/step - loss: 0.9790 - accuracy: 0.5281 - val_loss: 0.9415 - val_accuracy: 0.5423\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9790 - accuracy: 0.5289 - val_loss: 0.9416 - val_accuracy: 0.5423\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9790 - accuracy: 0.5288 - val_loss: 0.9423 - val_accuracy: 0.5427\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 755us/step - loss: 0.9794 - accuracy: 0.5301 - val_loss: 0.9421 - val_accuracy: 0.5414\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9788 - accuracy: 0.5289 - val_loss: 0.9417 - val_accuracy: 0.5409\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9788 - accuracy: 0.5284 - val_loss: 0.9423 - val_accuracy: 0.5427\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9788 - accuracy: 0.5299 - val_loss: 0.9415 - val_accuracy: 0.5423\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9788 - accuracy: 0.5286 - val_loss: 0.9416 - val_accuracy: 0.5405\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9787 - accuracy: 0.5295 - val_loss: 0.9420 - val_accuracy: 0.5427\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9788 - accuracy: 0.5291 - val_loss: 0.9417 - val_accuracy: 0.5405\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9787 - accuracy: 0.5292 - val_loss: 0.9414 - val_accuracy: 0.5423\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9788 - accuracy: 0.5284 - val_loss: 0.9418 - val_accuracy: 0.5427\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9788 - accuracy: 0.5298 - val_loss: 0.9415 - val_accuracy: 0.5405\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9788 - accuracy: 0.5286 - val_loss: 0.9412 - val_accuracy: 0.5436\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9789 - accuracy: 0.5283 - val_loss: 0.9419 - val_accuracy: 0.5427\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9788 - accuracy: 0.5293 - val_loss: 0.9419 - val_accuracy: 0.5427\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9787 - accuracy: 0.5294 - val_loss: 0.9415 - val_accuracy: 0.5405\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9788 - accuracy: 0.5282 - val_loss: 0.9418 - val_accuracy: 0.5405\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9788 - accuracy: 0.5295 - val_loss: 0.9417 - val_accuracy: 0.5405\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9787 - accuracy: 0.5289 - val_loss: 0.9417 - val_accuracy: 0.5427\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9788 - accuracy: 0.5294 - val_loss: 0.9415 - val_accuracy: 0.5405\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 722us/step - loss: 0.9787 - accuracy: 0.5285 - val_loss: 0.9420 - val_accuracy: 0.5427\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9786 - accuracy: 0.5295 - val_loss: 0.9415 - val_accuracy: 0.5405\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9785 - accuracy: 0.5286 - val_loss: 0.9411 - val_accuracy: 0.5414\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9790 - accuracy: 0.5285 - val_loss: 0.9414 - val_accuracy: 0.5409\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9787 - accuracy: 0.5278 - val_loss: 0.9424 - val_accuracy: 0.5414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9785 - accuracy: 0.5286 - val_loss: 0.9414 - val_accuracy: 0.5436\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9787 - accuracy: 0.5286 - val_loss: 0.9419 - val_accuracy: 0.5409\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 707us/step - loss: 0.9791 - accuracy: 0.5291 - val_loss: 0.9420 - val_accuracy: 0.5432\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9787 - accuracy: 0.5276 - val_loss: 0.9419 - val_accuracy: 0.5436\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 766us/step - loss: 0.9785 - accuracy: 0.5288 - val_loss: 0.9416 - val_accuracy: 0.5436\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9785 - accuracy: 0.5292 - val_loss: 0.9416 - val_accuracy: 0.5423\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9788 - accuracy: 0.5292 - val_loss: 0.9417 - val_accuracy: 0.5427\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9786 - accuracy: 0.5292 - val_loss: 0.9414 - val_accuracy: 0.5405\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 690us/step - loss: 0.9785 - accuracy: 0.5287 - val_loss: 0.9412 - val_accuracy: 0.5423\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9786 - accuracy: 0.5291 - val_loss: 0.9410 - val_accuracy: 0.5436\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9787 - accuracy: 0.5289 - val_loss: 0.9414 - val_accuracy: 0.5409\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9787 - accuracy: 0.5285 - val_loss: 0.9412 - val_accuracy: 0.5405\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 744us/step - loss: 0.9786 - accuracy: 0.5291 - val_loss: 0.9416 - val_accuracy: 0.5427\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9789 - accuracy: 0.5289 - val_loss: 0.9412 - val_accuracy: 0.5423\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9787 - accuracy: 0.5283 - val_loss: 0.9414 - val_accuracy: 0.5405\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9784 - accuracy: 0.5294 - val_loss: 0.9409 - val_accuracy: 0.5409\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9786 - accuracy: 0.5288 - val_loss: 0.9412 - val_accuracy: 0.5409\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9786 - accuracy: 0.5285 - val_loss: 0.9415 - val_accuracy: 0.5427\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9785 - accuracy: 0.5283 - val_loss: 0.9417 - val_accuracy: 0.5427\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9793 - accuracy: 0.5301 - val_loss: 0.9415 - val_accuracy: 0.5405\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9784 - accuracy: 0.5283 - val_loss: 0.9409 - val_accuracy: 0.5432\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9785 - accuracy: 0.5275 - val_loss: 0.9415 - val_accuracy: 0.5427\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9785 - accuracy: 0.5291 - val_loss: 0.9412 - val_accuracy: 0.5405\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 711us/step - loss: 0.9786 - accuracy: 0.5292 - val_loss: 0.9413 - val_accuracy: 0.5423\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 720us/step - loss: 0.9784 - accuracy: 0.5283 - val_loss: 0.9422 - val_accuracy: 0.5427\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9783 - accuracy: 0.5287 - val_loss: 0.9412 - val_accuracy: 0.5432\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9786 - accuracy: 0.5279 - val_loss: 0.9412 - val_accuracy: 0.5409\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9785 - accuracy: 0.5285 - val_loss: 0.9419 - val_accuracy: 0.5427\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 799us/step - loss: 0.9786 - accuracy: 0.5284 - val_loss: 0.9414 - val_accuracy: 0.5405\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9783 - accuracy: 0.5283 - val_loss: 0.9413 - val_accuracy: 0.5409\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 798us/step - loss: 0.9782 - accuracy: 0.5288 - val_loss: 0.9422 - val_accuracy: 0.5440\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9787 - accuracy: 0.5286 - val_loss: 0.9413 - val_accuracy: 0.5405\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9783 - accuracy: 0.5285 - val_loss: 0.9409 - val_accuracy: 0.5423\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 810us/step - loss: 0.9783 - accuracy: 0.5288 - val_loss: 0.9416 - val_accuracy: 0.5427\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 738us/step - loss: 0.9783 - accuracy: 0.5290 - val_loss: 0.9409 - val_accuracy: 0.5423\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9784 - accuracy: 0.5284 - val_loss: 0.9411 - val_accuracy: 0.5423\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 708us/step - loss: 0.9784 - accuracy: 0.5285 - val_loss: 0.9411 - val_accuracy: 0.5405\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9785 - accuracy: 0.5288 - val_loss: 0.9407 - val_accuracy: 0.5432\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9784 - accuracy: 0.5275 - val_loss: 0.9413 - val_accuracy: 0.5423\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9784 - accuracy: 0.5289 - val_loss: 0.9416 - val_accuracy: 0.5427\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 719us/step - loss: 0.9785 - accuracy: 0.5286 - val_loss: 0.9410 - val_accuracy: 0.5409\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9783 - accuracy: 0.5293 - val_loss: 0.9417 - val_accuracy: 0.5427\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9787 - accuracy: 0.5288 - val_loss: 0.9418 - val_accuracy: 0.5432\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9783 - accuracy: 0.5287 - val_loss: 0.9413 - val_accuracy: 0.5423\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9783 - accuracy: 0.5288 - val_loss: 0.9414 - val_accuracy: 0.5423\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 713us/step - loss: 0.9784 - accuracy: 0.5280 - val_loss: 0.9416 - val_accuracy: 0.5405\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9783 - accuracy: 0.5281 - val_loss: 0.9411 - val_accuracy: 0.5423\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9783 - accuracy: 0.5292 - val_loss: 0.9409 - val_accuracy: 0.5423\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9784 - accuracy: 0.5286 - val_loss: 0.9415 - val_accuracy: 0.5409\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9786 - accuracy: 0.5290 - val_loss: 0.9415 - val_accuracy: 0.5423\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9782 - accuracy: 0.5289 - val_loss: 0.9415 - val_accuracy: 0.5409\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9782 - accuracy: 0.5282 - val_loss: 0.9415 - val_accuracy: 0.5409\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9782 - accuracy: 0.5289 - val_loss: 0.9413 - val_accuracy: 0.5405\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9785 - accuracy: 0.5287 - val_loss: 0.9413 - val_accuracy: 0.5409\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9782 - accuracy: 0.5285 - val_loss: 0.9412 - val_accuracy: 0.5423\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9783 - accuracy: 0.5298 - val_loss: 0.9413 - val_accuracy: 0.5423\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 678us/step - loss: 0.9782 - accuracy: 0.5288 - val_loss: 0.9410 - val_accuracy: 0.5423\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 681us/step - loss: 0.9782 - accuracy: 0.5286 - val_loss: 0.9414 - val_accuracy: 0.5414\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9783 - accuracy: 0.5291 - val_loss: 0.9414 - val_accuracy: 0.5409\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 672us/step - loss: 0.9783 - accuracy: 0.5292 - val_loss: 0.9411 - val_accuracy: 0.5409\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9784 - accuracy: 0.5296 - val_loss: 0.9417 - val_accuracy: 0.5427\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 802us/step - loss: 0.9783 - accuracy: 0.5295 - val_loss: 0.9414 - val_accuracy: 0.5427\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9784 - accuracy: 0.5291 - val_loss: 0.9414 - val_accuracy: 0.5427\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 598us/step - loss: 0.9782 - accuracy: 0.5293 - val_loss: 0.9415 - val_accuracy: 0.5427\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 815us/step - loss: 0.9784 - accuracy: 0.5282 - val_loss: 0.9410 - val_accuracy: 0.5409\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 754us/step - loss: 0.9783 - accuracy: 0.5284 - val_loss: 0.9416 - val_accuracy: 0.5427\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 709us/step - loss: 0.9783 - accuracy: 0.5288 - val_loss: 0.9415 - val_accuracy: 0.5427\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9783 - accuracy: 0.5298 - val_loss: 0.9409 - val_accuracy: 0.5423\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9785 - accuracy: 0.5281 - val_loss: 0.9412 - val_accuracy: 0.5405\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 730us/step - loss: 0.9781 - accuracy: 0.5293 - val_loss: 0.9418 - val_accuracy: 0.5427\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9783 - accuracy: 0.5296 - val_loss: 0.9413 - val_accuracy: 0.5427\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9781 - accuracy: 0.5297 - val_loss: 0.9412 - val_accuracy: 0.5405\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9784 - accuracy: 0.5288 - val_loss: 0.9415 - val_accuracy: 0.5427\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9784 - accuracy: 0.5293 - val_loss: 0.9417 - val_accuracy: 0.5427\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9785 - accuracy: 0.5299 - val_loss: 0.9416 - val_accuracy: 0.5427\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9782 - accuracy: 0.5291 - val_loss: 0.9413 - val_accuracy: 0.5414\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9781 - accuracy: 0.5287 - val_loss: 0.9415 - val_accuracy: 0.5427\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 733us/step - loss: 0.9783 - accuracy: 0.5290 - val_loss: 0.9414 - val_accuracy: 0.5427\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 699us/step - loss: 0.9782 - accuracy: 0.5286 - val_loss: 0.9410 - val_accuracy: 0.5409\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9781 - accuracy: 0.5287 - val_loss: 0.9410 - val_accuracy: 0.5409\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9783 - accuracy: 0.5289 - val_loss: 0.9415 - val_accuracy: 0.5427\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9786 - accuracy: 0.5294 - val_loss: 0.9414 - val_accuracy: 0.5414\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9782 - accuracy: 0.5292 - val_loss: 0.9407 - val_accuracy: 0.5423\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 387us/step - loss: 0.9780 - accuracy: 0.5281\n",
      "Accuracy : 0.5280578136444092\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9407 - accuracy: 0.5423\n",
      "Accuracy : 0.5422753691673279\n",
      "Fold #9\n",
      "Epoch 1/200\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.1773 - accuracy: 0.2879 - val_loss: 1.1357 - val_accuracy: 0.2882\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 1.1080 - accuracy: 0.2879 - val_loss: 1.0864 - val_accuracy: 0.2882\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 1.0756 - accuracy: 0.4399 - val_loss: 1.0665 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 1.0612 - accuracy: 0.4591 - val_loss: 1.0566 - val_accuracy: 0.4591\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 688us/step - loss: 1.0520 - accuracy: 0.4591 - val_loss: 1.0472 - val_accuracy: 0.4591\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 1.0450 - accuracy: 0.4591 - val_loss: 1.0421 - val_accuracy: 0.4591\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 1.0389 - accuracy: 0.4620 - val_loss: 1.0346 - val_accuracy: 0.4936\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 1.0312 - accuracy: 0.4901 - val_loss: 1.0270 - val_accuracy: 0.5144\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 722us/step - loss: 1.0228 - accuracy: 0.5117 - val_loss: 1.0184 - val_accuracy: 0.5228\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 1.0155 - accuracy: 0.5222 - val_loss: 1.0120 - val_accuracy: 0.5232\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 1.0097 - accuracy: 0.5234 - val_loss: 1.0068 - val_accuracy: 0.5206\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 1.0045 - accuracy: 0.5276 - val_loss: 1.0016 - val_accuracy: 0.5228\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 1.0003 - accuracy: 0.5310 - val_loss: 0.9974 - val_accuracy: 0.5224\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9969 - accuracy: 0.5311 - val_loss: 0.9943 - val_accuracy: 0.5263\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9944 - accuracy: 0.5308 - val_loss: 0.9919 - val_accuracy: 0.5277\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9925 - accuracy: 0.5300 - val_loss: 0.9896 - val_accuracy: 0.5228\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9909 - accuracy: 0.5303 - val_loss: 0.9879 - val_accuracy: 0.5347\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9894 - accuracy: 0.5298 - val_loss: 0.9863 - val_accuracy: 0.5268\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 781us/step - loss: 0.9889 - accuracy: 0.5302 - val_loss: 0.9857 - val_accuracy: 0.5347\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9876 - accuracy: 0.5304 - val_loss: 0.9847 - val_accuracy: 0.5347\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9869 - accuracy: 0.5298 - val_loss: 0.9834 - val_accuracy: 0.5347\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 705us/step - loss: 0.9863 - accuracy: 0.5299 - val_loss: 0.9828 - val_accuracy: 0.5347\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9856 - accuracy: 0.5296 - val_loss: 0.9821 - val_accuracy: 0.5347\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 0.9852 - accuracy: 0.5301 - val_loss: 0.9816 - val_accuracy: 0.5343\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9847 - accuracy: 0.5308 - val_loss: 0.9810 - val_accuracy: 0.5347\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9842 - accuracy: 0.5302 - val_loss: 0.9801 - val_accuracy: 0.5272\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9839 - accuracy: 0.5308 - val_loss: 0.9798 - val_accuracy: 0.5347\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9831 - accuracy: 0.5305 - val_loss: 0.9794 - val_accuracy: 0.5347\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 723us/step - loss: 0.9826 - accuracy: 0.5303 - val_loss: 0.9784 - val_accuracy: 0.5272\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9822 - accuracy: 0.5304 - val_loss: 0.9779 - val_accuracy: 0.5272\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 745us/step - loss: 0.9819 - accuracy: 0.5302 - val_loss: 0.9779 - val_accuracy: 0.5347\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9815 - accuracy: 0.5306 - val_loss: 0.9773 - val_accuracy: 0.5347\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 790us/step - loss: 0.9810 - accuracy: 0.5302 - val_loss: 0.9766 - val_accuracy: 0.5272\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9807 - accuracy: 0.5302 - val_loss: 0.9763 - val_accuracy: 0.5246\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9807 - accuracy: 0.5301 - val_loss: 0.9764 - val_accuracy: 0.5272\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9802 - accuracy: 0.5302 - val_loss: 0.9756 - val_accuracy: 0.5268\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 616us/step - loss: 0.9799 - accuracy: 0.5315 - val_loss: 0.9759 - val_accuracy: 0.5347\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 884us/step - loss: 0.9799 - accuracy: 0.5293 - val_loss: 0.9751 - val_accuracy: 0.5246\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9795 - accuracy: 0.5308 - val_loss: 0.9755 - val_accuracy: 0.5272\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9793 - accuracy: 0.5314 - val_loss: 0.9750 - val_accuracy: 0.5268\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 798us/step - loss: 0.9791 - accuracy: 0.5305 - val_loss: 0.9747 - val_accuracy: 0.5268\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9792 - accuracy: 0.5304 - val_loss: 0.9748 - val_accuracy: 0.5263\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 762us/step - loss: 0.9788 - accuracy: 0.5313 - val_loss: 0.9748 - val_accuracy: 0.5272\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 786us/step - loss: 0.9787 - accuracy: 0.5302 - val_loss: 0.9744 - val_accuracy: 0.5272\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 854us/step - loss: 0.9784 - accuracy: 0.5305 - val_loss: 0.9740 - val_accuracy: 0.5268\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9782 - accuracy: 0.5298 - val_loss: 0.9735 - val_accuracy: 0.5268\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9782 - accuracy: 0.5320 - val_loss: 0.9732 - val_accuracy: 0.5263\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9782 - accuracy: 0.5303 - val_loss: 0.9737 - val_accuracy: 0.5272\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 722us/step - loss: 0.9779 - accuracy: 0.5309 - val_loss: 0.9732 - val_accuracy: 0.5268\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9778 - accuracy: 0.5312 - val_loss: 0.9733 - val_accuracy: 0.5268\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 655us/step - loss: 0.9776 - accuracy: 0.5309 - val_loss: 0.9730 - val_accuracy: 0.5263\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 770us/step - loss: 0.9777 - accuracy: 0.5309 - val_loss: 0.9731 - val_accuracy: 0.5263\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9773 - accuracy: 0.5310 - val_loss: 0.9733 - val_accuracy: 0.5246\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9775 - accuracy: 0.5295 - val_loss: 0.9734 - val_accuracy: 0.5272\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9774 - accuracy: 0.5309 - val_loss: 0.9726 - val_accuracy: 0.5281\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9773 - accuracy: 0.5297 - val_loss: 0.9724 - val_accuracy: 0.5272\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9773 - accuracy: 0.5310 - val_loss: 0.9723 - val_accuracy: 0.5263\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9771 - accuracy: 0.5306 - val_loss: 0.9726 - val_accuracy: 0.5272\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 698us/step - loss: 0.9770 - accuracy: 0.5301 - val_loss: 0.9723 - val_accuracy: 0.5263\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 760us/step - loss: 0.9768 - accuracy: 0.5308 - val_loss: 0.9725 - val_accuracy: 0.5268\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9767 - accuracy: 0.5311 - val_loss: 0.9723 - val_accuracy: 0.5263\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9767 - accuracy: 0.5304 - val_loss: 0.9722 - val_accuracy: 0.5259\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 783us/step - loss: 0.9769 - accuracy: 0.5294 - val_loss: 0.9724 - val_accuracy: 0.5232\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9769 - accuracy: 0.5307 - val_loss: 0.9723 - val_accuracy: 0.5232\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9765 - accuracy: 0.5306 - val_loss: 0.9721 - val_accuracy: 0.5263\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9766 - accuracy: 0.5307 - val_loss: 0.9725 - val_accuracy: 0.5259\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9768 - accuracy: 0.5318 - val_loss: 0.9724 - val_accuracy: 0.5232\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9765 - accuracy: 0.5306 - val_loss: 0.9719 - val_accuracy: 0.5232\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9763 - accuracy: 0.5308 - val_loss: 0.9718 - val_accuracy: 0.5232\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 734us/step - loss: 0.9765 - accuracy: 0.5301 - val_loss: 0.9719 - val_accuracy: 0.5268\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9764 - accuracy: 0.5312 - val_loss: 0.9720 - val_accuracy: 0.5232\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9763 - accuracy: 0.5314 - val_loss: 0.9719 - val_accuracy: 0.5263\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 698us/step - loss: 0.9763 - accuracy: 0.5308 - val_loss: 0.9718 - val_accuracy: 0.5272\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9764 - accuracy: 0.5303 - val_loss: 0.9723 - val_accuracy: 0.5263\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 764us/step - loss: 0.9765 - accuracy: 0.5307 - val_loss: 0.9718 - val_accuracy: 0.5224\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 745us/step - loss: 0.9761 - accuracy: 0.5306 - val_loss: 0.9718 - val_accuracy: 0.5259\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9762 - accuracy: 0.5310 - val_loss: 0.9716 - val_accuracy: 0.5259\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 705us/step - loss: 0.9762 - accuracy: 0.5299 - val_loss: 0.9721 - val_accuracy: 0.5272\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9764 - accuracy: 0.5312 - val_loss: 0.9717 - val_accuracy: 0.5259\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9762 - accuracy: 0.5306 - val_loss: 0.9716 - val_accuracy: 0.5268\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 705us/step - loss: 0.9762 - accuracy: 0.5307 - val_loss: 0.9722 - val_accuracy: 0.5268\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9763 - accuracy: 0.5311 - val_loss: 0.9720 - val_accuracy: 0.5219\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9761 - accuracy: 0.5304 - val_loss: 0.9718 - val_accuracy: 0.5259\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 654us/step - loss: 0.9761 - accuracy: 0.5308 - val_loss: 0.9718 - val_accuracy: 0.5232\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 800us/step - loss: 0.9760 - accuracy: 0.5308 - val_loss: 0.9716 - val_accuracy: 0.5268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9760 - accuracy: 0.5308 - val_loss: 0.9715 - val_accuracy: 0.5268\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9760 - accuracy: 0.5306 - val_loss: 0.9715 - val_accuracy: 0.5259\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9759 - accuracy: 0.5311 - val_loss: 0.9711 - val_accuracy: 0.5224\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9760 - accuracy: 0.5296 - val_loss: 0.9714 - val_accuracy: 0.5263\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 770us/step - loss: 0.9760 - accuracy: 0.5304 - val_loss: 0.9713 - val_accuracy: 0.5232\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9759 - accuracy: 0.5308 - val_loss: 0.9713 - val_accuracy: 0.5219\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9759 - accuracy: 0.5308 - val_loss: 0.9714 - val_accuracy: 0.5268\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9759 - accuracy: 0.5307 - val_loss: 0.9715 - val_accuracy: 0.5268\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 722us/step - loss: 0.9759 - accuracy: 0.5303 - val_loss: 0.9712 - val_accuracy: 0.5224\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9759 - accuracy: 0.5311 - val_loss: 0.9713 - val_accuracy: 0.5259\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9759 - accuracy: 0.5300 - val_loss: 0.9712 - val_accuracy: 0.5263\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9759 - accuracy: 0.5306 - val_loss: 0.9712 - val_accuracy: 0.5259\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9758 - accuracy: 0.5310 - val_loss: 0.9714 - val_accuracy: 0.5259\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9759 - accuracy: 0.5300 - val_loss: 0.9715 - val_accuracy: 0.5268\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9759 - accuracy: 0.5307 - val_loss: 0.9711 - val_accuracy: 0.5224\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9757 - accuracy: 0.5315 - val_loss: 0.9713 - val_accuracy: 0.5263\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9759 - accuracy: 0.5305 - val_loss: 0.9712 - val_accuracy: 0.5268\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 660us/step - loss: 0.9759 - accuracy: 0.5306 - val_loss: 0.9711 - val_accuracy: 0.5224\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 576us/step - loss: 0.9759 - accuracy: 0.5304 - val_loss: 0.9714 - val_accuracy: 0.5268\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 845us/step - loss: 0.9759 - accuracy: 0.5316 - val_loss: 0.9712 - val_accuracy: 0.5263\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9758 - accuracy: 0.5305 - val_loss: 0.9711 - val_accuracy: 0.5232\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 799us/step - loss: 0.9757 - accuracy: 0.5313 - val_loss: 0.9709 - val_accuracy: 0.5259\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9757 - accuracy: 0.5306 - val_loss: 0.9713 - val_accuracy: 0.5263\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 755us/step - loss: 0.9763 - accuracy: 0.5311 - val_loss: 0.9713 - val_accuracy: 0.5228\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 663us/step - loss: 0.9758 - accuracy: 0.5296 - val_loss: 0.9714 - val_accuracy: 0.5268\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9759 - accuracy: 0.5313 - val_loss: 0.9708 - val_accuracy: 0.5219\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9759 - accuracy: 0.5288 - val_loss: 0.9710 - val_accuracy: 0.5224\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9757 - accuracy: 0.5306 - val_loss: 0.9709 - val_accuracy: 0.5224\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9757 - accuracy: 0.5309 - val_loss: 0.9712 - val_accuracy: 0.5268\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 581us/step - loss: 0.9759 - accuracy: 0.5317 - val_loss: 0.9714 - val_accuracy: 0.5268\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 799us/step - loss: 0.9757 - accuracy: 0.5306 - val_loss: 0.9711 - val_accuracy: 0.5232\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 677us/step - loss: 0.9757 - accuracy: 0.5312 - val_loss: 0.9710 - val_accuracy: 0.5224\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9711 - val_accuracy: 0.5259\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9714 - val_accuracy: 0.5268\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9756 - accuracy: 0.5311 - val_loss: 0.9711 - val_accuracy: 0.5259\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9757 - accuracy: 0.5307 - val_loss: 0.9715 - val_accuracy: 0.5281\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9760 - accuracy: 0.5299 - val_loss: 0.9716 - val_accuracy: 0.5263\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9758 - accuracy: 0.5312 - val_loss: 0.9712 - val_accuracy: 0.5224\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9757 - accuracy: 0.5314 - val_loss: 0.9711 - val_accuracy: 0.5259\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9756 - accuracy: 0.5303 - val_loss: 0.9709 - val_accuracy: 0.5224\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9756 - accuracy: 0.5310 - val_loss: 0.9713 - val_accuracy: 0.5272\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9758 - accuracy: 0.5310 - val_loss: 0.9712 - val_accuracy: 0.5272\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9757 - accuracy: 0.5308 - val_loss: 0.9714 - val_accuracy: 0.5272\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 713us/step - loss: 0.9758 - accuracy: 0.5293 - val_loss: 0.9710 - val_accuracy: 0.5232\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9757 - accuracy: 0.5301 - val_loss: 0.9709 - val_accuracy: 0.5224\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9757 - accuracy: 0.5299 - val_loss: 0.9711 - val_accuracy: 0.5224\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9756 - accuracy: 0.5301 - val_loss: 0.9713 - val_accuracy: 0.5268\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 0.9756 - accuracy: 0.5313 - val_loss: 0.9711 - val_accuracy: 0.5268\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 690us/step - loss: 0.9756 - accuracy: 0.5308 - val_loss: 0.9708 - val_accuracy: 0.5259\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9756 - accuracy: 0.5306 - val_loss: 0.9709 - val_accuracy: 0.5224\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9757 - accuracy: 0.5309 - val_loss: 0.9712 - val_accuracy: 0.5259\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9756 - accuracy: 0.5301 - val_loss: 0.9711 - val_accuracy: 0.5268\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 703us/step - loss: 0.9756 - accuracy: 0.5308 - val_loss: 0.9707 - val_accuracy: 0.5224\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9756 - accuracy: 0.5305 - val_loss: 0.9709 - val_accuracy: 0.5259\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9756 - accuracy: 0.5308 - val_loss: 0.9713 - val_accuracy: 0.5268\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9706 - val_accuracy: 0.5224\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 710us/step - loss: 0.9757 - accuracy: 0.5290 - val_loss: 0.9712 - val_accuracy: 0.5224\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9755 - accuracy: 0.5309 - val_loss: 0.9710 - val_accuracy: 0.5259\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9755 - accuracy: 0.5308 - val_loss: 0.9709 - val_accuracy: 0.5263\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 681us/step - loss: 0.9755 - accuracy: 0.5304 - val_loss: 0.9709 - val_accuracy: 0.5224\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9755 - accuracy: 0.5305 - val_loss: 0.9712 - val_accuracy: 0.5272\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9755 - accuracy: 0.5305 - val_loss: 0.9710 - val_accuracy: 0.5263\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9756 - accuracy: 0.5308 - val_loss: 0.9709 - val_accuracy: 0.5232\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9756 - accuracy: 0.5310 - val_loss: 0.9707 - val_accuracy: 0.5219\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 696us/step - loss: 0.9758 - accuracy: 0.5283 - val_loss: 0.9708 - val_accuracy: 0.5224\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9756 - accuracy: 0.5305 - val_loss: 0.9710 - val_accuracy: 0.5224\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9754 - accuracy: 0.5313 - val_loss: 0.9710 - val_accuracy: 0.5259\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9755 - accuracy: 0.5311 - val_loss: 0.9707 - val_accuracy: 0.5224\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9755 - accuracy: 0.5302 - val_loss: 0.9708 - val_accuracy: 0.5224\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9755 - accuracy: 0.5305 - val_loss: 0.9706 - val_accuracy: 0.5224\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9756 - accuracy: 0.5293 - val_loss: 0.9708 - val_accuracy: 0.5224\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9757 - accuracy: 0.5288 - val_loss: 0.9705 - val_accuracy: 0.5228\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9756 - accuracy: 0.5296 - val_loss: 0.9705 - val_accuracy: 0.5224\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9756 - accuracy: 0.5296 - val_loss: 0.9710 - val_accuracy: 0.5268\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9757 - accuracy: 0.5303 - val_loss: 0.9713 - val_accuracy: 0.5281\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9756 - accuracy: 0.5311 - val_loss: 0.9708 - val_accuracy: 0.5263\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 0.9755 - accuracy: 0.5299 - val_loss: 0.9708 - val_accuracy: 0.5224\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 0s 711us/step - loss: 0.9754 - accuracy: 0.5300 - val_loss: 0.9708 - val_accuracy: 0.5263\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9755 - accuracy: 0.5301 - val_loss: 0.9709 - val_accuracy: 0.5268\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9755 - accuracy: 0.5307 - val_loss: 0.9704 - val_accuracy: 0.5224\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9755 - accuracy: 0.5302 - val_loss: 0.9709 - val_accuracy: 0.5268\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9754 - accuracy: 0.5310 - val_loss: 0.9708 - val_accuracy: 0.5259\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 694us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9710 - val_accuracy: 0.5263\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9755 - accuracy: 0.5311 - val_loss: 0.9708 - val_accuracy: 0.5268\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 733us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9705 - val_accuracy: 0.5232\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 739us/step - loss: 0.9753 - accuracy: 0.5309 - val_loss: 0.9707 - val_accuracy: 0.5259\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 792us/step - loss: 0.9754 - accuracy: 0.5293 - val_loss: 0.9710 - val_accuracy: 0.5263\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 799us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9706 - val_accuracy: 0.5232\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9754 - accuracy: 0.5296 - val_loss: 0.9707 - val_accuracy: 0.5232\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9753 - accuracy: 0.5305 - val_loss: 0.9708 - val_accuracy: 0.5263\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 730us/step - loss: 0.9753 - accuracy: 0.5303 - val_loss: 0.9712 - val_accuracy: 0.5272\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9706 - val_accuracy: 0.5259\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9706 - val_accuracy: 0.5268\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9754 - accuracy: 0.5306 - val_loss: 0.9710 - val_accuracy: 0.5259\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9755 - accuracy: 0.5303 - val_loss: 0.9706 - val_accuracy: 0.5268\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9753 - accuracy: 0.5309 - val_loss: 0.9702 - val_accuracy: 0.5224\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 854us/step - loss: 0.9753 - accuracy: 0.5298 - val_loss: 0.9709 - val_accuracy: 0.5268\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 735us/step - loss: 0.9753 - accuracy: 0.5306 - val_loss: 0.9706 - val_accuracy: 0.5263\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9753 - accuracy: 0.5307 - val_loss: 0.9707 - val_accuracy: 0.5272\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9754 - accuracy: 0.5302 - val_loss: 0.9703 - val_accuracy: 0.5263\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 718us/step - loss: 0.9753 - accuracy: 0.5300 - val_loss: 0.9705 - val_accuracy: 0.5263\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9752 - accuracy: 0.5309 - val_loss: 0.9704 - val_accuracy: 0.5259\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 670us/step - loss: 0.9754 - accuracy: 0.5301 - val_loss: 0.9704 - val_accuracy: 0.5224\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 688us/step - loss: 0.9752 - accuracy: 0.5309 - val_loss: 0.9707 - val_accuracy: 0.5268\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9754 - accuracy: 0.5314 - val_loss: 0.9706 - val_accuracy: 0.5268\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9753 - accuracy: 0.5310 - val_loss: 0.9706 - val_accuracy: 0.5268\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9752 - accuracy: 0.5304 - val_loss: 0.9710 - val_accuracy: 0.5259\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9754 - accuracy: 0.5305 - val_loss: 0.9702 - val_accuracy: 0.5259\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 684us/step - loss: 0.9753 - accuracy: 0.5301 - val_loss: 0.9704 - val_accuracy: 0.5263\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9753 - accuracy: 0.5297 - val_loss: 0.9703 - val_accuracy: 0.5224\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 806us/step - loss: 0.9752 - accuracy: 0.5309 - val_loss: 0.9701 - val_accuracy: 0.5224\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9752 - accuracy: 0.5308 - val_loss: 0.9705 - val_accuracy: 0.5272\n",
      "Epoch 198/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 710us/step - loss: 0.9752 - accuracy: 0.5306 - val_loss: 0.9704 - val_accuracy: 0.5268\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9752 - accuracy: 0.5302 - val_loss: 0.9705 - val_accuracy: 0.5268\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9751 - accuracy: 0.5308 - val_loss: 0.9704 - val_accuracy: 0.5268\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 377us/step - loss: 0.9750 - accuracy: 0.5308\n",
      "Accuracy : 0.5308119654655457\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9704 - accuracy: 0.5268\n",
      "Accuracy : 0.5267817378044128\n",
      "Fold #10\n",
      "Epoch 1/200\n",
      " 1/93 [..............................] - ETA: 0s - loss: 1.1074 - accuracy: 0.2624WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "84/93 [==========================>...] - ETA: 0s - loss: 1.0857 - accuracy: 0.3831WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0845 - accuracy: 0.3901 - val_loss: 1.0719 - val_accuracy: 0.4591\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 1.0676 - accuracy: 0.4591 - val_loss: 1.0632 - val_accuracy: 0.4591\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 1.0616 - accuracy: 0.4591 - val_loss: 1.0592 - val_accuracy: 0.4591\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 1.0589 - accuracy: 0.4591 - val_loss: 1.0553 - val_accuracy: 0.4591\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 0s 772us/step - loss: 1.0548 - accuracy: 0.4591 - val_loss: 1.0492 - val_accuracy: 0.4591\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 1.0479 - accuracy: 0.4591 - val_loss: 1.0381 - val_accuracy: 0.4591\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 1.0359 - accuracy: 0.4687 - val_loss: 1.0238 - val_accuracy: 0.5042\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 1.0252 - accuracy: 0.4917 - val_loss: 1.0135 - val_accuracy: 0.5166\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 0s 777us/step - loss: 1.0159 - accuracy: 0.5079 - val_loss: 1.0043 - val_accuracy: 0.5241\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 1.0079 - accuracy: 0.5177 - val_loss: 0.9967 - val_accuracy: 0.5317\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 0s 799us/step - loss: 1.0018 - accuracy: 0.5226 - val_loss: 0.9907 - val_accuracy: 0.5299\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9968 - accuracy: 0.5279 - val_loss: 0.9862 - val_accuracy: 0.5325\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9934 - accuracy: 0.5303 - val_loss: 0.9836 - val_accuracy: 0.5321\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 0s 696us/step - loss: 0.9915 - accuracy: 0.5291 - val_loss: 0.9804 - val_accuracy: 0.5321\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 0s 750us/step - loss: 0.9901 - accuracy: 0.5294 - val_loss: 0.9792 - val_accuracy: 0.5343\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 0s 756us/step - loss: 0.9886 - accuracy: 0.5301 - val_loss: 0.9782 - val_accuracy: 0.5347\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9879 - accuracy: 0.5291 - val_loss: 0.9770 - val_accuracy: 0.5321\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9870 - accuracy: 0.5293 - val_loss: 0.9762 - val_accuracy: 0.5325\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9864 - accuracy: 0.5301 - val_loss: 0.9755 - val_accuracy: 0.5325\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9860 - accuracy: 0.5294 - val_loss: 0.9748 - val_accuracy: 0.5339\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9856 - accuracy: 0.5286 - val_loss: 0.9741 - val_accuracy: 0.5339\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9849 - accuracy: 0.5276 - val_loss: 0.9745 - val_accuracy: 0.5356\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9848 - accuracy: 0.5300 - val_loss: 0.9734 - val_accuracy: 0.5343\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9845 - accuracy: 0.5295 - val_loss: 0.9724 - val_accuracy: 0.5325\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9840 - accuracy: 0.5286 - val_loss: 0.9714 - val_accuracy: 0.5343\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9835 - accuracy: 0.5289 - val_loss: 0.9709 - val_accuracy: 0.5339\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9831 - accuracy: 0.5291 - val_loss: 0.9700 - val_accuracy: 0.5339\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 0s 675us/step - loss: 0.9826 - accuracy: 0.5297 - val_loss: 0.9693 - val_accuracy: 0.5325\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9825 - accuracy: 0.5288 - val_loss: 0.9693 - val_accuracy: 0.5365\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 0s 761us/step - loss: 0.9823 - accuracy: 0.5303 - val_loss: 0.9684 - val_accuracy: 0.5343\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 0s 738us/step - loss: 0.9817 - accuracy: 0.5299 - val_loss: 0.9679 - val_accuracy: 0.5356\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9815 - accuracy: 0.5302 - val_loss: 0.9677 - val_accuracy: 0.5374\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9814 - accuracy: 0.5300 - val_loss: 0.9668 - val_accuracy: 0.5356\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9808 - accuracy: 0.5298 - val_loss: 0.9661 - val_accuracy: 0.5356\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9807 - accuracy: 0.5295 - val_loss: 0.9661 - val_accuracy: 0.5374\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9804 - accuracy: 0.5300 - val_loss: 0.9656 - val_accuracy: 0.5365\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9801 - accuracy: 0.5300 - val_loss: 0.9648 - val_accuracy: 0.5356\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9803 - accuracy: 0.5282 - val_loss: 0.9645 - val_accuracy: 0.5356\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 0s 720us/step - loss: 0.9801 - accuracy: 0.5296 - val_loss: 0.9640 - val_accuracy: 0.5356\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9797 - accuracy: 0.5295 - val_loss: 0.9633 - val_accuracy: 0.5365\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9793 - accuracy: 0.5292 - val_loss: 0.9627 - val_accuracy: 0.5356\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 0s 605us/step - loss: 0.9791 - accuracy: 0.5292 - val_loss: 0.9623 - val_accuracy: 0.5356\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 0s 825us/step - loss: 0.9790 - accuracy: 0.5296 - val_loss: 0.9617 - val_accuracy: 0.5343\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9789 - accuracy: 0.5300 - val_loss: 0.9618 - val_accuracy: 0.5374\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 0s 573us/step - loss: 0.9787 - accuracy: 0.5299 - val_loss: 0.9613 - val_accuracy: 0.5374\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 0s 887us/step - loss: 0.9786 - accuracy: 0.5302 - val_loss: 0.9608 - val_accuracy: 0.5374\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 0s 715us/step - loss: 0.9786 - accuracy: 0.5296 - val_loss: 0.9604 - val_accuracy: 0.5374\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9785 - accuracy: 0.5295 - val_loss: 0.9599 - val_accuracy: 0.5356\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9785 - accuracy: 0.5292 - val_loss: 0.9602 - val_accuracy: 0.5374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9782 - accuracy: 0.5289 - val_loss: 0.9595 - val_accuracy: 0.5374\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9780 - accuracy: 0.5300 - val_loss: 0.9594 - val_accuracy: 0.5374\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 0s 812us/step - loss: 0.9783 - accuracy: 0.5289 - val_loss: 0.9593 - val_accuracy: 0.5374\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 0s 711us/step - loss: 0.9783 - accuracy: 0.5289 - val_loss: 0.9592 - val_accuracy: 0.5374\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9778 - accuracy: 0.5296 - val_loss: 0.9589 - val_accuracy: 0.5374\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 0s 582us/step - loss: 0.9780 - accuracy: 0.5303 - val_loss: 0.9586 - val_accuracy: 0.5374\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 0s 815us/step - loss: 0.9779 - accuracy: 0.5297 - val_loss: 0.9588 - val_accuracy: 0.5374\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 0s 711us/step - loss: 0.9778 - accuracy: 0.5298 - val_loss: 0.9586 - val_accuracy: 0.5374\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9779 - accuracy: 0.5292 - val_loss: 0.9582 - val_accuracy: 0.5374\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 0s 720us/step - loss: 0.9775 - accuracy: 0.5287 - val_loss: 0.9581 - val_accuracy: 0.5374\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9774 - accuracy: 0.5292 - val_loss: 0.9579 - val_accuracy: 0.5374\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 0s 835us/step - loss: 0.9776 - accuracy: 0.5301 - val_loss: 0.9577 - val_accuracy: 0.5374\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9773 - accuracy: 0.5305 - val_loss: 0.9576 - val_accuracy: 0.5347\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9780 - accuracy: 0.5286 - val_loss: 0.9578 - val_accuracy: 0.5374\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 0s 786us/step - loss: 0.9773 - accuracy: 0.5306 - val_loss: 0.9575 - val_accuracy: 0.5347\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 0s 775us/step - loss: 0.9774 - accuracy: 0.5294 - val_loss: 0.9575 - val_accuracy: 0.5343\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 0s 735us/step - loss: 0.9773 - accuracy: 0.5300 - val_loss: 0.9571 - val_accuracy: 0.5374\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 0s 734us/step - loss: 0.9775 - accuracy: 0.5290 - val_loss: 0.9572 - val_accuracy: 0.5347\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 0s 782us/step - loss: 0.9774 - accuracy: 0.5300 - val_loss: 0.9572 - val_accuracy: 0.5347\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 0s 829us/step - loss: 0.9773 - accuracy: 0.5297 - val_loss: 0.9568 - val_accuracy: 0.5374\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 0s 709us/step - loss: 0.9772 - accuracy: 0.5305 - val_loss: 0.9569 - val_accuracy: 0.5374\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 0s 727us/step - loss: 0.9772 - accuracy: 0.5289 - val_loss: 0.9565 - val_accuracy: 0.5374\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9779 - accuracy: 0.5295 - val_loss: 0.9566 - val_accuracy: 0.5347\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 0s 838us/step - loss: 0.9770 - accuracy: 0.5294 - val_loss: 0.9563 - val_accuracy: 0.5374\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9771 - accuracy: 0.5296 - val_loss: 0.9564 - val_accuracy: 0.5387\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 0s 857us/step - loss: 0.9772 - accuracy: 0.5297 - val_loss: 0.9569 - val_accuracy: 0.5325\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 0s 744us/step - loss: 0.9771 - accuracy: 0.5288 - val_loss: 0.9564 - val_accuracy: 0.5374\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9771 - accuracy: 0.5303 - val_loss: 0.9565 - val_accuracy: 0.5374\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 0s 718us/step - loss: 0.9772 - accuracy: 0.5314 - val_loss: 0.9573 - val_accuracy: 0.5325\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9772 - accuracy: 0.5293 - val_loss: 0.9567 - val_accuracy: 0.5347\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 0s 753us/step - loss: 0.9770 - accuracy: 0.5304 - val_loss: 0.9561 - val_accuracy: 0.5374\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9773 - accuracy: 0.5313 - val_loss: 0.9564 - val_accuracy: 0.5343\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 0s 709us/step - loss: 0.9772 - accuracy: 0.5295 - val_loss: 0.9564 - val_accuracy: 0.5321\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9770 - accuracy: 0.5292 - val_loss: 0.9561 - val_accuracy: 0.5347\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 0s 716us/step - loss: 0.9769 - accuracy: 0.5300 - val_loss: 0.9565 - val_accuracy: 0.5321\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9771 - accuracy: 0.5291 - val_loss: 0.9562 - val_accuracy: 0.5321\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 0s 679us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9561 - val_accuracy: 0.5343\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 0s 755us/step - loss: 0.9768 - accuracy: 0.5300 - val_loss: 0.9560 - val_accuracy: 0.5343\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 0s 717us/step - loss: 0.9769 - accuracy: 0.5290 - val_loss: 0.9558 - val_accuracy: 0.5347\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9769 - accuracy: 0.5304 - val_loss: 0.9558 - val_accuracy: 0.5347\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9556 - val_accuracy: 0.5374\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 0s 835us/step - loss: 0.9771 - accuracy: 0.5284 - val_loss: 0.9560 - val_accuracy: 0.5321\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9768 - accuracy: 0.5304 - val_loss: 0.9556 - val_accuracy: 0.5347\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 0s 798us/step - loss: 0.9769 - accuracy: 0.5286 - val_loss: 0.9555 - val_accuracy: 0.5343\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9769 - accuracy: 0.5295 - val_loss: 0.9557 - val_accuracy: 0.5343\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 0s 777us/step - loss: 0.9768 - accuracy: 0.5306 - val_loss: 0.9557 - val_accuracy: 0.5343\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9769 - accuracy: 0.5301 - val_loss: 0.9554 - val_accuracy: 0.5374\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 0s 744us/step - loss: 0.9767 - accuracy: 0.5290 - val_loss: 0.9564 - val_accuracy: 0.5321\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9768 - accuracy: 0.5301 - val_loss: 0.9557 - val_accuracy: 0.5343\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9767 - accuracy: 0.5303 - val_loss: 0.9554 - val_accuracy: 0.5374\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9770 - accuracy: 0.5298 - val_loss: 0.9555 - val_accuracy: 0.5374\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 0s 681us/step - loss: 0.9770 - accuracy: 0.5309 - val_loss: 0.9557 - val_accuracy: 0.5343\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9769 - accuracy: 0.5290 - val_loss: 0.9554 - val_accuracy: 0.5343\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9766 - accuracy: 0.5302 - val_loss: 0.9556 - val_accuracy: 0.5343\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9767 - accuracy: 0.5295 - val_loss: 0.9554 - val_accuracy: 0.5343\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 0s 692us/step - loss: 0.9767 - accuracy: 0.5295 - val_loss: 0.9556 - val_accuracy: 0.5321\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 0s 749us/step - loss: 0.9768 - accuracy: 0.5294 - val_loss: 0.9554 - val_accuracy: 0.5343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9768 - accuracy: 0.5294 - val_loss: 0.9556 - val_accuracy: 0.5343\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 0s 734us/step - loss: 0.9766 - accuracy: 0.5305 - val_loss: 0.9553 - val_accuracy: 0.5347\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9768 - accuracy: 0.5297 - val_loss: 0.9556 - val_accuracy: 0.5343\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 0s 674us/step - loss: 0.9768 - accuracy: 0.5317 - val_loss: 0.9555 - val_accuracy: 0.5347\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9769 - accuracy: 0.5317 - val_loss: 0.9553 - val_accuracy: 0.5347\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 0s 690us/step - loss: 0.9765 - accuracy: 0.5301 - val_loss: 0.9553 - val_accuracy: 0.5339\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9768 - accuracy: 0.5293 - val_loss: 0.9552 - val_accuracy: 0.5321\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 0s 588us/step - loss: 0.9767 - accuracy: 0.5292 - val_loss: 0.9553 - val_accuracy: 0.5321\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 0s 802us/step - loss: 0.9766 - accuracy: 0.5301 - val_loss: 0.9550 - val_accuracy: 0.5347\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9767 - accuracy: 0.5305 - val_loss: 0.9550 - val_accuracy: 0.5343\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 0s 798us/step - loss: 0.9767 - accuracy: 0.5295 - val_loss: 0.9550 - val_accuracy: 0.5343\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9766 - accuracy: 0.5304 - val_loss: 0.9552 - val_accuracy: 0.5343\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 0s 777us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9553 - val_accuracy: 0.5343\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9767 - accuracy: 0.5285 - val_loss: 0.9553 - val_accuracy: 0.5343\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 0s 635us/step - loss: 0.9767 - accuracy: 0.5292 - val_loss: 0.9556 - val_accuracy: 0.5321\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 0s 799us/step - loss: 0.9767 - accuracy: 0.5295 - val_loss: 0.9556 - val_accuracy: 0.5321\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9765 - accuracy: 0.5286 - val_loss: 0.9550 - val_accuracy: 0.5374\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9767 - accuracy: 0.5301 - val_loss: 0.9551 - val_accuracy: 0.5339\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 0s 766us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9552 - val_accuracy: 0.5343\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 0s 728us/step - loss: 0.9765 - accuracy: 0.5289 - val_loss: 0.9555 - val_accuracy: 0.5325\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9768 - accuracy: 0.5273 - val_loss: 0.9552 - val_accuracy: 0.5325\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 0s 756us/step - loss: 0.9766 - accuracy: 0.5292 - val_loss: 0.9551 - val_accuracy: 0.5343\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 0s 657us/step - loss: 0.9766 - accuracy: 0.5294 - val_loss: 0.9557 - val_accuracy: 0.5321\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 0s 734us/step - loss: 0.9767 - accuracy: 0.5296 - val_loss: 0.9553 - val_accuracy: 0.5339\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9766 - accuracy: 0.5298 - val_loss: 0.9553 - val_accuracy: 0.5339\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9768 - accuracy: 0.5289 - val_loss: 0.9554 - val_accuracy: 0.5325\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 0s 667us/step - loss: 0.9766 - accuracy: 0.5299 - val_loss: 0.9551 - val_accuracy: 0.5321\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 0s 671us/step - loss: 0.9765 - accuracy: 0.5291 - val_loss: 0.9548 - val_accuracy: 0.5356\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 0s 666us/step - loss: 0.9766 - accuracy: 0.5305 - val_loss: 0.9555 - val_accuracy: 0.5339\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9766 - accuracy: 0.5297 - val_loss: 0.9551 - val_accuracy: 0.5343\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 0s 745us/step - loss: 0.9766 - accuracy: 0.5297 - val_loss: 0.9550 - val_accuracy: 0.5347\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9768 - accuracy: 0.5304 - val_loss: 0.9553 - val_accuracy: 0.5339\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9765 - accuracy: 0.5305 - val_loss: 0.9550 - val_accuracy: 0.5325\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9765 - accuracy: 0.5298 - val_loss: 0.9549 - val_accuracy: 0.5343\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 0s 711us/step - loss: 0.9767 - accuracy: 0.5300 - val_loss: 0.9552 - val_accuracy: 0.5321\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9765 - accuracy: 0.5285 - val_loss: 0.9549 - val_accuracy: 0.5343\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 0s 691us/step - loss: 0.9764 - accuracy: 0.5304 - val_loss: 0.9550 - val_accuracy: 0.5339\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 0s 668us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9548 - val_accuracy: 0.5343\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9765 - accuracy: 0.5302 - val_loss: 0.9550 - val_accuracy: 0.5321\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9766 - accuracy: 0.5292 - val_loss: 0.9555 - val_accuracy: 0.5325\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 0s 596us/step - loss: 0.9766 - accuracy: 0.5299 - val_loss: 0.9549 - val_accuracy: 0.5339\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 0s 803us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9548 - val_accuracy: 0.5343\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9767 - accuracy: 0.5305 - val_loss: 0.9550 - val_accuracy: 0.5321\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 0s 787us/step - loss: 0.9766 - accuracy: 0.5301 - val_loss: 0.9554 - val_accuracy: 0.5325\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 0s 625us/step - loss: 0.9765 - accuracy: 0.5289 - val_loss: 0.9548 - val_accuracy: 0.5343\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 0s 777us/step - loss: 0.9765 - accuracy: 0.5296 - val_loss: 0.9549 - val_accuracy: 0.5343\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9764 - accuracy: 0.5303 - val_loss: 0.9558 - val_accuracy: 0.5325\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9766 - accuracy: 0.5288 - val_loss: 0.9547 - val_accuracy: 0.5343\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 0s 697us/step - loss: 0.9766 - accuracy: 0.5305 - val_loss: 0.9547 - val_accuracy: 0.5343\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9768 - accuracy: 0.5300 - val_loss: 0.9549 - val_accuracy: 0.5339\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9765 - accuracy: 0.5294 - val_loss: 0.9552 - val_accuracy: 0.5321\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9765 - accuracy: 0.5300 - val_loss: 0.9550 - val_accuracy: 0.5325\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9550 - val_accuracy: 0.5325\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 0s 702us/step - loss: 0.9768 - accuracy: 0.5287 - val_loss: 0.9548 - val_accuracy: 0.5321\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9546 - val_accuracy: 0.5343\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 0s 680us/step - loss: 0.9763 - accuracy: 0.5297 - val_loss: 0.9547 - val_accuracy: 0.5343\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 574us/step - loss: 0.9771 - accuracy: 0.5274 - val_loss: 0.9549 - val_accuracy: 0.5325\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 0s 814us/step - loss: 0.9767 - accuracy: 0.5299 - val_loss: 0.9553 - val_accuracy: 0.5330\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9765 - accuracy: 0.5286 - val_loss: 0.9552 - val_accuracy: 0.5321\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 0s 776us/step - loss: 0.9763 - accuracy: 0.5302 - val_loss: 0.9548 - val_accuracy: 0.5339\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9763 - accuracy: 0.5299 - val_loss: 0.9547 - val_accuracy: 0.5356\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 0s 743us/step - loss: 0.9767 - accuracy: 0.5296 - val_loss: 0.9547 - val_accuracy: 0.5321\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9545 - val_accuracy: 0.5317\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 0s 603us/step - loss: 0.9764 - accuracy: 0.5299 - val_loss: 0.9546 - val_accuracy: 0.5343\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 0s 796us/step - loss: 0.9764 - accuracy: 0.5298 - val_loss: 0.9546 - val_accuracy: 0.5343\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 0s 695us/step - loss: 0.9765 - accuracy: 0.5302 - val_loss: 0.9546 - val_accuracy: 0.5339\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9768 - accuracy: 0.5299 - val_loss: 0.9550 - val_accuracy: 0.5321\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 0s 788us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9556 - val_accuracy: 0.5325\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9763 - accuracy: 0.5296 - val_loss: 0.9551 - val_accuracy: 0.5343\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 0s 712us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9558 - val_accuracy: 0.5321\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9765 - accuracy: 0.5297 - val_loss: 0.9555 - val_accuracy: 0.5339\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9765 - accuracy: 0.5286 - val_loss: 0.9552 - val_accuracy: 0.5343\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 0s 710us/step - loss: 0.9762 - accuracy: 0.5298 - val_loss: 0.9548 - val_accuracy: 0.5343\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 0s 678us/step - loss: 0.9765 - accuracy: 0.5301 - val_loss: 0.9548 - val_accuracy: 0.5339\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9767 - accuracy: 0.5296 - val_loss: 0.9550 - val_accuracy: 0.5343\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9764 - accuracy: 0.5296 - val_loss: 0.9556 - val_accuracy: 0.5339\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9765 - accuracy: 0.5293 - val_loss: 0.9552 - val_accuracy: 0.5343\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 0s 732us/step - loss: 0.9764 - accuracy: 0.5300 - val_loss: 0.9555 - val_accuracy: 0.5317\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9764 - accuracy: 0.5298 - val_loss: 0.9549 - val_accuracy: 0.5339\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 0s 723us/step - loss: 0.9767 - accuracy: 0.5288 - val_loss: 0.9552 - val_accuracy: 0.5339\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9763 - accuracy: 0.5303 - val_loss: 0.9553 - val_accuracy: 0.5339\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 0s 700us/step - loss: 0.9765 - accuracy: 0.5290 - val_loss: 0.9553 - val_accuracy: 0.5339\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 0s 721us/step - loss: 0.9763 - accuracy: 0.5298 - val_loss: 0.9548 - val_accuracy: 0.5334\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 0s 689us/step - loss: 0.9767 - accuracy: 0.5300 - val_loss: 0.9548 - val_accuracy: 0.5343\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 0s 701us/step - loss: 0.9763 - accuracy: 0.5300 - val_loss: 0.9549 - val_accuracy: 0.5339\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 0s 571us/step - loss: 0.9763 - accuracy: 0.5298 - val_loss: 0.9549 - val_accuracy: 0.5334\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 0s 819us/step - loss: 0.9765 - accuracy: 0.5295 - val_loss: 0.9550 - val_accuracy: 0.5343\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 0s 592us/step - loss: 0.9765 - accuracy: 0.5304 - val_loss: 0.9550 - val_accuracy: 0.5339\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 0s 706us/step - loss: 0.9764 - accuracy: 0.5294 - val_loss: 0.9549 - val_accuracy: 0.5343\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 0s 614us/step - loss: 0.9766 - accuracy: 0.5301 - val_loss: 0.9552 - val_accuracy: 0.5321\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 0s 756us/step - loss: 0.9766 - accuracy: 0.5282 - val_loss: 0.9551 - val_accuracy: 0.5321\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 0s 652us/step - loss: 0.9763 - accuracy: 0.5291 - val_loss: 0.9548 - val_accuracy: 0.5343\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 0s 922us/step - loss: 0.9765 - accuracy: 0.5293 - val_loss: 0.9548 - val_accuracy: 0.5343\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 0s 809us/step - loss: 0.9762 - accuracy: 0.5303 - val_loss: 0.9553 - val_accuracy: 0.5325\n",
      "\n",
      "Train split:\n",
      "636/636 [==============================] - 0s 452us/step - loss: 0.9762 - accuracy: 0.5291\n",
      "Accuracy : 0.5290906429290771\n",
      "\n",
      "Test split:\n",
      "71/71 - 0s - loss: 0.9553 - accuracy: 0.5325\n",
      "Accuracy : 0.532536506652832\n",
      "\n",
      "The final train accuracy is:0.5303450524806976 \n",
      "\n",
      "The final test accuracy is:0.5299220383167267 \n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"IW.csv\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data = np.array(df.iloc[:,0:3])\n",
    "classes = np.array(df['result'])\n",
    "\n",
    "fold = 0\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "    \n",
    "for train, test in kf.split(data,classes):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    data_train =  data[train]\n",
    "    data_test = data[test]\n",
    "    train_labels1 = classes[train]\n",
    "    test_labels1 = classes[test]\n",
    "\n",
    "    \n",
    "    train_labels = pd.get_dummies(train_labels1, prefix=\"result\")\n",
    "    test_labels = pd.get_dummies(test_labels1, prefix=\"result\")\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape = (3,1)),\n",
    "        keras.layers.Dense(5,activation='sigmoid'),#Adding the second layer eith sogmoid activation function\n",
    "        keras.layers.Dense(5,activation='sigmoid'),#Adding the third layer eith sogmoid activation function\n",
    "        keras.layers.Dense(3,activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    opt = optimizers.Adam(learning_rate)\n",
    "    \n",
    "    model.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"] )\n",
    "    with tf.device('/CPU:0'):    \n",
    "        history = model.fit(data_train,train_labels,batch_size = 221, epochs=200, validation_data = (data_test, test_labels))\n",
    "    \n",
    "    print(\"\\nTrain split:\")\n",
    "    train_loss, train_accuracy = model.evaluate(data_train, train_labels, verbose= 1)\n",
    "    print(\"Accuracy : {}\".format(train_accuracy))\n",
    "    \n",
    "    print(\"\\nTest split:\")\n",
    "    test_loss, test_accuracy = model.evaluate(data_test, test_labels, verbose= 2)\n",
    "    print(\"Accuracy : {}\".format(test_accuracy))\n",
    "    \n",
    "\n",
    "    train_acc = train_acc + train_accuracy\n",
    "    test_acc = test_acc + test_accuracy\n",
    "\n",
    "\n",
    "print(\"\\nThe final train accuracy is:{} \".format(train_acc/10))\n",
    "print(\"\\nThe final test accuracy is:{} \".format(test_acc/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rural-center",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the training went\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exposed-shannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6xElEQVR4nO3deXxcdb34/9d7luxrm61N2qaFUrovlFLAAmXfBGQRigoiyhdEwctVBPUK3p965YqiKFdARBbZFMUrggooZbnK0rJ039c0bZJm3ybJzLx/f3xOS9pO0rTNZNLM+/l4zKOZzzlzznvOTM97Psv5HFFVjDHGmL35Eh2AMcaYwckShDHGmJgsQRhjjInJEoQxxpiYLEEYY4yJyRKEMcaYmCxBGHMYEpFNInJ6H9YrFxEVkcBAxGWGFksQJin09YQah/0+4p2gL9ir/Cde+WcHOiZj+soShDHxtwa4etcT79f8ZcD6hEVkTB9YgjBJTURSvV/zld7jJyKS6i0rEJE/i0iDiNSJyBsi4vOWfV1EtolIs4isFpHTetnN88CJIpLvPT8bWALs6BaHT0S+JSKbRaRaRB4Tkdxuyz/jLasVkW/u9R58InKbiKz3lv9WRIb10yEyScwShEl23wTmAjOA6cAc4Fvesn8HKoBCoBj4BqAiMgH4EnCsqmYDZwGbetlHCPgTcIX3/Crgsb3W+az3mA+MA7KAnwOIyCTgF8BngJHAcKCs22tvAi4CTvaW1wP37f+tG9M7SxAm2X0K+E9VrVbVGuA7uBMxQBcwAhijql2q+oa6ycsiQCowSUSCqrpJVffXXPQYcJVXKzgZ+GOMOH6sqhtUtQW4HbjCa466FPizqr6uqh3AfwDRbq/9f8A3VbXCW34ncKl1TJtDZQnCJLuRwOZuzzd7ZQA/BNYBL4nIBhG5DUBV1wFfwZ2Iq0XkaREZSS9U9U1cTeRbuJN9ex/iCOBqLiOBrd221QrUdlt3DPCc1xTWAKzEJbHi3mIyZn8sQZhkV4k7we4y2itDVZtV9d9VdRzwceCWXX0Nqvqkqn7Me60Cd/VhX7/BNVvt3bzUUxxhoArYDozatUBEMnDNTLtsBc5R1bxujzRV3daHmIzpkSUIk0yCIpLW7REAngK+JSKFIlIAfBt3IkdEzheRI0VEgCbcr/KIiEwQkVO9zuwQ0O4t2597gTOA12Msewr4NxEZKyJZwPeBZ1Q1DDwLnC8iHxORFOA/2fP/7v3A90RkjBd3oYhceIDHxph9WIIwyeRF3Ml81+NO4LvAItyooqXAe14ZwHjgFaAF+BfwP6q6ENf/8ANgJ24kUhGuA7tXqlqnqn/X2DdheRh4HJc8NuISz5e91y0HbgSexNUm6nGd57v8FNcJ/pKINANvAcftLx5j9kfshkHGGGNisRqEMcaYmCxBGGOMickShDHGmJgsQRhjjIlpSF1pWVBQoOXl5YkOwxhjDhuLFy/eqaqFsZYNqQRRXl7OokWLEh2GMcYcNkRkc0/LrInJGGNMTJYgjDHGxGQJwhhjTExDqg8ilq6uLioqKgiFQokOxRyitLQ0ysrKCAaDiQ7FmKQw5BNERUUF2dnZlJeX4+ZcM4cjVaW2tpaKigrGjh2b6HCMSQpDvokpFAoxfPhwSw6HORFh+PDhVhM0ZgAN+QQBWHIYIuxzNGZgJUWC2J+qphDNoa5Eh2GMMYOKJQhgZ3MHzaFwv2+3traWGTNmMGPGDEpKSigtLd39vLOzs9fXLlq0iJtuuqnfYzLGmL4a8p3UfeHzCZFo/98XY/jw4XzwwQcA3HnnnWRlZfHVr3519/JwOEwgEPsjmD17NrNnz+73mIwxpq+sBgH4fUJ0gG6c9NnPfpZbbrmF+fPn8/Wvf5133nmHE044gZkzZ3LCCSewevVqABYuXMj5558PuOTyuc99jlNOOYVx48Zx7733DkisxpjkllQ1iO88v5wVlU37lIe63O2E04L+A97mpJE53PHxyQf0mjVr1vDKK6/g9/tpamri9ddfJxAI8Morr/CNb3yD3//+9/u8ZtWqVbz66qs0NzczYcIEbrjhBrsewBgTV3FLECLyMHA+UK2qU2IsF9y9dM8F2oDPqup73rJ/Az4PKO4+wdeoalzHNw7kjVcvu+wy/H6XjBobG7n66qtZu3YtIkJXV+zO8vPOO4/U1FRSU1MpKiqiqqqKsrKyAYzaGJNs4lmDeAT4OfBYD8vPwd0UfjzuBuu/AI4TkVLgJmCSqraLyG+BK7ztHZKefulvqW2jvSvMhJKcQ91Fn2RmZu7++z/+4z+YP38+zz33HJs2beKUU06J+ZrU1NTdf/v9fsLh/u9UN8aY7uLWB6GqrwN1vaxyIfCYOm8BeSIywlsWANJFJABkAJXxihPA74NINJ576FljYyOlpaUAPPLII4kJwhhjYkhkJ3UpsLXb8wqgVFW3AXcDW4DtQKOqvtTTRkTkOhFZJCKLampqDioQn0+IqKID1FHd3a233srtt9/OiSeeSCQSGfD9G2NMTySeJ0URKQf+3EMfxAvAf6nqm97zvwO3AhuA3wOXAw3A74BnVfU3+9vf7Nmzde8bBq1cuZKJEyf2+rrq5hA7GkNMGZmLz2dX6w5mffk8jTF9JyKLVTXmmPpE1iAqgFHdnpfhmpJOBzaqao2qdgF/AE6IZyB+bwqHSAJqEMYYM1glMkH8CbhKnLm4pqTtuKaluSKS4Y10Og1YGc9A/F6tIR4XyxljzOEqnsNcnwJOAQpEpAK4AwgCqOr9wIu4Ia7rcMNcr/GWvS0izwLvAWHgfeDBeMUJ4PNqEFFLEMYYs1vcEoSqLtjPcgVu7GHZHbiEMiB21yCsickYY3azqTawJiZjjInFEgQfNTFZDcIYYz5iCQJ3oRzErw9ix44dXHHFFRxxxBFMmjSJc889lzVr1sRlX7s88sgjLFiwZyvfzp07KSwspKOjo8fXfOlLXwLg/vvv57HH9r0IftOmTUyZss+o5X3WefLJJ3c/t6nLjTk8WYLA1SCE+FxNrap84hOf4JRTTmH9+vWsWLGC73//+1RVVe2xXn9fJHfxxRfz8ssv09bWtrvs2Wef5YILLthj2o6eXH/99Vx11VUHte+9E8Ts2bNtBlpjDkOWIHC3svTFacrvV199lWAwyPXXX7+7bMaMGcybN4+FCxcyf/58rrzySqZOnUooFOKaa65h6tSpzJw5k1dffRWA5cuXM2fOHGbMmMG0adNYu3Ytra2tnHfeeUyfPp0pU6bwzDPP7LHfnJwcTjrpJJ5//vndZU8//TQLFizg+eef57jjjmPmzJmcfvrp+yQrcFOM33333QAsXryY6dOnc/zxx3PfffftXmfTpk3MmzePWbNmMWvWLP75z38CcNttt/HGG28wY8YM7rnnnj2mLq+rq+Oiiy5i2rRpzJ07lyVLluzen01pbszgklTTffOX22DH0r0KFTTCuC5FfD4IHOCU3yVT4Zwf9Lh42bJlHHPMMT0uf+edd1i2bBljx47lRz/6EQBLly5l1apVnHnmmaxZs4b777+fm2++mU996lN0dnYSiUR48cUXGTlyJC+88ALg5nTa24IFC3jyySe5/PLLqaysZM2aNcyfP5+mpibeeustRISHHnqI//7v/96971iuueYafvazn3HyySfzta99bXd5UVERL7/8Mmlpaaxdu5YFCxawaNEifvCDH3D33Xfz5z//GXD3ttjljjvuYObMmfzxj3/kH//4B1ddddXumyrZlObGDC5WgwDoChEgPLBzfnvmzJnD2LFjAXjzzTf5zGc+A8DRRx/NmDFjWLNmDccffzzf//73ueuuu9i8eTPp6elMnTqVV155ha9//eu88cYb5Obm7rPt888/nzfffJOmpiZ++9vfcumll+L3+6moqOCss85i6tSp/PCHP2T58uU9xtfY2EhDQwMnn3wywO74ALq6uvjCF77A1KlTueyyy1ixYsV+32/393jqqadSW1u7O7ntmtK8oKBg95TmxpjESa4aRE+/9KtW0BENUhUYwRGFWf26y8mTJ/Pss8/2uLz71N89zYt15ZVXctxxx/HCCy9w1lln8dBDD3HqqaeyePFiXnzxRW6//XbOPPNMvv3tb+/xuvT0dM4++2yee+45nn76ae655x4AvvzlL3PLLbdwwQUXsHDhQu68884e41NVRGLPT3XPPfdQXFzMhx9+SDQaJS0trcft9PYed23fpjQ3ZnCxGgSAP4Ug4biMYjr11FPp6Ojgl7/85e6yd999l9dee22fdU866SSeeOIJwN11bsuWLUyYMIENGzYwbtw4brrpJi644AKWLFlCZWUlGRkZfPrTn+arX/0q7733Xsz9L1iwgB//+MdUVVUxd+5cYM8pxh999NFe48/LyyM3N5c333wTYHd8u7YzYsQIfD4fjz/++O6O9uzsbJqbm2Nur/t7XLhwIQUFBeTkDMx9OIwxB8YSBEAgSEC74nKhnIjw3HPP8fLLL3PEEUcwefJk7rzzTkaOHLnPul/84heJRCJMnTqVyy+/nEceeYTU1FSeeeYZpkyZwowZM1i1ahVXXXUVS5cu3d1x/b3vfY9vfetbMfd/5plnUllZyeWXX777l/qdd97JZZddxrx58ygoKNjve/j1r3/NjTfeyPHHH096evoe8T766KPMnTuXNWvW7K4NTZs2jUAgwPTp03fXWna58847WbRoEdOmTeO2227bb4IyxiROXKf7HmgHO903zduheQcrGMukkXnxC9AcMpvu25j+NVin+x48/CkA+KLhhNw0yBhjBiNLELA7QQQJY9MxGWOMkxQJYr+1Ar8ba59CmM5wgm5ObfbLanfGDKwhnyDS0tKora3t/eTi82oQEqYjbPeFHoxUldra2j4NpTXG9I8hfx1EWVkZFRUV1NTU9L5iYy2t2kykqomcdLt6dzBKS0ujrKws0WEYkzSGfIIIBoO7r1Tu1QPX83a1j4fLf8gDn5kW/8CMMWaQG/JNTH2WW8YoXy1rq1oSHYkxxgwKliB2yS2jIFLDptoWQl3WD2GMMZYgdskdRUq0jTxtZkNNa6KjMcaYhLMEsUupm5L7WN9q1lbHnkfIGGOSSdwShIg8LCLVIrKsh+UiIveKyDoRWSIis7otyxORZ0VklYisFJHj4xXnbqXHoMEMTvCvYE2VJQhjjIlnDeIR4Oxelp8DjPce1wG/6Lbsp8BfVfVoYDqwMk4xfiSQgow6jpNTVrNw9X6GxBpjTBKIW4JQ1deBul5WuRB4TJ23gDwRGSEiOcBJwK+87XSqakO84txD+ccoj2xie2UFq3Y0DcgujTFmsEpkH0QpsLXb8wqvbBxQA/xaRN4XkYdEJDPWBvrd2JMAON6/it8vrhiQXRpjzGCVyAQR6zZlirt4bxbwC1WdCbQCt/W4EZHrRGSRiCza79XS+zNyJgQzuWT4Rv74QSXhiM3LZIxJXolMEBXAqG7Py4BKr7xCVd/2yp/FJYyYVPVBVZ2tqrMLCwsPLSJ/EEbP5VhdRk1zBx9WNB7a9owx5jCWyATxJ+AqbzTTXKBRVber6g5gq4hM8NY7DVgxYFGNnUd283qG08g7G3vrQjHGmKEtbnMxichTwClAgYhUAHcAQQBVvR94ETgXWAe0Add0e/mXgSdEJAXYsNey+CqfB8BF+Rt5e+OR3HDKEQO2a2OMGUziliBUdcF+litwYw/LPgBi3gIv7kbMgJQszshYwzObZhOJKn5frO4SY4wZ2uxK6r35AzD6eCZ3LKGlI8yKShvuaoxJTpYgYhk7j+yWDRTQyNsbaxMdjTHGJIQliFhGzADgY7lVvLelPrGxGGNMgliCiKVoIgBzMmtsZldjTNKyBBFLZiGk5zPBV8Hm2jai0V7uZ22MMUOUJYhYRKBwIqMiW2jvilDVHEp0RMYYM+AsQfSkcAL5rRsAZaM1MxljkpAliJ4UTSTY2UghjWystQRhjEk+liB6Uuhm+pgU3GY1CGNMUrIE0ZNCN5LpuKwaNlkNwhiThCxB9CSrCNLymBLczoadliCMMcnHEkRPRCC/nFLfTrbWtdm9IYwxSccSRG+yihgWbaAromxraE90NMYYM6AsQfQms4iMLndPiB2Ndi2EMSa5WILoTVYhKaFahCh1rZ2JjsYYYwaUJYjeZBUjGiaXVnZagjDGJBlLEL3JdPe4LpBGals6EhyMMcYMLEsQvckqAqA8tdWamIwxSccSRG8yXYIYk9pCbYslCGNMcrEE0RuvBlGW0kxtqzUxGWOSiyWI3qTlgS9Aib/ZahDGmKRjCaI3Ph9kFlIojdYHYYxJOnFLECLysIhUi8iyHpaLiNwrIutEZImIzNpruV9E3heRP8crxj7JLGSYNlLX1knE7ixnjEki8axBPAKc3cvyc4Dx3uM64Bd7Lb8ZWBmXyA5EVjE5kXpUoaHNahHGmOQRtwShqq8Ddb2sciHwmDpvAXkiMgJARMqA84CH4hVfn2UVkRl2b6PWmpmMMUkkkX0QpcDWbs8rvDKAnwC3AvudQlVErhORRSKyqKampt+DJLOQ1I5aQK2j2hiTVBKZICRGmYrI+UC1qi7uy0ZU9UFVna2qswsLC/s3QoCsInzRLnJptaGuxpikksgEUQGM6va8DKgETgQuEJFNwNPAqSLym4EPz+NdLFdgI5mMMUkmkQniT8BV3mimuUCjqm5X1dtVtUxVy4ErgH+o6qcTFmXmcACGSTM7rYnJGJNEAvHasIg8BZwCFIhIBXAHEARQ1fuBF4FzgXVAG3BNvGI5JOn5AJSmhqizJiZjTBKJW4JQ1QX7Wa7AjftZZyGwsP+iOgheghiZ2sFGq0EYY5KIXUm9P16CKAm2sdOm/DbGJBFLEPuTmgPipyjYbn0QxpikYglif0QgPY8CXys1zVaDMMYkD0sQfZGeT5600NIRpq0znOhojDFmQFiC6Iv0fLK0GYCdzdbMZIxJDpYg+iJ9GJkRlyBqrKPaGJMkLEH0RXo+qV1NANYPYYxJGpYg+iI9n0BnA2A1CGNM8rAE0Rfp+fg6mwlK2GoQxpikYQmiL7yL5cZkdFmCMMYkDUsQfeEliPKMTksQxpikYQmiL7wEMTo9ZNNtGGOShiWIvtg1YV9KyGoQxpikYQmiL9LzAChOaaempQM3Ea0xxgxtliD6wqtBFPjb6AxHaQrZdBvGmKHPEkRfpOUBwjBfK2AXyxljkoMliL7w+SA9jxxtAaC6OZTggIwxJv76lCBEJFNEfN7fR4nIBSISjG9og0y3Cfuqm6wGYYwZ+vpag3gdSBORUuDvuPtHPxKvoAal9HwyuhoA2N5oNQhjzNDX1wQhqtoGXAz8TFU/AUyKX1iDUFYx/rYactIC7GhsT3Q0xhgTd31OECJyPPAp4AWvLBCfkAaprGJoqaIkN81qEMaYpNDXBPEV4HbgOVVdLiLjgFd7e4GIPCwi1SKyrIflIiL3isg6EVkiIrO88lEi8qqIrBSR5SJy8wG8n/jJKoa2nZTmBKlqsgRhjBn6+pQgVPU1Vb1AVe/yOqt3qupN+3nZI8DZvSw/BxjvPa4DfuGVh4F/V9WJwFzgRhFJfHNWdjEA4zParAZhjEkKfR3F9KSI5IhIJrACWC0iX+vtNar6OlDXyyoXAo+p8xaQJyIjVHW7qr7nbaMZWAmU9iXOuMoqAaA8tZmalg66ItEEB2SMMfHV1yamSaraBFwEvAiMBj5ziPsuBbZ2e17BXolARMqBmcDbPW1ERK4TkUUisqimpuYQQ+qFV4MoCzahCtV2sZwxZojra4IIetc9XAT8r6p2AYc6IZHEKNu9TRHJAn4PfMVLTjGp6oOqOltVZxcWFh5iSL3wahBFvkYAdlgzkzFmiOtrgngA2ARkAq+LyBigx5N2H1UAo7o9LwMqAbxk9HvgCVX9wyHup39kuuQzXOsBSxDGmKGvr53U96pqqaqe6/UZbAbmH+K+/wRc5Y1mmgs0qup2ERHgV8BKVf3xIe6j/wRSIGM4OV21AGy3ayGMMUNcn65lEJFc4A7gJK/oNeA/gcZeXvMUcApQICIV3uuDAKp6P64v41xgHdCGuzob4ERc/8ZSEfnAK/uGqr7Y1zcVN1klpISqSQv6rAZhjBny+nqx28PAMuCT3vPPAL/GXVkdk6ou6G2D6m6qcGOM8jeJ3T+ReNnFSEs1I3LT2WHXQhhjhri+JogjVPWSbs+/0+3XffLIKoGaNZTk2NXUxpihr6+d1O0i8rFdT0TkRCD5GuGziqClitK8NLbVJ9/bN8Ykl77WIK4HHvP6IgDqgavjE9Igll0C0S7GZ3fx++YQHeEIqQF/oqMyxpi46Osopg9VdTowDZimqjOBU+Ma2WCU5S6WG5fWjCpUNlgzkzFm6DqgO8qpalO3i9ZuiUM8g1v2CABGBdzgra11bYmMxhhj4upQbjk6OEcaxVPOSACKfW6KqQrrhzDGDGGHkiAOdaqNw49Xg8jtrCHoFyrqrQZhjBm6eu2kFpFmYicCAdLjEtFgFkiBzCJ8zZWMzDuOrVaDMMYMYb0mCFXNHqhADhs5I6GpkrL8dKtBGGOGtENpYkpOOaUuQeRlsLXOahDGmKHLEsSByhkJTdsYNSydnS0dhLoiiY7IGGPiwhLEgcoZCaEGxniNb9bMZIwZqixBHKgcd9O7sam7roWwZiZjzNBkCeJAeddCjPEulltf05LIaIwxJm4sQRwoL0Fkd1ZTkJXC2ipLEMaYockSxIHyEgRN2ziyKIu11c2JjccYY+LEEsSBCqZD+jBoqmR8UTZrq1tw9z4yxpihxRLEwfCuhTiqOIvmUJiqpo5ER2SMMf3OEsTByC2Fxq0cWeTGulozkzFmKLIEcTDyy6F+M+OLMgGso9oYMyRZgjgY+eXQ2cxwXwv5GUHWVluCMMYMPZYgDkZ+OQBSv5nxxdmsrbImJmPM0BO3BCEiD4tItYgs62G5iMi9IrJORJaIyKxuy84WkdXestviFeNB8xIE9Rs5uiSbVTuaiUZtJJMxZmiJZw3iEeDsXpafA4z3HtcBvwAQET9wn7d8ErBARCbFMc4DlzfG/Vu/kSmlubR0hNlU25rYmIwxpp/FLUGo6utAXS+rXAg8ps5bQJ6IjADmAOtUdYOqdgJPe+sOHikZkFUM9ZuYMjIXgKXbGhMclDHG9K9E9kGUAlu7Pa/wynoqj0lErhORRSKyqKamJi6BxrRrJFNxFikBH8ssQRhjhphEJgiJUaa9lMekqg+q6mxVnV1YWNhvwe1XfjnUbyLo9zFxRI7VIIwxQ04iE0QFMKrb8zKgspfywSW/HBorINzJ1NIclm9rso5qY8yQksgE8SfgKm8001ygUVW3A+8C40VkrIikAFd46w4u+eWAQuNWpozMpbkjzOY6u3mQMWboCMRrwyLyFHAKUCAiFcAdQBBAVe8HXgTOBdYBbcA13rKwiHwJ+BvgBx5W1eXxivOg7RrqWreRKaXHAvDh1gbGFmQmLiZjjOlHcUsQqrpgP8sVuLGHZS/iEsjgNXy8+3fnGiYedxp5GUFeX1PDRTN77E83xpjDil1JfbCyCiFjONSsxO8T5k8o4tXV1USsH8IYM0RYgjgUhROhehUApx5dRH1bFx9srU9wUMYY0z8sQRyKwglQsxpUOemoQvw+4e8rqxMdlTHG9AtLEIeiaCJ0NELzdnLTgxxbns/flu+w4a7GmCHBEsShKDza/Vu9EoDLjhnF+ppW/rJsRwKDMsaY/mEJ4lDsShA1qwG4aGYpRxVncfdLq+mKRBMYmDHGHDpLEIei20gmAL9P+NpZR7NxZyuP/2tzgoMzxphDYwniUHUbyQRw+sQi5k8o5K6/rrIbCRljDmuWIA7ViGmwYwlEugAQEe66dBqZqQG+8swHdIatqckYc3iyBHGoRs2BcMglCU9Rdho/uHgqyyubuOeVNQkMzhhjDp4liENVNsf9u/WdPYrPnFzC5bNHcf9r63l5RVUCAjPGmENjCeJQ5ZZC7ijY+vY+i7798UkcXZLDFx5bxPdfXEnYRjYZYw4jliD6w6g5+9QgADJTAzz3xRP49NzRPPj6Bq59dBFNoa4EBGiMMQfOEkR/GHUcNG1zNxDaS1rQz3cvmsp/XTyV/1u3kzN+/BrPvV9h10kYYwY9SxD9YZTXD7HpzR5XWTBnNM/ecAJF2Wn82zMfcuIP/sEP/7aKrXaTIWPMIGUJoj+UTHf9EEt+2+tqM0bl8ccbT+SXV81mamkuv1i4nlPuXsiPXlpNqCsyQMEaY0zfxO2GQUnF54PpC+CNu6GpEnJG9riq3yecMamYMyYVs72xnbv/toaf/WMdP391HSNz0zlv2gg+ObuMI4uyB/ANGGPMvsTd2G1omD17ti5atCgxO6/bAPfOhNPugHm3HNBL/7luJ+9sqmPZtiYWrq4mHFWOGZPPTaeN5+SjCuMUsDHGgIgsVtXZMZdZguhHD58DrTXwpXdB5KA2UdPcwR/f38aj/9pERX07s8fk88ljR3HhjJGkBvz9HLAxJtlZghgo7/4KXrgFbvgXFE86pE11hCM88dYWHn9rMxt3tlKal86COaMYmZfOEYVZTCjJJi1oCcMYc2gsQQyU5ir40QQ45XY45ev9sklV5c11O7n7b6v5sKJxd/mwzBRuPWsCF80stURhjDloCUsQInI28FPADzykqj/Ya3k+8DBwBBACPqeqy7xl/wZ8HlBgKXCNqoZ621/CEwTAw2dDRwvc0POQ14PV2hFmR1OI1Tua+fX/beTdTfUEfMKY4RkUZKVyyawyLptdhhxk85YxJvkkJEGIiB9YA5wBVADvAgtUdUW3dX4ItKjqd0TkaOA+VT1NREqBN4FJqtouIr8FXlTVR3rb56BIEP+6D/72DbjpfRg2Lm67UVUWrq5h0eY6NtS0sqGmldVVzUwakcPIvDQmjczl9IlFTBmZi88nRKKK32eJwxizp94SRDyHuc4B1qnqBi+Ip4ELgRXd1pkE/BeAqq4SkXIRKe4WW7qIdAEZQGUcY+0/Ez8Of/smvPbfcNEvDrqzen9EhPlHFzH/6CIAolHlyXe28Mf3t7G1rp1/rKrm3r+vpTA7FZ/AzpZOji7J5pQJhVwyq4xxhVlxicsYM3TEM0GUAlu7Pa8AjttrnQ+Bi4E3RWQOMAYoU9XFInI3sAVoB15S1Zdi7URErgOuAxg9enT/voODkTcaTr4VXrsLyo6FY68dkN36fMKn547h03PHAFDX2smrq6pZuKaGoE8ozEllydZGfrFwPfe9up7ZY/I5e0oJU0tzGTUsg6LsVAJ+u27SGPOReCaIWD+d927P+gHwUxH5ANfP8D4Q9vomLgTGAg3A70Tk06r6m302qPog8CC4JqZ+i/5QnHwbVL4PL34NMobB5E8MeAjDMlO45JgyLjmmbI/y6qYQf3h/G88uruC7L6zcXe4TKM5J4+iSbMYVZpGbHiQnLUBuRpDs1CAd4SgZKX5OOHK4Dbc1JknEM0FUAKO6PS9jr2YiVW0CrgEQ17O60XucBWxU1Rpv2R+AE4B9EsSg5PPBpQ/Dby6FZ68F8cOkCxIdFQBFOWlcf/IRXH/yEVQ3h1he2cT2hhDbG9upqG9neWUjb22oo72HqT9y04NMH5VHasDHB1sbaGzrIjPVzyePHUVhVirbG0OMK8ykLD+D1ICP2pZOSnJTmTU6f5/O8+ZQF0++vYWzp5QwZnhmn99DQ1snb22o5YxJJdavYkwcxTNBvAuMF5GxwDbgCuDK7iuISB7QpqqduBFLr6tqk4hsAeaKSAauiek0IMG9zwcoNRs+/Sw8fjH8/lpI/wOMnZfoqPZQlJ1G0YS0mMs6w1GaQ100hcI0h7pIDfipbGjnhaXbWbWjibaOCPOOLKA4N41NO1v55esbiCqkBHwxb7NampfOuMJMoqrUNHcwaUQOi7fUs7WunZ//Yx2fmjuGqqYQeRlB/CIs3lJPZkqAsvx0slIDFOWkUpyTRqgrwj0vr2VHU4hzp5Zw5wWTCXVG2VzXik+E0rx0FKhr7WBHYwcpAR9F2amUF2Ty4dYGttS1kZ+RwoSSbMYVZOLzCZ3hKC0dYfLSg/h6SDiRqFLf1klBVuoBH+doVImoEvCJjTBLgK5IlKA1nx6UeA9zPRf4CW6Y68Oq+j0RuR5AVe8XkeOBx4AIrvP6WlWt9177HeByIIxrevq8qnb0tr9BMYppb2118Otz3FTgn3gAJp6f6Ijioro5hCAUZKVQUd9OdXOIUFeU/IwUVm5v4uUVVWxvCuETyM9IYUlFA9lpQW49awIPvL6BD7Y2MCI3jcb2LsIRZfqoXDojSmVDOy2h8B41mnEFmZwxuZgHXttwSDGnBHxkpQZoaOskqhD0C0XZaeRnBmnvjNDWGaEzHCUnPUh1U4jWzgjjCjIpyEpla30baUE/OWkBMlICNLZ34fcJ4woz6eiK0hmJkhrwsXJ7E5tq3Yy9KX4fJblpnHRUAYVZabR3RWjvDFPV1MHOlg5y04OMGpbBiNw01lS1UN/WSTiqbKltJTc9yHnTRlBR386OxhCZqQHGFWSSlxFkS10bbZ0Rgn4fwzNTaO4I09DWScDvI8XvI+gXfD6hJCeNEbnprKtupjkUJjXoZ0RuGjsaQyzd1shRxdmU5qVR29pJXWsnQb+P8uEZLN3WSENbF3PGDmNsQSYBv49t9e34fW46+85wlHXVLexoCnHMmHzGFmQSVVhb1UxUlZF56YzMSyfF76O9K4LfJ9S3drKhppWuaJTs1ABFOWlUN4VoaOsiLyNIXkYK+Rkp3t9BwhHlw4oG2jojtHaEWV7ZRFF2KvPGF9IZiRCNQmckynub60kL+jlrcgmjh2fwqzc2cN/C9UwozuacKSVMHJHDhJJsSvPSCYUj/OmDSlZXNXvvPZ1hmSkMy0whHFHW17Tw0ooq8jOCnDm5hDHDMqhv62RTbSsiQqrfR0ZqgKNLsvH7hGXbGnlnYx0d4Sizy/MJ+n2oQklOGqlBH5t2tvKP1dWML8rmjInF1LZ2kBr00xWO8srKKvIzUjhzcjFZqQEq6ttZtaMZVSUrNUBWWoD1NS00h8IMy0zhmDH55GeksLm2jdHDMkhPOfhmX7tQLtGatsPTV0Lle3DiV2D+NyGQkuioEkpVd/+aVlVCXVHSU/yoKuGo7vOLr7G9i5rmEFGFMcMzSA34+df6WlbvaCIjNcCo/AwUpbIhRMAn5KYHGZGXRldY2dbQxvqaViaOyGbiiBzqWjtZvq2J9TUttHSEGZ6ZQl5GCjUtHVQ1hqhv6yQjJUBmqp+A30dTexf5GSmU5qfzz/W1tHeGGT0sk85IlKb2Llo7wuSmB+mMRNm4s5X0oJ/UoI+2zghHFGYxcUQOQZ/Q2hlhfU0L/7duJ22dEVL8PlKDroZTmJ1KU3uYzbWttHZGKMhKZURuGiJQlp/OhppWVu1oJj3oZ/SwDFo6wmxraAcg1Ut0neEozR1hUgI+8jOCRKJKRzhKVyS6+wS6S2rAR2ckiqrrfxpbkMmWuja6Iu58kJsepCMcIdQVJTstwLBMdzLqSYrfR15GkOrmXn/D9Zui7FTqWl0C7S414CMcVSLdys+eXMK2hnaWbmvcezNAz7VegKzUAO1dkT22F+v1AZ/Q1ul+xIhAT6dVn0Avm+rzOuAm/oxElZSAj7njhvPw1bMPaqCJJYjBoCsEf7kV3nsUSqbBJQ9B4YRER2USYNetZ2P9Z45GlaZQF7npwT2ao1SVbQ3tFOek7U6eLR2u+a84O21301ioK0JqwLdPU5aqUt3cwfbGEEcUZpKdFiQcibK9MUR2WoC8jBTaOyM0d7hkGPT7iESV7Y3tlOSkEfD7qG4KUdkYojMcpSw/HcCruQgluWmk+H1srWunqjlEJKqML8oiGPBR2dDO9obQ7oEOUVWy0wIcWZhNatAl4B1Nod21t8b2Lhra3KO+rZPGti6iqkwryyM/M0jQ76MgK5XGti6Wbmt0idznjslRJVm0hMK8uW4n2xtDjC/K4rSJbuR8c6iLtdUtrNnRzPbGECLwsSMLmDU6n20N7exoClHb0kl9WycBn3tPc8YOoyUU5u2NdbuP1ZFFboh4ZzhKQ1sn726qJxyJMmfscI4dm0+q38/7W+vxiaBAVVOIcETJzwgy76hCllQ08MHWBoqz0+iKuAR+yoQiqps7+Oe6nYTCEUpy0phSmkvQ76Mp1EVTe5hxhZnkZ6RQ1RTiX+traWzvYlxhJisqm6ht7eSey2cc1PfREsRgsvLP8PxN0NkKZ/x/MOcLEGqEYDoEDrx92xhjDkWiLpQzsUw8310f8b83wl++Bu88AHUboWQqXP08pOUkOkJjjAHsjnKJkV0Mn/odnHs3pA+DWVdB1TJ4agF02i1IjTGDg9UgEkXENS/N+YJ7Xv4x+MMX4InL4MpnINWmwjDGJJbVIAaLqZfCxb+ELf+Cxz/h+iWMMSaBLEEMJlMvhcsecdN0PHYh1KxOdETGmCRmCWKwmXQBXPEE7FwL9x0Hz38FIl2JjsoYk4QsQQxGR50FNy+BuTfA4l/Dk5dDqCnRURljkowliMEqczic/V9wwc9gw0J4YB58+LS7jqKrPdHRGWOSgI1iGuxmXQUFR8HvPw/P/T9XVjrbjXTKLEhsbMaYIc1qEIeD0XPhxnfg+v9zI52qlsH9H4N3f2WjnYwxcWMJ4nCRkgElU2DaJ+Gav0DuKHjhFrirHB67CFqqEx2hMWaIsQRxOCqdBde+BNf8FT52C2x9Gx46DXYsTXRkxpghxPogDlciMOZ49zj6PHjqCnjwFJh1NeSMgHHzoSzm/FvGGNMnVoMYCkpnwRffgimXwuJH4B/fdTWKJy+H1p2Jjs4Yc5iyBDFUZAyDix+Ab9fCbVvhtDvc8NhfngrrXnH3ozDGmANgCWKoEXFThs+7BT77grtm4jeXwA+PgL//J7Q3JDpCY8xhwhLEUFY2G27+AK78LYw/A974EfzPXFj/aqIjM8YcBixBDHUpmW7qjssegS+8CqnZ8PhF8LtroHZ9oqMzxgxiliCSSeks+H+vw0m3wuq/wM9mwW8uha3vJjoyY8wgFNcEISJni8hqEVknIrfFWJ4vIs+JyBIReUdEpnRbliciz4rIKhFZKSLHxzPWpBFMh1O/CTd/CKfcDts/gF+dDj+dAT8/Fl77oU0MaIwBQFQ1PhsW8QNrgDOACuBdYIGqrui2zg+BFlX9jogcDdynqqd5yx4F3lDVh0QkBchQ1Ybe9jl79mxdtGhRXN7PkNXR4u6LvWMptNXCxtchLQ+O/xLM+Tyk5yc6QmNMHInIYlWNedFUPC+UmwOsU9UNXhBPAxcCK7qtMwn4LwBVXSUi5SJSDLQDJwGf9ZZ1Ap1xjDV5pWbBvH//6Hnl+7DwLnj1u/Dmj2H6FXDMNdCwBcIhmPwJ8PkTF68xZsDEM0GUAlu7Pa8AjttrnQ+Bi4E3RWQOMAYoAyJADfBrEZkOLAZuVtXWOMZrAEbOhCufdjWKt++H95+ARQ9/tPzdX8Hsz0H+GMgb42oY/qAbXmuMGVLimSBinTH2bs/6AfBTEfkAWAq8D4SBIDAL+LKqvi0iPwVuA/5jn52IXAdcBzB69Oh+Cz7plUyFC++D0/8TVv4v5I+Fpkr46+3wh8/vuW5KNkw83035UTwZqldCMANGzXGjqIwxh6V4JogKYFS352VAZfcVVLUJuAZARATY6D0ygApVfdtb9VlcgtiHqj4IPAiuD6If4zfgblw0+3MfPZ9yCdRvgobNUL8ZOpqgbiOsfB4+fGrP1/pT3S1Ux58J2SXuvhZZxVbbMOYwEc8E8S4wXkTGAtuAK4Aru68gInlAm9fH8HngdS9pNInIVhGZoKqrgdPYs+/CJEowDYqOdo/uzr8Hti2GmlVQNAk6mmHNX2HJb2Hp7z5aLy0Piia6hy8ANath+JEwYhqkZEH5PMgu7p9Yw50QSOmfbRmThOI2iglARM4FfgL4gYdV9Xsicj2Aqt7vDV19DNfnsAK4VlXrvdfOAB4CUoANwDW7lvXERjENQl0h18HdXAk1a6B6hWuCql4J0TAUHOku2Otscev7AjBiukswbbXgC8LUS2H4Ee7vo86GrMI996EKFYtAfFB2jHv+9v3w0rdg8sVw1vcgq2jg37sxh4HeRjHFNUEMNEsQh5Fd3zsRiIShebtLCMuehcoP3OSDGQXQUuVqItGwW98XcB3j4oOyYyFjOFQth23e51481fV+7VgKpce4fwPpcPKtrjmsajlEOt2yjOGw9Fk3PfqRp7ubMOWMhJxSd4OmvXWFXA2qJ6074ZU73Ky6R8zvz6NlTNxYgjCHt/YGN8S2tQaW/9ElknAItrwFna2uSWrW1S7pLP8DBNJg3Mlwws1Qt97deW/j6y6pFBwF4nc1GRQKJ7rttnWbFl18rpksLddtc8R0d0Hhln+5JrAjT3fDgxu2fvS6smPh7QehejkgcOy1MPHjoFFXQ6pe6ZrSiie5pJVRAMPGQc1Kt5/8sbBjievcL5rk9tVe7/psRh0HBeM/6rtRha623gcARMIuIVa+91FSLJ/nbl+7SzTi9hONuPJAKlSvgncfgpEzXN9Rej40bXPHJK/bIJDa9W5ZxrCD+0y7QlDxrkvUeyfj5iqXvP1eC/iS38HqF+DjP3XH6mBEwu47k5p14K9troIt/3T3WKl8D9573A3GGDffHae9h313tLhm1RHT3We5/QPv+5SzZzzRLvddPdQ+uWjE9QkOG3dQL7cEYZKbqru+I7/8oxNak1djKZ7sTuJ1G10zWNN2l1QqFrkTSjQM2z90J+oJ58Kav7hOenBNXpmFEOlw2wqkuTmv1vwV3v/NR7UecP0ru5rRDoYv6E6kwQyXHEKNUDQZxs5z7y8ahtZqqPzQJbxwe+ztjD8T/CnQVgd1G6BlhysPpLvmvupV7nhoZN/XlkyFSRe5Wt07D7qYxs5zya5mlTsuRZPclC4Zw91xCKbD+LNczD6/O441q1zfVEsV5JTB8V+E7BHu9atfdImjcCLMvQFq18E/73X7HzcfLnnIJc5t77lp7KuWQck0yCyASJfryxp1nEvG0YhL2GtegkW/crXUvNFw5BmuqbLgSNcnlpIVu6+qscIly7cfcPEH0tx3Ii33o3vBp+XB5ItcbIE09x7eus81q4I71pFOdzyOPt+999p17vsCLonMvtbNkaZR91lqFNrrXLxd7S6+1Gw3PU5breu/K58HhUe5gSJv/Y/7oXTT+y7JHyBLEMYcikjYndxE3H/gzlZ3gsgqdr9yVd2Jyp8ChRPca0JNsPUdd4LML3dNV/Ub3Um5ZJo7iddvdp39bfVu2Yjp7ld/9Up3kssd5U5Sm990Cayr3TtRpbrEtO7vribk87uTdVqu+0WbM9INPU7NcieT0mMAgX/+zI00S8lyJ6zsEjj6XAhmuhpWzSp3Ap3/TRfPtvfc+8wudn1CK/7XnbwBjv2Cu/5l4xtunfwxrpZTtcIl1HA7jJjhjlXt2j2Ppz8FxpzoRsS9/QBUdbtVbuHRrua19FkXA7gmu/KPwZ+/sud20oe597t9iduP+KDLu1QqmOli0Kh7Pm4+jD7e7WvtK3slUHHNiv6gO5lHOt0Ahw5vypnJF8GMT7taTPZIOOHL7nhsfA3WvgQr/rTn9oaPh3Pugp1rXaIonQXvPeZ+dJRMdZ959ki37pJn3A+SWPwp7vvT2ep+ABRPgWFjXQ10148UcD8UTvoqTLrwoC5itQRhjOkfjRXuhLUrEcYSCUOowf2qV4WWakjPc7/wW6pc4tv1i13VlbXWQG7ZR1O7hDtds0lqzkej2tb8zSXYtFyXZIsm7nlCjEZdMtrylmtWS8t1NYmx81zS3KWz1fVz1W90zUHt9e6EGw27WkAgxQ3RzhgO0y5zCb43Hc3u9eFOyC3teSi36r7l0YirUai6BCc+754uea62u6uPbtfx3KV+EzRuc8er8GjwHfy0epYgjDHGxNRbgrDpvo0xxsRkCcIYY0xMliCMMcbEZAnCGGNMTJYgjDHGxGQJwhhjTEyWIIwxxsRkCcIYY0xMQ+pCORGpATYf5MsLgJ37XWvgWVwHbrDGZnEdGIvrwB1MbGNUtTDWgiGVIA6FiCzq6WrCRLK4Dtxgjc3iOjAW14Hr79isickYY0xMliCMMcbEZAniIw8mOoAeWFwHbrDGZnEdGIvrwPVrbNYHYYwxJiarQRhjjInJEoQxxpiYkj5BiMjZIrJaRNaJyG0JjGOUiLwqIitFZLmI3OyV3yki20TkA+9xboLi2yQiS70YFnllw0TkZRFZ6/2bP8AxTeh2XD4QkSYR+UoijpmIPCwi1SKyrFtZj8dHRG73vnOrReSsBMT2QxFZJSJLROQ5EcnzystFpL3bsbt/gOPq8bMbqGPWQ1zPdItpk4h84JUP5PHq6RwRv++ZqibtA/AD64FxQArwITApQbGMAGZ5f2cDa4BJwJ3AVwfBsdoEFOxV9t/Abd7ftwF3Jfiz3AGMScQxA04CZgHL9nd8vM/1QyAVGOt9B/0DHNuZQMD7+65usZV3Xy8BxyzmZzeQxyxWXHst/xHw7QQcr57OEXH7niV7DWIOsE5VN6hqJ/A0cGEiAlHV7ar6nvd3M7ASKE1ELAfgQuBR7+9HgYsSFwqnAetV9WCvpD8kqvo6ULdXcU/H50LgaVXtUNWNwDrcd3HAYlPVl1Q17D19CyiL1/4PJK5eDNgx6y0uERHgk8BT8dh3b3o5R8Tte5bsCaIU2NrteQWD4KQsIuXATOBtr+hLXlPAwwPdjNONAi+JyGIRuc4rK1bV7eC+vEBRgmIDuII9/9MOhmPW0/EZbN+7zwF/6fZ8rIi8LyKvici8BMQT67MbLMdsHlClqmu7lQ348drrHBG371myJwiJUZbQcb8ikgX8HviKqjYBvwCOAGYA23HV20Q4UVVnAecAN4rISQmKYx8ikgJcAPzOKxosx6wng+Z7JyLfBMLAE17RdmC0qs4EbgGeFJGcAQypp89usByzBez5Q2TAj1eMc0SPq8YoO6BjluwJogIY1e15GVCZoFgQkSDug39CVf8AoKpVqhpR1SjwS+LYFNEbVa30/q0GnvPiqBKREV7sI4DqRMSGS1rvqWqVF+OgOGb0fHwGxfdORK4Gzgc+pV6jtdccUev9vRjXbn3UQMXUy2eX8GMmIgHgYuCZXWUDfbxinSOI4/cs2RPEu8B4ERnr/Qq9AvhTIgLx2jZ/BaxU1R93Kx/RbbVPAMv2fu0AxJYpItm7/sZ1cC7DHaurvdWuBv53oGPz7PGrbjAcM09Px+dPwBUikioiY4HxwDsDGZiInA18HbhAVdu6lReKiN/7e5wX24YBjKunzy7hxww4HVilqhW7CgbyePV0jiCe37OB6H0fzA/gXNxogPXANxMYx8dw1b8lwAfe41zgcWCpV/4nYEQCYhuHGw3xIbB813EChgN/B9Z6/w5LQGwZQC2Q261swI8ZLkFtB7pwv9yu7e34AN/0vnOrgXMSENs6XPv0ru/a/d66l3if8YfAe8DHBziuHj+7gTpmseLyyh8Brt9r3YE8Xj2dI+L2PbOpNowxxsSU7E1MxhhjemAJwhhjTEyWIIwxxsRkCcIYY0xMliCMMcbEZAnCmP0QkYjsOWtsv836680GmqjrNIzpVSDRARhzGGhX1RmJDsKYgWY1CGMOkndfgLtE5B3vcaRXPkZE/u5NOPd3ERntlReLu/fCh97jBG9TfhH5pTfH/0siku6tf5OIrPC283SC3qZJYpYgjNm/9L2amC7vtqxJVecAPwd+4pX9HHhMVafhJsG71yu/F3hNVafj7jew3CsfD9ynqpOBBtzVueDm9p/pbef6+Lw1Y3pmV1Ibsx8i0qKqWTHKNwGnquoGbxK1Hao6XER24qaI6PLKt6tqgYjUAGWq2tFtG+XAy6o63nv+dSCoqt8Vkb8CLcAfgT+qakuc36oxe7AahDGHRnv4u6d1Yuno9neEj/oGzwPuA44BFnuziRozYCxBGHNoLu/277+8v/+JmxkY4FPAm97ffwduABARf2/3DRARHzBKVV8FbgXygH1qMcbEk/0iMWb/0sW7Sb3nr6q6a6hrqoi8jfuxtcAruwl4WES+BtQA13jlNwMPisi1uJrCDbhZQ2PxA78RkVzcjV/uUdWGfno/xvSJ9UEYc5C8PojZqroz0bEYEw/WxGSMMSYmq0EYY4yJyWoQxhhjYrIEYYwxJiZLEMYYY2KyBGGMMSYmSxDGGGNi+v8BeRDSHQhGMcUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See how the loss function went \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Loss Model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train', 'Cross Validation'], loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "another-collapse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax = plt.subplot()\n",
    "predict_results = model.predict(data_test)\n",
    "\n",
    "predict_results = predict_results.argmax(axis = 1)\n",
    "cm = confusion_matrix(test_labels1, predict_results)\n",
    "sb.heatmap(cm, annot = True, ax = ax);\n",
    "ax.set_xlabel('Predicted Label');\n",
    "ax.set_ylabel(\"True Labels\");\n",
    "ax.set_title(\"Confusion Matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-bullet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
